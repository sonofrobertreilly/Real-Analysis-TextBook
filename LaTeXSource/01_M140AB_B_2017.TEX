
% M140AB_B.TeX  Notes for `Single-Variable Analysis'
%
% Revised: 01/20/2017  Encoding Western ASCII
%


                  \chapter{Axioms for the Real Number System}
                  \label{ChaptB}


        \underline{Quotes for Chapter~\Ref{ChaptB}}:\IndB{chapter quotes}{for Chapter~\Ref{ChaptB} (Axioms for the System of Real Numbers)}

\V

\begin{quotation}
{\footnotesize
        (1) `Familiarity breeds contempt.'

        (From Aesop's {\em Fable of The Fox and the Lion}) %% Bartlett p.58 #20


\V

        (2) `If you should put even a little on a little, and should do this often, soon this too would become big.'

        (From Hesiod's `{\em Works and Days}', c. 700 BC)%% Bartlett p. 54 #27


\V

        (3) `How often have I said to you that when you have eliminated the impossible whatever remains, {\em however improbable}, must be the truth?'

        (Spoken by Sherlock Holmes to Dr. Watson in {\em The Sign of the Four}, by Sir Arthur Conan Doyle.)%% Bartlett p. 577

\V

        (4) `Chacun \`{a} son go\^{u}t'

        (Title of an aria in the operetta `Die Fledermaus (The Bat)', by Johann Strauss. It translates roughly as `To each according to his own taste'.)



}%EndFootNoteSize
\end{quotation}


\VV


            \small{\bf Introduction}

\V

        In Chapter~\Ref{ChaptA} it is assumed that the reader is already familiar
    with the natural numbers, the integers, and the rational numbers, as well as their main algebraic properties.
    Appendix~A provides the interested reader with a deeper study of the foundations of those numbers;
    for example, it provides an axiomatic treatment of the natural numbers using the Dedekind-Peano axioms for ${\NN}$,
    and develops the the integers and the rational numbers, and many of their properties, from the properties of the natural numbers.
    However, reading that treatment is not needed to understand the main body of {\TheseNotes} if one simply accepts the basic properties of these numbers.

        Likewise, in Chapter~\Ref{ChaptA} it is assumed that the reader is already familiar with basic properties of the system of {\em real} numbers.
    However, experience shows that to do analysis rigorously one needs to discuss the properties of real numbers in greater depth.
    The main goal of the present chapter is to provide an axiometic treatment of the real-number system.
    This is a list of primitive statements (`axioms') about real numbers that everyone will normally accept as being true, without demanding further proof;
    other properties of real numbers are then deduced rigorously from these axioms.
    For the interested reader, Appendix~C outlines a rigorous development of the real numbers, in terms of the rational numbers,
    from which the axioms given below can be deduced from the known properties of the rational numbers.
    One does not need to read that Appendix in order to understand the main body of {\TheseNotes}.

\V

        The properties of the Real Number System to be developed in this chapter split naturally into three classes:
    the `Algebraic Properties', the `Order Properties', and the `Completeness Property'.
    We devote a separate section to each class of properties.


\V
\V


                        \section{{\bf Algebraic Properties of the Real Numbers}}
                        \label{SectB10}\IndB{ZZ Sections}{\Ref{SectB10} Algebraic Properties of the Real Numbers}
        
\V
\V

        The set ${\RR}$ of real numbers comes with a pair of well-known binary operations, called `addition' and `multiplication'.
    In terms of Definition~\Ref{DefA60.10}, these are functions $\mbox{Add}_{{\RR}}:{\RR}{\times}{\RR} \,{\rightarrow}\, {\RR}$ and $\mbox{Mult}_{{\RR}}:{\RR}{\times}{\RR} \,{\rightarrow}\, {\RR}$.
    We follow convention and denote the infix representations of these operations by using the symbols $+$ and~${\cdot}$, respectively:
        \begin{displaymath}
        \mbox{Add}_{{\RR}}(x,y) \,=\, x+y, \h \mbox{Mult}_{{\RR}}(x,y) \,=\, x{\cdot}y \mbox{ for all $x,y$ in ${\RR}$}.
        \end{displaymath}
    Note that we assume that the reader is already familiar with these operations; we do not further define them here.

        We assume that the binary operations $+$ and ${\cdot}$ satisfy the following {\bf Algebraic Axioms for~${\RR}$}:

\V

        ({\bf Axiom A0}) (The Closure Laws for Addition and Multiplication) If $x$ and $y$ are real numbers, then
        \begin{displaymath}
        x+y \mbox{ and } x{\cdot}y \mbox{ are both real numbers}.
        \end{displaymath}
    The real numbers $x+y$ and $x{\cdot}y$ are called the {\bf sum of $x$ with $y$} and the {\bf product of $x$ with $y$}, respectively.

\V

        ({\bf Axiom A1}) (The Commutative Laws for Addition and Multiplication) If $x$ and $y$ are real numbers, then
        \begin{displaymath}
        x+y \,=\, y+x \mbox{ and } x{\cdot}y \,=\, y{\cdot}x.
        \end{displaymath}

\V

        ({\bf Axiom A2}) (The Associative Laws for Addition and Multiplication) If $x$, $y$ and $z$ are real numbers, then
        \begin{displaymath}
        (x+y)+z \,=\, x+(y+z) \mbox{ and } (x{\cdot}y){\cdot}z \,=\, x{\cdot}(y{\cdot}z).
        \end{displaymath}

\V

        {\bf Axiom A3} (The `Identity Element' Laws  for Addition and Multiplication) There is a unique real number, denoted $0$, such that
        \begin{displaymath}
        0+x \,=\, x+0 \,=\, x \mbox{ for every real number~$x$}.
        \end{displaymath}
    Likewise, there is a unique real number, denoted by $1$, such that
        \begin{displaymath}
        1{\cdot}x \,=\, x{\cdot}1 \,=\, x \mbox{ for every real number $x$}.
        \end{displaymath}
    The numbers $0$ and $1$ are called the {\bf additive identity} and the {\bf multiplicative identity}, respectively.

\V

        {\bf Axiom A4} (The `Inverse Element' Laws) For each real number $x$ there is a unique real number $u$ such that         
        \begin{displaymath}
        x + u \,=\, u + x \,=\, 0
        \end{displaymath}
    This unique $u$ is called the {\bf negative of $x$}, and is denoted by $-x$; thus the preceding equation takes the form
        \begin{displaymath}
        x+(-x) \,=\, (-x) + x \,=\, 0.
        \end{displaymath}
    (As usual, $0$ is the additive identity described in Axiom~(4).)

        Likewise, for each real number $y$ such that $y \,\,{\neq}\,\, 0$,
    there is a unique real number $v$ such that
        \begin{displaymath}
        y{\cdot}v \,=\, v{\cdot}y  \,=\, 1.
        \end{displaymath}
    This unique $v$ is called the {\bf reciprocal of $y$}, and is denoted ${\displaystyle \frac{1}{y}}$; thus the preceding equation takes the form
        \begin{displaymath}
        y{\cdot}\left(\frac{1}{y}\right) \,=\, \left(\frac{1}{y}\right){\cdot}y  \,=\, 1.
        \end{displaymath}
    (As usual, in this axiom $0$ and $1$ are the additive and multiplicative identities, respectively, described in Axiom~(4).)

        \underline{Note}: Some texts refer to $-x$ as the {\bf additive inverse of $x$}. Likewise, they often refer to $1/y$ as the {\bf multiplicative inverse of $y$}; they also may use the `exponent' notation $y^{-1}$ in place of~$1/y$.

\V

        {\bf Axiom A5} (The Distributive Laws for Addition and Multiplication) If $x$, $y$ and $z$ are real numbers, then
        \begin{displaymath}
        x{\cdot}(y+z) \,=\, (x{\cdot}y) + (x{\cdot}z) \mbox{ and } 
        (x+y){\cdot}z \,=\, (x{\cdot}z) + (y{\cdot}z).
        \end{displaymath}

\V

        {\bf Axiom A6} (The Nontriviality Law) The numbers $0$ and $1$ described in Axiom~A4 are distinct. That is,
        \begin{displaymath}
        1 \,\,{\neq}\,\, 0
        \end{displaymath}

\V
\V

            \subsection{\small{\bf Remarks}}
            \label{RemrkB10.20}


\hspace*{\parindent} (1) Axioms A0--A6 imply that the real number system, with its usual notions of `addition' and `multiplication',
    forms what in modern abstract algebra is called an {\bf algebraic field}, or, more briefly, a {\bf field}\IndA{field (in the sense of algebra)}.
    For that reason, we refer to these axioms as the {\bf field axioms for ${\RR}$}\IndB{axioms for ${\RR}$}{field axioms for ${\RR}$}.

\V

        (2) The field axioms A0--A6 do not come close to completely characterizing the real number system.
    For example, if in these axioms one replaces the phrase `real number' throughout by `rational number',
    and if now $+$ and ${\cdot}$ denote the usual operations on rational numbers,
    and $0$ and $1$ denote the usual elements of ${\QQ}$ with these symbols, then it is clear that the resulting axioms are satisfied by ${\QQ}$; that is, ${\QQ}$ is also a field. 
    Of course ${\QQ}$ and ${\RR}$ are very different fields; for example, the set ${\QQ}$ is countable but ${\RR}$ is not,
    and ${\RR}$ has an element $x$ such that $x^{2} \,=\, 2$ but ${\QQ}$ does not.

       Indeed, the field axioms for ${\RR}$ are not even strong enough, by themselves, to show that ${\RR}$ is an infinite set.
    For example, suppose that one replaces the phrase `real number' in these axioms by the `element of the doubleton set $\{0,1\}$',
    and define the binary operations $+$ and ${\cdot}$ on this set as follows:
        \begin{displaymath}
        0+0 \,=\, 1+1 \,=\, 0, \h 0+1 \,=\, 1+0 \,=\, 1; \h
        0{\cdot}0 \,=\, 0{\cdot}1 \,=\, 1{\cdot}0 \,=\, 0, \, 1{\cdot}1 \,=\, 1.
        \end{displaymath}
    Then the resulting system is also a field, but it has only two elements. Many authors denote this field by the symbol ${\ZZ}_{2}$,
    pronounced `${\ZZ}$-mod~$2$'. Note that in this field one has $-1 \,=\, 1$, since, by definition, $1+1 \,=\, 0$.

%% EXERCISE

\V

        (3) The field axioms refer to the special elements $0$ and $1$ and the operations $+$ and ${\cdot}$ on~${\RR}$.
    These symbols are widely used in algebra; but, as is clear from the preceding remark, their meanings can vary depending on the context.
    For example, the roles of the symbols $+$, $0$ and $1$ in the context of ${\RR}$ are very different from their roles in the context of the two-element field ${\ZZ}_{2}$:
    one has $1+1 \,\,{\neq}\,\, 0$ in the former case but $1+1 \,=\,0$ in the latter.

        Likewise, in the preceding remark one finds the familiar equation $x^{2} \,=\, 2$.
    A subtle point about this equation is that on the left side the symbol `$2$' refers to the number of factors in the product $x{\cdot}x$;
    that is, this `$2$' is a natural (`counting') number. In contrast, the number `$2$'
    appearing on the right side is shorthand for the quantity $1+1$, with the `$1$' and `$+$' referring to the field in question, namely ${\QQ}$ or ${\RR}$.

        If it might be unclear which role such a symbol is playing in a given context, one should do whatever is needed to make that role clear.
    For instance, one could write $1_{{\RR}}$, $1_{{\QQ}}$, $+_{{\RR}}$ $2_{{\NN}}$, etc for the various roles played by the symbol $1$;
    or one could refer in words to `the real multiplicative unit~$1$', etc. See Remark~\Ref{RemrkB10.35}~(3) below for further discussion on this issue.


\V
\V

%%%
\begin{quotation}
{\footnotesize \underline{\Notes}\IndB{\notes}{on alternate axioms for ${\RR}$} (on alternate axioms for ${\RR}$)

\V

\hspace*{\parindent}(1) Many authors express the axioms for ${\RR}$ slightly differently.
    For example, some write the `Additive Identity' law (see Axiom~A3) as `$x+0 \,=\, x$',
    and leave it as an exercise for the reader to show that $0+x \,=\, x$ follows from it in combination with the Additive Commutative Law.
    The advantage of that approach is that it provides a list of axioms which are weaker; that is, the axioms assume (slightly) less.
    Many authors find such `weakness' to be an aesthetically pleasing feature of an axiom system,
    and prefer a list of axioms that assume as little as possible. The disadvantage, of course,
    is that the reader pays for the author's aesthetic pleasure by needing to prove some minor details from these weaker axioms, such as $0+x \,=\, x$.
    This merely adds unnecessary clutter to the discussion.

        In contrast, some authors prefer to use axioms that are even {\em stronger} than the ones given above.
    For instance, they might use, in place of our Axiom~A4, the following statement:

\VA

       \h For every pair of real numbers $x$ and $z$, there exists a unique real number $u$ such that $x+u \,=\, z$;
    and for every pair $y$ and $w$ of real numbers with $y \,\,{\neq}\,\, 0$, there exists a unique $v$ such that $y{\cdot}v \,=\, w$.

\VA

\noindent Clearly these new statements reduce to our Axiom~A4 in the special cases $z \,=\, 0$ and $w \,=\, 1$, respectively.
    Note that these new statements can be combined into a single statement:

        \h For every triple of real numbers $a$, $b$ and $c$ with $a\,\,{\neq}\,\,0$, there is a unique real number $x$ such that $a{\cdot}x + b\,=\,c$.

\V

        (2) Most authors weaken Axioms~A3 and~A4 by omitting the word `unique' from the statements;
    the uniqueness is later deduced using the weaker statements of these axioms together with the earlier axioms.
    The problem with omitting the word `unique, however, is what usually results is a pair of axioms that display a serious ambiguity.
    For example, the `additive' portions of these axioms are normally written in the following revised form:

        \h A3$'$ There is a real number, denoted $0$, such that
        \begin{displaymath}
        0+x \,=\, x+0 \,=\, x \mbox{ for every real number~$x$}.
        \end{displaymath}


        \h A4$'$ For each real number $x$ there is a real number $u$ such that         
        \begin{displaymath}
        x + u \,=\, u + x \,=\, 0
        \end{displaymath}

\noindent It is not assumed in A3$'$ that the number $0$ described here is unique;
    indeed, the phrase `a real number' really means `at least one real number'. This fact then makes the meaning of A4$'$ ambiguous:
    it is not clear whether A4$'$ claims that there is a single $u$ which works simultaneously for each $0$ satisfying the first statement,
    or that for each such $0$ there exists a corresponding $u$, depending on the choice of $0$, which works.
    Of course if the first statement were to be followed immediately by the proof that the quantity $0$ is unique, the ambiguity would disappear.
    Unfortunately, most authors do not prove this uniqueness until after the second statement.
    
        The simplest way around this issue is to simply include `uniqueness' in the axiom itself, as we do in our Axioms~A3 and~A4 above.
    This has the added benefit of reducing `clutter': one does not need to separately state, then prove, this uniqueness.

\V

        (3) The two Distributive Laws expressed in Axiom~A5 are usually written
        \begin{displaymath}
        x{\cdot}(y+z) \,=\, x{\cdot}y + x{\cdot}z \mbox{ and } 
        (x+y){\cdot}z \,=\, x{\cdot}z + y{\cdot}z;
        \end{displaymath}
    note that in this version the right sides of the equations are missing the parentheses which appear in Axiom~A5 above.
    This formulation is acceptable because there are notational conventions in high-school algebra for the `order of precedence' of algebraic operations.
    For instance, in the expression $a{\cdot}b+c$, it is understood, because of these conventions,
    that the multiplication is carried out first, then the addition.
    That is,
        \begin{displaymath}
        a{\cdot}b+c \,=\, (a{\cdot}b) + c, \mbox{ NOT } a{\cdot}(b+c).
        \end{displaymath}
    Unless there is a need for extra clarity, we normally follow such conventions in order to minimize the use of parentheses.

\V

        (4) Axiom A6 is sometimes replaced by the statement `There is more than one real number'.
    It is easy to see that this formulation, in conjunction with the other axioms, is equivalent to Axiom~A6.
}%EndFootNoteSize
\end{quotation}
%##

\VV

        For the rest of this section everything is formulated in terms of the field ${\RR}$ of real numbers, since that is the most important example for us.
    However, since only the field axioms are used, the results (and proofs) are valid for any field.


        \subsection{\small{{\bf Definition}}}
        \label{DefB10.22}

\hspace*{\parindent} (1) If $x$ and $y$ are real numbers, then the {\bf difference between $x$ and $y$}, denoted $x-y$, is the number $x+(-y)$.
    The function $D:{\RR}{\times}{\RR} \,{\rightarrow}\, {\RR}$ given by the rule
    $D(x,y) \,=\, x-y$ is called the {\bf difference function}, or the {\bf subtraction}.

\V

        (2) If $x$ and $y$ are real numbers, and $y \,\,{\neq}\,\, 0$, then the {\bf quotient of $x$ by $y$}, denoted ${\displaystyle \frac{x}{y}}$ or $x/y$, is the number $x{\cdot}{\displaystyle \frac{1}{y}}$.
    The function $Q:{\RR}{\times}({\RR}{\setminus}\{0\}) \,{\rightarrow}\, {\RR}$ given by the rule $Q(x,y) \,=\, x/y$ is called the {\bf quotient function}, or {\bf division}.

\V
\V

        The next theorem states several familar algebraic facts; indeed, some are so familiar
    that it may seem that they are as obvious as the axioms, so that no proofs should be needed.
    However, the purpose for axiomatizing a subject is to list a small number of facts that can be taken as true (the axioms), and then to deduce all other facts from them.
    The results given here are to be deduced from the field axioms A0--A6.

%% GIVE EXERCISES OF THIS TYPE


            \subsection{\small{\bf Theorem}}
            \label{ThmB10.25}

\V

\hspace*{\parindent}(a) If $x$ is a real number then $0{\cdot}x \,=\, x{\cdot}0 \,=\, 0$, $-x \,=\, (-1){\cdot}x$ and $-(-x) \,=\, x$.
    In particular, $(-1){\cdot}(-1) \,=\, 1$.

\V

        (b) If $x$ and $y$ are real numbers then $-(x{\cdot}y) \,=\, (-x){\cdot}y \,=\, x{\cdot}(-y)$, and $(-x){\cdot}(-y) \,=\, x{\cdot}y$. 

\V

        (c) If $y$ is a real number such that $y \,\,{\neq}\,\, 0$, then $1/y \,\,{\neq}\,\, 0$, and $1/(1/y) \,=\, y$.

\V

        (d) If $y$ and $z$ are real numbers such that $y \,\,{\neq}\,\, 0$ and $z \,\,{\neq}\,\, 0$, then $y{\cdot}z \,\,{\neq}\,\, 0$.
    Furthermore, ${\displaystyle \frac{1}{y{\cdot}z} \,=\, \left(\frac{1}{y}\right){\cdot}\left(\frac{1}{z}\right)}$.


\V

        (e) Suppose that $x$, $y$ and $z$ are real numbers, with $z \,\,{\neq}\,\, 0$.
    Then
        \begin{displaymath}
        \frac{x+y}{z} \,=\, \frac{x}{z} + \frac{y}{z}
        \end{displaymath}
    Likewise,
        \begin{displaymath}
        \frac{x{\cdot}y}{z} \,=\, \left(\frac{x}{z}\right){\cdot}y \,=\, x{\cdot}\left(\frac{y}{z}\right).
        \end{displaymath}

\V

        (f) If $x$, $y$ and $z$ are real numbers then
        \begin{displaymath}
        z-x \,=\, (z-y) + (y-x).
        \end{displaymath}

\V

        (g) If $x$ and $y$ are real numbers such that $x{\cdot}y \,=\, 0$, then either $x \,=\, 0$ or $y \,=\, 0$.

\V

        {\bf Proof}

\V

        (a) Note that
        \begin{displaymath}
        0{\cdot}x \stackrel{(1)}{ \,=\, } (0+0){\cdot}x \stackrel{(2)}{ \,=\, }
        0{\cdot}x + 0{\cdot}x
        \end{displaymath}
    Indeed, Equation~(1) reflects the fact that $0 \,=\, 0+0$ (Axiom~A3), while Equation~(2) comes from the Distributive Laws (Axiom~A5).
    Now add $-(0{\cdot}x)$ to both sides of the equation $0{\cdot}x \,=\, 0{\cdot}x+0{\cdot}x$ to obtain
        \begin{displaymath}
        0 \stackrel{(3)}{ \,=\, } 0{\cdot}x + (-(0{\cdot}x)) \stackrel{(4)}{ \,=\, } (0{\cdot}x + 0{\cdot}x) + (-(0{\cdot}x))
     \stackrel{(5)}{ \,=\, } 0{\cdot}x + (0{\cdot}x + (-(0{\cdot}x)))
     \stackrel{(6)}{ \,=\, } 0{\cdot}x + 0  \stackrel{(7)}{ \,=\, } 0{\cdot}x.
        \end{displaymath}
    In the preceding string of equalities, Equations~(3) and~(6) use Axiom~A4; Equation~(4) reflects the result of adding $-(0{\cdot}x)$ to both sides of the previously obtained equation $0{\cdot}x \,=\, 0{\cdot}x + 0{\cdot}x$;
    Equation~(5) comes from the Associative Law for Addition; and Equation~(7) uses Axiom~A3.
    The desired result $0 \,=\, 0{\cdot}x$ now follows easily. The fact that $0 \,=\, x{\cdot}0$ then follows from the preceding together with the Commutative Law for Addition.

        Next notice that
        \begin{displaymath}
        0 \stackrel{(1)}{ \,=\, } 0{\cdot}x \stackrel{(2)}{ \,=\, }
    (1+(-1)){\cdot}x \stackrel{(3)}{ \,=\, } 1{\cdot}x + (-1){\cdot}x \stackrel{(4)}{ \,=\, } x+(-1){\cdot}x.
        \end{displaymath}
    In this last string of equalities, Equation~(1) follows from the result just proved above,
    Equation~(2) comes from the fact that $1+(-1) \,=\, 0$ (i.e., Axiom~A4), Equation~(3) uses the Distributive Law, and Equation~(4) uses the equation $1{\cdot}x \,=\, x$ (i.e., Axiom~A3).
    However, Axiom~A4 states that there is only one element of ${\RR}$ which when added to $x$ yields the value $0$, namely $-x$.
    Since, as has just been shown, $(-1){\cdot}x$ also has this property, it follows that $(-1){\cdot}x \,=\, -x$, as claimed.

        Similarly, note that, by Axioms~A4 and~A1 one has
        \begin{displaymath}
        0 \,=\, x+(-x) \,=\, (-x) + x
        \end{displaymath}
    The uniqueness of the additive inverse of $-x$ guaranteed by Axiom~A4 then implies that $x \,=\, -(-x)$, as claimed.

        Finally, apply the preceding results to the case $x \,=\, -1$ to obtain
        \begin{displaymath}
        1 \,=\, -(-1) \,=\, (-1){\cdot}(-1),
        \end{displaymath}
    as claimed.

\V

        (b) Notice that
        \begin{displaymath}
        -(x{\cdot}y) \,=\, (-1){\cdot}(x{\cdot}y) \,=\, ((-1){\cdot}x){\cdot}y \,=\, (-x){\cdot}y.
        \end{displaymath}
    In this string of equalities one uses the fact that $-u \,=\, (-1){\cdot}u$, proved in Part~(a), for two values of $u$; namely $u \,=\, x{\cdot}y$ and $u \,=\, x$; and one uses the Associative Law for Multiplication.
    A similar argument shows that $-(x{\cdot}y) \,=\, x{\cdot}(-y)$.

        Finally, note that by the Associative and Commutative Laws for Multiplication, together with the results of Part~(a) and Axiom~A3, one gets
        \begin{displaymath}
        (-x){\cdot}(-y) \,=\, ((-1){\cdot}x){\cdot}((-1){\cdot}y) \,=\, 
    (((-1){\cdot}x){\cdot}(-1)){\cdot}y \,=\,
        \end{displaymath}
        \begin{displaymath}
    ((x{\cdot}(-1)){\cdot}(-1)){\cdot}y
     \,=\, (x{\cdot}((-1){\cdot}(-1))){\cdot}y \,=\, 
    (x{\cdot}1){\cdot}y \,=\, x{\cdot}y,
        \end{displaymath}
    as claimed.

\V

        (c) Notice that if $1/y$ were to equal $0$ then it would follow from Part~(a) that $y{\cdot}(1/y) \,=\, y{\cdot}0 \,=\, 0$.
    However, by Axiom~A4 one has $y{\cdot}(1/y) \,=\, 1$, so it would then follow that $0 \,=\, 1$.
    Since this contradicts Axiom~A6, one sees that $1/y$ cannot equal $0$.
    Since this is the case, Axiom~A4 then implies that $1/y$ also has a unique multiplicative inverse;
    that is, there is a unique real number $u$ such that $(1/y){\cdot}u \,=\, 1$.
    However, by the definition of $1/y$, together with the Commutative Law, one has
        \begin{displaymath}
        1 \,=\, y{\cdot}\left(\frac{1}{y}\right) \,=\, \left(\frac{1}{y}\right){\cdot}y,
        \end{displaymath}
    so that $y$ and $u$ must be the same. That is, $y$ is the reciprocal of $1/y$, so that
        \begin{displaymath}
        y \,=\, \frac{1}{(1/y)},
        \end{displaymath}
    as claimed.

\V

        (d), (e), (f) and (g): The proofs of these parts are left as exercises.

\V
\V

        Definition~\Ref{DefA60.30} describes the `left-to-right extension', to $A^{k}$, of a general binary operation~${\ast}$ defined on a set~$A$.
    Theorem~\Ref{ThmA60.50} then states properties enjoyed by this extension if the operation ${\ast}$ is associative or, better yet, associative and commutative.
        Since, by Axioms A1 and~A2 above, the binary operations `$+$' and `${\cdot}$', addition and multiplication of real numbers,
    are both commutative and associative on ${\RR}$, those earlier results apply to them as well.
    It is convenient to reformulate those results here, and even to expand them slightly, in terms of the $+$ and~${\cdot}$ notation.

\VV

            \subsection{\small{\bf Definition}}
            \label{DefB10.30}

\V

        Let $k$ be a natural number such that $k\,\,{\geq}\,\,3$, and let $(x_{1}, x_{2},\,{\ldots}\,x_{k})$ be an ordered $k$-tuple of real numbers.

\V

        (1) The {\bf (finite) ordered sum}\IndA{ordered sums}\IndBD{ordered sums}{finite ordered sums} $x_{1} + x_{2} + \,{\ldots}\, + x_{k}$
    associated with this ordered $k$-tuple is defined recursively by the rule
        \begin{displaymath}
        x_{1} + x_{2} + \,{\ldots}\, x_{k-1} + x_{k} \,=\, (x_{1} + x_{2} + \,{\ldots}\, + x_{k-1}) + x_{k}.
        \end{displaymath}
    The parenthetical adjective `finite' is included here because in Chapter~\Ref{ChaptG}
    an analogous concept of {\em infinite} ordered sum is introduced. Until then, however, usually the word `finite' is omitted.

\V

        (2) In a similar manner, the {\bf (finite) ordered product}\IndA{ordered products}\IndBD{ordered products}{finite ordered products}
    $x_{1}{\cdot}x_{2}{\cdot}\,{\ldots}\,{\cdot}x_{k-1}{\cdot}x_{k}$ is defined by the rule
        \begin{displaymath}
        x_{1}{\cdot}x_{2}{\cdot}\,{\ldots}\,{\cdot}x_{k-1}{\cdot}x_{k}
     \,=\, 
        (x_{1}{\cdot}x_{2}{\cdot}\,{\ldots}\,{\cdot}x_{k-1}){\cdot}x_{k}
        \end{displaymath}

\V

        (3) \underline{Special Cases}: If $x_{1} \,=\, x_{2} \,=\, \,{\ldots}\, = x_{k} \,=\, c$,
    then often one writes $k\,c$ in place of the expression $x_{1}+x_{2}+\,{\ldots}\,+x_{k}$. Likewise,
    often one writes $c^{k}$ in place of $x_{2}{\cdot}x_{2}{\cdot}\,{\ldots}\,{\cdot}x_{k}$.

\V

        (4) Frequently the expression $x_{1} + x_{2} + \,{\ldots}\, x_{k-1} + x_{k}$
    is written more briefly as, say, ${\displaystyle \sum_{i=1}^{k} x_{i}}$;
    the symbol ${\displaystyle \sum}$ is the upper-case Greek letter `Sigma', which corresponds to the `S' sound (as in `{\bf S}um').


        Likewise, one can write the expression $x_{1}{\cdot}x_{2}{\cdot}\,{\ldots}\,{\cdot}x_{k-1}{\cdot}x_{k}$
    more briefly as ${\displaystyle \prod_{i=1}^{k} x_{i}}$; the symbol 
    ${\displaystyle \prod}$ is the upper-case Greek letter `Pi', which corresponds to the `P' sound (as in `{\bf P}roduct').

\VV

        The reformulation of Theorem~\Ref{ThmA60.50} in terms of addition and multiplication of real numbers is easy to carry out.
    The result is the following extension of the commutative and associative laws for addition and multiplication.

\V

            \subsection{\small{\bf Theorem} (Extended Associative/Commutative Laws in ${\RR}$)}
            \label{ThmB10.32}\IndA{extended associative/commutative laws in ${\RR}$}

\hspace*{\parindent} (a) Let $k$ and $m$ be natural numbers. Then for every ordered $k$-tuple $(x_{1}, x_{2},\,{\ldots}\,x_{k})$ in ${\RR}^{k}$
    and every ordered $m$-tuple $(x_{k+1}, x_{2},\,{\ldots}\,x_{k+m})$ in ${\RR}^{m}$ one has
        \begin{displaymath}
        \left(x_{1}+x_{2}+\,{\ldots}\,+x_{k}\right)
    +
         \left(x_{k+1}+x_{k+2}+\,{\ldots}\,+x_{k+m}\right)
     \,=\, 
        x_{1}+x_{2}+\,{\ldots}\,+x_{k} + x_{k+1}+x_{k+2}+\,{\ldots}\,+x_{k+m}.
        \end{displaymath}
    Likewise, one has
        \begin{displaymath}
        \left(x_{1}{\cdot}x_{2}{\cdot}\,{\ldots}\,{\cdot}x_{k}\right)
    {\cdot}
         \left(x_{k+1}{\cdot}x_{k+2}{\cdot}\,{\ldots}\,{\cdot}x_{k+m}\right)
     \,=\, 
        x_{1}{\cdot}x_{2}{\cdot}\,{\ldots}\,{\cdot}x_{k} {\cdot} x_{k+1}{\cdot}x_{k+2}{\cdot}\,{\ldots}\,{\cdot}x_{k+m}.
        \end{displaymath}
    In terms of the $\sum$ and $\prod$ notations, these equations take the forms
        \begin{displaymath}
        \left(\sum_{i=1}^{k} x_{k}\right) + \left(\sum_{j=1}^{m} x_{k+j}\right)
     \,=\, 
        \sum_{r=1}^{k+m} x_{r}
        \mbox{ and }
        \left(\prod_{i=1}^{k} x_{k}\right) {\cdot} \left(\prod_{j=1}^{m} x_{k+j}\right)
     \,=\, 
        \prod_{r=1}^{k+m} x_{r}.
        \end{displaymath}

\V

         (b) Let $k$ be a natural number, and let $p:{\NN}_{k} \,{\rightarrow}\, {\NN}_{k}$ be a permutation of the finite set ${\NN}_{k}$
    (see Definition~\Ref{DefA15.50}). Then for every ordered $k$-tuple $(x_{1}, x_{2},\,{\ldots}\,x_{k})$ in ${\RR}^{k}$ one has
        \begin{displaymath}
        x_{p(1)}+x_{p(2)}+\,{\ldots}\,+x_{p(k)} \,=\, 
        x_{1}+x_{2}+\,{\ldots}\,+x_{k}
    \mbox{ and }
        x_{p(1)}{\cdot}x_{p(2)}{\cdot}\,{\ldots}\,{\cdot}x_{p(k)} \,=\, 
        x_{1}{\cdot}x_{2}{\cdot}\,{\ldots}\,{\cdot}x_{k}.
        \end{displaymath}
    In terms of the $\sum$ and $\prod$ notations, these equations take the forms
        \begin{displaymath}
        \sum_{i=1}^{k} x_{p(i)} \,=\, \sum_{i=1}^{k} x_{i}
    \mbox{ and }
        \prod_{i=1}^{k} x_{p(i)} \,=\, \prod_{i=1}^{k} x_{i}.
        \end{displaymath}



\V

        {\bf Proof}\, Replace the symbol ${\ast}$ in Theorem~\Ref{ThmA60.50} throughout by $+$ to obtain the formulas involving addition.
    Likewise, replace ${\ast}$ by ${\cdot}$ throughout to obtain the formulas involving multiplication.

\V


            \subsection{\small{\bf Remarks}}
            \label{RemrkB10.35}

\V

\hspace*{\parindent} (1) The last several results have been formulated in terms of real numbers, but it is clear that they are valid in any field.

\V

        (2) The results of Theorem~\Ref{ThmB10.25} and Theorem~\Ref{ThmB10.32}, combined with the distributive laws for addition and multiplication
    (see Axiom~A5), allow one to work with algebraic expressions in the usual manner,
    as carried out in ordinary high-school algebra, without needing to explicitly refer back to Axioms A0 through~A6 time after time.

\V

        {\bf Example} One computes
        \begin{displaymath}
        (x+y)^{2} \,=\, (x+y){\cdot}(x+y) \,=\, (x+y){\cdot}x + (x+y){\cdot}y
     \,=\, 
        x{\cdot}x + y{\cdot}x + x{\cdot}y + y{\cdot}y
     \,=\, 
        x^{2} + 2\,x{\cdot}y + y^{2}
        \end{displaymath}
    Normally such calculations are left to the reader to carry out, sometimes without comment,
    sometimes with a vague hint such as `{\bf by the usual algebraic manipulations}\IndA{by the usual algebraic manipulations}
    \IndD{usual algebraic manipulations}{by the usual algebraic manipulations}.

\V

        (3) The role played by `$2$' in the terms $x^{2}$, $y^{2}$ and $2\,x{\cdot}y$ above is that of a natural number (i.e., a `counting' number),
    and {\em not} that of an element of the field; for example, $2\,x{\cdot}y$ and $x^{2}$ are shorthands for $x\,y + x\,y$ and $x{\cdot}x$, respectively.
    Likewise, in the expressions $k\,c$ and $c^{k}$ described in Part~(3) of Definition~\Ref{DefB10.30},
    the role of $k$ is as a counting number, that is, an element of~${\NN}$, not an element of the field.
    For example, the expression $3\,c$ is simply a shorthand for the repeated sum $c+c+c$,
    which has three~terms, and {\em not} `multiplication of $3$ with $c$ in the field'.
    This distinction becomes clearer in case the field is ${\ZZ}_{2} \,=\, \{0,1\}$, the field with two elements described in Remark~\Ref{RemrkB10.20}~(2):
    since the (infinite) set ${\NN}$ is not a subset of the (finite) set~${\ZZ}_{2}$, the expression $3\,c$,
    cannot mean `multiplication in the field ${\ZZ}_{2}$ of $3$ with $c$', since the natural number $3$ is not an element of the field ${\ZZ}_{2}$.

        In the next section, however, after introducing more axioms for the field ${\RR}$,
    we are able to replace our `primitive' notion of ${\NN}$ with an improved version which forms a subset of ${\RR}$.
    For these new counting numbers the equation $k\,c \,=\, k{\cdot}c$, with ${\cdot}$ now denoting multiplication of real numbers, does hold.


\VV



            \section{\bf Order Properties of the Real Numbers}
            \label{SectB20}\IndB{axioms for ${\RR}$}{order axioms for ${\RR}$}
    \IndB{ZZ Sections}{\Ref{SectB20} Order Properties of the Real Numbers}


\V

        The field axioms discussed in the preceding section involve both `plus signs' and `minus signs'.
    Despite that suggestive notation, no reasonable concepts of `positive number' or `negative number' can come out of that discussion.
    For that one needs to state some additional axioms.

\V
\V

        The set ${\RR}$ has a distinguished subset, the set of {\bf positive numbers}, that satisfies the following {\bf Order Axioms}:

\V

        {\bf Axiom O1} For every number $z$ exactly one of the following statements is true:
        \begin{displaymath}
        \mbox{`$z$ is positive'; \h `$z \,=\, 0$'; \h $-z$ is positive'}
        \end{displaymath}


\V

        {\bf Axiom O2} (The Closure Laws for Positive Numbers) The sum of two positive numbers is positive, and the product of positive numbers is positive.


\V
\V

            \subsection{\small{\bf Remarks}}
            \label{RemrkB20.200}


       \hspace*{\parindent} (1) The existence of a distinguished subset of ${\RR}$ that satisfy
    Axioms~O1 and~O2 cannot be deduced from the field axioms studied in the preceding section.
    Indeed, if the existence of such a subset could be deduced from the field axioms alone, then {\em every} field would have such a subset.
    Consider, however, the field ${\ZZ}_{2}$ described in Remark~\Ref{RemrkB10.20}~(2), and suppose it has such a subset.
    In that field there are exactly two distinct elements, denoted $0$ and $1$, and one has $-1 \,=\, 1$. By Axiom~O1 exactly one of the following statements is true:
        \begin{displaymath}
        \mbox{`$1$ is positive'; \h `$1 \,=\, 0$'; \h `$-1$ is positive'}
        \end{displaymath}
 Since in the field ${\ZZ}_{2}$ one has $-1 \,=\, 1$ and $1 \,\,{\neq}\,\, 0$,
    it follows that either none of these statements is true or two of them are true. In either case, Axiom~O1 cannot hold in this field.

\V

       (2) The real number system is not the only field which satisfies all the axioms considered so far.
    For example, the set ${\QQ}$ of rational numbers, together with its usual operations of addition and multiplication,
    and with its usual notion of `positive', satisfy these axioms. Any such system is called an {\bf ordered field}.
    \IndBD{field (in the sense of algebra)}{ordered field}
    In particular, every property obtained in this section remains valid in any ordered field.

\V

        (3) An ordered field is a set $S$ with a pair of binary operations $+$ and ${\cdot}$,
    together with a distinguished subset set $P$ of `positive' elements, which satisfies the axioms A0-A6, O1,~O2.
    If $S'$ is a second such ordered field, with corresponding operations $+'$ and ${\cdot}'$, and set of positives $P'$,
    then one says that they are {\bf isomorphic as ordered fields}\IndBD{field (in the sense of algebra)}{isomorphic ordered fields}
    provided there exists a bijection $f:S \,{\rightarrow}\, S'$ which is an isomorphism , in the sense of Definition~\Ref{DefA60.70},
    of $+$ with $+'$ and of ${\cdot}$ with~${\cdot}'$, and in addition $f$ maps $P$ onto~$P'$.

        Since ${\QQ}$ is a countable set while ${\RR}$ is uncountable, it is clear that these ordered fields are not isomorphic to each other.
    Examples of ordered fields which are isomorphic to neither ${\QQ}$ nor ${\RR}$ are given in the exercises.

%% GIVE EXERCISES a + b\,\sqrt{3}; nonArchimedean fields


            \subsection{\small{\bf Definitions}}
            \label{DefB20.10}

\V

\hspace*{\parindent}(1) The set of positive real numbers is denoted by the symbol ${\RR}^{+}$.

\V

        (2) An element $z$ in ${\RR}$ is said to be a {\bf negative number} provided $-z{\in}{\RR}^{+}$.
    The set of all negative numbers in ${\RR}$ is denoted ${\RR}^{-}$.

\V

        (3) If $c$ is a real number, then the {\bf absolute value of $\Bfm{c}$}\IndA{absolute value of a real number}
    is the number $|c|$ given by the rule
        \begin{displaymath}
        |c| \,=\, \left\{
        \begin{array}{rl}
        c & \mbox{if $c$ is positive} \\
        0 & \mbox{if $c \,=\, 0$} \\
       -c & \mbox{if $c$ is negative}
        \end{array}
                                \right.
        \end{displaymath}
    Similarly, the {\bf absolute-value function}\IndC{functions}{special functions}{absolute-value function}\IndD{absolute-value function}{functions}
    is the function $\mbox{abs}:{\RR} \,{\rightarrow}\, {\RR}$ given by the rule
        \begin{displaymath}
        \mbox{abs}\,(x) \,=\, |x| \mbox{ for every real number $x$}
        \end{displaymath}


\V
\V

            \subsection{\small{\bf Theorem}}
            \label{ThmB20.20}

\V

\hspace*{\parindent} (a) Suppose that $x_{1}$, $x_{2}$,\,{\ldots}\,$x_{k}$ are positive numbers.
    Then the sum $x_{1} + x_{2} + \,{\ldots}\, + x_{k}$ and product $x_{1}{\cdot}x_{2}{\cdot}\,{\ldots}\,{\cdot}x_{k}$ are also positive.
    (The repeated sums and products used here are defined, as in Definition~\Ref{DefA60.30}, using `left-to-right extensions'.)

\V

        (b) If $z{\in}{\RR}^{+}$ then $(-z){\in}{\RR}^{-}$.

\V

        (c) If $z,w{\in}{\RR}^{-}$ then $(z+w){\in}{\RR}^{-}$ but $z{\cdot}w{\in}{\RR}^{+}$.
    That is, the sum of two negative numbers is negative, but the product of two negative numbers is positive.

\V

        (d) If $z{\in}{\RR}^{+}$ and $w{\in}{\RR}^{-}$ then $z{\cdot}w{\in}{\RR}^{-}$.
    That is, the product of a positive number and a negative number is negative.

\V

        (e) If $z$ is a nonzero number then $z^{2}$ is positive and $-(z^{2})$ is negative.
    In particular, the multiplicative identity $1$ is positive, while $-1$ is negative.

\V

        (f) If $z{\in}{\RR}^{+}$ then $1/z{\in}{\RR}^{+}$.
    Likewise, if $z{\in}{\RR}^{-}$ then $1/z{\in}{\RR}^{-}$.

\V

        \underline{Partial Proof}: The proofs of Parts (a), (b), (d) and (e) are left as simple exercises. %% EXERCISES

\V

        (c) Suppose that $z,w{\in}{\RR}^{-}$. Then, by Part~(a), $-z$ and $-w$ are in ${\RR}^{+}$, and thus, by Axiom~O2, $(-z)+(-w)$ and $(-z){\cdot}(-w)$ are both in ${\RR}^{+}$.
    However, by Part~(a) of Theorem~\Ref{ThmB10.25}, together with the Distributive Law,
    it follows that $(-z)+(-w) \,=\, -(z+w)$, so $-(z+w){\in}{\RR}^{+}$.
    By definition of ${\RR}^{-}$, it follows that $(z+w){\in}{\RR}^{-}$, as claimed.
    Likewise, from Part~(b) of Theorem~\Ref{ThmB10.25} one sees that $z{\cdot}w \,=\, (-z){\cdot}(-w){\in}{\RR}^{+}$,
    so $(z{\cdot}w){\in}{\RR}^{+}$, as claimed.

\V


        (f) Note that if $z \,\,{\neq}\,\, 0$ then $1/z \,\,{\neq}\,\, 0$ (by Part~(c) of Theorem~\Ref{ThmB10.25}) and $z{\cdot}{\displaystyle \frac{1}{z}} \,=\, 1$;
    that is, by Part~(d), the product of $z$ with $1/z$ is in ${\RR}^{+}$.
    It then follows from Part~(c) that one cannot have $z$ in ${\RR}^{+}$ and $1/z$ in ${\RR}^{-}$ or {\em vice versa}.
    Thus either both $z$ and $1/z$ are in ${\RR}^{+}$ or both are in ${\RR}^{-}$, as claimed.

\V

        {\bf Remark} The careful reader will notice that in the preceding paragraphs the word `negative' is referred to in two different senses.
    For example, in Part~(a) the statement `$(-z){\in}{\RR}^{-1}$', when expressed in words,
    says that `the negative of $z$ (in the sense of Axiom~A6) is a negative number (in the sense of Part~(2) of Definition~\Ref{DefB20.10})'.

\V
\V

        Axioms O1 and O2 are called the `Order Axioms' for ${\RR}$ because they lead directly to the standard notion of `ordering of numbers', as follows:

\V

            \subsection{\small{\bf Definition}}
            \label{DefB20.30}

        Let $x$ and $y$ be real numbers.

\V

        (1) One says that {\bf $\Bfm{x}$ is less than $\Bfm{y}$} (in symbols: $x\,<\,y$) if $y-x$ is positive (in the sense of Definition~\Ref{DefB20.10}).
    As in ordinary English, one can also say that {\bf $\Bfm{y}$ is greater than $\Bfm{x}$} (in symbols: $y\,>\,x$) to mean the same thing.

\V

        (2) If either of the statements $x\,<\,y$ or $x \,=\, y$ is true, then one says that
    {\bf $\Bfm{x}$ is less than, or equal to, $\Bfm{y}$}; in symbols: $x\,\,{\leq}\,\,y$.
    In this case one can also say that {\bf $\Bfm{y}$ is greater than, or equal to, $\Bfm{x}$} (in symbols: $y\,\,{\geq}\,\,x$).


\V
\V

        The next result summarizes the basic facts about the relations $\,<\,$ and $\,\,{\leq}\,\,$ between real numbers.
    The reader should formulate the analogous facts for the relations $\,>\,$ and~$\,\,{\geq}\,\,$.

\V

            \subsection{\small{\bf Theorem}}
            \label{ThmB20.40}

        Throughout the statement of this theorem the quantities $u$, $v$, $x$, $y$ and $z$ are real numbers.

\V


        (a) If $z$ is any real number, then $z\,>\,0$ if, and only if, $z$ is positive.
    Likewise, $z\,<\,0$ if, and only if, $z$ is negative.


\V

        (b) (Trichotomy Property of Order) The numbers $x$ and $y$ satisfy exactly one of the following conditions:
        \begin{displaymath}
        x\,<\,y; \h  x \,=\, y; \h y\,<\,x.
        \end{displaymath}

\V

        (c) (Transitivity Properties of Order) If the numbers $x$, $y$ and $z$ satisfy the conditions that $x\,<\,y$ and $y\,<\,z$, then $x\,<\,z$.

        More generally, let $n$ be a natural number such that $n\,\,{\geq}\,\,3$,
    and suppose that $x_{1}$, $x_{2}$, $x_{3}$, \,{\ldots}\,$x_{n}$ are real numbers such that each of the following inequalities hold:
        \begin{displaymath}
        x_{1}\,<\,x_{2}; \h x_{2}\,<\,x_{3};
    \,\,{\ldots}\,
        x_{n-2}\,<\,x_{n-1};\h x_{n-1}\,<\,x_{n} \h ({\ast})
        \end{displaymath}
    Then for each pair of indices $i$ and $j$ in ${\NN}_{n}$ such that $i\,<\,j$ one has $x_{i}\,<\,x_{j}$.

        \underline{Note} One normally abbreviates the string of inequalities listed in $({\ast})$ by the expression
        \begin{displaymath}
        x_{1}\,<\,x_{2}\,<\,\,{\ldots}\,\,<\,x_{n-1}\,<\,x_{n}.
        \end{displaymath}

\V

        (d) (Addition Properties of Order) If $x\,<\,y$, then $x+u\,<\,y+u$. Similarly, if $x\,<\,y$ and $u\,<\,v$, then $x+u\,<\,y+v$.

\V

        (e) (Negation Property of Order) If $x\,<\,y$, then $-y\,<\,-x$.

\V

        (f) (Multiplication Properties of Order) Suppose that $x\,<\,y$.

        \h (i) If $u$ is positive then $u\,x\,<\,u\,y$

        \h (ii) If $u$ is negative then $u\,y\,<\,u\,x$.

        \h (iii) If $u \,=\, 0$ then $u\,x \,=\, u\,y \,=\, 0$.


\V

        (g) (Reciprocal Properties of Order) Let $x$ and $y$ be nonzero numbers, so that the reciprocals $1/x$ and $1/y$ exist. Suppose that $x\,<\,y$.
    Then the following statements hold:

         \h (i)\,\, If $x$ and $y$ are both positive, then their reciprocals are both positive and ${\displaystyle \frac{1}{y}\,<\,\frac{1}{x}}$.

         \h (ii)\, If $x$ and $y$ are both negative, then their reciprocals are both negative and ${\displaystyle \frac{1}{y}\,<\,\frac{1}{x}}$.

\V

        (h) If, in Parts (c), (d), (e), (f) and (g) above, one replaces each occurance of the symbol $\,<\,$ by the symbol $\,\,{\leq}\,\,$,
    the resulting statements remain true.

    \underline{Note} Only the symbol $\,<\,$ is to be replaced; the {\em words} `positive' and `negative' are not to be changed.

\V

        \underline{Partial Proof}:

\V

        The simple proofs of Parts~(a), (f), (g) and (h) are left as exercises. %% EXERCISES

        (b) Consider the number $z \,=\, y-x$. By Axiom~O1 exactly one of the following must hold:
        \begin{displaymath}
        z{\in}{\RR}^{+}; \mbox{ or } z \,=\, 0; \mbox{ or } -z{\in}{\RR}^{+}.
        \end{displaymath}
    However, $-z \,=\, -(y-x) \,=\, x-y$, so by Definition~\Ref{DefB20.30} the three possibilities for $z$ imply that exactly one of the following must hold:
        \begin{displaymath}
        x\,<\,y; \mbox{ or } x \,=\, y; \mbox{ or } y\,<\,x,
        \end{displaymath}
    as claimed.

\V

        (c) Note that, by Part~(f) of Theorem~\Ref{ThmB10.25}, one has $z-x \,=\, (z-y)+(y-x)$. However the hypothesis that $x\,<\,y$ and $y\,<\,z$ implies (by the definition of `$\,<\,$') that $z-y$ and $y-x$ are both positive.
    It now follows from Axiom~O2 that their sum is positive; that is, $z-x\,>\,0$, and thus $x\,<\,z$, as claimed.
    The more general version follows readily from this by using Mathematical Induction; the details are left as an exercise.

\V

        (d) Note that, by Part~(f) of Theorem~\Ref{ThmB10.25}, one has
        \begin{displaymath}
        y-x \,=\, (y-(-u)) + ((-u)-x) \,=\, (y+u) - (u+x) \,=\, (y+u) - (x+u)
        \end{displaymath}
    But, by the hypothesesis that $x\,<\,y$ one knows that $(y-x){\in}{\RR}^{+}$, hence $((y+u)-(x+u)){\in}{\RR}^{+}$, hence $x+u\,<\,y+u$, as claimed.

        If, in addition, $u\,<\,v$, then the preceding result also implies that $y+u\,<\,y+v$.
    Now use Transitivity to get $x+u\,<\,y+v$.

\V

        (e) Apply Part~(d) above, with $u \,=\, -(x+y)$, to get
        \begin{displaymath}
        x-(x+y) \,<\,y-(x+y),
        \end{displaymath}
    which after the obvious algebraic simplification becomes $-y\,<\,-x$.

\V

            \subsection{\small{\bf Remarks}}
            \label{RemrkB20.35}

\V

\hspace*{\parindent} (1) In light of the `Trichotomy Property', Part~(b) of the preceding theorem,
    the statement `$x\,\,{\leq}\,\,y$' is equivalent to `$x$ is not greater than $y$; in symbols, $x \not \,>\,y$.
    Likewise, the statement `$y\,\,{\geq}\,\,x$' is equivalent to `$y$ is not less than~$x$'; in symbols, $y \not \,<\,x$.
    Normally we use these equivalences without explicitly saying so.

\V

        (2) Sometimes one refers to inequalities of the form $x\,<\,y$ or $y\,>\,x$ as {\bf strict inequalities}\IndBD{inequalities}{strict inequalities},
    while those of the form $x\,\,{\leq}\,\,y$ or $y\,\,{\geq}\,\,x$ are called {\bf weak inequalities}.\IndBD{inequalities}{weak inequalities}

\V

        (3) The careful reader will observe a notational `anachronism' in Part~(c) of the preceding theorem.
    Indeed, the theorem concerns properties of the newly-defined notion of the order `$<$' in the real numbers.
    However, the same symbol `$<$' also appears here in the expression $i\,<\,j$ in Part~(c), indicating the relation between the natural numbers $i$ and~$j$.
    The meaning here of the symbol `$<$' (and its near relative `${\leq}$') in the context of
    natural numbers is assumed to be already known from our primitive notions of natural numbers.
    In contrast, the use of the symbol `$<$' (and the symbol $\,\,{\leq}\,\,$), in the context of real numbers, is in the process of being developed here.
    Such ambiguities occur frequently in mathematics. Normally the context makes it clear which meaning is intended.

\V
\V

            \subsection{\small{\bf Corollary}}
            \label{CorB20.61}

\V

\hspace*{\parindent}Suppose that $x$ and $y$ are real numbers such that $0\,<\,x\,\,{\leq}\,\,y$.
    Let $k$ be an element of ${\NN}$.
    Then $0\,<\,x^{k}\,\,{\leq}\,\,y^{k}$.
    Furthermore, one has $x^{k} \,=\, y^{k}$ if, and only if, $x \,=\, y$.

\V

        {\bf Proof}\, Left as an exercise.

\VV


            \subsection{\small{\bf The Infinity Symbols}}
            \label{RemrkB20.43}


        In analysis, as in calculus, it convenient to introduce the `infinity' symbols, $+{\infty}$ and $-{\infty}$.
    We use the infinity symbols in {\TheseNotes}, but subject to the following rules:

\VA

        \h (i)\,\, The symbols $+{\infty}$ and $-{\infty}$, pronounced `{\bf plus infinity} and {\bf minus infinity}, are distinct objects; that is, $-{\infty} \,\,{\neq}\,\, +{\infty}$. Also, neither symbol is a real number.
    As a class they are referred to as {\bf the infinities}.\IndBD{infinities}{$+{\infty}, -{\infty}$}. We often abbreviate the symbol $+{\infty}$ to~${\infty}$.

\VA

        \h (ii)\, The meaning of the phrase `$x$ is less than $y$' (and thus of the expression $x\,<\,y$),
    previously restricted to the case $x$ and $y$ are both real numbers, is extended to include
    the possibility that $x$ or $y$ might be $-{\infty}$ or $+{\infty}$ in accordance with the following rules:
        \begin{displaymath}
        -{\infty}\,<\,+{\infty}; \h -{\infty}\,<\,x \mbox{ and } x\,<\,+{\infty} \mbox{ for all $x$ in ${\RR}$}.
        \end{displaymath}
    The latter statement is sometimes abbreviated to: `$-{\infty}\,<\,x\,<\,+{\infty}$ for all real~$x$'.

\VA

        \h (iii) To say that a quantity $z$ is an {\bf extended real number}\IndBD{real numbers}{extended real numbers}
    means that either $z$ is a real number or $z$ is one of the infinities $+{\infty}$ or~$-{\infty}$.

\VA

        \h (iv) Following the standard usage, we allow a restricted {\bf arithmetic of infinities}.\IndBD{infinities}{arithmetic of infinities}
    More precisely, one is allowed to write:

        $-{\infty} \,=\, -(+{\infty}) \,=\, -({\infty})$ and ${\infty} \,=\, +{\infty} \,=\, -(-{\infty})$.

        $+{\infty}+c \,=\, +{\infty}$ and $-{\infty}+c \,=\, -{\infty}$ for every real number~$c$.

        $(+{\infty})+(+{\infty}) \,=\, +{\infty}$ and $(-{\infty})+(-{\infty}) \,=\, -{\infty}$.

        $(+{\infty}){\cdot}c \,=\, +{\infty}$ and $(-{\infty}){\cdot}c \,=\, -{\infty}$ for every extended real number $c\,>\,0$.

        $(+{\infty}){\cdot}c \,=\, -{\infty}$ and $(-{\infty}){\cdot}c \,=\, +{\infty}$ for every extended real number $c\,<\,0$.

        $c/(+{\infty}) \,=\, c/(-{\infty}) \,=\, 0$ for every real number~$c$.

        $|-{\infty}| \,=\, |+{\infty}| \,=\, +{\infty}$.

        In contrast, normally we are {\em not} allowed to use certain expressions,
    such as ${\infty}-{\infty}$, $0{\cdot}{\infty}$, ${\infty}/{\infty}$, or the corresponding expressions in which the symbol ${\infty}$ is replaced by either $+{\infty}$ or $-{\infty}$.
    Indeed, such expressions are called {\bf indeterminate forms},\IndA{indeterminate forms}
    and any exceptions to this proscription will be justified by the specific context.


\V

        Geometrically speaking, one thinks of the object $+{\infty}$ as being `to the right of every real number $x$ on the $x$-axis'.
    Likewise, one thinks of $-{\infty}$ as being `to the left of every real number $x$'.

\VV

        One of the distinctive features of analysis is  the type of techniques it frequently uses to prove the equality of two quantities.
    Unlike the situation in algebra, where one generally proves equality of, say, $A$ and $B$ directly, in analysis often such equality is proved indirectly,
    usually by showing that the statement $A\,{\neq}\,B$ cannot possibly be true.
    Many students initially find such a `proof by contradiction' less convincing than a direct proof.
    Perhaps they should consult with Sherlock Holmes; see Chapter~Quote~(4) at the beginning of this chapter.

        Among the most oldest of these indirect methods is the following simple result.

\V

            \subsection{\small{\bf Theorem} (The Principle of Eudoxus)}
            \label{ThmB20.63}\IndA{Eudoxus, Principle of}\IndD{Principle of Eudoxus}{Eudoxus, Principle of}

\hspace*{\parindent} (1) A necessary and sufficient condition for real numbers $A$ and $B$ to be equal is that the following condition hold:
        \begin{displaymath}
        |B-A|\,<\,{\varepsilon} \mbox{ for every real number ${\varepsilon}\,>\,0$}.
        \end{displaymath}

\V

        (2) Similarly, necessary and sufficient condition for real numbers $A$ and $B$ to be equal is that the following condition hold:
        \begin{displaymath}
        |B-A|\,\,{\leq}\,\,{\varepsilon} \mbox{ for every real number ${\varepsilon}\,>\,0$}.
        \end{displaymath}


\V

        {\bf Proof}\, (1) If $A \,=\, B$, then $|B-A| \,=\, 0$, hence $|B-A|\,<\,{\varepsilon}$ for every positive ${\varepsilon}$.

        Conversely, suppose that $A \,\,{\neq}\,\, B$, so that $|B-A|\,>\,0$.
        Choose ${\varepsilon} \,=\, |B-A|$. Then it is not the case that $|B-A|\,<\,{\varepsilon}$.

\V

        (2) Left as a simple exercise.

 %% EXERCISE?


\V

        The Principle of Eudoxus is so obvious that it may appear impossible that it could be the basis of anything significant.
    Nevertheless, we use it many times in {\TheseNotes}.
    Frequently it arises in conjunction with one of the results in the next theorem.

\V

            \subsection{\small{\bf Theorem}}
            \label{ThmB20.65}

\V

\hspace*{\parindent} (a) (The Magnitude--Interval Inequalities)\IndBD{inequalities}{magnitude-interval inequality} Let $M$ be a positive real number.

            \h (i)\,\, A necesary and sufficient condition for real numbers $x$ and $c$ to satisfy the inequality $|x-c|\,\,{\leq}\,\,M$ is that they satisfy the inequalities $-M+c\,\,{\leq}\,\,x\,\,{\leq}\,\,M+c$.
    Furthermore, the case $|x-c| \,=\, M$ occurs if, and only if, either $x \,=\, M+c$ of $x \,=\, -M+c$.

            \h (ii)\, A necessary and sufficient condition for $x$ and $c$ to satisfy the inequality $|x-c|\,\,{\geq}\,\,M$ is that either $x\,\,{\leq}\,\,-M+c$ or $x\,\,{\geq}\,\,M+c$.


            \h (iii) The statements, obtained from (i) and (ii) by replacing all occurances of the `weak inequality' symbols, $\,\,{\leq}\,\,$ and $\,\,{\geq}\,\,$, by the corresponding strict inequality symbols, $\,<\,$ and $\,>\,$, are also true.
    That is, $|x-c|\,<\,M$ if, and only if, $-M+c\,<\,x\,<\,M+c$;
    and $|x-c|\,<\,M$ if, and only if, $-M+c\,<\,x\,<\,M+c$.

        \underline{Note} In the important special case in which $c \,=\, 0$ one has $x-c \,=\, x$, and the preceding statements simplify a bit:
    $|x|\,\,{\leq}\,\,M$ if, and only if, $-M\,\,{\leq}\,\,x\,\,{\leq}\,\,M$, and so on.

\V

        (b) (The Basic Triangle Inequality)\IndBD{inequalities}{basic triangle inequality} Suppose that $x$ and $y$ are real numbers.
    Then
        \begin{equation}
        \label{IneqB.35AA}
        |x+y|\,\,{\leq}\,\,|x| + |y|
        \end{equation}
    and
        \begin{equation}
        \label{IneqB.35AB}
        |x-y|\,\,{\leq}\,\,|x| + |y|
        \end{equation}
      Furthermore, the case of `equality' holds in Inequality~\Ref{IneqB.35AA} if, and only if,
    $x$ and $y$ are {\em not} of mixed sign; that is, provided that either both are nonnegative or both are nonpositive.
    Likewise, the equality holds in~\Ref{IneqB.35AB} if, and only if, $x$ and $y$ {\em are} of mixed sign; equivalently, either $x\,\,{\geq}\,\,0$ and $y\,\,{\leq}\,\,0$ or $x\,\,{\leq}\,\,0$ and $y\,\,{\geq}\,\,0$.

\V

        (c) (The Extended Triangle Inequality)\IndBD{inequalities}{extended triangle inequality} Suppose that $x_{1}$, $x_{2}$,\,{\ldots}\,$x_{k}$ are real numbers.
    Then
        \begin{equation}
        \label{IneqB.35B}
        |x_{1} + x_{2} + \,{\ldots}\, + x_{k}|\,\,{\leq}\,\,|x_{1}| + |x_{2}| + \,{\ldots}\,+ |x_{k}|.
        \end{equation}
    Furthermore, the case of `equality' holds in Inequality~\Ref{IneqB.35B} if, and only if,
    the numbers $x_{1}$, $x_{2}$,\,{\ldots}\,$x_{k}$ are {\em not} of mixed sign;
    equivalently, either all of them are nonnegative, or all of them are nonpositive.

\V

        (d) (The Reverse Triangle Inequality)\IndBD{inequalities}{reverse triangle inequality} Suppose that $x$ and $y$ are real numbers. Then
        \begin{equation}
        \label{IneqB.35C}
        ||x| \,-\, |y||\,\,{\leq}\,\,|x-y|
        \end{equation}
    Furthermore, a necessary and sufficient for the case of equality to hold is that $x$ and $y$ are not of mixed sign,
    in the sense that either $x\,\,{\geq}\,\,0$ and $y\,\,{\geq}\,\,0$, or $x\,\,{\leq}\,\,0$ and $y\,\,{\leq}\,\,0$.

\V

        {\bf Proof}

\V

        (a) These inequalities follow directly from the definition of `absolute value'; the details are left as an exercise.

\V

        (b) Notice that, by Part~(a), one has
        \begin{displaymath}
        -|x|\,\,{\leq}\,\,x\,\,{\leq}\,\,|x|
    \mbox{ and }
        -|y|\,\,{\leq}\,\,y\,\,{\leq}\,\,|y|
        \end{displaymath}
    Thus, by Part~(g) of Theorem~\Ref{ThmB20.40}, one gets
        \begin{displaymath}
        -|x|-|y|\,\,{\leq}\,\,x+y,\,\,{\leq}\,\,|x| + |y|,
        \end{displaymath}
    Since $-|x|-|y| \,=\, -(|x|+|y|)$, it then follows from Part~(a) again that $|x+y|\,\,{\leq}\,\,|x|+|y|$, as claimed.
    Moreover, it also follows from Part~(a) that equality occurs in Inequality~\Ref{IneqB.35AA} if, and only if, either $x+y \,=\, |x|+|y|$ or $x+y \,=\, -(|x|+ |y|)$.
    Since $x\,\,{\leq}\,\,|x|$ and $y\,\,{\leq}\,\,|y|$, it follows from Part~(g) of Theorem~\Ref{ThmB20.40} again that
    $x+y \,=\, |x|+|y|$ precisely when $x \,=\, |x|$ and $y \,=\, |y|$; that is, when $x\,\,{\geq}\,\,0$ and $y\,\,{\geq}\,\,0$.
    Likewise, since $-|x|\,\,{\leq}\,\,x$ and $-|y\,\,{\leq}\,\,y|$, the only way to have $-(|x|+|y|) \,=\, x+y$ is if $x \,=\, -|x|\,\,{\leq}\,\,0$ and $y \,=\, -|y|\,\,{\leq}\,\,0$.

\V

        (c) This follows easily from Part~(b) by using Mathematical Induction on $k$.

\V

        (d) Note that, by the Basic Triangle Inequality, $|x-y|+|y|\,\,{\geq}\,\,|(x-y)+y| \,=\, |x|$.
    Thus, $|x-y|\,\,{\geq}\,\,|x|-|y|$. Interchanging the roles of $x$ and $y$ then yields $|y-x|\,\,{\geq}\,\,|y|-|x|$.
    Since one of the numbers $|x|-|y|$ or $|y|-|x|$ equals $||x|-|y||$, the desired inequality follows.
    The case of `equality' is left as an exercise.

\V


\VV

        {\bf Interpreting ${\NN}$, ${\ZZ}$ and ${\QQ}$ as Subsets of {\RR}}\IndBD{real numbers}{${\NN}$, ${\ZZ}$ and ${\QQ}$ as subsets of ${\RR}$}

\V

        The axiomatic treatment of ${\RR}$ being developed in this chapter describes various important properties of real numbers.
    However, it says nothing about the nature of these numbers; that is, what type of objects they are.
    In particular, the axioms do not specify the relation between `real number' and, say, the primitive notion of `natural number' used in Chapter~\Ref{ChaptA}.
    Experience from elementary calculus demonstrates the usefulness of being able to think of natural numbers, as well as integers and rational numbers,
    as being examples of real numbers. For example, in dealing with the function $f(x) \,=\, \sqrt{2}\,x^{3}$,
    one wants to treat the `$3$' in $x^{3}$ as a natural (i.e., counting) number: $x^{3}$ is the product $x{\cdot}x{\cdot}x$ with $3$ factors.
    In contrast, one wants the `$2$' in the expression $\sqrt{2}$ to be a real number so that extracting its square root makes sense.

        There is a simple solution, which does not require changing one's  primitive notion of `natural number', that works in any ordered field.
    Indeed, every such field has a naturally defined countably infinite subset which inherits,
    from the field operations of $+$ and~${\cdot}$ and the field ordering $\,<\,$,
    binary operations and an order structure `isomorphic' to the corresponding ones in the primitive notion of~${\NN}$.
    This subset is defined below. Since the ordered field of greatest interest for us is the field ${\RR}$ of real numbers,
    we formulate everything in terms of that field; but of course the construction works for every ordered field.

\V

        \underline{Temporary Notation}

\V

        In the theorem below we use the standard notation $0$, $1$, $+$, ${\cdot}$, $\,<\,$ when dealing with elements of ${\NN}$;
    but in ${\RR}$ we temporarily append the subscript `$r$' (for `real'): $0_{r}$, $1_{r}$, $+_{r}$, ${\cdot}_{r}$, $<_{r}$.

\V
\V

        \subsection{\small{{\bf Theorem}}}
        \label{ThmB25.20}

\V

        Let $f:{\NN} \,{\rightarrow}\, {\RR}$ be given by the rule $f(k) \,=\, k\,1_{r}$ for all $k$ in ${\NN}$;
    that is, $f(k) \,=\, 1_{r}\, +_{r}\, 1_{r}\, +_{r} \,+_{r} \,\,{\ldots}\,+_{r}\, 1_{r}$,  
    where the quantity on the right of this last equation is the sum in ${\RR}$ of $k$ copies of the real number~$1_{r}$;
    see Definition~\Ref{DefB10.30}. Let ${\NN}_{r}$ denote the image in ${\RR}$ of the function $f$; that is,
        \begin{displaymath}
        {\NN}_{r} \,=\, \{1_{r}, 1_{r}\,+_{r}\, 1_{r},\,{\ldots}\,\}
     \,=\, 
        \{k\,1_{r}: k{\in}{\NN}\}
        \end{displaymath}

\V

        (a) The function $f$ preserves the relation `less than', in the sense that if $k$ and $n$ are elements of ${\NN}$ such that $k\,<\,n$ then $f(k)\,<_{r}\,\,f(n)$.
    In particular, the function $f:{\NN} \,{\rightarrow}\, {\NN}_{r}$ is a bijection, hence the set ${\NN}_{r}$ is countably infinite.

\V

        (b) The bijection $f$ is an isomorphism of the binary operations addition and multiplication, in the sense of Definition~\Ref{DefA60.70};
    that is, 
        \begin{displaymath}
        f(j+k) \,=\, f(j) +_{r} f(k) \mbox{ and } f(j{\cdot}k) \,=\, f(j){\cdot}_{r}f(k) \mbox{ for all $j$ and $k$ in ${\NN}$} \h ({\ast})
        \end{displaymath}

\V

        {\bf Proof}

\V

        (a) Suppose that $k$ and $n$ are natural numbers such that $k\,<\,n$. As a notational convenience,
    for each $j{\in}{\NN}_{n}$ let $x_{j} \,=\, 1_{r}$, and let $m \,=\, n-k$, so that $m{\in}{\NN}$ (since $k\,<\,n$). Then one has
        \begin{displaymath}
        f(n) \,=\, n\,1_{r}
    \,=\, 
        x_{1} + x_{2} + \,{\ldots}\, + x_{k} + x_{k+1} + \,{\ldots}\,+x_{k+m}
     \,=\, 
        (x_{1} + \,{\ldots}\, + x_{k}) + (x_{k+1} + \,{\ldots}\, + x_{k+m}),
        \end{displaymath}
    where the last equation comes from Part~(a) of Theorem~\Ref{ThmB10.32}. That is, $f(n) \,=\, f(k) + m\,1_{r}$.
    Since $m\,1_{r}$ is positive in the ordered field~${\RR}$, it follows that $f(k)\,<_{r}\,f(n)$, as required.

        It is now clear from the definition of the set ${\NN}_{r}$ that the function $f:{\NN} \,{\rightarrow}\, {\NN}_{r}$ is a surjection.
    It is equally clear that it is also an injection, and thus a bijection, since if $i,j{\in}{\NN}$ with $i \,\,{\neq}\,\, j$,
    then either $i\,<\,j$ of $j\,<\,i$; in either case, it follows from what has just been proved that $f(i) \,\,{\neq}\,\, f(j)$.

\V

        (b) The `additive fact' $f(j+k) \,=\, f(j) +_{r} f(k)$ follows easily from the Extended Associative Law for Addition, as above.

    Concerning the equation $f(j{\cdot}k) \,=\, f(j){\cdot}_{r}f(k)$, let $A$ denote the set of natural numbers $k$
    such that $f(j{\cdot}k) \,=\, f(j){\cdot}_{r}f(k)$ for each $k$ in ${\NN}$. It is clear that $1{\in}A$,
    since $1$ and $1_{r}$ are the multiplicative identities in ${\NN}$ and ${\RR}$, respectively.
    The fact that $k$ being in $A$ implies that $(k+1){\in}A$ follows easily using the Distributive Laws in ${\NN}$ and ${\RR}$,
    together with the `additive fact' proved above; the details are left as an exeercise. %% EXERCISE?


\V
\V

        \subsection{\small{{\bf Remark}}}
        \label{RemrkB25.30}

\V

\hspace*{\parindent} The bijection $f:{\NN} \,{\rightarrow}\, {\NN}_{r}$ allows one to use
    the countably infinite set ${\NN}_{r}$ to carry out any `counting' activites for which one would ordinarily use the `primitive' set~${\NN}$.
    However, since ${\NN}_{r}$ is a subset of ${\RR}$ which is closed under addition and multiplication of reals,
    it also interacts usefully with other real numbers; see Remark~\Ref{RemrkA20.40}~(2).
    For example, we can now think of the `$2$' and the `$3$' in the example $\sqrt{2}\,x^{3}$ mentioned above as both being real numbers,
    with the `counting' interpretation of the `$3$' arising from the counting activity assigned to the countable set~${\NN}_{r}$.

\VV

        It is easy to form from the subset ${\NN}_{r}$ above, together with the operations operations of the ordered field~${\RR}$,
    subsets of ${\RR}$ which behave algebraically exactly like the `primitive' notions of the integers and the rational numbers.


\V

        \subsection{\small{{\bf Definition}} (The Integers and the Rational Numbers as Subsets of ${\RR}$)}
        \label{DefB25.40}

\V

        Let ${\NN}_{r}$ be the subset of ${\RR}$ described above.

\V

        (1) A real number $k$ is said to be a (real) {\bf integer} provided one of the following cases holds:

        \h (i)\,\, $k$ is in ${\NN}_{r}$;

        \h (ii)\, $-k$ is in ${\NN}_{r}$

        \h (iii)  $k \,=\, 0_{r}$.

\noindent The set of all such (real) integers is denoted by ${\ZZ}_{r}$.

        Note that the `negation' indicated in~(ii) is the usual negation from the axioms for the real numbers.

\V

        (2) A real number $x$ is said to be a (real) {\bf rational number} provided it can be expressed as a ratio $x \,=\, j/k$ where $j$ and $k$ are (real) integers, as defined in Part~(1), with $k\,>_{r}\,0_{r}$.
    The set of all such real rational numbers is denoted ${\QQ}_{r}$.

    Note that the division indicated by the expression $j/k$ is as described in Definition~\Ref{DefB10.22}.

\V
\V

        The subsets ${\NN}_{r}$ and ${\QQ}_{r}$ described above inherit naturally from the ordered field ${\RR}$
    binary operations of addition and multiplication, as well as an order relation.
    The inherited `order relation' is the obvious one; for example, if $x$ and $y$ are in ${\QQ}_{r}$,
    then they are in ${\RR}$, where the relation $x\,<\,y$ already makes sense. The inherited addition and multiplication requre a bit more work,  since (by definition) a binary operation must satisfy the `closure' requirement.


\V

        \subsection{\small{{\bf Theorem}}}
        \label{ThmB25.50}

\V

        Let ${\ZZ}_{r}$ and ${\QQ}_{r}$ be the sets of (real) integers and (real) rationals, respectively, described above.
    Then these sets are closed under the (real) binary operations $+_{r}$ and ${\cdot}_{r}$.
    That is, if $x$ and $y$ are in ${\ZZ}_{r}$, then $x+_{r}y$ and $x{\cdot}_{r}y$ are in ${\ZZ}_{r}$;
    similarly, if $x$ and $y$ are in ${\QQ}_{r}$, then so are $x+_{r}y$ and $x{\cdot}_{r}y$.
    Otherwise stated, the restrictions of these operations to ${\ZZ}_{r}{\times}{\ZZ}_{r}$
    and to ${\QQ}_{r}{\times}{\QQ}_{r}$ are binary operations on the sets ${\ZZ}_{r}$ and~${\QQ}_{r}$, respectively.

\VV
        \subsection{\small{{\bf Remarks}}}
        \label{ThmB25.55}

\V

\hspace*{\parindent}(1) It is not hard to see, using the bijection $f:{\NN}  \,{\rightarrow}\, {\NN}_{r}$ described above in Theorem~\Ref{ThmB25.20},
    that the sets ${\ZZ}_{r}$ and ${\QQ}_{r}$ defined here, together with the operations on them arising from the real $+_{r}$ and ${\cdot}_{r}$,
    form systems isomorphic with the corresponding `primitive' systems ${\ZZ}$ and~${\QQ}$, respectively.
    The same holds for the inherited `order' relations.

\V

        (2) In light of the preceding results, it makes sense to use, in place of the `primitive' concepts of ${\NN}$, ${\ZZ}$ and ${\QQ}$,
    the `new and improved' versions ${\NN}_{r}$, ${\ZZ}_{r}$ and ${\QQ}_{r}$ constructed above.
    We do exactly that for the rest of the main body of {\ThisText}. In particular, from now on the terms `natural number', `integer' and
    `rational number' refer to elements of the sets ${\NN}_{r}$, ${\ZZ}_{r}$ and~${\QQ}_{r}$ unless indicated explicitly to the contrary.

        Likewise, since the `primitive' versions of ${\NN}$, ${\ZZ}$ and ${\QQ}$ are no longer in use, we simplify notations and henceforth
    drop the subscript `$r$' from ${\NN}_{r}$, ${\ZZ}_{r}$ and ${\QQ}_{r}$, as well as from $+_{r}$, ${\cdot}_{r}$ and $<_{r}$.

\V

        (3) This is also a good place to introduce the customary abbreviation of omitting the infix `dot' for real multiplication and using `juxtaposition.
    Thus from now on we normally write, say, $x\,y$ instead of $x{\cdot}y$; but if clarity needs it, e.g., $3\,2$ {\em vs} $3{\cdot}2$, we'll include the dot.


\VV





\V
\V

        The final results in this section use the fact, developed above, that we can think of natural numbers and rational numbers as types of real numbers.


\V

        \subsection{\small{{\bf Theorem}}}
        \label{ThmB25.80}

\V

        

\V

        (a) Let $u$ be a real number and let $k$ be a natural number. Then the following formula holds:
        \begin{displaymath}
        1+u + \,{\ldots}\,+u^{k} \,=\, \left\{
        \begin{array}{cl}
        k+1 & \mbox{if $u \,=\, 1$} \\
                       &            \\
        {\displaystyle \frac{1-u^{k+1}}{1-u}} & \mbox{if $u \,\,{\neq}\,\, 1$}
        \end{array}
            \right.
        \end{displaymath}

\V

        (b) More generally, if $m$ is any natural number, then
        \begin{displaymath}
        u^{m} + u^{m+1} + \,{\ldots}\, + u^{m+k} \,=\, \left\{
        \begin{array}{cl}
        k+1 & \mbox{if $u \,=\, 1$} \\
                       &            \\
        {\displaystyle \frac{u^{m}-u^{k+m+1}}{1-u}} & \mbox{if $u \,\,{\neq}\,\, 1$}
        \end{array}
            \right.
        \end{displaymath}

\V

        (c) The following formula holds:
        \begin{displaymath}
        1-u^{k+1} \,=\, (1-u)(1+u+u^{2}+\,{\ldots}\,+u^{k}) \mbox{ for all $u$ in ${\RR}$}.
        \end{displaymath}

\V

        {\bf Proof}

\V

        (a) The case when $u \,=\, 1$ is trivial.  Thus, suppose that $u \,\,{\neq}\,\, 1$.
    Let $A$ be the set of natural numbers $k$ for which the statement is true.

        It is clear that $k \,=\, 1$ in $A$.
    Indeed, when $k \,=\, 1$ the statement to be proved reduces to
        \begin{displaymath}
        1+u \,=\, \frac{1-u^{2}}{1-u};
        \end{displaymath}
    note that the hypothesis $u \,\,{\neq}\,\, 1$ means that the indicated division is allowed.
    This last equation follows easily from the observation that $1-u^{2} \,=\, (1-u)(1+u)$ and thus, by Part~(e) of Theorem~\Ref{ThmB10.25}, one has
        \begin{displaymath}
        \frac{1-u^{2}}{1-u} \,=\, \frac{(1-u)(1+u)}{1-u} \,=\, 1+u.
        \end{displaymath}
    Next, suppose that $k$ is in $A$. Then the statement to be proved for $k+1$ is
        \begin{displaymath}
        1+u+u^{2}+\,{\ldots}\,+u^{k} + u^{k+1} \,=\, \frac{1-u^{k+2}}{1-u}.
        \end{displaymath}
    Notice that by the induction hypothesis (i.e., $k$ is in $A$), together with the definition of `Repeated Addition' and Parts~(e) and~(f) of Theorem~\Ref{ThmB10.25}, one sees that
        \begin{displaymath}
        1+u+u^{2}+\,{\ldots}\,+u^{k} + u^{k+1} \,=\, (1+u+u^{2}+\,{\ldots}\,+u^{k}) + u^{k+1} \,=\, 
    \frac{1-u^{k+1}}{1-u} + u^{k+1} \,=\, \frac{(1-u^{k+1})+ u^{k+1}(1-u)}{1-u} \,=\, 
        \end{displaymath}
        \begin{displaymath}
    \frac{(1-u^{k+1})+ (u^{k+1}-u^{k+2})}{1-u} \,=\, \frac{1-u^{k+2}}{1-u}.
        \end{displaymath}
    Thus $k+1$ is also in $A$; so, by Mathematical Induction, one has $A \,=\, {\NN}$ and hence the claimed result is true.

\V

        (b) Multiply both sides of the result in Part~(a) by $u^{m}$ and simplify.


\V

        (c) The result follows by multiplying both sides of the equations obtained in Part~(a) by the quantity~$(1-u)$.

\VV

        \subsection{\small{The Principle of Ingenious Cancellations}}\IndA{principle of ingenious cancellations}
        \label{RemrkB25.85}


%% Principle of Ingenious Cancellatio -- move to later
%%%%
%\begin{quotation}
%{\footnotesize \underline{\Note}\IndB{\notes}{on the Principle of Ingeneous %Cancellations} (on the principle of ingeneous cancellations)

        Students learning real analysis often find proofs in the texts to be mysterious;
    in too many cases, the authors write down complicated expressions, seemingly without motivation, that magically work to solve the problem at hand.
    Although on occasion an author really does perform a mathematical miracle, usually there is ample motivation for what the author does;
    but frequently the reader is simply not told about that motivation.
    The purpose of this brief discussion is outline one important idea that often lies behind the `miracles' found in analytical proofs.

        \underline{Typical Situation in Analysis}
    Much of real analysis is devoted, directly or indirectly, to the issue of approximating a quantity $A$ by a second quantity $B$.
    In such circumstances it is usually important to have an idea of the magnitude $|A-B|$ of the error in that approximation;
    for example, this is the case in situations in which one wants to use the Principle of Eudoxus to show equality of two quantities.
    Thus, many proofs in analysis contain a step that takes the following form.
    (In what follows the words in italics are supposed to represent the thoughts of the person who is doing the problem.)

\V


       \h \underline{Stating the Problem} {\em `I have to show that the error $|B-A|$ in the approximation $A\, {\approx}\,B$ is smaller than a certain given amount ${\varepsilon}\,>\,0$; that is,
        \begin{displaymath}
        |A-B|\,<\,{\varepsilon} \h ({\ast})
        \end{displaymath}
    How can I do that?'
    } % End italics

\V

\noindent Of course, any proof of such a fact must be based on what one already knows. Thus a key step in proving an inequality such as $({\ast})$ is this:


       \h \underline{Reminding Myself What I Already Know} {\em `Out of the enormous mass of mathematics that I have already learned,
    combined with the given hypotheses concerning $A$ and $B$, what facts seem relevant to the problem of showing Inequality~$({\ast})$?'
    } % End italics

\V

\noindent In real analysis the `relevant known facts' often look something like this:


        \h\underline{Relating What I Know to the Problem at Hand} {\em `Hey, in Theorem~X on Page~2348 it was proved that there are quantities $C$ and $D$ such that we know a lot about the differences $A-C$, $C-D$ and $D-B$.
    Thus, if I could somehow relate these `known' quantities to the quantity $A-B$ under study, then I might get somewhere.
    But look:
        \begin{displaymath}
        A-B \,=\, A-C+C-D+D-B \,=\, (A-C) + (C-D) +(D-B) \h ({\ast}{\ast})
        \end{displaymath}
    That is, by adding and subtracting just the right quantities, $C$ and $D$, in just the right way, and regrouping cleverly,
    I can relate the quantity of interest, $A-B$, to quantities about which I know something, namely $A-C$, $C-D$ and $D-B$.

        But wait: the problem actually asks about the magnitude $|A-B|$, not the simple difference $A-B$.
    However, I just learned about the Extended Triangle Inequality; maybe I can use that.
    Applying it to Equation~$({\ast}{\ast})$ above, I get
        \begin{displaymath}
        |A-B| \,=\, |(A-C) + (C-D) + (D-B)|\,\,{\leq}\,\,|A-C| + |C-D| + |D-C|
    \h ({\ast}{\ast}{\ast})
        \end{displaymath}
    This looks promising!'
    } % End italics

\V

\noindent The next step is easy to state:


        \underline{Reduce the Problem to Simpler Problems}
        {\em `If I can use my knowledge of the differences $A-C$, $C-D$ and $D-B$ to show that $|A-C|\,<\,{\varepsilon}/3$, $|C-D|\,<\,{\varepsilon}/3$ and $|D-B|\,<\,{\varepsilon}/3$,
    then Inequality~$({\ast}{\ast}{\ast})$ can be used to show that
        \begin{displaymath}
        |A-B|\,\,{\leq}\,\,|A-C| + |C-D| + |D-C|\,<\,\frac{{\varepsilon}}{3} + \frac{{\varepsilon}}{3}+\frac{{\varepsilon}}{3};
        \end{displaymath}
    that is, $|A-B|\,<\,{\varepsilon}$, as required.' 
    } % End of italics

        \underline{Remark} Choosing the factors of ${\varepsilon}$ above to all be $1/3$, $1/3$, $1/3$ is somewhat arbitrary.
    Any choice of factors $a$, $b$ and $c$ such that $a, b, c\,>\,0$ and $a+b+c \,=\, 1$ could work just as well.

\V

\noindent Unfortunately, in many problems completing this last step is hardest. Indeed, it may be that you {\em cannot} prove that, for example, $|A-C|\,<\,{\varepsilon}/3$:
    perhaps it is simply not true, or because \underline{you} can't figure out how to prove it (but someone else could).
    Should this occur, you may have to go back to an earlier step and try something else.
    (You don't see this happen in the proofs in textbooks, of course: authors normally don't publish their failed attempts!)

\V

        It is convenient, for future reference, to give a name to the idea outlined above,
    namely to simplify problems by adding and subtracting ingeniously chosen quantities.
    In {\TheseNotes} we use the name {\bf The Principle of Ingenious Cancellations}.
    (This definitely {\em not} standard terminology in analysis.)

\VV

        \underline{Note} The preceding discussion, and especially Equation~$({\ast}{\ast})$,
    involves repeated use of the famous `Add-and-Subtract Trick'\IndBD{principle of ingenious cancellations}{add-and-subtract trick} from high-school algebra:
    one simplifies an algebraic expression by adding and subtracting the same  quantity, then regrouping.
    In high-school algebra one also encounters a similar `Multiply-and-Divide Trick'\IndBD{principle of ingenious cancellations}{multiply-and-divide trick},
    which involves multiplying and dividing a quantity of interest by the same nonzero quantity.
    Both tricks are used extensively in analysis.
    
%}%EndFootNoteSize
%\end{quotation}
%%##

\V
\V


\V
\V

                        \section{{\bf Some Terminology and Notation Based on Order}}
                        \label{SectB25}\IndB{ZZ Sections}{\Ref{SectB25} Some Terminology Based on Order}
        
\V
\V

        The order properties of ${\RR}$ lead to frequently used terminology and notation.
    As usual, it also makes sense in a general ordered field.

\V

            \subsection{\small{\bf Definition} (Intervals in ${\RR}$; Partitions of Intervals)}
            \label{DefB20.130}

\V

        \hspace*{\parindent}(1) Let $a$ and $b$ be real numbers with $a\,<\,b$.
    A nonempty subset $I$ of ${\RR}$ is said to be a
    {\bf bounded interval in ${\RR}$ with endpoints $a$ and $b$} if $I$ equals one of the four sets $(a,b)$, $[a,b]$, $[a,b)$, $(a,b]$ given as follows:

       \h\h (i)\,\, $(a,b) \,=\, \{x{\in}{\RR}: a\,<\,x\,<\,b\}$;
        \h (ii)\, $[a,b] \,=\, \{x{\in}{\RR}: a\,\,{\leq}\,\,x\,\,{\leq}\,\,b\}$;

       \h\h (iii) $(a,b] \,=\, \{x{\in}{\RR}: a\,<\,x\,\,{\leq}\,\,b\}$;
        \h (iv) $[a,b) \,=\, \{x{\in}{\RR}: a\,\,{\leq}\,\,x\,<\,b\}$.

\noindent More precisely, the interval $(a,b)$ is the {\bf open interval with endpoints $a$ and $b$}\IndBD{intervals in ${\RR}$}{open intervals},
    while 
$[a,b]$ is the {\bf closed interval with left endpoint $a$ and right endpoint $b$}\IndBD{intervals in ${\RR}$}{closed intervals}.
    Intervals of the form $(a,b]$ or $[a,b)$ are said to be {\bf half-open} or {\bf semiopen}.


\V

        (2) A nonempty subset $J$ of ${\RR}$ is said to be an {\bf unbounded interval in ${\RR}$} if either

        \h (a) $J \,=\, {\RR}$; or

        \h (b) there exists a real number $c$ such that $J$ is one of the four sets $(-{\infty},c)$, $(-{\infty},c]$, $[c,+{\infty})$, $(c,+{\infty})$ given as follows:

\VA

        \h\h (i$'$)\,\, $(-{\infty},c) \,=\, \{x{\in}{\RR}: x\,<\,c\}$
        \h (ii$'$) $(c,+{\infty}) \,=\, \{x{\in}{\RR}: c\,<\,x\}$


        \h\h (iii$'$)\, $(-{\infty},c] \,=\, \{x{\in}{\RR}: x\,\,{\leq}\,\,c\}$
        \h (iv$'$) $[c,+{\infty}) \,=\, \{x{\in}{\RR}: c\,\,{\leq}\,\,x\}$

\VA

\noindent Unbounded intervals of the form in (i$'$) and (ii$'$) are sometimes called {\bf open half-lines};
    likewise, those of the form in (iii$'$) and (iv$'$) are called {\bf closed half-lines}.
    The point $c$ is then called {\bf the endpoint of $J$}.

        It is sometimes convenient to use the expression $(-{\infty},+{\infty})$ as alternate notation for the set ${\RR}$.

\V

        (3) A nonempty subset $I$ of ${\RR}$ is said to be an {\bf interval in ${\RR}$} provided it is either a bounded interval or an unbounded interval;
    that is, if it is one of the nine types of sets described in Parts~(1) and~(2) above.

        A real number $x$ is said to be an {\bf interior point} of an interval $I$ provided $x{\in}I$ and $x$ is not an endpoint of~$I$.
    \IndBD{intervals in ${\RR}$}{endpoints/interior points of an interval}

\V

        (4) Let $I$ be a closed bounded interval ${\RR}$; that is, $I \,=\, [a,b]$ for some real numbers $a$ and $b$ with $a\,<\,b$.
    Let $k$ be a natural number.
    A {\bf partition of the interval $I$ into $k$ subintervals}\IndB{partition}{of an interval} is set $P$, consisting of exactly $k+1$ points of $I$, such that the endpoints $a$ and $b$ are in~$P$.
    Thus, $P$ can be written in the form $P \,=\, \{a, x_{1}, x_{2}, \,{\ldots}\,,x_{k-1},b\}$.

        It is customary, although not required, that the interior points $x_{1}$, $x_{2}$,\,{\ldots}\,$x_{k-1}$ of $[a,b]$ in the set $P$ be labeled so that if $i\,<\,j$ then $x_{i}\,<\,x_{j}$.
    If that is done, then it becomes convenient to set $x_{0} \,=\, a$ and $x_{k} \,=\, b$, and to write $P \,=\, \{a \,=\, x_{0}\,<\,x_{1}\,<\,x_{2}\,<\,\,{\ldots}\,\,<\,x_{k-1}\,<\,x_{k} \,=\, b\}$.
    When this notational convention is in effect, the number $x_{j}$ is called the {\bf $j$-th partition point associated with $P$}; also, the subinterval $[x_{j-1},x_{j}]$, whose endpoints are consecutive partition points, is called the {\bf $j$-th subtinterval of $I$ determined by the partition $P$}.
    With this notation, one often writes the length $x_{j}-x_{j-1}$ of the $j$-th subinterval by ${\Delta}x_{j}$; note that ${\Delta}x_{j}\,>\,0$.
    Finally, the {\bf norm of $P$},
    also called the {\bf mesh of $P$}, is the quantity $||P||$ given by\IndC{partition}{of an interval}{norm, mesh}
        \begin{displaymath}
        ||P|| \,=\, {\max}\,\{{\Delta}x_{1},{\Delta}x_{2},\,{\ldots}\,{\Delta}x_{k}\}.
        \end{displaymath}


        A {\bf refinement of a partition $P$ of $I$}\IndC{partition}{of an interval}{refinement}
    is a partition $P'$ of $I$ such that $P' \,{\subseteq}\, P$.
        The set of all partitions of the interval $I \,=\, [a,b]$ is denoted by ${\cal P}_{I}$.



\V
\V

            \subsection{\small{\bf Examples}}
            \label{ExampB20.135}

\V

\hspace*{\parindent}(1) Suppose that $c$ is a real number and that $R\,>\,0$. Then the set of all $x$ in ${\RR}$ such that $|x-c|\,<\,R$ is an open interval.
    Indeed, by Part~(h) of Theorem~\Ref{ThmB20.65} the inequality above is equivalent to
        \begin{displaymath}
        -R\,<\,x-c\,<\,R.
        \end{displaymath}
    By adding $c$ to each term one then gets the equivalent statement
        \begin{displaymath}
        c-R\,<\,x\,<\,c+R.
        \end{displaymath}
    In other words the desired set consists precisely of the numbers $x$ in the open interval $(c-R,c+R)$.

        Similarly, the set of all $x$ in ${\RR}$ such that $|x-c|\,\,{\leq}\,\,R$ is a closed interval, namely the interval $[c-R,c+R]$.


\V

        (2) The set of all $x$ in ${\RR}$ such that $|5-2x|\,<\,3$ is an open interval in ${\RR}$.
    Indeed, by Part~(h) of Theorem~\Ref{ThmB20.65}, the inequality above is equivalent to
        \begin{displaymath}
        -3\,<\,5-2x\,<\,3.
        \end{displaymath}
    By subtracting $5$ from each term, one sees that this is equivalent to
        \begin{displaymath}
        -8\,<\,-2x\,<\,-2.
        \end{displaymath}
    Now multiply both sides by the negative quantity $-1/2$, and recall that multiplication by negative numbers reverses inequalities, to get the equivalent
        \begin{displaymath}
        1\,<\,x\,<\,4.
        \end{displaymath}
    That is, the given set is the open interval $(1,4)$.

\V

        (3) The set $A$ of all $x$ in ${\RR}$ such that $1-x^{2}\,>\,0$ is an interval in ${\RR}$.
    Indeed, it is clear that if $-1\,<\,x\,<\,1$ then $x^{2}\,<\,1$, so the given set $A$ contains the open interval $(-1,1)$ as a subset.
    Moreover, if $x$ is {\em not} in $(-1,1)$ then either $x\,\,{\geq}\,\,1$ or $x\,\,{\leq}\,\,-1$.
    In either case it is clear that $x^{2}\,\,{\geq}\,\,1$, so such $x$ cannot be in $A$.
    Thus, $A \,=\, (-1,1)$.

\V

        (4) Consider now the set $B$ of all $x$ in ${\RR}$ such that $2-x^{2}\,>\,0$.
    At first glance it would appear that an argument similar to that used in the preceeding example would show that this is also an interval in ${\RR}$, namely the open interval $(-\sqrt{2},\sqrt{2})$.
     However, this argument presupposes that there exists a real number whose square equals~$2$.
    Unfortunately, the existence of such a number does {\em not} follow from the axioms currently at our disposal;
    for example, the rational numbers also satisfy these axioms, yet there is  no rational number whose square equals~$2$.
    In other words, from the axioms given so far we cannot determine whether $B$ is an interval (i.e., whether $B$ is of one of the nine forms given above) or not.

%% EXERCISE Determine whether the set $\{x: |5-2|x||\,<\,3$ is an interval
%% using only the axioms of an ordered field.

\V
\V

        {\bf Remark} In the notations $(a,b)$ and $[a,b]$ given above for open and closed bounded intervals in ${\RR}$, it is required that $a\,<\,b$.
    This requirement is nearly universal in analysis. In particular, most text books do not permit one to write
    $(3,-1)$ as an alternate notation for the open interval $(-1,3)$, even though the meaning seems clear.
    Likewise, most texts do not allow one to write, for instance, $[2,2]$ as a shorthand for $\{x{\in}{\RR}: 2\,\,{\leq}\,\,x\,\,{\leq}\,\,2\}$,
    i.e., for the singleton set $\{2\}$.

        These notational restrictions can be annoying. For example, suppose that one is studying a real-valued function $f:[2,5] \,{\rightarrow}\, {\RR}$
    defined on the closed interval $[2,5]$.
    Then it would be natural to ask about the `interval' whose endpoints are $f(2)$ and $f(5)$.
    However, it is possible that one might have $f(2) \,=\, f(5)$, in which case the `interval with endpoints $f(2)$ and $f(5)$' would be a `degenerate' interval consisting of a single point, namely the common value of $f(2)$ and $f(5)$.
    Or, it could be that $f(2)\,>\,f(5)$, so that there is an honest interval with endpoints $f(2)$ and $f(5)$, but in this case it should be denoted $[f(5),f(2)]$.
    Unfortunately, it often happens that one does not actually know the values of $f(2)$ or $f(5)$.

        It turns out that there is a simple solution which does not require violating the `$a\,<\,b$' requirement for intervals.

\V

            \subsection{\small{\bf Definition} (Segments in ${\RR}$)}
            \label{DefB20.140}

\V

        Let $a$ and $b$ be real numbers.

\V

        (1) The {\bf segment in ${\RR}$}\IndA{segments in ${\RR}$} determined by the numbers $a$ and $b$ is the set $\mbox{Seg}\,[a,b]$
    consisting of all real numbers $x$ such that either $a\,\,{\leq}\,\,x\,\,{\leq}\,\,b$ or $b\,\,{\leq}\,\,x\,\,{\leq}\,\,a$.
    The numbers $a$ and $b$ are called the {\bf endpoints of the segment $\mbox{Seg}\,\Bfm{[a,b]}$};
    note that if $a \,=\, b$ then the segment has only one endpoint. An element $x$ of the segment
    $\mbox{Seg}\,[a,b]$ is said to be {\bf weakly between $\Bfm{a}$ and~$\Bfm{b}$}\IndA{weak betweenness}.
    (`Weakly' because one allows the possibility that $x \,=\, a$ or $x \,=\, b$.)

\V

        (2) Suppose that $a \,\,{\neq}\,\, b$, so that either $a\,<\,b$ or $b\,<\,a$.
    Then any number $x$ such that $a\,<\,x\,<\,b$ or $b\,<\,x\,<\,a$, depending on whether $a\,<\,b$ or $b\,<\,a$,
    is called an {\bf interior point of the segment $\mbox{Seg}\,\Bfm{[a,b]}$}. Such points are said to be
    {\bf strictly between the endpoints $a$ and $b$}.\IndA{strictly between}

\V

        (3) If the endpoints of a segment are the numbers $a$ and $b$, then the {\bf length}\IndBD{segments in ${\RR}$}{length of a segment in ${\RR}$}
    is the number~$|b-a|$; equivalently, $|a-b|$.

\VV

        {\bf Remarks} (1) The definition of `segment' extends the concept of `closed bounded interval'.
    One could similarly extend the concepts of `open interval', `half-open interval' and `unbounded interval' as well,
    but we do not do so, since there is no need in {\ThisText} for those extensions.

\V

        (2) It is a simple exercise to show that every interval in an ordered field is a convex set.

\V
\V

        The following theorem list some basic facts about segments in ${\RR}$.

\V

            \subsection{\small{\bf Theorem}}
            \label{ThmB20.150}

\V

        Suppose that $a$ and $b$ are real numbers.

\V

        (a) For each real number $c$ one has $\mbox{Seg}\,[c,c] \,=\, \{c\}$.


\V

        (b) If $a\,<\,b$ then $\mbox{Seg}\,[a,b]$ equals the closed interval $[a,b]$, while if $b\,<\,a$, then $\mbox{Seg}\,[a,b] \,=\, [b,a]$.
    More concisely, if $a \,\,{\neq}\,\, b$ then
        \begin{equation}
        \label{EqnB.75}
        \mbox{Seg}\,[a,b] \,=\, [\min\{a,b\},\max\{a,b\}].
        \end{equation}

\V

        (c) For every pair of real numbers $a$ and $b$, equal or not, one has $\mbox{Seg}\,[a,b] \,=\, \mbox{Seg}\,[b,a]$.
    In other words, the order in which one writes down the numbers $a$ and $b$ does not affect the resulting segment.


\V


        (d) A necessary and sufficient condition for $x$ to be an element of $\mbox{Seg}\,[a,b]$ is that $|x-a|+|b-x| \,=\, |b-a|$.


\V

        {\bf Partial Proof}

\V

        The proofs of Parts (a), (b), and (c) are left as simple exercises.

\V

        Proof of (d): Note first that for {\em every} real $x$ one has $b-a \,=\, (x-a) + (b-x)$.
    Thus, by Part~(2) of Theorem~\Ref{ThmB20.65}, the Triangle Inequality, one has
        \begin{displaymath}
        |x-a| + |b-x|\,\,{\leq}\,\,|b-a| \h ({\ast})
        \end{displaymath}
    with equality in $({\ast})$ if, and only if, the numbers $x-a$ and $b-x$ are either both nonnegative or both nonpositive.

        Suppose first that $x{\in}\mbox{Seg}\,[a,b]$; then either $a\,\,{\leq}\,\,x\,\,{\leq}\,\,b$ or $b\,\,{\leq}\,\,x\,\,{\leq}\,\,a$.
    In the first case $x-a$ and $b-x$ are both nonnegative, while in the second case $x-a$ and $b-x$ are both nonpositive.
    In either case, the conditions for equality in~$({\ast})$ are satisfied, so the desired equation holds.

        Conversely, suppose that the desired equation holds, and thus one gets equality in~$({\ast})$.
    It then follows, by reversing the previous argument, that $x{\in}\mbox{Seg}\,[a,b]$, as required.

%% INCLUDE THESE PROOFS AS EXERCISES

\VV

            \subsection{\small{\bf Corollary}}
            \label{CorB20.150A}
\V

        Suppose that $a$ and $b$ are real numbers. Then a necessary and sufficient condition for a number $x$
    to be an element of $\mbox{Seg}\,[a,b]$ is that there exist a number $t$ in the closed interval $[0,1]$ such that
        \begin{displaymath}
        x \,=\, t\,a + (1-t)\,b \h ({\ast})
        \end{displaymath}

\V

        {\bf Proof} Suppose that Equation $({\ast})$ holds for some $t$ in $[0,1]$.
    Using the fact that $t\,\,{\geq}\,\,0$ and $1-t\,\,{\geq}\,\,0$, together with the usual order properties, one easily computes that
        \begin{displaymath}
        |x-a| + |b-x| \,=\, |(t\,a + (1-t)\,b) - a| + |b - ((t\,a) + (1-t)\,b)|
     \,=\, 
        |(1-t)\,(b-a)| + |t\,(b-a)|
     \,=\, 
        (1-t)\,|b-a| + t\,|b-a| \,=\, |b-a|
        \end{displaymath}
    It follows from Part~(d) of the preceding theorem that $x{\in}\mbox{Seg}\,[a,b]$.

        Conversely, suppose that $x{\in}\mbox{Seg}\,[a,b]$. If $x \,=\, a$, then clearly $x \,=\, 1{\cdot}a + (1-1){\cdot}b$,
    which is Equation~$({\ast})$ with $t \,=\, 1$. Likewise, the case $x \,=\, b$ corresponds to $t \,=\, 0$ in Equation~$({\ast})$.
    Finally, suppose that $x$ is an interior point of $\mbox{Seg}\,[a,b]$, so that $|x-a|\,>\,0$, $|b-x|\,>\,0$, and of course $|b-a|\,>\,0$.
    As is pointed out in the proof of Theorem~\Ref{ThmB20.150}, the nonzero quantities $x-a$, $b-x$ and $b-a$ must all be of the same sign.
    Thus, if one sets $t \,=\, (b-x)/(b-a)$, then $t\,>\,0$ and $1-t \,=\, (x-a)/(b-a)\,>\,0$, so $0\,<\,t\,<\,1$.
    It is a straight-forward calculation to verify that $x \,=\, t\,a + (1-t)\,b$.

\VV

           \subsection{\small{\bf Remarks}}
            \label{RemrkB20.150B}
\V

\hspace*{\parindent}(1) Many authors use the results of the preceding corollary as the {\em definition} of `segment'.
    One major advantage is that it makes sense in Euclidean spaces of arbitrary dimension, where there is no natural concept of `order'.
    In contrast, our Definition~\Ref{DefB20.140} uses strongly the concept of `order' that is valid in ${\RR}$, and thus is easier to use in that context.

\V


        (2) The case $t \,=\, 1/2$ in the preceding corollary is important enough to have its own terminology.
    Indeed, when $t \,=\, 1/2$ one has $x \,=\, t\,a + (1-t)\,b \,=\, (a+b)/2$. This point is called the
    {\bf midpoint of $\mbox{Seg}\,[a,b]$}.\IndBD{segments in ${\RR}$}{midpoint of a segment in ${\RR}$}.
    It follows easily from the preceding corollary that if $x$ is the midpoint of $\mbox{Seg}\,[a,b]$,
    then $x{\in}\mbox{Seg}\,[a,b]$ and $|x-a| \,=\, |b-x| \,=\, |b-a|/2$. Speaking geometrically,
    the distance of the midpoint from either endpoint equals half the length of the segment. (Of course if $a \,=\, b$, then all three points coincide.)

\V


            \subsection{\small{\bf Definition} (Convex Sets in ${\RR}$)}
            \label{DefB20.155A}
\V

        A nonempty subset $X$ of ${\RR}$ is said to be {\bf convex}\IndA{convex subsets of ${\RR}$} if, for every pair of points $x$ and $y$ in $X$,
    one has $\mbox{Seg}\,[x,y] \,{\subseteq}\, X$; that is, if $x$ and $y$ are in $X$ then so is every number that is weakly between $x$ and~$y$.

\V



            \subsection{\small{\bf Examples}}
            \label{ExampB20.155B}

\V

        (1) Every singleton subset $\{c\}$ of ${\RR}$ is a convex set in~${\RR}$. Indeed, $\{c\} \,=\, \mbox{Seg}\,[c,c]$.

\V

        (2) It is easy to see that every interval in ${\RR}$, whether closed, open, bounded or unbounded, is a convex subset, as is every segment in ${\RR}$.

\V

        The question of whether there are any other convex subsets of ${\RR}$ cannot be answered using only the algebra and order axioms.
    Indeed, in the ordered field ${\QQ}$ let $S$ be the set of all (rational) numbers $x$ such that $x^{2}\,\,{\leq}\,\,2$.
    It is easy to see that this set is bounded in ${\QQ}$; for example, if $x{\in}S$, then clearly $|x|\,<\,4$.
    Nevertheless, it can be shown that this set is not an interval or segment in~${\QQ}$.
    A full treatment of this question requires use of the `Completeness' property of the real numbers; see Theorem~\Ref{ThmB30.160}.

\V
\V

        {\bf Functions Which Preserve the Order}

\V

        The presence of the order relation on ${\RR}$ makes it natural to single out those real-valued functions that, in some sense, `preserve' the order.

\V

            \subsection{\small{\bf Definition}}
            \label{DefB20.160}\IndBD{functions}{increasing/decreasing/monotonic functions}
    \IndBD{functions}{strictly increasing/decreasing/monotonic functions}

\V

        Let $f:X \,{\rightarrow}\, {\RR}$ be a real-valued function defined on a nonempty subset $X$ of ${\RR}$.
    (The set $X$ need not be the full domain of the function $f$.)

\V

        (1) One says that $f$ is {\bf strictly increasing on $X$} provided that, for each pair of elements $x_{1}$ and $x_{2}$ in $X$ with $x_{1}\,<\,x_{2}$,
    one has $f(x_{1})\,<\,f(x_{2})$. Likewise, one says that $f$ is {\bf nondecreasing on $X$},
    or that $f$ is {\bf monotonic up on $X$}, provided that for each pair of elements $x_{1}$ and $x_{2}$ in $X$ with $x_{1}\,<\,x_{2}$ one has $f(x_{1})\,\,{\leq}\,\,f(x_{2})$.

\V

        (2) One says that $f$ is {\bf strictly decreasing on $X$} provided that, for each pair of elements $x_{1}$ and $x_{2}$ in $X$ with $x_{1}\,<\,x_{2}$,
    one has $f(x_{1})\,>\,f(x_{2})$. Likewise, one says that $f$ is {\bf nonincreasing on $X$}, or that $f$ is {\bf monotonic down on $X$},
    provided that for each pair of elements $x_{1}$ and $x_{2}$ in $X$ with $x_{1}\,<\,x_{2}$ one has $f(x_{1})\,\,{\geq}\,\,f(x_{2})$.

\V

        (3) One says that $f$ is {\bf monotonic on $X$} if either $f$ is monotonic up on $X$ or $f$ is monotonic down on $X$.
    Likewise, one says $f$ is {\bf strictly monotonic on $X$} if either $f$ is strictly increasing on $X$ or $f$ is strictly decreasing on $X$.

\V

%%%
\begin{quotation}
{\footnotesize \underline{\Note}\IndB{\notes}{on the `increasing/decreasing' terminology } (on the `increasing/decreasing' terminology)
\hspace*{\parindent}(1) Many authors use the words `increasing' and `decreasing' to mean the same as the phrases `strictly increasing' and `strictly decreasing', 
    respectively, found in the preceding definition. Unfortunately, many other authors use the words `increasing' and `decreasing'
    to mean the same as the words `nondecreasing' and `nonincreasing', respectively.
    This conflict of usage can easily cause confusion, especially if the author neglects to make clear which usage is intended.

\V

        (2) In contrast, the meanings given here of the words `nondecreasing' and `nonincreasing' are standard;
    there appears to be no disagreement among authors. However, students often find these terms confusing.
    The main reason may be because the statement `$f$ is a nondecreasing function on $X$'
    does {\em not} mean the same as `$f$ is not a decreasing function on $X$'.
    For example, consider the `squaring function' $f:{\RR} \,{\rightarrow}\, {\RR}$, given by the rule $f(x) \,=\, x^{2}$ for all $x$ in ${\RR}$.
    This function is certainly not a decreasing function on ${\RR}$; for instance, $0\,<\,1$ but $f(0)\,<\,f(1)$.
    However, it is also not a nondecreasing function on ${\RR}$, since $f(-1)\,>\,f(0)$.

        A second source of this confusion may be that the word `nondecreasing' involves both `non' --
    a negative word -- and `decreasing' -- a word which connotes, roughly speaking,
    `becoming less' -- to describe a concept which tries to indicate `getting larger': that is, it is a type of `cognitive dissonance'.

\V

        (3) In {\TheseNotes} we generally use the terminology with the least ambiguity:
    strictly increasing and strictly decreasing; monotonic up and monotonic down.
    On occasion we may use the `nonincreasing/nondecreasing' terminology, mainly to remind reader that these words do appear in the mathematical literature.
}%EndFootNoteSize
\end{quotation}
%##


\V
\V


      The concepts of `strictly increasing/decreasing' and `monotonic up/down' also apply to sequences of real numbers;
    indeed, they correspond to the case $X \,=\, {\NN}$.
    It is convenient, however, to repeat the definitions in the context of sequences since the custom is to write the functions values using subscripts.

\V

            \subsection{\small{\bf Definition}}
            \label{DefB20.180}\IndBD{sequences}{increasing/decreasing/monotonic sequences}
    \IndBD{sequences}{strictly increasing/decreasing/monotonic sequences}

\V

        Let ${\xi} \,=\, (x_{1},x_{2},\,{\ldots}\,)$ be an infinite sequence of real numbers.

\V

        (1) One says that ${\xi}$ is a {\bf strictly increasing sequence} provided $x_{k+1}\,>\,x_{k}$ for each $k$ in ${\NN}$.
    It is said to be a {\bf monotonic-up sequence} provided $x_{k+1}\,\,{\geq}\,\,x_{k}$ for each $k$ in ${\NN}$.

\V

        (2) One says that ${\xi}$ is a {\bf strictly decreasing sequence} provided $x_{k+1}\,<\,x_{k}$ for each $k$ in ${\NN}$.
    It is said to be a {\bf monotonic-down sequence} provided $x_{k+1}\,\,{\leq}\,\,x_{k}$ for each $k$ in ${\NN}$.

\V

        (3) One says that ${\xi}$ is a {\bf monotonic sequence} if either it is monotonic up or it is monotonic down.
    Likewise, it is said to be a {\bf strictly monotonic sequence} if either it is strictly increasing or strictly decreasing.

\V

        (4) The sequence ${\xi}$ is said to be {\bf eventually strictly increasing} provided there exists $M$ in ${\RR}$ such that $x_{k+1}\,>\,x_{k}$ for all $k\,\,{\geq}\,\,M$.
    The concepts of `eventually monotonic up', `eventually strictly decreasing' `eventually monotonic down', `eventually monotonic' and `eventually strictly monotonic' are defined in an analogous manner.\IndC{sequences}{sequence which is eventually}{monotonic}


\V
\V

            \subsection{\small{\bf Examples}}
            \label{ExampB20.190}

\V

\hspace*{\parindent}(1) A constant sequence is both monotonic up and monotonic down.

\V

        (2) Let ${\xi} \,=\, (x_{1},x_{2},\,{\ldots}\,)$ be the sequence given by the rule
        \begin{displaymath}
        x_{k} \,=\, k(k-3)(k-6) \mbox{ for each $k$ in ${\NN}$}.
        \end{displaymath}
    Clearly $x_{1} \,=\, 10$, $x_{2} \,=\, 8$, $x_{3} \,=\, 0$, $x_{4} \,=\, -8$, $x_{5} \,=\, -10$, $x_{6} \,=\, 0$;
    in particular, the sequence ${\xi}$ is neither monotonic up nor montonic down.
    It is left as an exercise to verify that if $k\,\,{\geq}\,\,6$ then $x_{k+1}\,>\,x_{k}$;
    that is, the sequence ${\xi}$ is {\em eventually} strictly increasing.

%% EXERCISE Write preceding $x_{k}$ as $x_{k} \,=\, k^{3} - 9k + 18$, and ask
%%  them to do the same analysis. But don't mention that it's the same x_{k}

\V

        (3) Let ${\tau} \,=\, (t_{1},t_{2},\,{\ldots}\,)$ be given by the rule
        \begin{displaymath}
        t_{k} \,=\, \frac{1+(-1)^{k}}{k}.
        \end{displaymath}
    It is easy to see that this sequence is not eventually monotonic.



\V
\V

        The simple concepts of `bounded' and `unbounded' subsets of ${\RR}$ are important in analysis.

            \subsection{\small{\bf Definition}}
            \label{DefB20.195A}\IndB{bounded, unbounded}{subsets of ${\RR}$}
    \IndB{bounded, unbounded}{unbounded}

        Let $A$ be a subset of ${\RR}$.

\V

        (1) A real number $M$ is said to be an {\bf upper bound of $A$}\IndBD{bounded, unbounded}{upper bound of a set} if $M\,\,{\geq}\,\,x$ for all $x$ in $A$;
    equivalently, if there does {\em not} exist $x{\in}A$ such that $x\,>\,M$. Likewise, a real number $m$ is said to be a {\bf lower bound of $A$}
    \IndBD{bounded, unbounded}{lower bound of a set} if $m\,\,{\leq}\,\,x$ for all $x$ in $A$; equivalently, if there does {\em not} exist $x{\in}A$ such that $x\,<\,m$.


\V

        (2) The set $A$ is said to be {\bf bounded above}\IndBD{bounded, unbounded}{set is bounded above, bounded on the right},
    or sometimes {\bf bounded on the right}, if $A$ has an upper bound. If no such upper bound exists, then $A$ is said to be {\bf unbounded above},
    or {\bf unbounded on the right}\IndBD{bounded, unbounded}{set is unbounded above, unbounded on the right}

        Similarly, the set $A$ is said to be {\bf bounded below}, or {\bf bounded on the left}, if $A$ has a lower bound.\IndBD{bounded, unbounded}
    {set is bounded below, bounded on the left} If no such lower bound exists then
    $A$ is said to be {\bf unbounded below}\IndBD{bounded, unbounded}{set is unbounded below, unbounded on the left} or {\bf unbounded on the left}.

        {\bf Remark} The `on the right' and `on the left' phrasing corresponds to the standard geometric interpretation of the set ${\RR}$ as a horizontal straight line
    with negative numbers to the left of $0$ and positive numbers to the right.

\V

        (3) A subset $A$ of ${\RR}$ is said to be a {\bf bounded set in ${\RR}$}\IndB{bounded, unbounded}{bounded/unbounded subsets of ${\RR}$}
    if it is bounded above and bounded below; equivalently, there exist real numbers $m$ and $M$ such that $m\,\,{\leq}\,\,x\,\,{\leq}\,\,M$ for every $x$ in~$A$.
    If $A$ is not a bounded set then $A$ is said to be an {\bf unbounded set}.


\V

        (4) Let $f:X \,{\rightarrow}\, {\RR}$ be a real-valued function defined on a nonempty set $X$.
    \IndB{bounded, unbounded}{bounded, unbounded real-valued functions} Let $A \,=\, f[X]$ denote the image of $X$ under $f$;
    that is, $A \,=\, \{y{\in}{\RR}: y \,=\, f(x) \mbox{ for at least one $x$ in $X$}\}$.
    One says that the function $f$ is {\bf bounded above on $X$} provided the set $A$ is bounded above, in the sense of Part~(2) above.
    Likewise, $f$ is said to be {\bf bounded below on $X$} if $A$ is bounded below.
    Finally, $f$ is said to be {\bf bounded on $X$} if $A$ is a bounded set, in the sense of Part~(3).

\VV

        The next result is simple, and `obviously true'. It is included mainly for future reference.

\V

            \subsection{\small{\bf Theorem}}
            \label{ThmB20.195B}

\V

        Let $A$ be a subset of ${\RR}$.

\V

        (a) If $A$ is a finite set, then $A$ is is bounded in ${\RR}$.

\V

        (b) If $A$ is bounded above in ${\RR}$, then every subset of $A$ is bounded above in~${\RR}$.

\V

        (c) Suppose that $A$ can be expressed as the finite union $A \,=\, A_{1}\,{\cup}\,A_{2}\,{\cup}\,\,{\ldots}\,\,{\cup}\,A_{n}$ of subsets of~$A$.
    If each of these subsets is bounded above in~${\RR}$, then $A$ is bounded above in~${\RR}$.

\V

        (d) Let $f:X \,{\rightarrow}\, {\RR}$ be a real-valued function defined on a nonempty set $X$.
    Suppose that $X$ can be expressed as the finite union $X \,=\, X_{1}\,{\cup}\,X_{2}\,{\cup}\,\,{\ldots}\,\,{\cup}\,X_{n}$ of subsets of~$X$.
    If $f$ is bounded above in ${\RR}$ on each of the subsets $X_{1}$, $X_{2}$,\,{\ldots}\,$X_{n}$, then $f$ is bounded above in ${\RR}$ on~$X$.

\V

        (e) If, in Parts~(b), (c) and~(d) above, each occurance of `bounded above' is replaced by `bounded below', then the resulting statements are true.
    Likewise, if each such occurance is replaced by `bounded', then the resulting statements are true.

\V

        The simple proof is left as an exercise. %% EXERCISE

\V

                    \subsection{\small{{\bf Remarks}}}
                    \label{RemrkB20.195BB}

\V

\hspace*{\parindent} (1) The phrasing used in Part~(1) of the preceding definition makes it clear that if $A \,=\, {\emptyset}$, then {\em every} real number $M$ is an upper bound of $A$.
    Indeed, the `equivalent' formulation given there of $M$ being an upper bound of $A$ is that there not exist $x$ in $A$ with a given property,
    namely that $x\,>\,M$. But if $A \,=\, {\emptyset}$, then there does not exist $x$ in $A$, with or without the given property, so $M$ is an upper bound of~$A$.
    A similar argument shows that if $A \,=\, {\emptyset}$, then {\em every} real number $m$ is a lower bound of $A$. In particular, the empty set is a bounded subset of~${\RR}$.

\V

        (2) Some authors phrase the definition of a set $A$ being a bounded subset of ${\RR}$ as follows: There exists a real number $B\,\,{\geq}\,\,0$ such that $|x|\,\,{\leq}\,\,B$ for every $x$ in~$A$.
    The proof that this is equivalent to the definition given above is left as a simple exercise. % EXERCISE


\VV


            \subsection{\small{\bf Corollary}}
            \label{CorB20.195C}

\V

\hspace*{\parindent} (a) Let $A$ be a subset of ${\RR}$, and suppose that
    $B$ is a subset of $A$ such that $A\,{\setminus}\,B$ is a finite set. If $B$ is bounded above in ${\RR}$, or $B$ is bounded below in~${\RR}$, or $B$ is bounded in~${\RR}$,
    then $A$ has the corresponding boundedness property.

        (b) Likewise, let $f:X \,{\rightarrow}\, {\RR}$ be a real-valued function defined on a nonempty set~$X$.
    Suppose that there exists a subset $Y$ of $X$ such that $X\,{\setminus}\,Y$ is a finite set.
    If $f$ is bounded above in ${\RR}$ on~$Y$, or $f$ is bounded below in~${\RR}$ on~$Y$, or $f$ is bounded in~${\RR}$ on~$Y$,
    in the sense of Part~(4) of Definition~\Ref{DefB20.195A} above, then $f$ has the corresponding boundedness property on~$X$.

\V

        {\bf Proof} (a) This follows using Parts~(c), (d) and~(e) of the preceding theorem 
by noting that $A \,=\, B\,{\cup}\,(A\,{\setminus}\,B)$.

\V

        (b) This follows easily from Part~(a).


\VV



        Part~(4) of Definition~\Ref{DefB20.195A} includes the special case $X \,=\, {\NN}$; that is, the case of sequences of real numbers.
    \IndB{bounded, unbounded}{bounded, unbounded sequences of real numbers} The following result
    often simplifies the determination of whether a given real sequence is has one of the `boundedness' properties.

\V

            \subsection{\small{\bf Theorem}}
            \label{ThmB30.15}

\V

        Let ${\xi} \,=\, (x_{1}, x_{2},\,{\ldots}\,x_{k},\,{\ldots}\,)$ be a sequence of real numbers.

\V

        (a) A necessary and sufficient condition for the sequence ${\xi}$ to be bounded above is that there exist a real number $M$ such that
        \begin{displaymath}
        x_{k}\,\,{\leq}\,\,M \mbox{ for all but finitely many values of the index~$k$};
        \end{displaymath}
    equivalently, the sequence is eventually bounded above by~$M$.
    Similarly, a necessary and sufficient condition for the sequence ${\xi}$ to be bounded below is that there exist a real number $m$ such that
        \begin{displaymath}
        x_{k}\,\,{\geq}\,\,m \mbox{ for all but finitely many values of the index~$k$};
        \end{displaymath}
    equivalently, the sequence is eventually bounded below by $m$.

\V

        (b) A necessary and sufficient condition for ${\xi}$ to be a bounded sequence (i.e., to be bounded above and below)
    is that there exist a real number $M\,>\,0$ such that $|x_{k}|\,\,{\leq}\,\,M$ for all but finitely many values of~$k$.

\V

        {\bf Proof} (a) This follows directly from Part~(b) of Corollary~\Ref{CorB20.195C}.

        \V

        (b) See Part (b) of Remark~\Ref{RemrkB20.195BB} above.

\VV


        \underline{Notation}: In {\TheseNotes} it convenient to denote the set of all upper bounds of a nonempty subset $A$ of ${\RR}$ by the symbol $U_{A}$.
    Likewise the set of all lower bounds is denoted $L_{A}$.\IndB{bounded, unbounded}{notations $U_{A}$, $L_{A}$}
    (This notation is not standard in mathematics.)
    Then stating that $A$ bounded above is equivalent to the statement $U_{A} \,\,{\neq}\,\, {\emptyset}$, and similarly for `bounded below'.

\V
\V

            \subsection{\small{\bf Examples}}
            \label{ExampB30.20}

\V

\hspace*{\parindent}(1) Let $a$ and $b$ be real numbers such that $a\,<\,b$.
    Then the closed interval $[a,b]$ and the open interval $(a,b)$ are both bounded sets.
    Indeed, for each set it is clear that $a$ is a lower bound and $b$ an upper bound.

        Note that $U_{[a,b]} \,=\, U_{(a,b)} \,=\, [b,+{\infty})$;
likewise, $L_{[a,b]} \,=\, L_{(a,b)} \,=\, (-{\infty},a]$.
    In particular, the number $b$ is simultaneously the right-hand endpoint of each of the sets $[a,b]$ and $(a,b)$,
    and the least element of the upper bounds of the sets $[a,b]$ and $(a,b)$.
    Similarly, the number $a$ is simultanously the left-hand endpoint and the greatest of the lower bounds for the sets $([a,b])$ and $(a,b)$.

\V

        (2) The set ${\RR}^{+}$ of all positive real numbers is bounded below but unbounded above.
    Indeed, it is clear that $0$ is a lower bound for ${\RR}$.
    In contrast, there is no upper bound for ${\RR}^{+}$; for if $M$ were such a number then one would have $M\,\,{\geq}\,\,x$ for all $x$ in ${\RR}^{+}$.
    In particular one would have $M\,\,{\geq}\,\,M+1$, which is impossible.
    But then $M+1$ would also be in ${\RR}^{+}$, so that $M$ would have to satisfy $M\,\,{\geq}\,\,M+1$, which is impossible.

        Note that $U_{{\RR}^{+}} \,=\, {\emptyset}$ while $L_{{\RR}^{+}} \,=\, (-{\infty},0]$.

\V

        (3) The set ${\NN}$ of all natural numbers, viewed as a subset of~${\RR}$, is bounded below.
    Indeed, it is clear that $L_{{\NN}}$ is the interval $(-{\infty},1]$. In contrast,
    the axioms for an ordered field are not enough to guarantee that the subset ${\NN}$ of ${\RR}$ is unbounded above in~${\RR}$.

\VV

        The condition for a subset of ${\RR}$ to be a bounded set is frequently described in the following equivalent ways.

\V

            \subsection{\small{\bf Theorem}}
            \label{ThmB30.25}

\VV

\hspace*{\parindent} (a) A necessary and sufficient condition for a nonempty subset $A$ of ${\RR}$ to be a bounded set in ${\RR}$
    is that there exist a nonnegative real number $B$ such that $|x|\,\,{\leq}\,\,B$ for all $x$ in~$A$.

\V

        (b) A necessary and sufficient condition for a nonempty subset $A$ of ${\RR}$ to be a bounded set in ${\RR}$
    is that there exist a real number $c$ and a nonnegative real number $B$ such that $|x-c|\,\,{\leq}\,\,B$ for all $x$ in~$A$.

        Equivalently, a necessary and sufficient condition for a nonempty subset $A$ of ${\RR}$ to be a bounded set in ${\RR}$
    is that for {\em every} real number $c$ there exist a nonnegative real number $B$ such that $|x-c|\,\,{\leq}\,\,B$ for all $x$ in~$A$.

\V

        The simple proof is left as an exercise. % EXERCISE?

\V

%%%
\begin{quotation}
{\footnotesize \underline{\Note}\IndB{\notes}{on complicated definitions} (on complicated definitions) The conditions stated in Part~(b) of the preceding theorem may seem strange.
    However, these formulations of the concept of `bounded subset of ${\RR}$' have a major advantage which is invisible in the context of the main body of {\ThisText}:
    they easily extend to the much more general context of `bounded subsets of a metric space'.
    (`Metric space' is an important concept from advanced analysis; it is not needed for {\ThisText}.)

        It happens frequently in mathematical writing that an author chooses a more complicated formulation of a concept,
    in preference to a version which is simpler or more intuitive, because the complicated version extends more easily to a more general context.
    Whether such a choice is pedagogically wise depends on the circumstances.
}%EndFootNoteSize
\end{quotation}
%##

\VV

        The concept of a subset of ${\RR}$ being `bounded above' or `bounded below' gives rise to some natural questions:

        Suppose that $A$ is a nonempty subset of ${\RR}$ such that $A$ is bounded above.
    Does $A$ have a `maximum element'? Likewise, if $A$ is bounded below, does $A$ have a `minimum element'?

\noindent The study of these questions gives rise to some concepts that play an important role in analysis.


\V
\V

            \subsection{\small{\bf Definition}}
            \label{DefB30.60}

        Let $A$ be a nonempty subset of ${\RR}$.

\V

        (a) A real number $M$ is said to be  {\bf the maximum element of $A$}\IndBD{maximum, minimum}{maximum element}, and one writes $M \,=\, \max\,A$, provided $M$ satisfies the following conditions:


        \h (i) $M$ is an element of $A$.

        \h (ii) If $x{\in}A$, then $x\,\,{\leq}\,\,M$.

\noindent In other words, $M$ is an upper bound of the set $A$ which is also an element of~$A$.

\V

        (b) Likewise, a real number $m$ is said to be {\bf the minimum element of $A$}\IndBD{maximum, minimum}{minimum element},
    and one writes $m \,=\, \min\,A$, provided $m$ satisfies the following conditions:


        \h (i') $m$ is an element of $A$.

        \h (ii') If $x{\in}A$, then $x\,\,{\geq}\,\,m$.

\noindent In other words, $m$ is a lower bound of the set $A$ which is also an element of~$A$.

\V

        (c) \underline{Important Special Case}:\IndBD{functions}{maximum value of a function on a set}\IndBD{functions}{minimum value of a function on a set}
    Suppose that $f:X \,{\rightarrow}\, {\RR}$ is a real-valued function defined on a nonempty set~$X$, and let $A \,=\, f[X]$; see Definition~\Ref{DefA30.15}. 
    If the set $A$ has maximum element $M$ then one calls $M$ the {\bf maximum value of the function $\Bfm{f}$ on the set $\Bfm{X}$}.
    Similarly, if $A$ has minimum element $m$ then one calls $m$ the {\bf minimum value of the function $\Bfm{f}$ on the set $\Bfm{X}$}.
    The numbers $M$ and $m$ are called the {\bf extreme values of $\Bfm{f}$ on~$\Bfm{X}$}.\IndBD{functions}{extreme values of a function on a set}

        Since the minimum and maximum values $m$ and $M$ decribed above are actual {\em values} of $f$ on the set~$X$,
    there must exist at least one element $c$ of $X$ such that $f(c) \,=\, m$, and at least one element $d$ of $X$ such that $f(d) \,=\, M$.
    One then says that {\bf $\Bfm{f}$ assumes its maximum value for $\Bfm{X}$ at~$\Bfm{c}$, and it assumes its minimum value for $\Bfm{X}$ at $\Bfm{d}$}.
    \IndBD{functions}{assumes maximum, minimum values for a set}.
    Likewise, one says that {\bf \Bfm{f} has a local minimum at $\Bfm{c}$} provided 
    there is an open interval $I$ containing $c$ such that $f$ has its minimum value for the set $X\,{\cap}\,I$ at~$c$.
    The concept of {\bf local maximum} is defined similarly.\IndBD{functions}{local minimum, local maximum of a function}.

\VV

            \subsection{\small{\bf Remarks}}
            \label{RemrkB30.70}

\V

\hspace*{\parindent} (1) Conditions (ii) and (ii') are obviously equivalent to the following conditions:

        \h Modified (ii) If $x{\in}A$ and $x \,\,{\neq}\,\, M$, then $x\,<\,M$.

        \h Modified (ii') If $x{\in}A$ and $x \,\,{\neq}\,\, m$, then $x\,>\,m$.

\noindent Although these formulations may come closer to the intuitive concept of $M$ being bigger (or $m$ being smaller) than every other number in the set,
    the original formulation turns out to be easier to use in practice.

\V

      (2) It is clear from the order properties that a nonempty subset can have at most one maximum and at most one minimum,
    so the use of the word `the' in the phrases `{\em the} maximum element' and `{\em the} minimum element' is justified.
    For example, if $M_{1}$ and $M_{2}$ are elements of $A$ such that $M_{1} \,\,{\neq}\,\, M_{2}$,
    then the smaller of these numbers cannot also satisfy Condition~(ii).
    Of course there are many bounded nonempty subsets of ${\RR}$ which have neither a maximum element nor a minimum element; see the examples below.

\V

        (3) It is incorrect to write statements such as $\max\,({\RR}) \,=\, +{\infty}$ or $\min\,({\RR}) \,=\, -{\infty}$.
    By definition, the max and min of a set $A$ of real numbers must be elements of that set;
    but $+{\infty}$ and $-{\infty}$ are not real numbers and thus can't be elements of the set~$A$.

\V

        (4) Suppose that the set $A$ is a finite set, so that $A \,=\, \{x_{1}, x_{2}, \,{\ldots}\,x_{n}\}$
    for some numbers $x_{1}$, $x_{2}$,\,{\ldots}\,$x_{n}$. Then one often writes $\max\,\{x_{1}, x_{2},\,{\ldots}\,x_{n}\}$
    in place of~$\max\,A$, and $\min\,\{x_{1}, x_{2},\,{\ldots}\,x_{n}\}$ in place of~$\min\,A$.

\V

        (5) On occasion one uses the words `greatest' or `largest' instead of `maximum'; likewise, one uses `least' or `smallest' instead of `minimum'.

\V


\V
\V

            \subsection{\small{\bf Examples}}
            \label{ExampB30.80}

\V

\hspace*{\parindent}(1) Let $a$ and $b$ be real numbers with $a\,<\,b$, and let $A$ be the closed interval $[a,b]$ in~${\RR}$.
    Thus $A \,=\, \{x{\in}{\RR}: a\,\,{\leq}\,\,x\,\,{\leq}\,\,b\}$.
    Clearly $b$ satisfies Condition~(i) of Definition~\Ref{DefB30.60}, since $x \,=\, b$ is a special case of $x\,\,{\leq}\,\,b$.
    Likewise, Condition~(ii) is satisfied. That is, the closed interval $[a,b]$ has a maximum element, and it is the right endpoint $b$ of this interval.
    Similarly, the left endpoint $a$ is the minimum element of $[a,b]$.

\V

        (2) Let $a$ and $b$ be as in the preceding example, but now let $A$ be the {\em open} interval $(a,b)$.
    It is clear that the right endpoint $b$ still satisfies Condition~(ii) for being the maximum of $A$, but it fails Condition~(i).
    Indeed, the open interval $(a,b)$ has neither a maximum element nor a minimum element.

\V

        (3) Let $A$ be the set of all real numbers of the form ${\displaystyle 1-\frac{1}{n}}$ for $n$ in ${\NN}$;
    that is,
        \begin{displaymath}
        A \,=\, \left\{{\displaystyle 0, \frac{1}{2}, \frac{2}{3},\,{\ldots}\,\frac{n-1}{n},\,{\ldots}\,}\right\}.
        \end{displaymath}
    (Recall that we interpret rational numbers as being elements of the set~${\RR}$.)

        It is clear that the set $A$ has a minimum element, namely the number $0$.
    Indeed, $0$ is in the set $A$, since it corresponds to the case of $n \,=\, 1$ in the definition of $A$.
    And it is clear that $0\,\,{\leq}\,\,1-1/n$ for all $n$ in ${\NN}$, since $n\,\,{\geq}\,\,1$ implies $0\,<\,1/n\,\,{\leq}\,\,1$.

        In contrast, the set $A$ has no maximum element.
    In fact, if a number $x$ satisfies Condition~(i), then it cannot satisfy Condition~(ii).
    More precisely, such $x$ must be of the form $x \,=\, 1-1/n$ for some $n$ in ${\NN}$;
    but clearly $1-1/(n+1)$ is an element of $A$ larger than $x$.


\V

        (4) Let $A \,=\, \{ -2, 3, 7, 1, 0, -10\}$. It is clear by inspection that the smallest element of this set is the number $-10$, while the largest is the number $7$.
    That is, $\min\,A \,=\, -10$, $\max A \,=\, 7$.

\V

        (5) Let $f:{\RR} \,{\rightarrow}\, {\RR}$ be the function given by the equation
        \begin{displaymath}
        f(x) \,=\, x\,(1-x) \mbox{ if $|x|\,<\,1$}; \h f(x) \,=\, 0 \mbox{ if $|x|\,\,{\geq}\,\,1$}.
        \end{displaymath}
    It is clear that if $0\,<\,x\,<\,1$, then $0\,<\,1-x\,<\,1$, hence $0\,<\,x\,(1-x)\,<\,1$.
    In particular, $f(x)\,\,{\geq}\,\,0$ for all $x$ in~${\RR}$, and $f$ assumes its
    minimum value of~$0$ for ${\RR}$ at every $x$ such that $|x|\,\,{\geq}\,\,1$.
    As for the maximum value of~$f$, recall the well-known method of `Completing the Square',\IndA{completing the square} from high-school algebra, to get
        \begin{displaymath}
        x\,(1-x) \,=\, x - x^{2} \,=\, \frac{1}{4}-\frac{1}{4} + x - x^{2} \,=\, 
        \frac{1}{4} - \left(x - \frac{1}{2}\right)^{2} \h ({\ast})
        \end{displaymath}
    It is clear that the right side of~$({\ast})$ assumes its maximum value of~$1/4$ when $x \,=\, 1/2$.

\VV

            \section{\bf Completeness of the Real Numbers}\IndA{completeness of the real numbers}%\\\
            \label{SectB30}\IndB{ZZ Sections}{\Ref{SectB30} Completeness of the Reals}

\V

        It has been noted several times that the results obtained so far in this chapter apply to every ordered field.
    In particular, these results by themselves cannot distinguish between the ordered fields ${\QQ}$ and~${\RR}$.
    Among the differences between just these two fields are these:

\VA
        \h (i)\, In Chapter~\Ref{ChaptA} it was proved that the set ${\QQ}$ is countable, while the set ${\RR}$ is uncountable.

        \h (ii) It is well known that the algebraic equation $x^{2} \,=\, 2$ has a solution in ${\RR}$, but does not have one in~${\QQ}$.
    (This is usually expressed as `the number $\sqrt{2}$ is irrational'.)


\VA

        The aim of the current section is to formulate additional properties which distinguish ${\RR}$ from all other ordered fields.
    For various reasons the issues considered in this section fall under the general heading of
    the {\bf Completeness of the Real Number System~$\Bfm{{\RR}}$}.

\V

        \underline{Remark}: Note that the axioms considered so far, namely A0-A6, O1 and O2, enjoy several pleasant properties:
    they are easy to state; the properties of ${\RR}$ that they describe are familiar; and everyone believes that ${\RR}$ has these properties.
    Even the minor differences in presentation of these axioms that one can find in various texts are mainly cosmetic.

        In contrast, the `Completeness' aspects of ${\RR}$ considered in the current section
     are much less straight forward than the algebraic and order properties considered before.
    For one thing, there are several quite different approaches to `Completeness' in the mathematical literature,
    and at first glance these approaches may not appear to be at all closely related.
    In addition, most of these approaches requires a fair amount of preparation before the formulation can be carried out.
    Finally, to a greater or lesser degree each of these approaches is based on properties of real numbers which are {\em not} especially familiar.
    Indeed, many readers will not have considered the issue of `Completeness' before,
    so whatever we end up adding to our axiom system for ${\RR}$ in order to obtain `completeness' can hardly be considered `axiomatic',
    in the common meaning of that word as being `obviously true'.

\VV

%%%
\begin{quotation}
{\footnotesize \underline{\Note}\IndB{\notes}{on motivating the concept of completeness}(on motivating the concept of `Completeness')
        As motivation for the approach to `Completeness' to be followed here, it helps to look at the situation in geometric terms.
    Thus, think of the real number system ${\RR}$ as forming the standard $x$-axis of analytical geometry; that is, as a straight line.
    Within this line there lies the subset ${\QQ}$ of all rational numbers.
    To the `naked eye' the sets ${\QQ}$ and ${\RR}$ look very much alike: each consists of lots and lots of `dots' that are spread uniformly throughout the line.

        Of course one knows intellectually that these sets are quite different -- as mentioned above, ${\QQ}$ is countable, ${\RR}$ is not -- but cardinality is not a precise enough concept for this discussion.
    The true issue is that in this geometric interpretation the set ${\QQ}$ has lots of `holes'; for example, there is a `hole' in the rationals where the number $\sqrt{2}$ ought to appear.
    (Each such `hole' in ${\QQ}$ is infinitely small -- only a single point wide -- but there are uncountably many of them.)
    In contrast, the straight line (i.e., ${\RR}$) is, in our intuition,  `continuous' and thus has no such `holes'.
    Otherwise stated, there is no need to adjoin any new points to the standard set ${\RR}$ in order to make it `complete', i.e., free of `holes'.
    Otherwise stated, ${\RR}$ is `complete'.
}%EndFootNoteSize
\end{quotation}       
%##

\VV

        {\bf Remark} In the various approaches to completeness given below,  several candidates for additional axioms, called `Principles', are proposed.
    Each of these `Principles' makes sense in any ordered field; in particular, each makes sense in both ${\QQ}$ and~${\RR}$,
    the ordered fields of primary interest in {\ThisText}. (Of course, `making sense' in any ordered field is not the same as `being true';
    for example, all of the Principles expounded below make sense in~${\QQ}$, but none are valid in~${\QQ}$.)
    Thus in the statements of these `Principles',
    unless explicitly stated otherwise, the word `number' can refer to an element of any given ordered field;
    but there is no harm in restricting the meaning of `number' to either `rational number' or `real number'.
    Several of these approaches are grouped together for efficiency since they are so similar to each other.

\VV

        \underline{Approach \#1: Using Bolzano's Endpoint Principles}\IndBD{Bolzano, Bernhard (1781-1848)}{endpoint principles}

\V

        In the year 1817, Bernhard Bolzano\IndA{Bolzano, Bernhard (1781-1848)} published a pamphlet on the foundations of calculus.
    In it he singled out for special attention a certain property which he claimed to hold for the real number system.
    The reformulation of that property given here is in terms of certain subsets of ${\RR}$,
    a mode of expression that is natural today, but which was not common in~$1817$.
    The formulation given here differs a bit from Bolzano's, but not in any essential way.

\VV

        Using the terminology developed in the preceding section, Bolzano's approach to `Completeness' can be described as
    clarifying the relation between the concepts of `convexity' and `interval'. In doing so,
    Bolzano finds a way to distinguish between the general ordered field and the specific case of the real numbers.
    There is one case, however, in which this relation is the same for all ordered fields:

\V

            \subsection{\small{\bf Proposition}}
            \label{PropB30.07A}
\V

        If $S$ is a convex set of numbers which is unbounded both above and below,
    then $S$ is the set of all numbers; in particular, $S$ is the interval $(-{\infty},+{\infty})$.

\V

        {\bf Proof} Let $z$ be any number. Since, by hypothesis, $S$ is unbounded both above and below,
    there exist numbers $x$ and $y$ in $S$ such that $x\,<\,z\,<\,y$. It then follows from the convexity hypothesis for $S$ that $z{\in}S$ as well.
    That is, every number is in~$S$, as claimed.

\VV

        Bolzano's original approach focuses on convex sets $S$ of numbers which are bounded above but not bounded below.
    Specifically, the question is whether such a set must be an interval, in the sense of Definition~\Ref{DefB20.130}.
    More precisely, the question is whether there exists a number $B$ such that $S$ is one of the intervals $(-{\infty},B]$ or $(-{\infty},B)$.
    (If $S$ is to be an interval, than the hypothesis that $S$ be unbounded below requires that it extend on the left to~$-{\infty}$.)

\V

        {\bf Key Example} Let $S$ be the set consisting of all numbers $x\,\,{\geq}\,\,0$ such that $x^{2}\,<\,2$, together with all negative numbers.
    It is clear from the order properties of multiplication that the set $S$ is convex and bounded above; for example, the number~$3$ is an upper bound.
    Obviously it is also unbounded below. The question therefore is whether this convex set is actually an interval in the given ordered field.

        At first the answer appears obvious: clearly $S$ is the open interval $(-{\infty},\sqrt{2})$.
    However, the existence of a number whose square equals~$2$ cannot be deduced from the axioms for an ordered field.
    Indeed, if that existence could be so deduced, then since the rational numbers also form an ordered field,
    it would follow that there would exist a {\em rational} number whose square equals~$2$, which of course is not the case.
    Thus we need one or more additional axioms for ${\RR}$ which allow us to deduce facts such as the existence of square roots.

\V


        Bolzano's analysis of this situation suggests three equivalent principles which would hold for ${\RR}$, although not for~${\QQ}$.

\V

            \subsection{\small{\bf Bolzano's Right-Endpoint Principle}}
            \label{DefB30.07B}\IndBD{Bolzano, Bernhard (1781-1848)}{right-endpoint principle}

\V

        If $S$ is a convex set of numbers which is bounded above but not bounded below,
    then there exists a number~$B$ such that $S$ is an unbounded interval with right endpoint~$B$.
    That is, either $S \,=\, (-{\infty},B)$ or $S \,=\, (-{\infty},B]$.

\VV
            \subsection{\small{\bf Bolzano's Left-Endpoint Principle}}
            \label{DefB30.07C}\IndBD{Bolzano, Bernhard (1781-1848)}{left-endpoint principle}

\V

        If $S$ is a convex set of numbers which is bounded below, but not bounded above,
    then there exists a number~$A$ such that $S$ is an interval with left endpoint~$A$.
    That is, either $S \,=\, (A,+{\infty})$ or $S \,=\, [A,+{\infty})$.

\V

\VV
            \subsection{\small{\bf Bolzano's Two-Endpoints Principle}}
            \label{DefB30.07D}\IndBD{Bolzano, Bernhard (1781-1848)}{two-endpoints principle}

\V

        If $S$ is a bounded convex set of numbers which has more than one element,
    then there exist numbers~$A$ and $B$, with $A\,<\,B$, such that $S$ is an interval with left endpoint~$A$ and~$B$ .
    That is, one of the following statements holds: $S \,=\, (A,B)$, $S \,=\, [A,B)$, $S \,=\, (A,B]$ or $S \,=\, [A,B]$.

\VV

        {\bf Remark} It is easy to see that each of these principles implies the others, so only one is needed.
    Bolzano explicitly formulated the right-endpoint principle (although in slightly different form; see below.)
    However, it appears that he implicitly accepted the others as well.


%%%
\begin{quotation}
{\footnotesize \underline{\Note}\IndB{\notes}{on Bolzano's formulation of the Right-Endpoint Principle} (on Bolzano's formulation of the Right-Endpoint Principle)


    Bolzano's formulation of the principle in question essentially as follows:

\V

        Suppose that a certain property~$P$ of real numbers is not enjoyed by all numbers~$x$.
    Suppose, in addition, there exists a number $u$ such that the Property~$P$ is satisfied by all $x\,<\,u$.
    Then there exists a {\em largest} number $U$ such that Property~$P$ is satisfied by all $x\,<\,U$.

\V

        It is easy to show that Bolzano's formulation of the principle is equivalent to the convex-set version given in Definition~\Ref{DefB30.07C};
    that is, each formulation implies the other.

        First, suppose that Bolzano's version of the principle holds. Let $S$ be a set
    which satisfies the hypotheses of the convex-set version of the principle, and define $P$ to be the property
    `is less than or equal to at least one element of the set~$S$'; note that since convex sets are, by definition, nonempty,
    the property $P$ is satisfied by at least one number. To see that $P$ satisfies Bolzano's first hypothesis, let $M$ be an upper bound for the set $S$; 
    by hypothesis, such $M$ exists. Clearly, if $y\,>\,M$, then $y$ does not enjoy Property~$P$.
    Next, let $u$ be any element of the set $S$. The definition of $P$ implies that if $x\,<\,u$ then $x$ satisfies Property~$P$.
    That is, Property~$P$ satisfies Bolzano's second hypothesis.
    Let $U$ be the number whose existence Bolzano's version of the principle now guarantees.
    It is easy to check that $B \,=\, U$ satisfies the conclusion of the convex-set version of the principle.
 
        Conversely, suppose that the convex-set version of the principle holds. Let a property~$P$ be given which satisfies Bolzano's hypotheses,
    and let $S$ be the set consisting of all numbers $u$ such that if $x\,<\,u$, then $x$ enjoys Property~$P$.
    Bolzano's second hypothesis implies that $S$ is nonempty. Furthermore, let $M$ be a number which does not enjoy Property~$P$;
    such $M$ exists by Bolzano's first hypothesis. It follows that if $u{\in}S$, then $M$ cannot satisfy $M\,<\,u$,
    for otherwise $M$ would satisfy Property~$P$. Thus $M\,\,{\geq}\,\,u$; that is, $S$ is bounded above by~$M$.
    To show that $S$ is convex, suppose that $u$ and $v$ are in $S$, and let $w \,=\, \max\{u,v\}$.
    If $w \,=\, u$ then, by definition of the set~$S$, every $x\,<\,w$ satisfies Property~$P$; the same conclusion holds if $w \,=\, v$.
    It follows that if $z\,\,{\leq}\,\,w$ then every $x\,<\,z$ satisfies $x\,<\,w$ and therefore lies in~$S$.
    It follows eaily that $\mbox{Seg}\,[u,v] \,{\subseteq}\, S$, as required. Thus the convex-set version implies that
    there is a number $B$ such that $S$ is an interval with right endpoint~$B$. Clearly the number $U \,=\, B$ satisfies Bolzano's conclusion.

\V

        {\bf Remark} Bolzano's formulation of the principle is, in a sense more general than the convex-set version,
    since the set of $x$ which satisfy Property~$P$ need not form a convex set at all. For example, let $f:{\RR} \,{\rightarrow}\, {\RR}$
    be given by the formula $f(x) \,=\, 2-x^{2}$ for eac~$x$, and let $P$ be the property `$x$ is a number such that $f(x)\,<\,0$'.
    Property $P$ clearly satisfies Bolzano's hypotheses; indeed, $x \,=\, 0$ does not satisfy Property~$P$,
    while $x \,=\, -2$ can be used as Bolzano's~$u$ (as can many other values of~$x$).
    Nevertheless, the set of $x$ which satisfy Property~$P$ is not convex, since clearly $x \,=\, -2$ and $x \,=\, +2$ both satisfy it, but $x \,=\, 0$ does not.

        In this case it is easy to see that the quantity $U$ referred to in Bolzano's formulation is the number~$-\sqrt{2}$;
    that is, $U$ is the smaller of the two solutions of the quadratic equation $f(x) \,=\, 0$.
    Indeed, it was the analysis of such equations that led Bolzano to his formulation of the principle.
}%EndFootNoteSize
\end{quotation}
%##

\VV

        The `Bolzano' approach to completeness described above has been largely replaced in modern texts by the following.

\VV

        \underline{Approach \#2: Using the Supremum Principle or the Infimum Principle}\IndA{supremum, infimum}

\V

       Bolzano's Right-Endpoint Principle asserts, in effect, that if $S$ is a certain type of convex set, then $S$ is an interval with a right endpoint.
    It is easy to use Bolzano's idea to extend the concept of `right endpoint' to {\em every} nonempty subset $X$ of numbers which is bounded above.
    Indeed, associate with such $X$ the set $S_{X}$ of all numbers $y$ such that $y\,\,{\leq}\,\,x$ for at least one element $x$ in~$X$.
    It is clear from the hypotheses on $X$, and the usual order properties, that $S_{X}$
    is a nonempty superset of $X$ which is convex, bounded above and not bounded below.
    If $S_{X}$ has a right endpoint $B$ in the sense of Bolzano's Principle, then one calls $B$ the right endpoint of the original set~$X$;
    and of course if $S_{X}$ does {\em not} have a right endpoint in the sense of Bolzano's Principle, then one says that $X$ also has no right endpoint.


        {\bf Remark} Similar statements hold for Bolzano's Left-Endpoint Principle; but since the two principles are so closely related,
    we restrict our attention for now to the `Right-Endpoint' case, and include the `Left-Endpoint' case in Definition~\Ref{DefB30.08A}.

\VV

        It is useful to characterize the `right endpoint' of $X$ described above directly,
    without needing to introduce the auxiliary convex set $S_{X}$.

\V

            \subsection{\small{{\bf Lemma}}}
            \label{LemmaB30.08}

\V

         Let the sets $X$ and $S_{X}$ be as above.

\V

        (1) Suppose that $S_{X}$ has a right endpoint in the sense of Bolzano;
that is, there is a number $B$
    such that either $S_{X} \,=\, (-{\infty},B)$ or $S_{X} \,=\, (-{\infty},B]$. Then the number $B$ satisfies the following conditions:

\VA

        \h (i)\, The number $B$ is an upper bound of the original set $X$;

        \h (ii) For every number $y\,<\,B$ there exists at least one $x$ in $X$ such that $y\,<\,x$.

\VA

        (2) Conversely, if there exists a number $B$ which satisfies Conditions~(i) and~(ii),
    then $B$ is the right endpoint of $S_{X}$ in the sense of Bolzano.

\V

        {\bf Proof} Part (1) is obviously true, so let us prove only Part~(2).
    Indeed, let $S_{X}$ be the set of all numbers $y$ such that $y\,\,{\leq}\,\,x$ for at least one $x$ in~$X$,
    so that the set $S_{X}$ is a convex superset of~$X$ which is unbounded below.
    If $y{\in}S_{X}$ then, by definition of~$S_{X}$, Condition~(i), and the transitivity of~`$<$',
    it follows that $y\,\,{\leq}\,\,B$; that is, the convex set $S_{X}$ is bounded above, by~$B$.
    Furthermore, if $y\,<\,B$ then, by Condition~(ii) there exists $x$ in $X$ such that $y\,<\,x$, so in particular $y\,\,{\leq}\,\,x$ and thus $y{\in}S_{X}$.
    It follows that the open interval $(-{\infty},B)$ is a subset of $S_{X}$. If $S_{X}  \,=\, (-{\infty},B)$, we are done.
    If, instead, $S_{X} \,\,{\neq}\,\, (-{\infty},B)$, then there must be at least one number $z$ such that $z{\in}S_{X}$, and thus $z\,\,{\leq}\,\,B$, but $z \not \in (-{\infty},B)$, and thus $z\,\,{\geq}\,\,B$.
    In this situation it follows that $z \,=\, B$, so that $S_{X} \,=\, (-{\infty},B)\,{\cup}\,\{B\} \,=\, (-{\infty}, B]$, as required.

\VV

        The preceding result suggests calling the number $B$ satisfying (i) and (ii) to be the `right endpoint' of the set~$X$, and doing so would be fine.
    Likewise, the obvious modification of the preceeding discussion would allow one to use
    Bolzano' `Left-Endpoint Principle' to define the left endoint of any nonempty set which is bounded below.
    However, the custom in modern analysis is to restrict the `right endpoint' and `left endpoint' terminology to the special case of intervals.
    For sets of more general type the following Latin-based terminology is preferred.

\V

            \subsection{\small{{\bf Definition (Supremum, Infimum)}}}
            \label{DefB30.08A} \IndA{supremum, infimum}
\V

        Let $X$ be a nonempty subset of numbers.

\V

        (a) Suppose that there exists a number $B$ satisfying the following conditions:

\VA

        \h Condition (i)\, The number $B$ is an upper bound of $X$; that is, if $x{\in}X$, then $x\,\,{\leq}\,\,B$.

        \h Condition (ii)\, For every number $y\,<\,B$ there exists at least one $x$ in $X$ such that $y\,<\,x\,\,{\leq}\,\,B$

\VA

        If such a number $B$ exists, it is called the {\bf supremum of $\Bfm{X}$}, and is denoted by ${\sup}\,X$.

\V

        (b) Likewise, suppose that there exists a number $b$ satisfying the following conditions:

\VA

        \h Condition (i$'$)\, The number $b$ is a lower bound of $X$; that is, if $x{\in}X$, then $x\,\,{\geq}\,\,b$.

        \h Condition (ii$''$)\, For every number $y\,>\,b$ there exists at least one $x$ in $X$ such that $b\,\,{\leq}\,\,x\,<\,y$.

\VA

        If such a number $b$ exists, it is called the {\bf infimum of $\Bfm{X}$}, and is denoted by ${\inf}\,X$.


\VV

        The following are the analogs to Bolzano's `Right-Endpoint Principle' and `Left-Endpoint Principle'.

\V

            \subsection{\small{\bf The Supremum Principle}}
            \label{DefB30.08C}\IndBD{supremum, infimum}{supremum principle}

\V

        If $X$ is a nonempty set of numbers such that $X$ is bounded above, then $X$ has a supremum.

\VV

            \subsection{\small{\bf The Infimum Principle}}
            \label{DefB30.08F}\IndBD{supremum, infimum}{infimum principle}

\V

        If $X$ is a nonempty set of numbers such that $X$ is bounded below, then $X$ has an infimum.

\VV

            \subsection{\small{\bf Remarks}}
            \label{RemrkB30.08FF}

\V

\hspace*{\parindent} (1) Condition (ii) in Part~(a) Definition~\Ref{DefB30.08A} is called the {\bf Approximation Property of the Supremum}.
    \IndBD{supremum, infimum}{approximation property for supremum} Likewise, Condition~(ii$'$) in Part~(b) of the same definition is called the
    {\bf Approximation Property of the Infimum}.\IndBD{supremum, infimum}{approximation property for infimum}
    The reason for this terminology will be make clear in an exercise.

    % EXERCISE

\V

        (2) The use of the phrase `{\em the} supremum' suggests that if a set $X$ has a supremum, it is unique; likewise for `{\em the} infimum'.
    It is easy to show that these suggestions are correct.

\V

        (3) The Latin nouns `supremum' and `infimum' translate into ordinary English as the phrases `the greatest one' and `the least one', respectively.
    Note that the Latin nouns `maximum' and `minimum' also translate to exactly the same phrases.
    In mathematics, however, there is a subtle technical difference which does not hold in ordinary English usage.

\VA

        \underline{Example} If one writes that `the number $B$ is the maximum of the set $S$', it is implied that $B$ is actually an element of the set~$S$.
    In contrast, to say that `the number $B$ is the supremum of the set $S$' does {\em not} imply that $B$ is an element of~$S$;
    consider, for instance, the case in which $S$ is the open interval $(1,2)$, so that ${\sup}\,S \,=\, 2$, but $2$ is not an element of the set.
    In particular, the Supremum Principle does {\em not} state that a nonempty set $S$ which is bounded above must have a maximum element.
    Similar comments hold for the (subtle) disinction between `minimum' and `infimum'.

\V

        (4) Because of the Latin roots of the nouns `supremum' and `infimum', the custom in mathematics is to use the Latin formations of their plurals: 
    `suprema' and `infima' respectively. A minority of authors, however, use the English versions of the plurals: `supremums' and `infimums'.
    Similarly, one usually writes `maxima' and `minima', not `maximums' and `minimums'.

\V

        (5) One pronounces the `su' in the expression `${\sup}\,X$' the same as the `su' found in the word `super', {\em not} as the `su' found in the word `submarine'.
    Likewise, the `in' found in the expression `${\inf}\,S$' is pronounced the same as the `in' found in the word `into'.

%% EXERCISE Suppose that $B$ is the supremum of $S$ but not in $S$. Then $B$ is the maximum (and supremum) of $S' \,=\, S\,{\cup}\,\{B\}$.
%%    However, if $B$ is the maximum element of some set $T$, then $B$ need not be the supremum of the set $T' \,=\, T\,{\setminus}\,\{B\}.$


\VV

        \underline{Approach \#3: Using the Least-Upper Bound Principle or the Greatest-Lower-Bound Principle}

\V

        The next pair of principles require no further preparation for their statements.

            \subsection{\small{\bf The Least-Upper-Bound Principle}}
            \label{DefB30.08D}\IndA{least-upper-bound principle}

        Let $X$ be a nonempty set of numbers which is bounded above. Then $X$ has a {\em least} upper bound, denoted $\mbox{lub}\,X$.
    More precisely, let $U_{X}$ denote the set of all the upper bounds of $X$ (so that $U_{X}$ is nonempty by the hypothesis that $X$ is bounded above.)
    Then the set $U_{X}$ has a minimum (i.e., least) element.

\VV


\V

            \subsection{\small{{\bf The Greatest-Lower-Bound Principle}}}
            \label{DefB30.08G}\IndA{Greatest-Lower-Bound Principle}

\V

        Suppose that $X$ is a nonempty set of numbers which is bounded below. Then $X$ has a {\em greatest} lower bound, denoted $\mbox{glb}\,X$.
    More precisely, let $L_{X}$ denote the set of all the lower bounds of $X$ (so that $L_{X}$ is nonempty by the hypothesis that $X$ is bounded below.)
    Then $L_{X}$ has a maximum (i.e., greatest) element.

\V

        {\bf Remark} The expressions `lub' and `glb' are both pronounced to rhyme with the English word `flub'.


\VV

            \subsection{\small{\bf Examples}}
            \label{ExamplB08.08I}

       Suppose the ordered field under consideration is~${\QQ}$, the ordered field of rational numbers.
    Then some bounded sets have both a greatest lower bound and a least upper bound in ${\QQ}$, some have neither, and some have one but not the other.

\V

        (1) Let $S_{1} \,=\, \{x{\in}{\QQ}: 0\,\,{\leq}\,\,x\,<\,1$. It is easy to see that $S_{1}$ has both a greatest lower bound and a least upper bound, 
    namely $b \,=\, 0$ and $B \,=\, 1$, respectively.
    Note that $\mbox{glb}\,S_{1}$ is an element of $S_{1}$ while $\mbox{lub}\,S_{1}$ is not.

        It is also instructive to check directly from the definition of `supremum', Definition~\Ref{DefB30.08A}~(a), that ${\sup}\,S_{1} \,=\, 1$.
    Indeed, it is obvious that $B \,=\, 1$ satisfies Part~(i) of that definition.
    As for Part~(ii), let $y$ be any number such that $y\,<\,1$. If $y\,<\,0$ then {\em every} $x$ in $S_{1}$ satisfies $y\,<\,x$.
    And if $0\,\,{\leq}\,\,y\,<\,1$ then $x \,=\, (y+1)/2$ is in $S_{2}$ and satisfies $y\,<\,x$.
    A similar argument shows directly from Part~(b) of the same definition that  ${\inf}\,S_{1} \,=\, 0$.

\V

        (2) Let $S_{2} \,=\, \{x{\in}{\QQ}: x\,\,{\geq}\,\,0 \mbox{ and } x^{2}\,<\,2\}$.
    Obviously $S_{2}$ is bounded above (by $3$, for example), and clearly this set has a greatest lower bound, namely $b \,=\, 0$.
    Suppose that $S_{2}$ has a least upper bound $B$ in~${\QQ}$. It may appear to be an `obvious fact' that such $B$ must satisfy the equation $B^{2} \,=\, 2$;
    this would then contradict the well-known fact that there is no rational number whose square equals~$2$.
    Unfortunately, the `obvious fact' in question is not especially easy to prove directly.
    Such facts will be handled in a much more general manner in Chapter~\Ref{ChaptD};
    thus there is no harm in simply accepting this `obvious fact', and therefore the conclusion that
    the ordered field ${\QQ}$ does not satisfy the Least-Upper-Bound Principle, on faith for now.


\VV

        \underline{Warning}
    Many texts in analysis do not distinguish between the concepts of `supremum of $X$' and `least upper bound of $X$' as we do in {\ThisText}.
    More precisely, they {\em define} the expression `${\sup}\,X$' to mean the least upper bound of the set~$X$ (when such exists). In other words,
    in these texts the Latin word `supremum' is simply an abbreviation for -- and a bad translation of -- the English phrase `least upper bound of $X$'.

        There are several difficulties with this usage. The most glaring issue is that there is 
    a well-established shorthand for `least upper bound of~$X$', namely `$\mbox{lub}\,X$';
    this notation is as brief as the `${\sup}$' notation, and it is certainly more natural.

        Another problem is that this definition does not mention the key feature of `supremum; namely Condition~(ii) of Definition~\Ref{DefB30.08A},
    what we refer to as the `Approximation Property of the Supremum'. These texts eventually
    do prove that this feature follows from the `least upper bound' property, and of course they use it repeatedly.
    Some texts even refer to this feature as the `Approximation Property', but many give it no name at all.

        Perhaps the most serious difficulty with this common usage, however, is that it forces a cognitive dissonance into the discussion.
    More precisely, the notation $C \,=\, {\sup}\,X$ in those texts refers to the property of $C$ being the {\em least} number of a certain set
    -- and not even the given set $X$ itself -- whereas the root meaning of the Latin word `supremum' is {\em greatest},
    which is much closer to the intuition of `right endpoint of~$X$'.

        In {\ThisText} we avoid that cognitive dissonance by carefully maintaining the conceptual distinction between $C$ being a right endpoint,
    i.e., the supremum, of $X$, and the same $C$ simultaneously being a least element, i.e., the least element of the set $U_{X}$ of upper bounds of~$X$.
    Otherwise stated, sometimes it is useful to look at a given number $C$ `from the right', while sometimes it is more useful to look at $C$ `from the left'.

\VV

        The next several results clarify and extend the concepts just introduced.

\V

            \subsection{\small{\bf Lemma}}
            \label{LemmaB30.08J}

\V

        Let $X$ be a nonempty set of numbers, and let $Y \,=\, \{y:y \,=\, -x \mbox{ for some number $x$ in $X$}$.
    Let $U_{X}$ be the set of upper bounds of $X$;
    likewise, let $L_{Y}$ be the set of lower bounds of~$Y$.

\V

         (a) The set $L_{Y}$ is nonempty if, and only if, $U_{X}$ is nonempty;
    that is, $Y$ is bounded below if, and only if, $X$ is bounded above.
    Furthermore, if this happens, then $L_{Y} \,=\, \{l: l \,=\, -u \mbox{ for some number $u$ in $U_{X}$}\}$.

\V

         (b) Suppose that such boundedness occurs. Then $X$ has a least upper bound if, and only if, $Y$ has a greatest lower bound.
    Furthermore, in this case one has $\mbox{glb}\,Y \,=\, - \mbox{lub}\,X$. Of course, this is equivalent to ${\inf}\,Y \,=\, -{\sup}\,X$.

\V

         (c) If in Part~(b) `least upper bound' and `greatest lower bound' are replaced throughout by `supremum' and `infimum', respectively,
    then the resulting statements remain true.

\V

        {\bf Proof} (a) Suppose that $u{\in}U_{X}$, so that $u\,\,{\geq}\,\,x$ for all $x$ in $X$.
    Then $-u\,\,{\leq}\,\,-x$ for all $x$ in $X$, hence $l \,=\, -u$ is a lower bound for~$Y$.
    Similarly, if $l{\in}L_{X}$ then $l\,\,{\leq}\,\,y$ for all $y$ in $Y$; that is, $l\,\,{\leq}\,\,-x$, and thus $-l\,\,{\geq}\,\,x$, for all $x$ in $X$.
    The desired result now follows.

\V

        (b) This follows by a similar argument.

\V

        (c) This is left as an exercise.

\V

            \subsection{\small{\bf Theorem}}
            \label{ThmB30.08K}

\V

\noindent (a) Let $X$ be a nonempty set of numbers. If $X$ has both a greatest lower bound and a least upper bound,
    then $\mbox{glb}\,X\,\,{\leq}\,\,\mbox{lub}\,X$, with equality if, and only if, $X$ is a singleton set.

\V

        (b) Let $X$ and $Y$ be nonempty sets of numbers such that $X \,{\subseteq}\, Y$.
    If $X$ and $Y$ both have least upper bounds, then $\mbox{lub}\,X\,\,{\leq}\,\,\mbox{lub}\,Y$.
    Likewise, if both $X$ and $Y$ have greatest lower bounds, then $\mbox{glb}\,X\,\,{\geq}\,\,\mbox{glb}\,Y$.

        \underline{Warning} Note the reversal of the order which occurs in the `glb' case.

\V

        (c) Let $X$ and $Y$ be nonempty sets of numbers such that $x\,\,{\leq}\,\,y$ for all $x$ in $X$ and all $y$ in $Y$.
    If $X$ has a least upper bound and $Y$ has a greatest lower bound, then $\mbox{lub}\,X\,\,{\leq}\,\,\mbox{glb}\,Y$.

\V


         (d) If in the previous parts `least upper bound' and `greatest lower bound' are replaced throughout by `supremum' and `infimum', respectively,
    then the resulting statements remain true.

\V

        {\bf Proof} The simple proof is left as an exercise.

\V

    It is easy to extend the concepts of `supremum and `infimum, and likewise the concepts of `least upper bound' and `greatest lower bound',
    to include {\em unbounded} sets.

            \subsection{\small{\bf Definition}}
            \label{DefB30.08K}

\V

\hspace*{\parindent} (1) Let $X$ be a nonempty set of numbers. If $X$ is unbounded above, then one sets ${\sup}\,X \,=\, +{\infty}$ and $\mbox{lub}\,X \,=\, +{\infty}$.
    Likewise, if $X$ is unbounded below, then one sets ${\inf}\,X \,=\, -{\infty}$ and $\mbox{glb}\,X \,=\, -{\infty}$.

\V

        (2) Let $Y$ be a nonempty set of numbers. One says that {\bf \Bfm{Y} has a supremum}\IndBD{supremum, infimum}{supremum and infimum of unbounded sets}
    if either $Y$ has a supremum in the sense of Definition~\Ref{DefB30.08A} (in which case $Y$ must be bounded above)
    or $Y$ is unbounded above (in which case ${\sup}\,Y \,=\, +{\infty}$).

        One defines the meaning of `$Y$ has an infimum' analogously.

\V

        (3) One defines the meaning of `$Y$ has a least upper bound' and `$Y$ has a greatest lower bound'
    by replacing `supremum' and `infimum' above by these phrases in the usual manner.

\VV
            \subsection{\small{\bf Remarks}}
            \label{RemrkB30.08LL}

\V

        \hspace*{\parindent}(1) The Supremum, Infimum, Least-Upper-Bound and Greatest-Lower-Bound Principles described above
    are all formulated for nonempty sets which are bounded either above or below, depending on the specific case.
    With the extension of the concepts just given, one could reformulate these principles more briefly;
    for example, with the extended concept of `supremum' the original Supremum Principle is equivalent to the following statement:

\VA

        \h `Every nonempty set of real numbers has a supremum.'

\VA

\noindent Despite the temptation to use these new formulations, in {\ThisText} we elect to follow convention and stay with the original formulations above.

\V

        (2) The `Approximation Properties' for Supremum and Infimum, see Part~(1) of Remark~\Ref{RemrkB30.08FF},
    hold for the extended notions of `supremum' and `infimum' described above: replace the numbers $B$ and $b$ in those conditions by $+{\infty}$ and $-{\infty}$, respectively.

\V

        (3) Some authors extend the concepts of `supremum' and `infimum'
    (and likewise `least upper bound' and `greatest lower bound') to apply to the empty set, while others use these concepts only in the context of nonempty sets.
    In {\ThisText} the preference is to NOT apply these concepts to the empty~set.

    The main reason is that there is no such extension of these concepts for which all the standard properties also remain correct.
    For instance, since ${\emptyset}$ is a subset of every set of numbers, to extend the concept of `least upper bound' to ${\emptyset}$ one would want,
    by Part~(b) of the preceding theorem, $\mbox{lub}\,{\emptyset}\,\,{\leq}\,\,\mbox{lub}\,X$
    for every set $X$ which has a least upper bound. For this to hold one would need ${\sup}\,{\emptyset} \,=\, -{\infty}$.
    By a similar argument one would need ${\inf}\,{\emptyset} \,=\, +{\infty}$.
    However, with these values Part~(a) of the same theorem would fail to hold.

\VV

        Here are some standard facts about suprema and infima.

\V

            \subsection{\small{\bf Theorem}}
            \label{TheoremB30.08M}

\V

        Let $X$ and $Y$ be nonempty sets of numbers, and let $W$ be the set of all numbers $w$ of the form $x+y$ for some $x$ in $X$ and some $y$ in~$Y$.

\V

        (a) If each of the sets $X$ and $Y$ has a finite supremum, then $W$ also has a finite supremum, and ${\sup}\,W \,=\, {\sup}\,X + {\sup}\,Y$.

\V

        (b) If each of the sets $X$ and $Y$ has a finite infimum, then $W$ also has a finite infimum, and ${\inf}\,W \,=\, {\inf}\,X + {\inf}\,Y$.

\V

         (c) If in Parts (a) and~(b) the words `supremum' and `infimum' are replaced by `least upper bound' and `greatest lower bound', respectively,
    then the resulting statements remain true.

\V

        {\bf Proof} (a) For simplicity let $A \,=\, {\sup}\,X$ and $B \,=\, {\sup}\,Y$, and set $C \,=\, A+B$.
    Note that if $x{\in}X$ and $y{\in}B$, then $x\,\,{\leq}\,\,A$ and $y\,\,{\leq}\,\,B$, hence $x+y\,\,{\leq}\,\,A+B$.
    It follows that $A+B$ is an upper bound of the set $Z$. Next, let ${\varepsilon}\,>\,0$ be any positive number.
    It follows from the properties of `supremum' that there exist $x$ in $X$ and $y$ in $Y$ such that $A-{\varepsilon}/2\,<\,x$ and $B-{\varepsilon}/2\,<\,y$.
    Thus
        \begin{displaymath}
        \left(A-\frac{{\varepsilon}}{2}\right) + \left(B-\frac{{\varepsilon}}{2}\right)\,<\,x+y; \mbox{ that is, }
        C-{\varepsilon}\,<\,x+y.
        \end{displaymath}
    Since $w \,=\, x+y$ is in $W$, and ${\varepsilon}$ is arbitrary, it follows that $C \,=\, {\sup}\,W$, as required.

\V

        (b) This follows from Part~(a) by using Lemma~\Ref{ThmB30.08J}

\V

        (c) This is obvious.

\VV

        The approaches to `Completeness' described above clearly have a common origin, namely the Bolzano Right-Endpoint Principle.
    The final approach to be considered here is quite different in spirit.

\VV

        \underline{Approach \#4: The Bisection Principle}

\V

        \underline{Background} For thousands of years people have had the need to find rational approximations to solutions of polyomial equations;
    for example, to compute the square root of~$2$ is equivalent to solving the quadratic equation $x^{2}-2 \,=\, 0$.
    The procedure given below is perhaps the most obvious method, and probably has been been known since ancient times;
    it was certainly known by both Bolzano and Cauchy, and is called {\em Bolzano's Method}\IndBD{bisection}{Bolzano's method} by many authors.

\V

        \subsection{\small{{\bf Example}:} The Square Root of $2$}
        \label{ExampB25.90}

\V
        {\bf Motivation} It is well-known that there is no rational number whose square equals~$2$.
    For the moment let us assume that such a {\em real} number does exist, and try to determine it as accurately as possible.

        The obvious procedure for generating approximations of $\sqrt{2}$ starts by choosing positive rational numbers $a_{1}$ and $b_{1}$ such that $a_{1}^{2}\,<\,2$ and $b_{1}^{2}\,>\,2$;
    for instance, one might set $a_{1} \,=\, 1$ and $b_{1} \,=\, 3$, so that $a_{1}^{2} \,=\, 1\,<\,2$ and $b_{1}^{2} \,=\, 9\,>\,2$.
   Thus $a_{1}$ is too small to be $\sqrt{2}$, while $b_{1}$ is too big.
    By simple order properties it follows that $\sqrt{2}$ -- assuming it exists -- must lie in the interval $[a_{1},b_{1}]$.

        Now cut the interval $[a_{1},b_{1}]$ at its midpoint $c_{1} \,=\, {\displaystyle \frac{a_{1}+b_{1}}{2} \,=\, 2}$
    into equal halves $[a_{1},c_{1}]$ and $[c_{1},b_{1}]$; see Remark~\Ref{RemrkB20.150B}. That is, `bisect' the original interval.
    Note that $c_{1}$ is also a positive rational number, hence $c_{1}^{2} \,\,{\neq}\,\, 2$ (since $\sqrt{2}$ cannot be rational).
    Thus $\sqrt{2}$ must lie in one of the subintervals $[a_{1},c_{1}]$ or $[c_{1},b_{1}]$.
    More precisely, it lies in $[a_{1},c_{1}]$ if $c_{1}^{2}\,>\,2$ and it lies in $[c_{1},b_{1}]$ if $c_{1}^{2}\,<\,2$.
    In either case, let $[a_{2},b_{2}]$ denote the half of $[a_{1},b_{1}]$ containing $\sqrt{2}$.

        By similar reasoning this {\bf bisection procedure} can be used to cut $[a_{2},b_{2}]$ into equal halves, one of which must contain $\sqrt{2}$.
    If one continues this bisection procedure indefinitely, one obtains an infinite sequence of intervals $[a_{1},b_{1}]$, $[a_{2},b_{2}]$,\,{\ldots}\,$[a_{k},b_{k}]$, \,{\ldots}\,, where each $a_{k}$ and $b_{k}$ is rational, such that:

\VA

        \h (i) $a_{j}^{2}\,<\,2\,<\,b_{j}^{2}$ for each $j$ in ${\NN}$;

        \h (ii) ${\displaystyle b_{j+1}-a_{j+1} \,=\,\frac{b_{j}-a_{j}}{2}}$ for each $j$ in ${\NN}$.
    That is, each interval in this sequence (after the first) is half the length of its predecessor.

\V

\noindent One's geometric intuition about numbers then pictures these intervals as `squeezing in' towards the desired number $\sqrt{2}$.
    Here is the calculation up to the case $k \,=\, 10$, based on the initial choices $a_{1} \,=\, 1$, $b_{1} \,=\, 3$ suggested above:
        \begin{displaymath}
        \begin{array}{||l|r|c|c|c|c|c|c|c|c|c|c|c|c|c|c||} \hline
        k &   1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 & 11 & 12 & 13 & 14 & 15 \\ \hline
          &     &   &   &   &   &   &   &   &   &  &  &  &  &  &    \\
         a_{k} & 1 & 1 & {\displaystyle \frac{2}{2}} & {\displaystyle \frac{5}{4}} & {\displaystyle \frac{11}{8}} &
        {\displaystyle \frac{22}{16}} & {\displaystyle \frac{45}{32}} & {\displaystyle \frac{90}{64}} &{\displaystyle  \frac{181}{128}} &
        {\displaystyle \frac{362}{256}} & {\displaystyle \frac{724}{512}} & {\displaystyle \frac{1448}{1024}} & {\displaystyle \frac{2896}{2048}}  & {\displaystyle \frac{5792}{4096}} & {\displaystyle \frac{11585}{8192}} \\ 
          &     &   &   &   &   &   &   &   &   & &  &  &  &  &  \\  \hline
           &     &   &   &   &   &   &   &   &   &  &  &  &  &  &  \\
        b_{k} & 3 & 2 &{\displaystyle  \frac{3}{2}} & {\displaystyle \frac{6}{4}} & {\displaystyle \frac{12}{8}} &
        {\displaystyle \frac{23}{16}} & {\displaystyle \frac{46}{32}} & {\displaystyle \frac{91}{64}} &{\displaystyle  \frac{182}{128}} &
        {\displaystyle \frac{363}{256}} & {\displaystyle \frac{725}{512}}  & {\displaystyle \frac{1449}{1024}} & {\displaystyle \frac{2897}{2048}} & {\displaystyle \frac{5793}{4096}} & {\displaystyle \frac{11586}{8192}}  \\ 
  &     &   &   &   &   &   &   &   &   & &  &  &  &  &   \\ \hline
        \end{array}
        \end{displaymath}
    The reader can easily verify that $a_{j}^{2}\,<\,2\,<\,b_{j}^{2}$ for each $j \,=\, 1,2,\,{\ldots}\,15$.
    The final column of the table tells one that the location of the number $\sqrt{2}$ has been specified with error no bigger than $1/8192$; in particular, the error is less than~$0.0002$.
    Clearly the accuracy can be improved indefinitely by simply repeating the bisection procedure.

        Note that in the preceding discussion it is {\em assumed} that there is a number $x$ such that $x^{2} \,=\, 2$;
    in other words, one assumes that $\sqrt{2}$ exists. However, a major reason that one actually
    {\em believes} that such a number does exist is because of the very existence such methods for approximating it to any desired degree of accuracy.
    Indeed, the intuition formed by computation like the preceding is this: The number that one seeks, $\sqrt{2}$,
    is the unique real number that lies in each of the intervals $[a_{k},b_{k}]$, $k \,=\, 1,2,3,\,{\ldots}\,$, constructed above.
    If there were no such square root, then these intervals would be squeezing in on a `hole' in the real line;
    but we have been taught (probably in analytical geometry) that no such `holes' exist.
    In terms of set-theoretic notation, the intersection ${\bigcap}_{k=1}^{{\infty}} [a_{k},b_{k}]$ is a singleton set; namely, the set $\{\sqrt{2}\}$.

        Another way to look at the preceding calculation, without mentioning `holes in a line', is illustrated by expressing $a_{15}$ and $b_{15}$ as decimals to eight places:
        \begin{displaymath}
        a_{15} \,=\, \frac{11585}{8192} \,=\, 1.41418457; \h
        b_{15} \,=\, \frac{11586}{8192} \,=\, 1.41430664
        \end{displaymath}
    From this one sees that the number we seek, $\sqrt{2}$, has been determined through the third place to the right of the decimal point;
    it seems obvious that with sufficient time the procedure could be extended produce as many of the decimal digits of the desired number as one might want.
    Thus if one believes what one was taught in grade-school arithmetic, namely that every infinite decimal corresponds to a real number,
    then it seems clear that this process really is producing a real number with the desired property.


%----------------------

        The preceding example suggests another candidate for an axiom that is enjoyed by the real numbers but not by the rationals.


\V

            \subsection{\small{\bf Definition}}
            \label{DefB30.05A}
\V

        \hspace*{\parindent}Let $(X_{1}, X_{2},\,{\ldots}\,X_{n},\,{\ldots}\,)$ be an ordered sequence of sets.
    One says that this is a {\bf nested sequence}\IndA{nested sequence of sets} provided for each index $n$ one has $X_{n+1} \,{\subseteq}\, X_{n}$.

\VV

            \subsection{\small{\bf Examples}}
            \label{ExampB30.05AA}
\V

\hspace*{\parindent}(1) Let $(I_{1}, I_{2},\,{\ldots}\,I_{n},\,{\ldots}\,)$
    be an ordered sequence of closed bounded intervals in~${\RR}$.
    Thus, each set $I_{k}$ is of the form $[a_{n},b_{n}]$ with $a_{n}\,<\,b_{n}$.
    It is easy to see, from the definition of `interval, that this sequence is nested if, and only if,
    for every index~$n$ one has $a_{n}\,\,{\leq}\,\,a_{n+1}$ and $b_{n+1}\,\,{\leq}\,\,b_{n}$. Furthermore, since $a_{1}\,\,{\leq}\,\,a_{2}\,\,{\leq}\,\,a_{n}\,<\,b_{n}\,\,{\leq}\,\,b_{n-1}\,\,{\leq}\,\,\,{\ldots}\,\,\,{\leq}\,\,b_{1}$,
    it follows easily that $a_{i}\,<\,b_{j}$ for each pair of indices $i$ and~$j$.

\V

        (2) The nested sequence of intervals described above is said to be a {\bf bisection sequence}\IndB{bisection}{bisection sequence} provided that
    for each index $n$ the interval $[a_{n+1},b_{n+1}]$ is one of the halves of the preceding interval $[a_{n},b_{n}]$.
    That is, if one sets $c_{n} \,=\, (a_{n}+b_{n})/2$, so $c_{n}$ is the midpoint of $[a_{n},b_{n}]$,
    then $[a_{n+1},b_{n+1}]$ is one of the two subintervals $[a_{n},c_{n}]$ or $[c_{n},b_{n}]$.
    (Equivalently, either $a_{n+1} \,=\, a_{n}$ and $b_{n+1} \,=\, c_{n}$, or $a_{n+1} \,=\, c_{n}$ and $b_{n+1} \,=\, b_{n}$.)
    One then says that this bisection sequence is {\bf based on} the original interval $[a_{1},b_{1}]$.

\V

            \subsection{\small{\bf The Bisection Principle}}
            \label{DefB30.05B}\IndB{bisection}{bisection principle}
\V

        Suppose that $[a_{1},b_{1}]$, $[a_{2},b_{2}]$, \,{\ldots}\,$[a_{n},b_{n}]$,\,{\ldots}\, is a bisection sequence,
    in the sense of Definition~\Ref{DefB30.05A}.
    Then the intersection ${\bigcap}_{k=1}^{{\infty}} [a_{k},b_{k}]$ of this family of intervals is a set with exactly one element.
    If $c$ is that number, then one says that one obtains $c$ by the {\bf bisection procedure}\IndB{bisection}{bisection procedure, method} or the {\bf bisection method} starting with the initial interval $[a_{1},b_{1}]$.

\VV

        It is an instructive exercise to return to Example~\Ref{ExampB25.90} above to show that
    the Bisection Principle does {\em not} hold in the or dered field~${\QQ}$. Note that this exercise is not as simple as it may seem at first.

%%EXERCISE ON \sqrt{2}; GIVE HINTS?

%% EXERCISE ON CUBE ROOT OF 10; EXERICISE ON MONOTONIC FUNCTION f FOR WHICH BISECTION PRODUCES A UNIQUE c BUT f(c)  \,\,{\neq}\,\, y_{0}?.

\VV

        All seven of the major `Principles' listed above -- Right-Endpoint and Left-Endpoint, Supremum and Infimum, Least-Upper-Bound and Greatest-Lower-Bound, Bisection
    -- are encountered frequently in analysis, so it is important to know them all.


\V

        The next theorem says, in effect, that all these `Principles' are equivalent in any ordered field.

\V

            \subsection{\small{\bf Theorem}}
            \label{ThmB30.10A}

        The seven principles stated above, namely Bolzano's Right-Endpoint and Left-Endpoint Principles, the Supremum and Infimum Principles,
    the Least-Upper-Bound and Greatest-Lower-Bound Priniples and the Bisection Principle, are equivalent.
    That is, if one of these principles holds in a given ordered field, then all the others also hold in that field.

\V

        {\bf Proof} The equivalence of the Right-Endpoint Principle and the Left-Endpoint Principle is easy to check and is left as an exercise.
    The same is true for the equivalence of the Supremum and Infimum Principles and for the equivalence of the Least-Upper-Bound and Greatest-Lower-Bound Principles.
    Also, the equivalence of the Supremum Principle with the Right-Endpoint Principle follows from Lemma~\Ref{LemmaB30.08}.
    Thus, it suffices to show the equivalence of the Supremum Principle with the Least-Upper-bound Principle and with the Bisection Principle.

\V

            \subsection{\small{Lemma}}
            \label{LemmaB30.08CC}

\V

        The Supremum Principle implies the Least-Upper-Bound Principle. Moreover, in this situation one has ${\sup}\,X \,=\, \mbox{lub}\,X$ for every nonempty set $X$ which is bounded above.

\V

        {\bf Proof}\, Suppose that $X$ is a nonempty set which is bounded above. Then the Supremum Principle implies that $X$ has a supremum; call it~$B$. 
    Condition~(i) of Definition~\Ref{DefB30.08A} then implies that $B$ is in the set~$U_{X}$ of upper bounds of~$X$.
    Furthermore, suppose that $y\,<\,B$. Then by Condition~(ii) of the same definition there exists $x{\in}X$ such that $y\,<{\leq}\,\,x$;
    in particular, if $y\,<\,B$ then $y$ is {\em not} an upper bound of~$X$. Thus $B$ is the {\em least} element of~$U_{X}$.
    That is, the existence of ${\sup}\,X$ implies the existence of $\mbox{lub}\,X$.
    Moreover, the fact that $B$ is the least upper bound of $X$ translates to the equation ${\sup}\,X \,=\, \mbox{lub}\,X$, as required.


\V

            \subsection{\small{Lemma}}
            \label{LemmaB30.08CCC}

\V

        The Least-Upper-Bound Principle implies the Bisection Principle.

\V

        {\bf Remark} We actually prove the contrapositive statement: if the Bisection Principle fails to hold, then so does the Least-Upper-Bound Principle.

\V

        {\bf Proof}\, Suppose that the Bisection Principle is {\em not} valid. Let $[a_{1},b_{1}]$, $[a_{2},b_{2}]$,\,{\ldots}\, be a bisection sequence
    for which the conclusion of this principle, namely that there exists exactly one number which lies in each of the intervals $[a_{n},b_{n}]$, fails to hold.
    This failure occurs either when there is no number which lies in each interval or when there is more than one such number.

\VA

        \h \underline{Case 1} Suppose that there does not exist any number which lies in all of the intervals in the given bisection sequence.
    If this happens, then for every number $u$ there exists an index $m$ such that $u \not \in [a_{m},b_{m}]$.
    For this $m$ one then has either $u\,<\,a_{m}$ or $u\,>\,b_{m}$. Based on this observation,
    let $X$ be the set of all numbers $x$ such that $x\,<\,a_{k}$ for at least one index~$k$.
    Clearly every number less than $a_{1}$ is in $X$, so $X \,\,{\neq}\,\, {\emptyset}$.
    Likewise, $b_{n}\,>\,a_{k}$ for every $k$ and $n$ so clearly each $b_{n}$ is an upper bound for~$X$.
    Let $c$ be any upper bound for~$X$. Then certainly $c\,\,{\geq}\,\,a_{n}$ for every~$n$;
    indeed, if $c\,<\,a_{k}$ for some $k$ then $c\,<\,x\,<\,a_{k}$ for, say, $x \,=\, (c+a_{k})/2$,
    and clearly $x{\in}X$, contrary to $c$ being an upper bound of~$X$. But by the observation above, with $u \,=\, c$,
    it follows that there must exist $m$ such that $c\,>\,b_{m}$, and therefore $c$ is not the least upper bound of~$X$.
    In other words, no upper bound of $X$ is the least upper bound of~$X$, so in this case the Least-Upper-Bound Principle fails.

\VA

        \h \underline{Case 2} Suppose that the set of numbers which lie in each interval $[a_{n},b_{n}]$ has more than one element.
    Let $c$ and $d$ be such numbers with $c \,\,{\neq}\,\, d$; without loss of generality we may assume that they are labeled so that $c\,<\,d$.
    Then one has $a_{n}\,\,{\leq}\,\,c\,<\,d\,\,{\leq}\,\,b_{n}$ for each index~$n$. It follows from the definition of `bisection sequence' that
        \begin{displaymath}
        0\,<\,d-c\,\,{\leq}\,\,b_{n}-a_{n} \,=\, \frac{b_{1}-a_{1}}{2^{n-1}} \mbox{ for each index $n$}.
        \end{displaymath}
    Let $Y$ be the set of numbers of the form $(b_{n}-a_{n})/2^{n-1}$ with $n$ in~${\NN}$, so that $d-c$ is a positive lower bound for the set~$Y$.
      Now let $L$ be any positive lower bound for $Y$,
    so that $0\,<\,L\,\,{\leq}\,\,(b_{1}-a_{1})/2^{n-1}$ for each $n$. Then $0\,<\,2\,L\,\,{\leq}\,\,(b_{1}-a_{1})/2^{n}$ for each~$n$ in~${\NN}$.
    Since $1/2^{n}\,<\,1/2^{0} \,=\, 1$ for every $n$ in~${\NN}$, it follows that $2\,L$ must also be a lower bound for $Y$.
    Since $2\,L\,>\,L$, because $L\,>\,0$, it follows that $Y$ does not have a greatest lower bound.
    Thus in this case the Greatest-Lower-Bound Principle fails to hold.

        In summary, if the Bisection Principle fails to hold, then either the Least-Upper-Bound Principle must fail (Case~1)
    or the Greatest-Lower-Bound Principle must fail (Case~2); in either case, {\em both} of these principles must fail since they are equivaent.

\V

            \subsection{\small{Lemma}}
            \label{LemmaB30.08CCCC}

\V

        The Bisection Principle implies the Supremum Principle.

\V

        {\bf Proof} Let $X$ be a nonempty set of numbers which is bounded above.
    To simplify the exposition a bit, let $S$ denote the set of all numbers $y$ such that $y\,<\,x$ for at least one element $x$ in $X$,
    and let $U_{X}$ denote the set of upper bounds of~$X$; the hypotheses on $X$ ensure that
    both these sets are nonempty and that every number is an element of exactly one of these sets.
    Let $a_{1}$ be an element of $S$ and $b_{1}$ an element of~$U_{X}$; clearly $a_{1}\,<\,b_{1}$.
    Let $m_{1}$ be the midpoint of the interval $[a_{1},b_{1}]$, and note, as above, that $m_{1}$ is in exactly one of the sets $S$ or $U_{X}$.
    If $m_{1}{\in}S$, then define $[a_{2},b_{2}]$ to be the half interval $[m_{1},b_{1}]$;
    while if $m_{1}{\in}U_{X}$, define $[a_{2},b_{2}]$ to be $[a_{1},m_{1}]$. It is clear that $a_{2}{\in}S$ and $b_{2}{\in}U_{X}$.
    Continuing this way one obtains a bisection sequence $[a_{1},b_{1}]$, $[a_{2},b_{2}]$, \,{\ldots}\, $[a_{n},b_{n}]$\,{\ldots}\, such that $a_{n}{\in}S$ and $b_{n}{\in}U_{X}$.
    The Bisection Principle implies that there is exactly one number $c$ which lies in each of these intervals.

        \underline{Claim 1} The number $c$ satisfies Condition~(i) of Definition~\Ref{DefB30.08A}. That is, $c$ is an upper bound of the set~$X$.

        \underline{Proof of Claim 1} Suppose not. Then there exists a number $x$ in $X$ such that $c\,<\,x$.
    Since $c$ is the only number which lies in each of the intervals $[a_{n},b_{n}]$,
    it follows that there exists an index $m$ such that $x \not \in [a_{m}, b_{m}]$.
    Since $a_{n}\,\,{\leq}\,\,c$ for all $n$, it follows that that $a_{n}\,<\,x$ for all $n$, including $n \,=\, m$.
    Thus the only way $x$ could not be in $[a_{m}, b_{m}]$ is if $x\,>\,b_{m}$.
    Since, by construction, $b_{m}{\in}U_{X}$, it follows that $z\,\,{\leq}\,\,b_{m}\,<\,x$
    for every element $z$ of $X$, including $z \,=\, x$, which is impossible. Thus, no such $x$ exists, so $c$ is an upper bound of $X$, as claimed.

        \underline{Claim 2} The number $c$ satisfies Condition~(ii) of Definition~\Ref{DefB30.08A}, i.e., the Approximation Property for the Supremum.
    That is, if $y\,<\,c$ then there exists $x$ in $X$ such that $y\,<\,x$.

        \underline{Proof of Claim 2} If $y\,<\,c$ then, by the fact that $c$ is the only number which lies in each interval $[a_{n}, b_{n}]$,
    it follows that there must be an index $m$ such that $y\not \in [a_{m},b_{m}]$.
    Since $y\,<\,c\,\,{\leq}\,\,b_{n}$ for all $n$, it follows that $y$ cannot satisfy $y\,>\,b_{m}$,
    and therefore $y\,<\,a_{m}$. However, $a_{m}{\in}S$ by construction, so there exists $x$ in $X$ such that $a_{m}\,<\,x$ and thus $y\,<\,x$, so that Condition~(ii) is satisfied.

        It follows that $X$ has a supremum, namely $c$, and the Supremum Principle is satisfied, as required.

\VV

        The fact that the Supremum Principle implies the Least-Upper-Bound Principle, the Least-Upper-Bound Principle implies the Bisection Principle,
    and the Bisection Principle implies the Supremum Principle, guarantees that all three of these principles are equivalent.
    Combined with the other equivalences obtained earlier, it follows that all seven principles are equivalent, as claimed.


\VV

        In light of the preceding theorem, the following makes sense.

\V

            {\bf The Completeness Axiom}\IndA{completeness axiom for {\RR}}

\V

        At least one of the seven preceding `Principles' holds in the ordered field~${\RR}$;
    equivalently, {\em each} of the preceding `Principles' holds in the ordered field~${\RR}$.
    One abbreviates this by saying that ${\RR}$ is a {\bf complete ordered field}\IndBD{algebraic field}{complete ordered field}.

\VV

        \underline{Remark} Adding the Completeness Axiom allows one to distinguish between the ordered fields ${\RR}$ and~${\QQ}$.
    It may come as a surprise that no further axioms for ${\RR}$ are needed.
    More precisely, {\em every} pair of complete ordered fields are essentially the same, in a sense to be made clearer in Appendix~C.


%%%
\begin{quotation}
{\footnotesize \underline{\Note}\IndB{\notes}{on Dedekind's treatment of $\sqrt{2}$} (on Dedekind's treatment of $\sqrt{2}$)

        The proof to be given below that ${\QQ}$ does not satisfy the Least-Upper-Bound Principle is based on a clever observation
    made by Richard Dedekind in his famous pamphlet of~1872 {\em Stetigkeit und irrationale zahlen} (Continuity and Irrational Numbers).


\VA

        \h \underline{Dedekind's Observation}
    Let $x$ be a positive rational number; it is well known that that $x^{2} \,\,{\neq}\,\, 2$.
    Now let ${\displaystyle y \,=\, \frac{x\,(x^{2} + 6)}{3\,x^{2} + 2}}$; note that clearly $y$ is also a positive rational number.
    Then it is a simple exercise, which the reader is encouraged to carry out, to show that $y^{2}$ lies strictly between $x^{2}$ and~$2$.
    That is, if $x^{2}\,>\,2$ then $x^{2}\,>\,y^{2}\,>\,2$, while if $x^{2}\,<\,2$ then $x^{2}\,<\,y^{2}\,<\,2$.

\VA

        The application of Dedekind's observation to the issue at hand is simple.
    Indeed, let $S$ be the set of rational numbers $x$ such that $x\,>\,0$ and $x^{2}\,<\,2$;
    This set is nonempty; for example $1{\in}S$. It is also bounded above in ${\QQ}$ by, say, $3$.
    Let $B$ be any positive number in ${\QQ}$. It is impossible that $B^{2} \,=\, 2$, so either $B^{2}\,>\,2$ or $B^{2}\,<\,2$.
    Suppose first that $B^{2}\,<\,2$. Then by Dedekind's observation there exists a rational number $y$ such that $0\,<\,B\,<\,y$ and $y^{2}\,<\,2$.
    In particular, $y{\in}S$, so $B$ is not an upper bound of the set $S$.
    Next, suppose that $B^{2}\,>\,2$. Then by Dedekind's observation there exists
    a rational number $y$ such that $B\,<\,y$ and $2\,<\,y^{2}\,<\,B^{2}$.     Since $y^{2}\,>\,2$, it follows that $y$ is an upper bound of~$S$.
    In this case, $B$ is also an upper bound of $S$, but because $y\,<\,B$ it is clear that $B$ is not the {\em least} such upper bound.
    In particular, no rational nnumber can be the least upper bound of~$S$.

        \underline{Remark} It is worth pondering how someone might come up with the formula for~$y$ used by Dedekind.

}%EndFootNoteSize
\end{quotation}       
%##

            \subsection{\small{\bf Remarks}}
            \label{RemrkB30.10B}

\V

\hspace*{\parindent} (1) In light of the fact, mentioned above, that the Bisection Principle does {\em not} hold in the ordered field~${\QQ}$,
    it follows that ${\QQ}$ is {\em not} a complete ordered field.

\V

        (2) Most modern textbooks choose the Least-Upper-Bound Principle as their choice of the `official' Completeness Axiom for~${\RR}$,
    and then treat all the other principles as theorems to be proved using this axiom (combined, of course, with the axioms for an ordered field).

        The obvious advantage is simplicity: the Least-Upper-Bound Principle can be stated
    with virtually no preparation other than knowing the meaning of `least element of a set' and `upper bound of a set', both simple ideas.

        One obvious disadvantage, however, is that most readers first encounter the phrase `least upper bound'
    about three paragraphs before the statement of the corresponding axiom, so it is hard to argue that this axiom's claim is already `clearly true'.
    In particular, the existence of a certain number, which this axiom claims, is not obvious to the beginners that have never considered the issue before.

        A less obvious difficulty, but perhaps even more important for beginners,
    is that this principle involves sets of numbers which can be of arbitrary complexity.
    However, most beginning students of analysis have little experience with complicated sets of numbers.
    Any axiom which involves sets of such variety can hardly be considered to be `obviously true'.
    (The same objections could be raised about choosing the Greatest-Lower-Bound  Principle as the Completeness Axiom;
    but hardly any text uses that Principle as its version of the Completeness Axiom, so that issue is moot.)

\V

        (3) The Bolzano Principles, along with Supremum and Infimum Principles, also have the defect of not being `obviously true'.
    In addition, they require substantially more preparation before one can even state them.
    Finally, all these principles are comparatively recent: Bolzano's is the oldest, and it dates from the early nineteenth century.

\V

        (4) The Bisection Principle is, of course, considerably more complicated to state than the other principles.
    However, the statement involves approximation techniques which have been in common use for millenia, and thus really are familiar.
    In addition, the sets which appear in this principle are simple and well known: intervals.
    Even a beginner should be willing to accept this statement about real numbers as being `obviously true'; that is, `axiomatic'.
    The statement of this Principle also reflects the fact that `Completeness' should support the intuition that there are no `holes' in the real numbers;
    a `hole' would correspond to the case in which the intersection of the nested intervals in question is the empty set.

\V

        (5) There are other principles that could be used as the `Completeness Axiom'.
    For example, the most elementary approach would be to base it on the fact that every real number has a representation in terms of the decimal notation,
    where here `elementary' refers to the fact everybody learns the relevant facts about this representation in elementary-school arithmetic.
    Some of these alternate approaches are discussed later.

\VV

        The next several results show some properties of ${\RR}$ which do not follow directly
    from the axioms of an ordered field, and thus require `Completeness'.

\V

            \subsection{\small{\bf Theorem}}
            \label{ThmB30.30}

        The subset ${\NN}$ of ${\RR}$ is unbounded above in ${\RR}$.

\V

        \underline{Proof}: For each $n$ in ${\NN}$ let $a_{n} \,=\, 0$ and $b_{n} \,=\, 1/2^{n-1}$.
    Then the intervals $[a_{1}, b_{1}]$, $[a_{2},b_{2}]$, \,{\ldots}\, $[a_{n},b_{n}]$, \,{\ldots}\,
    obviously form a bisection sequence of intervals in~${\RR}$. It is also obvious that the number $0$ is an element of each of these intervals.
    Since, by the Bisection Principle, there is exactly one number with this property,
    it follows that for every number $u\,>\,0$ there exists an index $n$ such that $u \not \in [0,1/2^{n-1}]$, and thus $u\,>\,1/2^{n-1}$.
    In particular, let $u \,=\, 1/B$ for some positive number~$B$. Then one has $B\,<\,2^{n-1}$. In particular, no number can be an upper bound for~${\NN}$.

\V


            \subsection{\small{\bf Corollary} (The Principle of Archimedes)}\IndA{Archimedes, Principle of}\IndD{Principle of Archimedes}{Archimedes, Principle of}
            \label{CorB30.40}

\V

        Let ${\varepsilon}$ and $M$ be positive real numbers.

\V

         \h (a) There exists a natural number $k$ such that $k\,{\varepsilon}\,>\,M$.


\V

        \h (b) Equivalently, there exists a natural number $k$ such that $M/k\,<\,{\varepsilon}$.

\V

        \h (c) More generally, there exists a real number $B$ such that if $k$ is a natural number such that $k\,\,{\geq}\,\,B$, then $k\,{\varepsilon}\,>\,M$;
    equivalently, $M/k\,<\,{\varepsilon}$.

\V

        The simple proof is left as an exercise. Note that Part~(c) is the formulation
    of the Principle of Archimedes which is most often used in practice.


\V
\V

            \subsection{\small{\bf Remarks}}
            \label{RemrkB30.50}

\hspace*{\parindent}(1) The `Archimedes' referred to in the name `Archimedean Principle'
    is the most celebrated  Greek geometer and scientist of ancient times, Archimedes of Syracuse (c.~250 BC).
    To understand what Archimedes means, think of ${\varepsilon}$ as `very small, but positive', and $M$ as `enormously large'.
    Then the property states that by repeatedly adding a small quantity to itself, one can obtain quantities which are arbitrarily large.
    (Compare this with Chapter Quote~\#2, made hundreds of years before Archimedes.)
    Another way of paraphrasing this property is that `There are no infinitely small positive quantities.'


\V

        (2) One can easily prove directly, without invoking completeness, that the ordered field ${\QQ}$ has the Archimedean Principle `within itself'.
    Equivalently, one can prove that the sets ${\NN}$ and ${\QQ}$ are unbounded above (and below) in the ordered field~${\QQ}$;
    compare with Theorem~\Ref{ThmA20.10}.
    In contast, one cannot prove that either of the sets ${\NN}$ or ${\QQ}$ is unbounded above
    in ${\RR}$ using only the axioms from Sections~\Ref{SectB10} and~\Ref{SectB20}.
    Indeed, there exist examples of ordered fields for which the sets ${\NN}$ and~${\QQ}$, viewed as subsets of the field, are bounded above in that field. 
    Such fields are called {\em non-Archimedean fields} in light of the preceding corollary.
    We have no need to study such fields in {\ThisText}, but it is good to know that they exist.

\V
\V

        The Archimedien Principle implies the following useful result.

\V

            \subsection{\small{\bf Theorem} (Density of ${\QQ}$ in ${\RR}$)}\IndB{density}{of ${\QQ}$ in ${\RR}$}
            \label{ThmB30.55}

\V

  \hspace*{\parindent}Let $c$ be any real number. Then for every ${\varepsilon}\,>\,0$
    there are infinitely many rational numbers $r$ such that $|r-c|\,<\,{\varepsilon}$.


\V

        {\bf Proof} For simplicity, assume that $c\,>\,0$; the other cases can be reduced to this and are left to the reader.
    Let $n_{0}$ be a natural number such that $1/n_{0}\,<\,{\varepsilon}$; such $n_{0}$ exists by the Principle of Archimedes.
    Then, also by the Principle of Archimedes, there exists an integer $k$, necessarily positive, such that $k/n_{0}\,>\,c$.
    Let $m_{0}$ be the smallest such~$k$; see~\Ref{PrinA10.11}. Then $(m_{0}-1)$ is an integer such that $(m_{0}-1)/n\,\,{\leq}\,\,c\,<\,m_{0}/n_{0}$.
    One computes that 
        \begin{displaymath}
        0\,<\,\frac{m_{0}}{n_{0}} - c\,\,{\leq}\,\,\frac{m_{0}}{n_{0}} - \frac{m_{0}-1}{n_{0}}
     \,=\,
        \frac{1}{n_{0}}\,<\,{\varepsilon}
        \end{displaymath}
    Next, apply the same argument to the same $c$, but now with the original ${\varepsilon}$ replaced by ${\varepsilon}_{1} \,=\, m_{0}/n_{0} - c$,
    to get natural numbers $m_{1}$ and $n_{1}$ such that $0\,<\,c - m_{1}/n_{1}\,<\,{\varepsilon}_{1}$. Clearly $m_{1}/n_{0}\,<\,m_{0}/n_{0}$.
    Continuing this way, one gets a sequence of rational numbers $m_{j}/n_{j}$, $j \,=\, 0,1,2,\,{\ldots}\,$ such that $0\,<\,c-m_{j}/n_{j}\,<\,{\varepsilon}$.
    The rational numbers $r_{j} \,=\, m_{j}/n_{j}$ have been constructed to be be distinct, so there are infinitely many of them.

\V

        {\bf Remarks} (1) For obvious reasons, the preceding theorem is often abbreviated to the statement that
    `the rational numbers form a dense subset of~${\RR}$'. We use this formulation as the basis for a more general concept of `denseness' later.

\V

        (2) Many texts define the concept of `denseness of ${\QQ}$ in ${\RR}$' as follows:

\VA

        \h If $a$ and $b$ are real numbers such that $a\,<\,b$,
    then there exists a rational number $r$ such that $a\,<\,r\,<\,b$.

\VA

\hspace*{\parindent} It is a simple exercise to prove that these formulations are equivalent. %% EXERCISE?

\VV

        The next results are closely related to the Bisection Principle.

\V


            \subsection{\small{\bf Theorem} The Nested-Intervals and Nested-Segments Theorems in ${\RR}$}\IndA{nested intervals/segments theorems in ${\RR}$}
            \label{ThmC20.40}

\V

\hspace*{\parindent}(a) (The Nested-Intervals Theorem) Let $(I_{1}, I_{2},\,{\ldots}\,I_{k}\,{\ldots}\,)$
    be a sequence of closed bounded intervals in~${\RR}$.

         \underline{Claim 1} If the sequence $(I_{1}, I_{2},\,{\ldots}\,I_{k},\,{\ldots}\,)$ is nested
    (see Definition~\Ref{DefB30.05A}), then the intersection $J \,=\, {\bigcap}\,_{k=1}^{{\infty}} I_{k}$
    of these intervals is a nonempty subset of~${\RR}$.

        More precisely, write each $I_{k} \,=\, [a_{k},b_{k}]$, where $a_{k}$ and $b_{k}$ are real numbers such that $a_{k}\,<\,b_{k}$,
    and let ${\alpha} \,=\, (a_{1}, a_{2},\,{\ldots}\,a_{k},\,{\ldots}\,)$ and ${\beta} \,=\, (b_{1}, b_{2},\,{\ldots}\,b_{k},\,{\ldots}\,)$
    be the corresponding sequences of endpoints of these intervals. As usual, let $S_{{\alpha}}$ and $S_{{\beta}}$ denote the term-sets
    $\{a_{1}, a_{2},\,{\ldots}\,a_{k}, \,{\ldots}\,\}$ and $\{b_{1},b_{2},\,{\ldots}\,b_{k},\,{\ldots}\,\}$ of these sequences,
    and let $A \,=\, {\sup}\,S_{{\alpha}}$ and $B \,=\, {\inf}\,S_{{\beta}}$. Then $A$ and $B$ are both finite, and $J \,=\, \mbox{Seg}\,[A,B]$.

        \underline{Claim 2} If, in addition, for every ${\varepsilon}\,>\,0$ there exists an index $k$ such that $|b_{k}-a_{k}|\,<\,{\varepsilon}$,
    then $A \,=\, B$ and $J$ is a singleton set~$\{c\}$, where $c \,=\, A \,=\, B$.

\V

        (b) (The Nested-Segments Theorem) Replace `interval' throughout Part~(a) by `segment' and `$[a_{k},b_{k}]$' by `$\mbox{Seg}\,[a_{k},b_{k}]$',
    and drop the requirement $a_{k}\,<\,b_{k}$. The resulting claims are still true.

\V

        \underline{Proof}

\V

        (a) \underline{Claim 1} It is shown in Example~\Ref{ExampB30.05AA}~(1) that the sequence ${\alpha}$ is monotonic up,
    while the sequence ${\beta}$ is monotonic down. It is also shown that ${\alpha}$ is bounded above (by $b_{j}$ for each index~$j$,
    while ${\beta}$ is bounded below (by $a_{i}$ for each~$i$). It follows from basic properties of `supremum' and `infimum'
    that $A$ and $B$ are both finite and that $A\,\,{\leq}\,\,B$.

        Since $A$ is an upper bound for the set $S_{{\alpha}}$ it follows that  $a_{k}\,\,{\leq}\,\,A\,\,{\leq}\,\,B$ for each index~$k$;
    similarly, $A\,\,{\leq}\,\,B\,\,{\leq}\,\,b_{k}$ for each~$k$. More precisely, if $x$ is any real number such that 
    $A\,\,{\leq}\,\,x\,\,{\leq}\,\,B$, then $a_{k}\,\,{\leq}\,\,A\,\,{\leq}\,\,x\,\,{\leq}\,\,B\,\,{\leq}\,\,b_{k}$
    for each index~$k$. That is, every element of the set $\mbox{Seg}\,[A,B]$ is an element of each of the intervals $[a_{k},b_{k}]$,
    which implies that $\mbox{Seg}\,[A,B] \,{\subseteq}\, J$.

    Conversely, suppose that $y \not \in \mbox{Seg}\,[A,B]$. Then either $y\,<\,A$ or $y\,>\,B$. Suppose that the former situation holds.
    Then, by the Approximation Property for Suprema, there exists an element $a_{k}$ in the set $S_{{\alpha}}$ such that $y\,<\,a_{k}$.
    It follows that for this $k$ one has $y \not \in [a_{k},b_{k}]$, and thus $y \not \in J$.
    By a similar argument, using the Approximation Property for Infima, one sees that if $y\,>\,B$ then $y \not \in J$.
    It follows that $J \,{\subseteq}\, \mbox{Seg}\,[A,B]$.

        Combining these results implies that $\mbox{Seg}\,[A,B] \,=\, J$, as claimed.

        {\bf Remark} One must write $J \,=\, \mbox{Seg}\,[A,B]$, and not $J \,=\, [A,B]$, because it is possible that $A \,=\, B$ instead of $A\,<\,B$;
    the latter situation would be required to use the interval notation $[A,B]$.

\VA

        \underline{Claim 2} From the string of inequalities $a_{k}\,\,{\leq}\,\,A\,\,{\leq}\,\,B\,\,{\leq}\,\,b_{k}$, valid for each~$k$,
    it follows that
        \begin{displaymath}
        0\,\,{\leq}\,\,|B-A|\,\,{\leq}\,\,|b_{k}-a_{k}| \mbox{ for each index $k$}.
        \end{displaymath}
    Now let ${\varepsilon}\,>\,0$ be given. From the hypothesis in this Claim, there exists $k$ such that $|b_{k}-a_{k}|\,<\,{\varepsilon}$.
    It follows that $0\,\,{\leq}\,\,|B-A|\,<\,{\varepsilon}$ for every ${\varepsilon}\,>\,0$.
    It then follows from the Principle of Eudoxus that $A \,=\, B$, as claimed.

\V

        (b) The simple modifications of the preceding proof needed to prove the desired result are left to the reader.

\V

        \underline{Note} The absolute values which appear in the statement and proof of Claim~2 in Part~(a) are obviously not really needed.
    However including them makes the transition from Part~(a) to Part~(b) a bit simpler.

\VV

            \subsection{\small{\bf Remarks}}
            \label{ThmC20.45}

\V

\hspace*{\parindent}(1)  Some texts apply the name `Nested-Intervals Principle' only to the result stated in Claim~1 of the preceding theorem.
    Also, some authors use the name `Cantor Intersection Theorem' in place of `Nested-Intersection Theorem'.

\V

        (2) In his famous treatment of analysis, {\em Foundations of Modern Analysis},
    French mathematician Jean Dieudonn\'{e} used Claim~(1) of Part~(a) of the preceding theorem, together with the Archimedean Principle, as his `Completeness Axiom'.
    It is easy to show that this version of `Completeness' is equivalent to all the other versions discussed in this chapter.


\VV


        {\bf Reminder} Definition~\Ref{DefB20.130} describes the concept of `interval in ${\RR}$' by writing down nine different cases.
    Assuming that ${\RR}$ is complete allows one to sometimes avoid slogging through these nine cases.

\V

            \subsection{\small{\bf Theorem}}
            \label{ThmB30.160}

\V

        Let $X$ be a subset of ${\RR}$. Then the following statements are equivalent.

        \h (i)\, The set $X$ is an interval in ${\RR}$, in the sense of Definition~\Ref{DefB20.130}.

        \h (ii) The set $X$ has at least two points, and $X$ is a convex subset of ${\RR}$, in the sense of Definition~\Ref{DefB20.140}.

\V

        {\bf Proof} The fact that Statement~(i) implies Statement~(ii) has already been pointed out; see Example~\Ref{ExampB20.155B}.

        Conversely, suppose that Statement (ii) holds. Let $a \,=\, {\inf}\,X$ and $b \,=\, {\sup}\,X$.
    These quantities certainly exist, since the set $X$ is nonempty. Moreover, the fact that $X$ has at least two elements implies that $a \,\,{\neq}\,\, b$.
    Of course, it is possible that $a \,=\, -{\infty}$ or $a{\in}{\RR}$, and it is possible that $b{\in}{\RR}$ or $b \,=\, +{\infty}$.
    Now consider the various possibilities:

    \h (a) If $a{\in}X$ and $b{\in}X$, then set $I \,=\, [a,b]$.

    \h (b) If $a{\in}X$ and $b \not \in X$, then set $I \,=\, [a,b)$.

    \h (c) If $a \not \in X$ and $b{\in}X$, then set $(a,b]$.

    \h (d) If $a \not \in X$ and $b \not \in X$, then set $I \,=\, (a,b)$.

\noindent It is easy to show that $X \,=\, I$; in particular, $X$ is an interval.
    For example, suppose that (d) holds, so that $I \,=\, (a,b)$. Then $I \,=\, \{u{\in}{\RR}:a\,<\,u\,<\,b\}$.
    If $x{\in}X$ then $a\,\,{\leq}\,\,x\,\,{\leq}\,\,b$, since $a$ is a lower bound for $X$ and $b$ is an upper bound for $X$.
    Moreover, $a \,\,{\neq}\,\, x$ and $b \,\,{\neq}\,\, u$, since Condition~(d) holds.
    Thus, $a\,<\,x\,<\,b$. That is, $X \,{\subseteq}\, I$.

        Conversely, suppose that $u{\in}I$, so that $a\,<\,u\,<\,b$.
    By the properties of `$\inf$' and `$\sup$', there must exist elements $x_{1}$ and $x_{2}$ of $X$ such that
        \begin{displaymath}
        a\,\,{\leq}\,\,x_{1}\,<\,u\,<\,x_{2}\,\,{\leq}\,\,b.
        \end{displaymath}
    In particular, $u{\in}\mbox{Seg}\,[x_{1},x_{2}]$.
    Since $X$ is convex, it follows that $\mbox{Seg}\,[x_{1},x_{2}] \,{\subseteq}\, X$.
    In particular, since $u{\in}\mbox{Seg}\,[x_{1},x_{2}]$, it follows that $u{\in}X$. That is, $I \,{\subseteq}\, X$.
    The fact that $X \,=\, I$ now follows.

        The proof in Cases~(a), (b) and (c) that one also has $X \,=\, I$ is similar, and is left to the reader.



            \section{\bf Base-$N$ Reprsentations of Real Numbers}\IndA{base-$N$ representations of real numbers}
            \label{SectB40}\IndB{ZZ Sections}{\Ref{SectB40} Base-$N$ Representations}

\V

        Any axiom system for the real number system should be able to reproduce all the familiar features of that system.
    One of the most important of those features -- important because it is in constant use by almost everyone --
    is the decimal representation of real numbers; that is, representation to base~10.
    Of course representations using other bases are also important; for example, in computer programming
    representations in base-$2$ (`binary') and base-$16$ (`hexadecimal') are widely used.
    The next several results clarify and justify the use of such representations, at least for numbers in the closed unit interval~$[0,1]$.
    (In {\ThisText} we use these representations only for such numbers; the extension of the theory to {\em all} real numbers is then easy to carry out.)

\V

            \subsection{\small{\bf Definition}}
            \label{DefB30.65A}

\V

        Let $N$ be a fixed natural number such that $N\,\,{\geq}\,\,2$.

\V


        (1) The {\bf base $\Bfm{N}$ digits}\IndB{base $N$ representations of real numbers}{base $N$ digits} are the nonegative integers $k$ such that $0\,\,{\leq}\,\,k\,\,{\leq}\,\,N-1$.

        \underline{Remark} In {\ThisText} the only bases that are used are $N \,=\, 2, 3, 10$.
    In these cases the `base-$N$' terminology is normally replaced by `{\bf binary}', `{\bf ternary}' and `{\bf decimal}', respectively.
    \IndBD{base $N$ representations of real numbers}{binary digits}
    \IndBD{base $N$ representations of real numbers}{ternary digits}
    \IndBD{base $N$ representations of real numbers}{decimal digits}

\V

        (2) Let $(d_{1}, d_{2},\,{\ldots}\,d_{k})$ be a $k$-tuple of base-$N$ digits.
    The  corresponding {\bf base-$\Bfm{N}$ fraction}\IndB{base $N$ representations of real numbers}{base $N$ fractions} is the rational number
    $0 \stackrel{(N)}{.}d_{1}\,d_{2}\,\,{\ldots}\,d_{k}$ given by the rule
        \begin{displaymath}
        0 \stackrel{(N)}{.}d_{1}\,d_{2}\,\,{\ldots}\,d_{k} \,=\, \frac{d_{1}}{N} + \frac{d_{2}}{N^{2}} + \,{\ldots}\, + \frac{d_{k}}{N^{k}}.
        \end{displaymath}
    The the symbol $\stackrel{(N)}{.}$ in this expression is called the {\bf base-$\Bfm{N}$ point}\IndB{base $N$ representations of real numbers}{base-$N$ point};
    if $N \,=\, 10$, the `$(N)$' above the dot is usually omitted, and the symbol is simply called the {\bf decimal point}.
    Also, the leading zero before this point is optional; it is usually included however for ease of reading.

        \underline{Remark} Since $0\,\,{\leq}\,\,d_{j}\,\,{\leq}\,\,N-1$ for each index~$j$,
    it follows from Part~(a) of Theorem~\Ref{ThmB25.80}, using $u \,=\, 1/N$ in that theorem,
    that $0\stackrel{(N)}{.}d_{1}\,d_{2}\,\,{\ldots}\,\,d_{k}\,\,{\leq}\,\,$
        \begin{displaymath}
        \frac{N-1}{N} + \frac{N-1}{N^{2}} + \,{\ldots}\, + \frac{N-1}{N^{k}}
     \,=\, 
        \left(\frac{N-1}{N}\right)\,\left(1 + \frac{1}{N} + \,{\ldots}\, + \frac{1}{N^{k-1}}\right)
     \,=\, 
        \end{displaymath}
        \begin{displaymath}
        \left(\frac{N-1}{N}\right)\,\left(\frac{1-(1/N)^{k}}{1-(1/N)}\right)
     \,=\, 
        \,\left(1- \frac{1}{N^{k}}\right)
    \,<\, 1.
        \end{displaymath}
    That is, every base-$N$ fraction lies in the interval $[0,1)$. Also it is easy to show that a number $x$ in $[0,1)$
    is a base-$N$ fraction if, and only if, it can be expressed as a fraction $k/N^{m}$ where $k$ and $m$ are nonnegative integers and $k\,<\,N^{m}$.

\V

        (3) Let ${\sigma} \,=\, (d_{1}, d_{2},\,{\ldots}\,d_{n},\,{\ldots}\,)$ be an infinite sequence of base-$N$ digits, a so-called {\bf base-$\Bfm{N}$ sequence}\IndB{base $N$ representations of real numbers}{base $N$ sequence}.
    Associate with ${\sigma}$ the set $X_{{\sigma}} \,=\, \{0\,\stackrel{(N)}{.}\,d_{1}, 0\,\stackrel{(N)}{.}\,d_{1}\,d_{2},\,{\ldots}\, 0\,\stackrel{(N)}{.}\,d_{1}\,d_{2},\,\,{\ldots}\,d_{k},\,{\ldots}\,\}$, 
    consisting of all the base-$N$ fractions which arise from these digits in the given order.
    It is clear, from the preceding `Remark', that this set is bounded above (by~$1$) and thus, by `Completeness', has a finite supremum.
    The number ${\sup}\,X_{{\sigma}}$
    is called {\bf the real number with base-$\Bfm{N}$ representation determined by the sequence ${\sigma}$};
    it is denoted by the infinite expression $0\,\stackrel{(N)}{.}\,d_{1}\,d_{2}\,\,{\ldots}\,d_{n}\,\,{\ldots}\,$.

\V

        It follows from what was said above that for each base-$N$ sequence ${\sigma} \,=\, (d_{1}, d_{2},\,{\ldots}\,)$
    the corresponding number $0\,\stackrel{(N)}{.}\,d_{1}\,d_{2}\,\,{\ldots}\,$ lies in the interval $[0,1]$.
    The next result says, among other things, that {\em every} number in $[0,1]$ has a base-$N$ representation of this type.

\V

            \subsection{\small{\bf Theorem}}
            \label{ThmB30.65B}

\V

\hspace*{\parindent} (a) Let $N$ be any natural number such that $N\,\,{\geq}\,\,2$,
    and let $x$ be any number in the closed interval $[0,1]$ in ${\RR}$. Then there exists at least one base-$N$ sequence
    ${\sigma} \,=\, (d_{1}, d_{2},\,{\ldots}\,d_{n},\,{\ldots}\,)$ such that $x \,=\, 0\,\stackrel{(N)}{.}\,d_{1}\,d_{2}\,\,{\ldots}\,d_{n}\,\,{\ldots}\,$.

\V

        (b) Suppose that $x$ and $y$ are real numbers in the interval $[0,1]$ with base-$N$ representations $x \,=\, 0\,\stackrel{(N)}{.}\,d_{1}\,d_{2}\,\,{\ldots}\,$ and $y \,=\, 0\,\stackrel{(N)}{.}\,c_{1}\,c_{2}\,\,{\ldots}\,$.
    Suppose futher that $d_{n}\,\,{\leq}\,\,c_{n}$ for each index~$n$.
    Then $x\,\,{\leq}\,\,y$, with equality if, and only if, $d_{n} \,=\, c_{n}$ for each~$n$.
    More precisely, if for some index $k$ one has $d_{k}\,<\,c_{k}$, then ${\displaystyle x\,\,{\leq}\,\,y-\left(\frac{c_{k}-d_{k}}{N^{k}}\right)}$.

        \underline{Extreme Cases} The number $x \,=\, 0$ corresponds to the base-$N$ sequence ${\sigma}_{0} \,=\, (0,0,\,{\ldots}\,0,\,{\ldots}\,)$,
    and to no other base-$N$ sequence. Likewise, the number $x \,=\, 1$ corresponds to the base-$N$ sequence
    ${\sigma}_{N-1} \,=\, (N-1,N-1,\,{\ldots}\,N-1,\,{\ldots}\,)$, and to no other base-$N$ sequence.

        \underline{Remark} Recall that the only base-$N$ representations under consideration here start with zero to the left of the decimal point.
    In particular, the familiar base-$N$ representation $1\,\stackrel{(N)}{.}\,0\,0\,\,{\ldots}\,0\,{\ldots}\,$ for the number~$1$ is not allowed here.

\V

        (c) Suppose that $0\,<\,x\,<\,1$. Then a necessary and sufficient condition
    for $x$ to correspond to more than one base-$N$ sequence is that $x$ be a base-$N$ fraction; see Part~(a) of Definition~\Ref{DefB30.65A}.
    More precisely, suppose that $x$ equals the base-$N$ fraction $0\,\stackrel{(N)}{.}\,d_{1}\,d_{2}\,\,{\ldots}\,d_{k}$.
    Since, by hypothesis, $x\,>\,0$, it follows that at least one of the digits in this expression must be positive.
    Since any zero digits beyond the final nonzero digit contribute nothing to the value of the number~$x$,
    one can omit all such `trailing zero digits' and assume that the final digit $d_{k}$ is positive.
    Then $x$ corresponds to the base-$N$ sequences ${\sigma} \,=\, (d_{1}, d_{2},\,{\ldots}\, d_{k-1}, d_{k}, 0, 0,\,{\ldots}\,0, \,{\ldots}\,)$
    and ${\tau} \,=\, (d_{1}, d_{2}, \,{\ldots}\, d_{k-1}, (d_{k}-1),N-1, N-1, \,{\ldots}\,N-1, \,{\ldots}\,)$, and to no other such sequences.

\V

        (d) If $x$ is given by the base-$N$ representation $x \,=\, 0\,\stackrel{(N)}{.}\,d_{1}\,d_{2}\,\,{\ldots}\,d_{n}\,\,{\ldots}\,$.
    then for each $k$ one has
        \begin{displaymath}
        |x - 0\,\stackrel{(N)}{.}\,d_{1}\,d_{2}\,\,{\ldots}\,d_{k}|\,\,{\leq}\,\,\frac{1}{N^{k}}.
        \end{displaymath}
    Furthemore, one has equality for some $k$ if, and only if, $d_{m} \,=\, 0$ for all $m\,>\,k$; that is, if, and only if, $x$ is a base-$N$ fraction.

\V

        (e) Suppose that $x$ and $y$ are numbers in the interval $[0,1]$ which are given by the base-$N$ representations
    $x \,=\, 0\,\stackrel{(N)}{.}\,d_{1}\,d_{2}\,\,{\ldots}\,d_{n}\,{\ldots}\,$ and
    $y \,=\, 0\,\stackrel{(N)}{.}\,c_{1}\,c_{2}\,\,{\ldots}\,c_{n}\,{\ldots}\,$.
    If for some natural number $k$ one has $d_{j} \,=\, c_{j}$ for $1\,\,{\leq}\,\,j\,\,{\leq}\,\,k$, then $|x-y|\,\,{\leq}\,\,1/N^{k}$.

\V

        (f) Suppose that $x$ and $y$ are as in Part~(e) above, with $x \,\,{\neq}\,\, y$.
    Let $m$ be the smallest natural number such that $d_{m} \,\,{\neq}\,\, c_{m}$.
    Then $|x-y|\,\,{\geq}\,\,||d_{m}-c_{m}| - 1|/1/N^{m}$. In particular, if the digits $d_{m}$ and $c_{m}$ differ by at least~$2$,
    then $|x-y|\,\,{\geq}\,\,1/N^{m}$.

        {\bf Proof} Most of the proof simply reviews ideas from grade-school arithmetic.

\V

        (a) Recursively define a sequence $d_{1}$, $d_{2}$,\,{\ldots}\, of base-$N$ digits as follows:

        \h \underline{Initial Step} Note that there exists at least one base-$N$ digit $d$ such that $d/N\,\,{\leq}\,\,x$; for example, $d \,=\, 0$ has this property.
    Define $d_{1}$ to be the maximal such digit. It is clear that ${\displaystyle \frac{d_{1}}{N}\,\,{\leq}\,\,x\,\,{\leq}\,\,\frac{d_{1} + 1}{10}}$.
    Indeed, if $d_{1}\,<\,N-1$ then $d_{1}+1$ is also a base-$N$ digit, so that the stronger inequality
    ${\displaystyle \frac{d_{1} + 1}{N}\,>\,x}$ follows from the maximality condition on $d_{1}$.
    If $d_{1} \,=\, N-1$, so that $1+d_{1} \,=\, N$ is not a base-$N$ digit, then ${\displaystyle \frac{1+d_{1} }{N} \,=\, \frac{N}{N} \,=\, 1}$,
    so the required inequality follows from the hypothesis $x\,\,{\leq}\,\,1$.

        \h \underline{Recursive Step} Suppose that digits $d_{1}$, $d_{2}$, \,{\ldots}\,$d_{k}$ have been defined so that
        \begin{displaymath}
        \frac{d_{1}}{N} + \,{\ldots}\, + \frac{d_{k}}{N^{k}}
    \,\,{\leq}\,\,
        x
    \,\,{\leq}\,\,
        \frac{d_{1}}{N} + \,{\ldots}\, + \frac{1+d_{k}}{N^{k}};
        \end{displaymath}
    that is,
        \begin{displaymath}
        0\,\stackrel{(N)}{.}\,d_{1}\,d_{2}\,\,{\ldots}\,d_{k} \,\,{\leq}\,\, x\,\,{\leq}\,\,
        0\,\stackrel{(N)}{.}\,d_{1}\,d_{2}\,\,{\ldots}\,d_{k} + \frac{1}{10^{k}} \h ({\ast})
        \end{displaymath}
    If the inequality on the left side of~$({\ast})$ is actually an equation, then define $d_{k+1} \,=\, 0$;
    it is then easy to show that one will have $d_{m} \,=\, 0$ for all $m\,\,{\geq}\,\,k+1$.
    If, instead, the inequality on the left side of~$({\ast})$ is strict, then let $d_{k+1}$ be the greatest of the base-$N$ digits $d$ such that
    ${\displaystyle \frac{d}{N^{k+1}}\,\,{\leq}\,\,x-\left(\frac{d_{1}}{N} + \,{\ldots}\, + \frac{1+d_{k}}{N^{k}}\right)}$.
    Then, as before, the maximality condition on $d_{k+1}$ implies
        \begin{displaymath}
        \frac{d_{1}}{N} + \,{\ldots}\, + \frac{d_{k}}{N^{k}} + \frac{d_{k+1}}{N^{k+1}}
    \,\,{\leq}\,\,
        x
    \,\,{\leq}\,\,
        \frac{d_{1}}{10} + \,{\ldots}\, + \frac{d_{k}}{10^{k}} + \frac{1+d_{k+1}}{10^{k+1}};
        \end{displaymath}
    that is,
        \begin{displaymath}
        0\,\stackrel{(N)}{.}\,d_{1}\,d_{2}\,{\ldots}\,d_{k}\,d_{k+1} 
    \,\,{\leq}\,\,
        0\,\stackrel{(N)}{.}\,d_{1}\,d_{2}\,\,{\ldots}\,d_{k}\,d_{k+1} + \frac{1}{10^{k+1}}.
        \end{displaymath}
        Let ${\sigma} \,=\, (d_{1}, d_{2},\,{\ldots}\,d_{n},\,{\ldots}\,)$ be the resulting decimal sequence.

        \underline{Claim} The given number $x$ satisfies $x \,=\, 0.d_{1}\,d_{2}\,\,{\ldots}\,d_{n}\,\,{\ldots}\,$.

        \underline{Proof of Claim} Let $X_{{\sigma}}$ be the set of base-$N$ fractions $\{0\,\stackrel{(N)}{.}\,d_{1}, 0\,\stackrel{(N)}{.}\,d_{1}\,d_{2}, \,{\ldots}\,\}$.
    It is clear from the left side of~$({\ast})$ than $x$ is an upper bound of the set~$X_{{\sigma}}$.
    Furthermore, if ${\varepsilon}\,>\,0$ is given, then, by the Archimedes Principle,
    there exists $k$ such that ${\displaystyle \frac{1}{N^{k}}\,<\,{\varepsilon}}$.
    It follows from this, when combined with the right side of~$({\ast})$, that
        \begin{displaymath}
        x-{\varepsilon}\,<\,x- \frac{1}{N^{k}}\,\,{\leq}\,\, 0\,\stackrel{(N)}{.}\,d_{1}\,d_{2}\,\,{\ldots}\,d_{k}.
        \end{displaymath}
    Since the right side of the last inequality is an element of $X_{{\sigma}}$, and ${\varepsilon}\,>\,0$ is arbitrary,
    it follows from Definition~\Ref{DefB30.08A} that $x \,=\, {\sup}\,X_{{\sigma}}$, as required.

\V

        (b) This follows easily from the definition of base-$N$ representation together with Part~(a) of Theorem~\Ref{ThmB25.80}.

\V

        (c) Suppose that $x$ is a positive base-$N$ fraction, so that $x$ can be written in the form~ $0\,\stackrel{(N)}{.}\,d_{1}\,d_{2}\,\,{\ldots}\,d_{k}\,0\,0\,{\ldots}\,$,
    with $d_{k}\,>\,0$. Then it is easy to show, using Part~(a) of Theorem~\Ref{ThmB25.80} that
    $x \,=\, 0\,\stackrel{(N)}{.}\,d_{1}\,\,{\ldots}\,d_{k-1}\,(d_{k}-1)\,(N-1)\,(N-1)\,{\ldots}\,$.
    Reversing this argument, one sees that if $x$ has a base-$N$ representation which ends entirely in the base-$N$ digit~$N-1$,
    then it has a second representation which ends entirely in the base-$N$ digit~$0$, and thus is a base-$N$ fraction.

        Now suppose that $x$ cannot be expressed in either of the preceding forms;
    that is, it is not possible to express $x$ with a base-$N$ representation that ends
    entirely in the base-$N$ digit~$0$ or ends entirely in the base-$N$ digit~$(N-1)$.
    Let $0\,\stackrel{(N)}{.}\,d_{1}\,d_{2}\,\,{\ldots}\,d_{n}\,\,{\ldots}\,$ and $0\,\stackrel{(N)}{.}\,c_{1}\,c_{2}\,\,{\ldots}\,c_{n}\,\,{\ldots}\,$ be 
    base-$N$ representations of~$x$. Suppose, first, that $d_{1} \,\,{\neq}\,\, c_{1}$; without loss of generality, assume that $d_{1}\,<\,c_{1}$.
    Then clearly
        \begin{displaymath}
        0\,\stackrel{(N)}{.}\,0\,d_{2}\,\,{\ldots}\,d_{n}\,\,{\ldots}\,
     \,=\, 
        \frac{c_{1}-d_{1}}{N} +
        0\,\stackrel{(N)}{.}\,0\,c_{2}\,\,{\ldots}\,c_{n}\,\,{\ldots}\,
        \end{displaymath}
    Arguing as above, one sees that
        \begin{displaymath}
        0\,\stackrel{(N)}{.}\,0\,d_{2}\,\,{\ldots}\,d_{n}\,\,{\ldots}\,
    \,\,{\leq}\,\,
        0\,\stackrel{(N)}{.}\,0\,(N-1)\,\,{\ldots}\,(N-1)\,\,{\ldots}\,
     \,=\, \frac{1}{N}
        \end{displaymath}
    with equality if, and only if, $d_{k} \,=\, N-1$ for each $k\,\,{\geq}\,\,2$.
    By hypothesis one has $c_{1}\,>\,d_{1}$. Also $0\,\stackrel{(N)}{.}\,0\,c_{2}\,\,{\ldots}\,c_{n}\,\,{\ldots}\,
    \,\,{\geq}\,\,0$, with equality if, and only if, $c_{k} \,=\, 0$ for every $k\,\,{\geq}\,\,2$.
    It follows that $c_{1}-d_{1} \,=\, 1$, $0\,\stackrel{(N)}{.}\,0\,d_{2}\,\,{\ldots}\,d_{n}\,\,{\ldots}\, \,=\, 1$,
    and $0\,\stackrel{(N)}{.}\,0\,c_{2}\,\,{\ldots}\,c_{n}\,\,{\ldots}\, \,=\, 0$.
    Thus, $c_{1}\,>\,d_{1}$ conflicts with the hypothesis that $x$ does not admit either of the forms above.

\V

        (d), (e) and (f) The proofs of these statements are left as exercises.


\VV

        Part (b) of the preceding theorem says, in effect, that if two numbers in $[0,1]$ have
    base-$N$ representations which are the same for the first $k$ digits, then the numbers differ by at most $1/N^{k}$.
    Unfortunately, the converse is very far from true: numbers which are close to each other may fail to agree in any of their digits;
    see, for example, the decimal expressions for the number $1/10$,
    $0.1\,0\,0\,{\ldots}\,0\,{\ldots}\,$ and $0.0\,9\,9\,\,{\ldots}\,9\,{\ldots}\,$.
    For the applications of base-$N$ representations used in {\ThisText}, the following partial result is sufficient.

\V

            \subsection{\small{\bf Theorem}}
            \label{ThmB30.65C}

\V


         Let $x$ and $y$ be numbers in $[0,1]$ with base-N representations $\stackrel{(N)}{.}\,d_{1}\,d_{2}\,\,{\ldots}\,$ and
    $0\,\stackrel{(N)}{.}\,c_{1}\,c_{2}\,\,{\ldots}\,$, respectively.
    Suppose that there is an index $k$ such that $d_{j} \,=\, c_{j}$ for each $j$ such that $1\,\,{\leq}\,\,j\,\,{\leq}\,\,k$,
    but $d_{k+1} \,\,{\neq}\,\, c_{k+1}$. Let $m \,=\, |d_{k+1}-c_{k+1}|$, so that $m\,\,{\geq}\,\,1$.
    Then one has
        \begin{displaymath}
        |x-y|\,\,{\geq}\,\,\frac{m-1}{N^{k+1}}
        \end{displaymath}
    In particular, if the first unequal digits $d_{k+1}$ and $c_{k+1}$ differ by at least $2$ units, then $|x-y|\,\,{\geq}\,\,1/N^{k+1}$.

\V

        The simple proof is left as an exercise.

\VV

%--------------
\StartSkip{
            \subsection{\small{\bf Extended Supremum, Infimum}}
            \label{RemrkB30.110}


\hspace*{\parindent} (1) If $X$ is a nonempty set which is {\em not} bounded above, it is convenient to set ${\sup}\,X \,=\, +{\infty}$.
    Likewise, if $X$ is a nonempty set which is {\em not} bounded below, one sets ${\inf}\,X \,=\, -{\infty}$.
    With these conventions, the concepts of ${\sup}\,X$ and ${\inf}\,X$ make sense for every nonempty set of real numbers.

\V

        (3) In {\TheseNotes} we do not assign a meaning to the expressions ${\sup}\,{\emptyset}$ and ${\inf}\,{\emptyset}$.
    Note, however, that some texts find it convenient, if a bit unsettling, to define ${\sup}\,{\emptyset} \,=\, -{\infty}$ and ${\inf}\,{\emptyset} \,=\, +{\infty}$.

\V
\V

        The simple proofs of the following facts concerning supremums and infimums are left as exercises for the reader.


            \subsection{\small{\bf Theorem}}
            \label{ThmB30.150}

\V

\hspace*{\parindent}(a) If $X$ is a nonempty subset of ${\RR}$ then ${\inf}\,X\,\,{\leq}\,\,{\sup}\,X$;
    moreover, one gets equality (i.e., one has ${\inf}\,X \,=\, {\sup}\,X$) if, and only if, $X$ is a singleton set.

\V

        (b) Suppose that $X$ and $Y$ are nonempty sets such that $X \,{\subseteq}\, Y$.
    Then:

        \h (i)\, ${\sup}\,X\,\,{\leq}\,\,{\sup}\,Y$

        \h (ii) ${\inf}\,X\,\,{\geq}\,\,{\inf}\,Y$

\noindent \underline{Warning}: Note that the inequality used in Part~(ii) is the reverse of that in Part~(i). This reversal can cause confusion.

\V

        (c) Suppose that $X$ and $Y$ are nonempty sets of real numbers, and that for all $x$ in $X$ and all $y$ in $Y$ one has $x\,\,{\leq}\,\,y$.
    Then ${\sup}\,X\,\,{\leq}\,\,{\inf}\,Y$.


\V
\V

        Definition~\Ref{DefB20.130} describes the concept of `interval in ${\RR}$' by writing down nine different cases.
    Assuming that ${\RR}$ is complete allows one to sometimes avoid slogging through these nine cases.

\V

            \subsection{\small{\bf Theorem}}
            \label{ThmB30.160}

\V

        Let $X$ be a subset of ${\RR}$. Then the following statements are equivalent.

        \h (i)\, The set $X$ is an interval in ${\RR}$, in the sense of Definition~\Ref{DefB20.130}.

        \h (ii) The set $X$ has at least two points, and $X$ is a convex subset of ${\RR}$, in the sense of Definition~\Ref{DefB20.140}.

\V

        {\bf Proof} The fact that Statement~(i) implies Statement~(ii) has already been pointed out; see Example~\Ref{ExampB20.155B}.

        Conversely, suppose that Statement (ii) holds. Let $a \,=\, {\inf}\,X$ and $b \,=\, {\sup}\,X$.
    These quantities certainly exist, since the set $X$ is nonempty. Moreover, the fact that $X$ has at least two elements implies that $a \,\,{\neq}\,\, b$.
    Of course, it is possible that $a \,=\, -{\infty}$ or $a{\in}{\RR}$, and it is possible that $b{\in}{\RR}$ or $b \,=\, +{\infty}$.
    Now consider the various possibilities:

    \h (a) If $a{\in}X$ and $b{\in}X$, then set $I \,=\, [a,b]$.

    \h (b) If $a{\in}X$ and $b \not \in X$, then set $I \,=\, [a,b)$.

    \h (c) If $a \not \in X$ and $b{\in}X$, then set $(a,b]$.

    \h (d) If $a \not \in X$ and $b \not \in X$, then set $I \,=\, (a,b)$.

\noindent It is easy to show that $X \,=\, I$; in particular, $X$ is an interval.
    For example, suppose that (d) holds, so that $I \,=\, (a,b)$. Then $I \,=\, \{u{\in}{\RR}:a\,<\,u\,<\,b\}$.
    If $x{\in}X$ then $a\,\,{\leq}\,\,x\,\,{\leq}\,\,b$, since $a$ is a lower bound for $X$ and $b$ is an upper bound for $X$.
    Moreover, $a \,\,{\neq}\,\, x$ and $b \,\,{\neq}\,\, u$, since Condition~(d) holds.
    Thus, $a\,<\,x\,<\,b$. That is, $X \,{\subseteq}\, I$.

        Conversely, suppose that $u{\in}I$, so that $a\,<\,u\,<\,b$.
    By the properties of `$\inf$' and `$\sup$', there must exist elements $x_{1}$ and $x_{2}$ of $X$ such that
        \begin{displaymath}
        a\,\,{\leq}\,\,x_{1}\,<\,u\,<\,x_{2}\,\,{\leq}\,\,b.
        \end{displaymath}
    In particular, $u{\in}\mbox{Seg}\,[x_{1},x_{2}]$.
    Since $X$ is convex, it follows that $\mbox{Seg}\,[x_{1},x_{2}] \,{\subseteq}\, X$.
    In particular, since $u{\in}\mbox{Seg}\,[x_{1},x_{2}]$, it follows that $u{\in}X$. That is, $I \,{\subseteq}\, X$.
    The fact that $X \,=\, I$ now follows.

        The proof in Cases~(a), (b) and (c) that one also has $X \,=\, I$ is similar, and is left to the reader.

\V
\V

        In analysis one frequently must consider the union and intersection of a family of intervals.
    The following examples illustrate some of the possibilities.

\V

            \subsection{\small{\bf Examples}}
            \label{ExampB30.170}

\V

\hspace*{\parindent}(1) For each $k$ in ${\NN}$ let $I_{k}$ be the open interval $(0,1/k)$ with $k$ in ${\NN}$.
    One readily determines that
        \begin{displaymath}
        {\bigcap}_{k=1}^{{\infty}} I_{k} \,=\, {\emptyset} \mbox{ and }
        {\bigcup}_{k=1}^{{\infty}} I_{k} \,=\, I_{1} \,=\, (0,1).
        \end{displaymath}

\V

        (2) For each $k$ in ${\NN}$ let $I_{k}$ be the closed interval $[0,1/k]$ with $k$ in ${\NN}$.
    One readily determines that
        \begin{displaymath}
        {\bigcap}_{k=1}^{{\infty}} I_{k} \,=\, \{0\} \mbox{ and }
        {\bigcup}_{k=1}^{{\infty}} I_{k} \,=\, I_{1} \,=\, [0,1].
        \end{displaymath}

\V

        (3) For each $k$ in ${\NN}$ let $I_{k}$ be the unbounded interval $[k,+{\infty})$ with $k$ in ${\NN}$.
    One readily determines that
        \begin{displaymath}
        {\bigcap}_{k=1}^{{\infty}} I_{k} \,=\, {\emptyset} \mbox{ and }
        {\bigcup}_{k=1}^{{\infty}} I_{k} \,=\, I_{1} \,=\, [1,+{\infty}).
        \end{displaymath}

\V

        (4) For each $k$ in ${\NN}$ let $I_{k}$ be the closed bounded interval $[-2+1/k,4-1/k]$.
    One readily checks that
        \begin{displaymath}
        {\bigcap}_{k=1}^{{\infty}} I_{k} \,=\, [-1,3] \mbox{ and }
        {\bigcup}_{k=1}^{{\infty}} I_{k} \,=\, (-2,4).
        \end{displaymath}

\V
\V

        Of particular importance in analysis are sets that can be formed from the union of open intervals.
}%\EndSkip
%---------------------

\V

%----------------------------------------------------
\StartSkip{
            \subsection{\small{\bf Theorem}}
            \label{ThmB30.180}

        Suppose that ${\cal F}$ is a nonempty family of open intervals in ${\RR}$, and let $W \,=\, {\bigcup} {\cal F}$ be the union of these intervals.
    Then $W$ can be expressed as the union of a {\em countable family} of {\em mutually disjoint} open intervals in ${\RR}$.

\V

        {\bf Proof} 


Define a binary relation $\,{\sim}\,$ on $W$ by the rule
        \begin{displaymath}
        \mbox{If $x$ and $y$ are in $W$, then } x\,{\sim}\,y \mbox{ if, and only if, Seg}\,[x,y] \,{\subseteq}\, W.
        \end{displaymath}
    It is easy to see that $\,{\sim}\,$ is an equivalence relation on $W$; the
details are left as an exercise.
    It follows from basic properties of `equivalence classes' that $W$ is the {\em disjoint} union of these classes.
    Thus it suffices to show that each of these equivalence classes is an open interval, and that there are only countably many of them.

\V

        \underline{Claim 1} Each equivalence class for the equivalence relation $\,{\sim}\,$ is an open interval in ${\RR}$.

        \underline{Proof of Claim 1} Let $U_{0}$ be such an equivalence class;
    denote the infimum and supremum of $U_{0}$ by ${\alpha}_{0}$ and ${\beta}_{0}$, respectively.
    Note that $U_{0}$ is a subset of the open interval $({\alpha}_{0},{\beta}_{0})$.
    Now let $x_{0}$ be any element of $U_{0}$. Since $x_{0}{\in}W$, there must exist an open interval $(a,b)$ in the family ${\cal F}$ such that $a\,<\,x_{0}\,<\,b$.
    It is clear that every point of $(a,b)$ is equivalent to $x_{0}$, and thus $(a,b)$ is a subset of the equivalence class $U_{0}$.
    In particular, since there are elements of $(a,b)$ that are less than $x_{0}$, and elements of $(a,b)$ that are greater than $x_{0}$,
    it follows that ${\alpha}_{0}\,<\,x_{0}\,<\,{\beta}_{0}$.
    In particular, ${\alpha}_{0}$ and ${\beta}_{0}$ are not themselves elements of $U_{0}$.
    In contrast, however, suppose that $z$ is an element of $({\alpha}_{0},{\beta}_{0})$.
    Then, by definition of ${\alpha}_{0}$ and ${\beta}_{0}$, there exist elements $y_{1}$ and $y_{2}$ of $U_{0}$
    such that ${\alpha}_{0}\,<\,y_{1}\,<\,z\,<\,y_{2}\,<\,{\beta}_{0}$.
    Since $y_{1}$ and $y_{2}$ are both in the equivalence class $U_{0}$,
    it follows that $\mbox{Seg}\,[y_{1},y_{2}] \,{\subseteq}\, U_{0}$, and thus, in particular, $z{\in}U_{0}$
    (since $y_{1}\,<\,y_{2}$ implies that $z{\in}\mbox{Seg}\,[y_{1},y_{2}]$). Since $z$ can be any element of $U_{0}$, it now follows that $U_{0} \,=\, ({\alpha}_{0},{\beta}_{0})$, and thus $U_{0}$ is an open interval, as claimed.

\V

        \underline{Claim 2} The set $W/{\sim}$ of all equivalence classes for the equivalence relation $\,{\sim}\,$ is countable.

        \underline{Proof of Claim 2} Let $(r_{1},r_{2},\,{\ldots}\,r_{k},\,{\ldots}\,)$ be an enumeration of the set ${\QQ}$ of all rational numbers.
    (Such a sequence exists because the set ${\QQ}$ is countably infinite.)
 For each equivalence class $U$ of the relation ${\sim}$, let $A_{U}$ be the set of all $k$ in ${\NN}$ such that $r_{k}{\in}U$.
    Since (by Claim~1 above) $U$ is an open interval, it follows from Theorem~\Ref{ThmB30.55} that $A_{U} \,\,{\neq}\,\, {\emptyset}$.
    Now define $G:W/{\sim} \,{\rightarrow}\, {\NN}$ by the rule that if $U$ is an equivalence class of ${\sim}$,
    then $G(U)$ is the smallest element of the set $A_{U}$; see the Least-Natural-Number Principle.
    It is clear that $G$ is an {\em injection} of $W/{\sim}$ onto a subset of ${\NN}$.
    Indeed, if $U$ and $V$ are elements of $W/{\sim}$ such that $G(U) \,=\, G(V) \,=\, k$, then $r_{k}{\in}U$ and $r_{k}{\in}V$, hence $U$ and $V$ are not disjoint from each other.
    By a basic property of `equivalence classes', this implies $U \,=\, V$.

        Since there exists an injection of $W/{\sim}$ onto a subset of ${\NN}$, it follows that $W/{\sim}$ has the same cardinality as a subset of ${\NN}$,
    and thus is itself a countable set, as claimed.

\V

        The sets that can be formed as in the preceding theorem play an important role in calculus.
        %% TEMPORARY REFERENCE ~\Ref{ChaptE}
    Roughly speaking, they are the most general sets on which the concept of `derivative' (see Chapter~E) makes complete sense.

\V

            \subsection{\small{\bf Definition}}
            \label{DefB30.185}

        A nonempty subset of ${\RR}$ is said to be an {\bf open set in {\RR}} provided it can be expressed as the union of a nonempty family of open intervals in ${\RR}$.
    For sake of completeness, one also defines the empty set to be an open set in ${\RR}$.

\V
\V

        We end this section with a simple concept that is sometimes useful.

\V

            \subsection{\small{\bf Definition}}
            \label{DefB30.190}

\V

        Let $X$ be a nonempty subset of ${\RR}$, and let $A \,=\, \{z{\in}{\RR}: z \,=\, |y-x| \mbox{ for at least one pair of numbers $x$ and $y$ in $X$}\}$.
    Then the {\bf diameter of $X$}, denoted $\mbox{diam}\,(X)$, is the quantity ${\sup}\,A$.
    Stated more briefly:
        \begin{equation}
        \label{EqnB.100}
        \mbox{diam}\,(X) \,=\, {\sup}\,\{|y-x|: x,y{\in}X\}
        \end{equation}

\V
\V

        The proofs of the following facts about `diameter' are left as easy exercises.

\V

            \subsection{\small{\bf Theorem}}
            \label{ThmB30.200}

\V

        Let $X$ be a nonempty subset of ${\RR}$. Then:

\V

        (a) One has $0\,\,{\leq}\,\,\mbox{diam}\,(X)\,\,{\leq}\,\,+{\infty}$;

\V

        (b) One has $\mbox{diam}\,(X) \,=\, 0$ if, and only if, $X$ is a singleton set;
    likewise, one has $\mbox{diam}\,(X) \,=\, +{\infty}$ if, and only if, $X$ is unbounded.

\V

        (c) If $X$ is a bounded set then $\mbox{diam}\,(X) \,=\, {\sup}\,X - {\inf}\,X$.

\V

        (d) If $X$ and $Y$ are nonempty bounded subsets of ${\RR}$ then
        \begin{displaymath}
        \mbox{diam}\,(X\,{\cup}\,Y)\,\,{\leq}\,\,\mbox{diam}\,(X) + \mbox{diam}\,(Y).
        \end{displaymath}

\V

        (e) Suppose that $X$ and $Y$ are nonempty subsets of ${\RR}$ such that $X \,{\subseteq}\, Y$.
    Then $\mbox{diam}\,(X)\,\,{\leq}\,\,\mbox{diam}\,(Y)$.

\V

        (f) Equation~\Ref{EqnB.100} remains valid if the absolute value sign on the right side is removed;
    that is, if one replaces $|y-x|$ by $y-x$.

\V
\V
}%\EndSkip
%----------------------------------

%--------------------------------
\StartSkip{ % ADDENDUM I, II
\newpage

%\thispagestyle{myheadings}

\V
\V

                        \section{ADDENDUM ONE TO CHAPTER~\Ref{ChaptB}}: All Complete Ordered Fields are Equivalent
                        \label{SectBAdd1}

SectBAdd1 ADDENDUM ONE TO CHAPTER~\ref{ChaptB}: All Complete Ordered Fields are Equivalent

\VV

        We have seen that the ordered fields ${\QQ}$ and~${\RR}$ are similar to each other, but definitely not equivalent;
    for example, the former set is countably infinite, while the latter is uncountable.
    Such differences can be explained by the fact that ${\RR}$ satisfies the Completeness Axiom, while ${\QQ}$ does not.
    However, this immediately raises the question of whether there are additional axioms needed to finish the description of the real number system.
    The main goal of this Addendum is to show that this cannot happen; roughly speaking, we can stop with the list of axioms already obtained.

\V

%--------------------------------------
% Positive Dedekind Cuts

        The basic idea uses the fact that every complete ordered field has the ordered field ${\QQ}$ as a dense subset; see Theorem~\Ref{ThmB30.55}.
    More specifically, in his famous pamphlet of~1872 {\em Stetigkeit und irrationale zahlen} (Continuity and Irrational Numbers),
    Richard Dedekind introduced the concept of what is now called a `Dedekind cut' in the set~${\QQ}$.
    We follow here the simplified approach found in the classic book {\em Grundlagen der Analysis} (Foundations of Analysis) by Edmund Landau.
    In Landau's approach, one deals first only with {\em positive} numbers, and then later extends the theory to all numbers.
    In particular, we focus for now on the sets ${\RR}^{+}$ and ${\QQ}^{+}$, consisting of positive real and rational numbers, respectively.
    Likewise, we use the prefix `$+$' repeatedly as a reminder that we deal here with positive quantities only.

\V

        {\bf Observation} If $x$ is any positive real number, then $x$ determines a subset $D_{x}^{+}$ of ${\QQ}^{+}$ given by the following rule:

\VA

        \h $D_{x}^{+} \,=\, \{r{\in}{\QQ}: 0\,<\,r\,<\,x\}$.

\VA

\noindent It follows easily from the Archimedean Principle in ${\RR}$ (and thus in ${\RR}^{+}$)
    that the set $D_{x}^{+}$ is nonempty, does not equal ${\QQ}^{+}$, and has no greatest element.
    Furthermore, it has the property that if $r{\in}D_{x}^{+}$, then $s{\in}D_{x}^{+}$ for each rational number $s$ such that $0\,<\,s\,<\,r$.
    It is obvious that if $x_{1}$ and $x_{2}$ are positive real numbers, then $x_{1} \,=\, x_{2}$ if, and only if, $D_{x_{1}}^{+} \,=\, D_{x_{2}}^{+}$.
    Dedekind's clever idea (as modified in Landau's approach) is to consider the reverse situation.

\V

        {\bf Definition} A {\bf Dedekind $+$-cut} is a subset $A$ of ${\QQ}^{+}$ with the following properties:

\VA

        (a) The set $A$ is nonempty, but $A \,\,{\neq}\,\, {\QQ}^{+}$.

\VA

        (b) For every number $a$ in $A$, if $r$ is any rational number such that $0\,<\,r\,<\,a$, then $r{\in}A$.

\VA

        (c) The set $A$ does not have a maximum element.

\V

 \noindent In {\ThisText} we denote the set of all Dedekind $+$-cuts by ${\cal D}_{{\QQ}}^{+}$.

\VV

        {\bf Theorem} For every $x \,=\, {\RR}^{+}$ the set $D_{x}^{+}$ described above is a Dedekind $+$-cut.
    Conversely, every Dedekind $+$-cut $A$ is of the form $D_{x}^{+}$ for exactly one $x$ in~${\RR}^{+}$.

        \underline{Modern statement}: There is a natural bijection $F:{\RR}^{+} \,{\rightarrow}\, {\cal D}_{{\QQ}}^{+}$, given by the rule
        \begin{displaymath}
        F(x) \,=\, D_{x} \mbox{ for all $x$ in ${\RR}^{+}$} \h ({\ast})
        \end{displaymath}
    The inverse of this map is given by $F^{-1}(A) \,=\, {\sup}\,A$ for each $A$ in ${\cal D_{{\QQ}}}^{+}$.

\V

        The simple proof is left as an exercise.

\V

        One can go further. Indeed, it is possible to define a natural `order' relation,
    as well as natural operations of `addition' and `multiplication', on the set ${\cal D}_{{\QQ}}^{+}$:

\V

        \underline{Definition 1} Let $A$ and $B$ be Dedekind $+$-cuts. One says that {\bf \Bfm{A} is less than $\Bfm{B}$}, denoted $A\,<\,B$, provided $A$ is a proper subset of~$B$.

\VA

        \underline{Claim 1} Express the Dedekind $+$-cuts $A$ and $B$ in the form $A \,=\, D_{x}^{+}$ and $B \,=\, D_{y}^{+}$ for positive real numbers $x$ and $y$, as above.
    Then $A\,<\,B$ if, and only if, $x\,<\,y$.

        \underline{Proof} Suppose that $0\,<\,x\,<\,y$. Then $x{\in}D_{y}^{+}$, by the definition of $D_{y}^{+}$.
    Also, if $a{\in}A$ then $0\,<\,a\,<\,x\,<\,y$ hence $a{\in}B$. Since, by the definition of  `$+$-cut',
    one has $x \not \in A$, it follows that $A$ is a proper subset of $B$, as required.

        Conversely, suppose that $A\,<\,B$; that is, $A$ is a proper subset of~$B$.
    Let $x$ and $y$ be the positive real numbers such that $A \,=\, D_{x}^{+}$ and $B \,=\, D_{y}^{+}$.
    Since $A$ is a proper subset of $B$, there exists $b$ in $B$ such that $b \not \in A$.
    By the definition of $D_{x}^{+}$, this implies that $x\,\,{\leq}\,\,b$. However, by definition of $B$ one has $b\,<\,y$.
    Thus $x\,\,{\leq}\,\,b\,<\,y$, so $x\,<\,y$, as required.

\V

        \underline{Definition 2} Let $A$ and $B$ be Dedekind $+$-cuts. The {\bf sum of $\Bfm{A}$ and $\Bfm{B}$}, denoted $A+B$,
    is the set of all (positive) rational numbers $c$ of the form $c \,=\, a+b$ with $a$ in $A$ and $b$ in $B$.

        \underline{Claim 2} (i) If $A$ and $B$ are Dedekind $+$-cuts, then so is the set $A+B$.

        (ii) Let $x$ and $y$ be the positive reals such that $A \,=\, D_{x}^{+}$ and $B \,=\, D_{y}^{+}$. Then $A+B \,=\, D_{x+y}^{+}$;
    otherwise stated, $D_{x}^{+} + D_{y}^{+} \,=\, D_{x+y}^{+}$, where the addition on the left is of $+$-cuts, and that on the right is of real numbers.

\VA

        \underline{Proof of Claim 2} (i) For brevity write $C \,=\, A+B$. First note that $A$ and $B$, being $+$-cuts,
    are nonempty subsets of ${\QQ}^{+}$, so there exist numbers $a$ and $b$ in $A$ and $B$, respectively.
    In particular, $c \,=\, a+b$ is an element of $C$, so the set $C$ is nonempty.
    Furthermore, since neither $A$ nor $B$ equals ${\QQ}^{+}$, it follows that there are positive rational numbers $r$ and $s$ such that $r \not \in A$ and $s \not \in B$.
    It then follows from Parts~(b) and~(c) of the definition of `$+$-cut' given above, that $0\,<\,a\,<\,r$ and $0\,<\,b\,<\,s$ for all $a$ in $A$ and all $b$ in $B$.
    Thus $0\,<\,a+b\,<\,r+s$ for all such $a$ and $b$; that is, $0\,<\,c\,<\,r+s$ for all $c$ in $C$, so $C \,\,{\neq}\,\, {\QQ}^{+}$.
    In particular, the set $C$ satisfies Part~(a) of the definition of `$+$-cut'. As for Part~(b) of that definition,
    suppose that $c{\in}C$ and $r$ is a rational number such that $0\,<\,r\,<\,c$.
    Express $c$ in the form $c \,=\, a+b$ for some $a$ in $A$ and $b$ in~$B$, and let $a' \,=\, {\displaystyle a\,\frac{r}{c}}$, ${\displaystyle b' \,=\, b\,\frac{r}{c}}$.
    Since $0\,<\,r\,<\,c$ it is clear that $0\,<\,a'\,<\,a$ and $0\,<\,b'\,<\,b$, and thus $a'{\in}A$ and $b{\vdots}{\in}B$.
    Furthermore, $a'+b' \,=\, {\displaystyle (a+b)\frac{r}{c} \,=\, c\,\frac{r}{c} \,=\, r}$, so $r{\in}C$, as required.
    
    Finally, it is clear that $C$ does not have a maximum element, since neither $A$ nor $B$ does. It follows that $C$ is a Dedekind $+$-cut, as claimed.

        (ii) The equation $C \,=\, D_{x+y}^{+}$ is easy to verify.

\V


        \underline{Definition 3} Let $A$ and $B$ be Dedekind $+$-cuts.
    The {\bf product of $\Bfm{A}$ and $\Bfm{B}$},
    denoted $A\,B$, is the set of all numbers of the form $a\,b$, where $a{\in}A$ and $b{\in}B$.

        \underline{Claim 3} (i) If $A$ and $B$ are Dedekind $+$-cuts, then so is the set $A\,B$.

        (ii) Let $x$ and $y$ be the positive reals such that $A \,=\, D_{x}^{+}$ and $B \,=\, D_{y}^{+}$. Then $A\,B \,=\, D_{x\,y}^{+}$; otherwise stated, 
    $D_{x}^{+}\,D_{y}^{+} \,=\, D_{x\,y}^{+}$, where the multiplication on the left is of $+$-cuts, and that on the right is of real numbers.

\VA

        \underline{Proof of Claim 3} (i) For brevity, write $C \,=\, A\,B$. The proof that $C$ satisfies Parts~(a) and~(c)
    of the definition of `Dedekind $+$-cut' similar to the corresponding part of the proof of Claim~2 above.
    As for the proof that it satisfies Part~(b) of that definition, suppose that $c{\in}C$, and write $c \,=\, a\,b$ for some $a$ in $A$ and $b$ in~$B$.
    Let $r$ be any rational number such that $0\,<\,r\,<\,c$, and let $w \,=\, {\displaystyle \frac{c}{r} \,=\, \frac{a\,b}{r}}$, so that $w\,>\,1$.
    Let $w_{1}$ be any rational number such that $1\,<\,w_{1}\,<\,w$, and let $w_{2} \,=\, w/w_{1}\,>\,1$, so that $w_{1}\,w_{2} \,=\, w$.
    Then $0\,<\,a/w_{1}\,<\,a$ and $0\,<\,b/w_{2}\,<\,b$, so it is clear that $a' \,=\, a/w_{1}{\in}A$ and $b' \,=\, b/w_{2}{\in}B$.
    But $a'\,b' \,=\, (a\,b)/(w_{1}\,w_{2}) \,=\, (a\,b)/w \,=\, r$, so that $r{\in}C$, as required.

        (ii) This is obvious.

\V

        


        {\bf Remarks} (1) The definitions, given above, of `Dedekind $+$-cut', `order', `addition' and `multiplication',
    are formulated purely in terms of the internal structure of the rational numbers.
    The same is true of the statements and proofs of the Part~(i) portions of each of the three claims.
    Only the statements and proofs of the Part~(ii) portions of these claims involve the real number system.

\V

        (2) The proof of the theorem above uses only the fact that ${\RR}$ is a complete ordered field;
    that is, ${\RR}$ is an ordered field which satisfies the Completness Axiom. Thus all complete ordered fields have the same cardinality as the set~${\cal D}_{{\QQ}}$. 

% Positive Dedekind cuts


%--------------------------------------
\StartSkip{ % Full Dedekind Cuts

        The basic idea, which is due to Richard Dedekind, uses the fact that we can treat the set ${\QQ}$ of rational numbers as a subset of~${\RR}$.
    We follow the simplified approach found in the classic book {\em Grundlagen der Analysis} (English: {\em Foundations of Analysis}) by Edmund Landau.

        {\bf Observation} If $x$ is any real number, then $x$ determines a subset $D_{x}$ of ${\QQ}$ given by the following rule:

\VA

        \h $D_{x} \,=\, \{r{\in}{\QQ}: r\,<\,x\}$.

\VA

\noindent It follows easily from the Archimedean Principle in ${\RR}$ that the set $D_{x}$ is nonempty, does not equal ${\QQ}$, and has no greatest element.
    Furthermore, it has the property that if $r{\in}D_{x}$, then $s{\in}D_{x}$ for each rational number $s$ such that $s\,<\,r$.
    It is obvious that if $x_{1}$ and $x_{2}$ are real numbers, then $x_{1} \,=\, x_{2}$ if, and only if, $D_{x_{1}} \,=\, D_{x_{2}}$.
    Dedekind's clever idea was to consider the reverse situation.

\V

        {\bf Definition} (1) A {\bf Dedekind cut} is a subset $A$ of ${\QQ}$ with the following properties:

        (a) The set $A$ is nonempty, but $A \,\,{\neq}\,\, {\QQ}$.

\V

        (b) For every number $a$ in $A$, if $r$ is any rational number such that $r\,<\,a$, then $r{\in}A$.

\V

        (c) The set $A$ does not have a maximum element.

\V

        (2) A Dedekind cut is said to be a {\bf positive cut} provided it contains a positive rational number.

\V

 \noindent In {\ThisText} we denote the set of all Dedekind cuts by ${\cal D}_{{\QQ}}$.

\VV

        {\bf Remarks} (1) In Dedekind's definition, a `cut' is a {\em pair} $(A,B)$ of subsets of ${\QQ}$.
    Roughly speaking, $A$ is a set of the type described above, and $B \,=\, {\QQ}\,{\setminus}\,A$. Note that $B$ may have a minimum element in~${\QQ}$.
    Since $A$ determines $B$, no new information is gained by including $B$ in the definition.

\V

        (2) The `roughness' referred to above in the phrase `roughly speaking' comes from the fact that
    Dedekind allowed the possibility that $A$ might have a maximum element (in which case $B$ would not have a minimum element).
    This introduced a minor complication which the definition given here avoids.

\VV

        {\bf Dedekind's Theorem} For every $x \,=\, {\RR}$ the set $D_{x}$ described above is a Dedekind cut.
    Conversely, every Dedekind cut $A$ is of the form $D_{x}$ for exactly one real number~$x$.

        \underline{Modern statement}: There is a natural bijection $F:{\RR} \,{\rightarrow}\, {\cal D_{{\QQ}}}$, given by the rule
        \begin{displaymath}
        F(x) \,=\, D_{x} \mbox{ for all $x$ in ${\RR}$} \h ({\ast})
        \end{displaymath}
    The inverse of this map is given by $F^{-1}(A) \,=\, {\sup}\,A$ for each $A$ in ${\cal D_{{\QQ}}}$.

\V

        The simple proof is left as an exercise.

\V

        One can go further. Indeed, it is possible to define a natural `order' relation,
    as well as natural operations of `addition' and `multiplication', on the set ${\cal D}_{{\QQ}}$:

\V

        \underline{Definition 1} Let $A$ and $B$ be Dedekind cuts. One says that {\bf \Bfm{A} is less than $\Bfm{B}$}, denoted $A\,<\,B$, provided $A$ is a proper subset of~$B$.

        \underline{Claim 1} Express the Dedekind cuts $A$ and $B$ in the form $A \,=\, D_{x}$ and $B \,=\, D_{y}$ for real numbers $x$ and $y$, as above.
    Then $A\,<\,B$ if, and only if, $x\,<\,y$.

        \underline{Proof} Suppose that $x\,<\,y$. Then $x{\in}D_{y}$, by the definition of $D_{y}$.
    Also, if $a{\in}A$ then $a\,<\,x\,<\,y$ hence $a{\in}B$. Since, by the definition of  `cut', one has $x \not \in A$, it follows that $A$ is a proper subset of $B$, as required.

        Conversely, suppose that $A\,<\,B$; that is, $A$ is a proper subset of $B$.
    Let $x$ and $y$ be the real numbers such that $A \,=\, D_{x}$ and $B \,=\, D_{y}$.
    Since $A$ is a proper subset of $B$, there exists $b$ in $B$ such that $b \not \in A$.
    By the definition of $D_{x}$, this implies that $b\,\,{\geq}\,\,x$. However, by definition of $B$ one has $b\,<\,y$.
    Thus $x\,\,{\leq}\,\,b\,<\,y$, so $x\,<\,y$, as required.

\V

        \underline{Definition  2} Let $A$ and $B$ be Dedekind cuts. The {\bf sum of $\Bfm{A}$ and $\Bfm{B}$}, denoted $A+B$,
    is the set of all rational numbers $c$ of the form $c \,=\, a+b$ with $a$ in $A$ and $b$ in $B$.

        \underline{Claim 2} If $A$ and $B$ are Dedekind cuts, then so is the set $A+B$.
    Furthermore, if $A \,=\, D_{x}$ and $B \,=\, D_{y}$ for real numbers $x$ and $y$, then $A+B \,=\, D_{x+y}$.

        \underline{Proof of Claim 2} For brevity write $C \,=\, A+B$. First note that $A$ and $B$, being cuts,
    are nonempty subsets of ${\QQ}$, so there exist numbers $a$ and $b$ in $A$ and $B$, respectively.
    In particular, $c \,=\, a+b$ is an element of $C$, so the set $C$ is nonempty.
    Furthermore, since neither $A$ nor $B$ equals ${\QQ}$, it follows that there are rational numbers $r$ and $s$ such that $r \not \in A$ and $s \not \in B$.
    It then follows from Parts~(b) and~(c) of the definition of `cut' given above, that $a\,<\,r$ and $b\,<\,s$ for all $a$ in $A$ and all $b$ in $B$.
    Thus $a+b\,<\,r+s$ for all such $a$ and $b$; that is, $c\,<\,r+s$ for all $c$ in $C$, so $C \,\,{\neq}\,\, {\QQ}$.
    In particular, the set $C$ satisfies Part~(a) of the definition of `cut'. As for Part~(b) of that definition,
    suppose that $c{\in}C$ and $r$ is a rational number such that $r\,<\,c$. Express $c$ as $c \,=\, a+b$ for some $a$ in $A$ and $b$ in~$B$, so that $r\,<\,a+b$.
    Let $w  \,=\, (a+b) - r$, so $w\,>\,0$, and let $s \,=\, a-(w/2)$, $t \,=\, b-(w/2)$.
    Then $s$ and $t$ are rational numbers with $s\,<\,a$ and $t\,<\,b$, so $s{\in}A$ and $t{\in}B$, and thus $(s+t){\in}C$.
    However, $s+t \,=\, (a-(w/2)) + (b-(w/2)) \,=\, (a+b) - w \,=\, r$, so $r{\in}C$, hence the set $C$ satisfies Part~(b) of the definition of `cut'.
    Finally, it is clear that $C$ does not have a maximum element, since neither $A$ nor $B$ does. It follows that $C$ is a cut, as claimed.
    The equation $C \,=\, D_{x+y}$ now follows easily.

\V

        The definition of `multiplication' in ${\cal D}_{{\QQ}}$ requires a bit more care because multiplication by negative rationals reverses the order.
    Thus we begin by defining multiplication for {\em positive} cuts.

        \underline{Definition 3} (i) Let $A$ and $B$ be positive Dedekind cuts; note that $A$ and $B$ must both contain the number~$0$.
    The {\bf product of $\Bfm{A}$ and $\Bfm{B}$}, denoted $A\,B$, is the set consisting of all negative rational numbers
    together with all rational numbers $c$ if the form $c \,=\, a\,b$, where $a$ and $b$ are any nonnegative elements of $A$ and $B$, respectively.
    

\V

        {\bf Remark} The proof of the theorem above uses only the fact that ${\RR}$ is a complete ordered field;
    that is, ${\RR}$ is an ordered field which satisfies the Completness Axiom. Thus all complete ordered fields have the same cardinality as the set~${\cal D}_{{\QQ}}$. 
}%\EndSkip Full Dedekind cuts
-----------------------------------

\V

                        \section{ADDENDUM TO CHAPTER~\ref{ChaptB}: Construction of the Real Numbers from the Rational Numbers}
                        \label{SectBAdd}



\V
\V

        The material in this Addendum is not needed later on in {\TheseNotes}. Nevertheless,
    every mathematician should eventually become familiar with the basic ideas that appear here.

\VV

        \underline{Introductory Remark} In the early days of the rigorization of analysis, by mathematicians such as Cauchy and Bolzano,
    the concept of `real number' seems to have been taken for granted and treated `already known'.
    Of course these mathematicians understood that the real numbers possess the properties that,
    earlier in the current chapter, we refer to as the `ordered field' and `completenenss' properties.
    It appears that they did not feel it necessary to construct the real numbers from more primitive types of numbers, such as the rationals.
    By the $1870$s, however, the desire to dig further into the foundations of analysis caused several mathematicians, notably Dedekind and Cantor,
    to construct the real number system directly in terms of the ordered field of rational numbers; the latter field then became the `primitive object'.

        In this Addendum we present three approaches of constructing the real numbers directly from the rationals.

        The first approach is perhaps the one that most naturally comes to mind when the issue is first risen.
    It is based on the simple observation, familiar to all math students, that every nonnegative real number $x$ can be represented by a decimal expression.
    More precisely, such $x$ can be represented by an infinite string of decimal digits, with only finitely many nonzero digits to the left of the decimal point.
    Furthmore, each such string corresponds naturally to a unique infinite sequence of rational numbers,
    namely the numbers obtained by successively truncating the full decimal expansion after finitely many digits to the right of the decimal point.
    One simply reverses this process to define the nonnegative real numbers in terms of infinite sequences of rational numbers.
    The algebraic and order concepts for real numbers are then defined in terms of the corresponding (known) concepts for rational numbers.
    the extension of this construction to include negative numbers is easy to carry out.
    Of course the fact that some real numbers have two different decimal representations,
    such as $1/10 \,=\, 0.1 \,=\, 0.09999\,{\ldots}\,$, does complication the treament; but it is not difficult to work around it.



        The second method discussed in this Addendum is essentially that published in 1872 by the German mathematician Richard Dedekind.
    It is also based on a simple observation: every real number $x$ determines a subset ${\QQ}_{x}$ of the set ${\QQ}$, namely all $r$ in ${\QQ}$ less than $x$.
    Dedekind's method is much more elegant than the decimal-based construction mentioned above.
    If you learn only one method for constructing the reals from the rationals, focus on Dedekind's construction.

%% DO DEDEKIND FIRST ON POSITIVE NUMBERS

        The third approach is due to Cantor and is based Cauchy sequences of rational numbers.
    Cantor's method lacks the directness of the decimal approach and the elegance of Dedekind's.
    Nevertheless, it is important for analysis because, unlike the other methods,
    it allows one to generalize the concept of `completeness' to types of spaces which are much more general than the system of real numbers.
    Since these more general spaces are beyond the scope of {\ThisText}, the treatment of Cantor's approach is relegated to the exercises.%\\\

\VV
}%% \EndSkip
%-----------------------------------------

\newpage

        {\bf CONSTRUCTION OF THE REAL NUMBERS FROM THE RATIONALS USING DECIMALS}%\\\

\VV

        {\bf Definition} A {\bf positive decimal string} is a function ${\alpha}:{\ZZ} \,{\rightarrow}\, {\ZZ}_{9}$ with the following properties:

        \h (i)\, There exists $N{\in}{\ZZ}$ such that ${\alpha}(n) \,=\, 0$ for all $n\,<\,N$, and

        \h (ii) ${\alpha}(k) \,\,{\neq}\,\, 0$ for at least one $k$ in ${\ZZ}$.

\noindent The set of all such strings is denoted $D^{+}$.

\VV

        {\bf Notation} 

\VV

        {\bf Example} 


\VV



\newpage

\input{Exercises_M140AB_B_2017} %% NOTE: Automatically starts on a new page

%------------------------------------------------
%% 
%% Catch Basin for Old Start/End Skips
%%
%--------------
\StartSkip{

        The extended commutative and associative laws, described in Theorem~\Ref{ThmB10.32} above,
    can be used to prove the following facts. Although these facts are very simple, they are also surprisingly useful in analysis.
    They extend the familiar `Add-and-Subtract' and `Multiply-and-Divide' tricks used so often in high-school algebra.

\V

        \subsection{\small{{\bf Theorem}}}
        \label{ThmB10.100}

\V

\hspace*{\parindent}(a)\IndA{Add-and-Subtract trick} Let $a$ and $b$ be real numbers. If $x_{1}$, $x_{2}$,\,{\ldots}\, $x_{k}$, are real numbers, then
        \begin{displaymath}
        b-a \,=\, (b-x_{k}) + (x_{k}-x_{k-1}) + (x_{k-1}-x_{k-2}) + \,{\ldots}\, + (x_{2}-x_{1}) + (x_{1}-a).
        \end{displaymath}

\V

        (b)\IndA{Multiply-and-Divide trick} Let $c$ and $d$ be nonzero real numbers. If $y_{1}$, $y_{2}$,\,{\ldots}\, $y_{k}$ are nonzero real numbers, then
        \begin{displaymath}
        \frac{d}{c} \,=\, \left(\frac{d}{y_{k}}\right){\cdot} 
                          \left(\frac{y_{k}}{y_{k-1}}\right){\cdot}
                          \left(\frac{y_{k-1}}{y_{k-2}}\right){\cdot}
        \,{\ldots}\,
                          \left(\frac{y_{2}}{y_{1}}\right){\cdot}
                          \left(\frac{y_{1}}{c}\right)
        \end{displaymath}

\V

        {\bf Proof}

\V

        (a) By the definition of `subtraction' the equation to be proved can be rewitten as
        \begin{displaymath}
        b + (-a) \,=\, 
        (b + (-x_{k})) + (x_{k} + (-x_{k-1})) + (x_{k-1} + (-x_{k-2})) + \,{\ldots}\, + (x_{2} + (-x_{1})) + (x_{1} + (-a)) \h ({\ast})
        \end{displaymath}

        By repeated use of the Extended Associative Law for Addition (see Part~(b) of Theorem~\Ref{ThmB10.32} above),
    the right side of this last equation can be written in the form
        \begin{displaymath}
        b + (-x_{k} + x_{k}) + (-x_{k-1} + x_{k-1}) + \,{\ldots}\, + (-x_{1} + x_{1}) + (-a)
        \end{displaymath}
    By Axiom~A5 this simplifies to $b + 0 + \,{\ldots}\, + 0 + (-a)$,
    while by Axiom~A4 it simplifies further to $b + (-a)$, that is, to $b-a$, as required.

\V

        (b) The proof of this part is similar, and is left as an exercise.

\V
        \subsection{\small{{\bf Remark}}}
        \label{RemrkB10.105}

        The `Add-and-Subtract' trick described in Part~(a) of the previous theorem has very little value as written,
    since the numbers $x_{1}$, $x_{2}$,\,{\ldots}\,$x_{k}$ need not be related to the numbers $a$ and $b$ in any significant way.
    The result becomes a powerful tool only when the $x$'s are chosen, not at random, but in a {\em clever} way.
    (Of course, what constitutes being `clever' depends strongly on the given context:
    the $x$'s must be chosen in a way that relates to the issue at hand.)
    A similar remark holds for the `Multiply-and-Divide' trick described in Part~(b): to be useful, the numbers $y_{1}$,\,{\ldots}\,$y_{k}$ should be chosen {\em cleverly}.

}%\EndSkip
%----------------------------

%----------------------
\StartSkip{% Repeated Addition/Multiplication

If $(x_{1},x_{2},\,{\ldots}\,x_{k})$ is a $k$-tuple of real numbers,
    than the expression $x_{1}+x_{2}+\,{\ldots}\,+x_{k}$ denotes the number $S_{k}(x_{1},x_{2},\,{\ldots}\,x_{k})$.
    This quantity is also denoted by the expression $\sum_{j=1}^{k} x_{j}$.

\V

        (2) If $(x_{1},x_{2},\,{\ldots}\,x_{k})$ is a $k$-tuple of real numbers,
    than the expression $x_{1}{\cdot}x_{2}{\cdot}\,{\ldots}\,{\cdot}x_{k}$ denotes the number $P_{k}(x_{1},x_{2},\,{\ldots}\,x_{k})$.
    This quantity is also denoted by the expression $\prod_{j=1}^{k} x_{j}$.

\V

        (3) \underline{Special Cases}: If $x_{1} \,=\, x_{2} \,=\, \,{\ldots}\, = x_{k} \,=\, c$, then one usually writes $k\,c$ in place of the expression $c+c+\,{\ldots}\,+c$.
    Likewise, one writes $c^{k}$ in place of $c{\cdot}c{\cdot}\,{\ldots}\,{\cdot}c$.



        The operation of `addition', `$+$', allows one to form the sum $x_{1}+x_{2}$ of any pair of real numbers $x_{1}$ and $x_{2}$.
    It is then possible to form the more general sum $x_{1} + x_{2} + \,{\ldots}\, + x_{k}$ of $k$ reals $x_{1}$, $x_{2}$,\,{\ldots}\,$x_{k}$,
    where $k\,\,{\geq}\,\,3$, as a string of individual simple sums, i.e., sums of pairs of numbers.
    For example, if $k \,=\, 3$, then one can form the sum $x_{1} + x_{2} + x_{3}$ by the rule $x_{1} + x_{2} + x_{3} \,=\, (x_{1} + x_{2}) + x_{3}$;
    that is, first form the simple sum $y \,=\, x_{1} + x_{2}$, then form the simple sum $y+x_{3}$.
    Of course one could just as well form the desired sum by the different rule $x_{1} + x_{2} + x_{3} \,=\, x_{1} + (x_{2} + x_{3})$;
    that is, first form the simple sum $z \,=\, x_{2}+x_{3}$, then form the simple sum $x_{1} + z$.
    Of course, the Associative Law for Addition (see Axiom~A2) implies that these two rules must yield the same value for the sum $x_{1} + x_{2} + x_{3}$.

        As $k$ increases, the number of reasonable ways to express $x_{1} + x_{2} + \,{\ldots}\, + x_{k}$ as a succession of simple sums also increases.
    For example, if $k \,=\, 4$ one could have
        \begin{displaymath}
        ((x_{1} + x_{2}) + x_{3}) + x_{4}         \mbox{ or } 
        ((x_{1} + x_{2}) + (x_{3} + x_{4}))       \mbox{ or }
        (x_{1} + (x_{2} + x_{3})) + x_{4}         \mbox{ or }
        \end{displaymath}
    Nevertheless, one must choose a specific rule for defining the general sum $x_{1} + x_{2} + \,{\ldots}\, + x_{k}$ in terms of a string of simple sums.
    The choice used in {\TheseNotes} is based on the first rule in the example for $k \,=\, 3$ above: start from the left, and add successive terms on the right.

\V

            \subsection{\small{\bf Theorem}}
            \label{ThmB10.27}

\V

\hspace*{\parindent}(a) There are unique functions $S_{k}:{\RR}^{k} \,{\rightarrow}\, {\RR}$, for $k$ in ${\NN}$, such that

        \h (i)\, $S_{1}(x) \,=\, x$ for all $x$ in ${\RR}$;

        \h (ii) $S_{k+1}(x_{1},x_{2},\,{\ldots}\,x_{k},x_{k+1}) \,=\, S_{k}(x_{1},x_{2},\,{\ldots}\,x_{k})+x_{k+1}$ for all $(x_{1},\,{\ldots}\,x_{k+1})$ in ${\RR}^{k+1}$.

\V

        (b) Likewise, there are unique functions $P_{k}:{\RR}^{k} \,{\rightarrow}\, {\RR}$, for $k$ in ${\NN}$, such that

        \h (i)\, $P_{1}(x) \,=\, x$ for all $x$ in ${\RR}$;

        \h (ii) $P_{k+1}(x_{1},x_{2},\,{\ldots}\,x_{k},x_{k+1}) \,=\, P_{k}(x_{1},x_{2},\,{\ldots}\,x_{k}){\cdot}x_{k+1}$ for all $(x_{1},\,{\ldots}\,x_{k+1})$ in ${\RR}^{k+1}$.

\V

        The simple proof by induction is left as an exercise.

\V
\V

        \underline{Note} It is clear that $S_{2}(x_{1},x_{2}) \,=\, x_{1}+x_{2}$, $S_{3}(x_{1},x_{2},x_{3}) \,=\, (x_{1}+x_{2})+x_{3}$, and so on.
    Likewise, $P_{2}(x_{1},x_{2}) \,=\, x_{1}{\cdot}x_{2}$, $P_{3}(x_{1},x_{2},x_{3}) \,=\, (x_{1}{\cdot}x_{2}){\cdot}x_{3}$, and so on.

\V
\V

            \subsection{\small{\bf Definition}}
            \label{DefB10.30}

        Let $k$ be a natural number such that $k\,\,{\geq}\,\,2$, and let $S_{k}$ and $P_{k}$ be the functions described in the preceding theorem.

\V

        (1) (Repeated Addition) If $(x_{1},x_{2},\,{\ldots}\,x_{k})$ is a $k$-tuple of real numbers,
    than the expression $x_{1}+x_{2}+\,{\ldots}\,+x_{k}$ denotes the number $S_{k}(x_{1},x_{2},\,{\ldots}\,x_{k})$.
    This quantity is also denoted by the expression $\sum_{j=1}^{k} x_{j}$.

\V

        (2) (Repeated Multiplication) If $(x_{1},x_{2},\,{\ldots}\,x_{k})$ is a $k$-tuple of real numbers,
    than the expression $x_{1}{\cdot}x_{2}{\cdot}\,{\ldots}\,{\cdot}x_{k}$ denotes the number $P_{k}(x_{1},x_{2},\,{\ldots}\,x_{k})$.
    This quantity is also denoted by the expression $\prod_{j=1}^{k} x_{j}$.

\V

        (3) \underline{Special Cases}: If $x_{1} \,=\, x_{2} \,=\, \,{\ldots}\, = x_{k} \,=\, c$, then one usually writes $k\,c$ in place of the expression $c+c+\,{\ldots}\,+c$.
    Likewise, one writes $c^{k}$ in place of $c{\cdot}c{\cdot}\,{\ldots}\,{\cdot}c$.

\VV

            \subsection{\small{\bf Remarks}}
            \label{RemrkB10.31}

\V

\hspace*{\parindent}(1) One can easily compute that
        \begin{displaymath}
        x_{1}+x_{2}+x_{3} \,=\, (x_{1}+x_{2})+x_{3}; \h x_{1}+x_{2}+x_{3}+x_{4} \,=\, ((x_{1}+x_{2})+x_{3})+x_{4};
        \end{displaymath}
        \begin{displaymath}
        x_{1}+x_{2}+x_{3}+x_{4}+x_{5} \,=\, (((x_{1}+x_{2})+x_{3})+x_{4})+x_{5}.
        \end{displaymath}
    The general formula is of the form
        \begin{equation}
        \label{EqnB.05A}
        x_{1} + x_{2} + \,{\ldots}\,+ x_{k} \,=\, 
        ((  \,{\ldots}\, ((x_{1} + x_{2}) + x_{3}) + \,{\ldots}\, + x_{k-2}) + x_{k-1}) + x_{k}
        \end{equation}

        Here are the corresponding formulas for repeated multiplication:
        \begin{displaymath}
        x_{1}{\cdot}x_{2}{\cdot}x_{3} \,=\, (x_{1}{\cdot}x_{2}){\cdot}x_{3}; \h x_{1}{\cdot}x_{2}{\cdot}x_{3}{\cdot}x_{4} \,=\, ((x_{1}{\cdot}x_{2}){\cdot}x_{3}){\cdot}x_{4}; \h x_{1}{\cdot}x_{2}{\cdot}x_{3}{\cdot}x_{4}{\cdot}x_{5} \,=\, (((x_{1}{\cdot}x_{2}){\cdot}x_{3}){\cdot}x_{4}){\cdot}x_{5}.
        \end{displaymath}
    The general formula is of the form
        \begin{equation}
        \label{EqnB.05B}
        x_{1} {\cdot} x_{2} {\cdot} \,{\ldots}\,{\cdot} x_{k} \,=\, 
        ((  \,{\ldots}\, ((x_{1} {\cdot} x_{2}) {\cdot} x_{3}) {\cdot} \,{\ldots}\, {\cdot} x_{k-2}) {\cdot} x_{k-1}) {\cdot} x_{k}
        \end{equation}

\V

        (2) The definitions of `repeated addition' and `repeated multiplication' given above seem `natural';
    they also agree with the conventions followed by most scientific calculators. They seem the {\em natural} definitions, however, primarily because of the
    `{\bf Left-to-Right Bias}'\IndA{left-to-right bias} that permeates much of mathematics;
   for instance, in the expression $a+b+c$ one thinks of $a$ as the first of the numbers to be added, $b$  the second, and $c$ the last.
    The expression $(a+b)+c$ reflects this because to compute it as written one first computes $a+b$, and only then adds the final number $c$ to the result.

    Had mathematicians followed a right-to-left bias instead, it would have seemed more `natural' to define $a+b+c$ to mean $a+(b+c)$, with $a$ now playing the role of `last'  number added in.
    Of course the Associative Law for Addition tells us that these definitions would be equivalent, so in principle it wouldn't matter which one we chose.

\V

        (3) The careful reader will observe that in Part~(3) of Definition~\Ref{DefB10.30} we write $k\,c$, and not $k{\cdot}c$,
    as the shorthand for $\sum_{j=1}^{k} x_{k}$ in the special case in which $x_{j} \,=\, c$ for all $j \,=\, 1,2,\,{\ldots}\,k$.
    This is not a typographical error: in order that the notation $k{\cdot}c$ make sense in the context of the axioms above,
    the quantities $k$ and $c$ should both be real numbers. However, in the definition above the quantity $k$ is a natural number,
    while the quantity $c$ is a real number.
    And as we know (see Remark~\Ref{RemrkB10.20}~(5) above), the axioms given so far (`field axioms') are not strong enough to imply even that ${\RR}$ is an infinite set.
    For instance, in the equation $x+x \,=\, 2\,x$, the role of the `$2$' is  to count the number of terms in the sum;
    it is {\em not} being used as a shorthand for $1+1$, where here $1$ and $+$ refer to the additive identity and addition, respectively, in the field ${\RR}$.
    Indeed, based only on Axioms A0--A6, it is possible to have $1+1 \,=\, 0$; see the field ${\ZZ}_{2}$ discussed in Remark~\Ref{RemrkB10.20}~(5).

        If all this seems a bit too `fussy' for you, fear not: once we cover the next batch of axioms,
    we can then treat elements of ${\NN}$ in the usual way as if they were actually real numbers; see Section~\Ref{SectB25}.

\V
\V

            \subsection{\small{\bf Examples}}
            \label{ExampB10.32}

\V

\hspace*{\parindent}(1) By Definition~\Ref{DefB10.30}, one has $3 + 5 + 1 + 0 + 2 \,=\, (((3+5)+1)+0)+2$.
    Note that the expression on the right involves four applications of the original addition function
    (i.e., the binary operation referred to in the axioms). Indeed, here is how one evaluates this expression:
        \begin{displaymath}
        3+5 \,=\, 8, \h 8+1 \,=\, 9; \h 9+0 \,=\, 9; \h 9+2 \,=\, 11.
        \end{displaymath}
    That is, $3 + 5 + 1 + 0 + 2 \,=\,11$.

    Note that computing the value of the expression $3 + 5 + 1 + 0 + 2$ using the definition of this repeated sum requires that one carry out the individual sums of pairs of numbers in exactly the order used here.
    To key in the expression $3 + 5 + 1 + 0 + 2$ on a graphing calculator, with no parentheses,
    one would enter the numbers and the plus signs `left to right', and the calculator would compute the intermediate steps just as above,
    although it might not show any of the intermediate sums ($8$, $9$, $9$) until the `Equals' or `Answer' key gets pressed.

\V

        (2) The expression $3+(5+(1+(0+2)))$ is similar to, but different from, the expression $(((3+5)+1)+0)+2$ discussed in the preceding example.
    In particular, it is {\em not} legal at this point to say that $3 + 5 + 1 + 0 + 2 \,=\, 3+(5+(1+(0+2)))$:
    the expression on the right side of this last equation is not the expression given in the definition of the repeated sum on the left side.

        These expressions differ only in the placement of their parentheses.
    Indeed, to compute the new expression $3+(5+(1+(0+2)))$ as written, one must again evaluate the additions `from the inside out':
        \begin{displaymath}
        0+2 \,=\, 2; \h 1+2 \,=\, 3; \h 5+3 \,=\, 8; \h 3+8 \,=\, 11.
        \end{displaymath}
    Thus, the expressions are different in the strong sense that when one evaluates them as written, the intermediate results do not agree.
    Of course, the {\em final} result, namely $11$, is the same value for both expressions;
    but to see from the axioms for ${\RR}$ that they {\em must} have the same value, even before evaluating them as above,
    requires at least four applications of the Associative Law for Addition. (Try it.)

\V
\V
        
        \underline{NOTES}:

\V

        (1) Because of the `successive' nature of the algebraic processes used in the preceding definition,
    one sometimes use the phrases `{\bf successive addition}' and `{\bf successive multiplication}' instead of the `repeated' terminology.

\V

        (2) As is illustrated in Example~(1) above, the definitions of `repeated addition' and `repeated multiplication' specify a particular order in which additions and multiplications of pairs of numbers are to be carried out. 
    For this reason one also refers to these operations as {\bf ordered addition} and {\bf ordered multiplication}.


    
\V
\V

        As is indicated in Example~\Ref{ExampB10.32}, a major reason for introducing the ideas of repeated addition is to allow one to cut down the number of parentheses that appear in complicated expressions.
    Thus, definition allows one to eliminate all the parentheses from the expression $(((3+5)+1)+0)+2$ and replace it by the less cluttered expression $3 + 5 + 1 + 0 + 2$.
    The `elimination of parentheses' feature of repeated addition just illustrated seems to apply only to repeated additions {\em on the right}:
    if one first adds the $3$ to the $5$, then add the $1$ to the sum of $3$ and $5$, and so on, we can indicate that without parentheses.
    Indeed, when in Part~(2) of that example we evaluate the expression $3+(5+(1+(0+2)))$,
    it seems like a coincidence that it adds up to the same value as the original expression $(((3+5)+1)+0)+2$.
    However, it turns out that, because of the Associative Law for Addition, this equality is {\em not} a fluke,
    and that the apparent bias towards additions on the right is an illusion.


\V
        {\bf Example} Consider the following string of repeated additions on the left: $a+(b+(c+(d+e)))$.
    In this case the first binary operation to be carried out is $d+e$, then this is used to compute $c+(d+e)$, and so on.
    It is not particularly obvious from the definition of `repeated additions' that this last expression also equals $a+b+c+d+e$;
    i.e., that it equals $a+(b+(c+(d+e)))$, but it does; here is a proof:

        By repeated use of the Associative Law for Addition one can write
        \begin{displaymath}
        a+(b+(c+(d+e)))  \stackrel{(1)}{ \,=\, }(a+b) + (c+(d+e))  \stackrel{(2)}{ \,=\, } ((a+b)+c)+(d+e) \stackrel{(3)}{ \,=\, } (((a+b)+c)+d) + e   \stackrel{(4)}{ \,=\, } a+b+c+d+e
        \end{displaymath}
    In this extended computation, Equation~(1) uses the Associative Law $A+(B+C) \,=\, (A+B)+C$ with $A \,=\, a$, $B \,=\, b$ and $C \,=\, (c+(d+e))$;
    Equation~(2) uses this law with $A \,=\, a+b$, $B \,=\, c$ and $C \,=\, d+e$; and Equation~(3) uses this law with $A \,=\,((a+b)+c)$, $B \,=\, d$ and $C \,=\, e$.
    Finally, Equation~(4) uses the definition of $a+b+c+d+e$ to obtain the desired equation $a+(b+(c+(d+e))) \,=\, a+b+c+d+e$.


\V
\V

        The preceding example illustrates an important, and annoying, feature of the axiomatic approach:
    the cost of founding a theory on a small collection of low-level axioms can be the need to work hard to obtain results that one normally treats as being `obviously true'.
    For instance, in high school algebra one would make the following simplification almost without thinking:
        \begin{displaymath}
        (a+b+(c+(d+a+d)+e+b)+a+b)+c \,=\, 3a+3b+2c+2d+e
        \end{displaymath}
    The reader is invited to prove this equation directly using the Associative and Commutative Laws for Addition, together with the definition of `repeated sums' given above.

\V


        The rest of this section is devoted mainly to some theorems that can be used to justify the `obvious simplifications' which one carries out in algebra.
    Since these results use only Axioms~A0--A6, their conclusions are valid in any field.

\V


            \subsection{\small{\bf Preliminary Observation}}
            \label{ObservB10.35}

        In ordinary language we often speak of `adding up a set of numbers' or `mutiplying together a set of numbers'.
    The use of the `set' here, however, is generally not appropriate.
    For example, consider the sum
        \begin{displaymath}
        1+3+7+2+1+4+3+1
        \end{displaymath}
    Which `set' of  numbers is being added up here? It is tempting say that it is the set $\{1,3,7,2,1,4,3,1\}$.
    But in set-theoretic terms, this is the same as the set $\{1,3,7,2,4\}$, and we certainly do {\em not} mean the sum $1+3+7+2+4$.
    The problem, of course, is that the `set' concept does not recognize repetitions in the listing out of the elements of a set.

        There is an obvious way around this issue. For example, suppose that we need to study a sum of the form $x_{1}+x_{2}+\,{\ldots}\,+x_{k}$,
    in which there are exactly $k$ summands, but we want to allow the possibility of repetitions in the sum.
    Then we could talk about the `sum of the entries of the $k$-tuple $(x_{1},x_{2},\,{\ldots}\,x_{k})$'.

        Of course, a $k$-tuple of real numbers is simply a {\em function} $f:\{1,2,\,{\ldots}\,k\} \,{\rightarrow}\, {\RR}$; see Definition~\Ref{DefA30.30}.
    Thus we could rephrase the problem in the following form: given a function $f:{\NN}_{k} \,{\rightarrow}\, {\RR}$, determine the sum of the values of the function $f$ over the set ${\NN}_{k}$.
    Note that the role of the function $f$ is to \underline{label}, or \underline{index}, the terms to be added.

         In most situations the use of the set ${\NN}_{k}$ for labeling the terms of a sum or product of $k$ numbers works fine.
    However, we have been trained since childhood to think of the natural numbers as having a natural order: first $1$, then $2$ and so on.
    Using these numbers to label the terms then automatically imposes a corresponding `order' on these terms, an order that may have no intrinsic meaning for the numbers in question.

        {\bf Example} Suppose the task is to add up all the numbers in the following  $3$-by-$3$ matrix:
        \begin{displaymath}
        A \,=\, 
                \left[
        \begin{array}{rrr}
        2 & -3 & 4 \\
        4 &  2 & 7 \\
       -5 &  1 & 9
        \end{array}
                        \right]
        \end{displaymath}
    One {\em could} label these entries as a string of nine numbers, i.e., as a $9$-tuple, using a labeling function $f:{\NN}_{9} \,{\rightarrow}\, {\RR}$.
    However, there is certainly no {\em natural} choice of such a labeling. (You prefer to label them `row-by-row'? I prefer `column-by-column'; and the next person prefers to label them along diagonals.)
    Indeed, the obvious choice, and the one used in elementary matrix theory, is to label the entries by {\em pairs} of numbers that indicate the location (row,column) of each entry in the matrix,
    More specifically, one uses $f:{\NN}_{3}{\times}{\NN}_{3} \,{\rightarrow}\, {\RR}$ so that $f(1,1) \,=\, 2$, $f(1,2) \,=\, -3$ and so on.

    Thus, in what follows we consider the somewhat more general situation of a finite nonempty set $X$ -- the {\bf set of labels} -- and a function $f:X \,{\rightarrow}\, {\RR}$ -- the {\bf labeling function};
    and we wish to discuss the sum of the values of the function~$f$; that is, the sum of the terms labeled by $f$.
    The `ordered $k$-tuple' situation mentioned above then corresponds to the special case $X \,=\, {\NN}_{k}$ for some~$k$.

\V
\V

            \subsection{\small{\bf Theorem} (Generalized Commutative Laws for Addition and Multiplication)}
            \label{ThmB10.40}

        Let $X$ be a finite set with exactly $k\,\,{\geq}\,\,2$ objects (the `labels'),
    and let $f:X \,{\rightarrow}\, {\RR}$ be a real-valued function defined on $X$ (the `labeling function').
    Suppose that $g$ and $h$ are bijections of ${\NN}_{k} \,=\, \{1,2,\,{\ldots}\,k\}$ onto $X$.
    Then
        \begin{displaymath}
        f(g(1)) + f(g(2)) + \,{\ldots}\,+ f(g(k)) \,=\, 
        f(h(1)) + f(h(2)) + \,{\ldots}\,+ f(h(k)) \h ({\ast})_{k}
        \end{displaymath}
    and
        \begin{displaymath}
        f(g(1)) {\cdot} f(g(2)) {\cdot} \,{\ldots}\,{\cdot} f(g(k)) \,=\, 
        f(h(1)) {\cdot} f(h(2)) {\cdot} \,{\ldots}\,{\cdot} f(h(k)) \h ({\ast}{\ast})_{k}
        \end{displaymath}
    (The repeated additions and multiplications are as descibed in Definition~\Ref{DefB10.30} above.)

\V

        {\bf Proof}\, Let $A$ be the subset of ${\NN}$ consisting of the number~$1$ together with all $k\,\,{\geq}\,\,2$ such that for every set $X$ with exactly $k$ elements and every function $f:X \,{\rightarrow}\, {\RR}$, Equations~$({\ast})_{k}$ and~$({\ast}{\ast})_{k}$ hold for all such bijections $g$ and $h$.
    Clearly $1{\in}A$, by definition of $A$.

        Suppose first that $k \,=\, 2$, so that $X \,=\, \{a,b\} \,=\, \{b,a\}$ for a pair of distinct objects $a$ and $b$.
    (The expression of $X$ as either $\{a,b\}$ or $\{b,a\}$ is to emphasize that the `order' in which one displays the elements of $X$ is immaterial.)
    There are then exactly four possibilities for $g$ and $h$:

        \h (i)\,\, $g(1) \,=\, h(1) \,=\, a$ and $g(2) \,=\, h(2) \,=\, b$;

        \h (ii)\,  $g(1) \,=\, h(2) \,=\, a$ and $g(2) \,=\, h(1) \,=\, b$;

        \h (iii)   $g(1) \,=\, h(1) \,=\, b$ and $g(2) \,=\, h(2) \,=\, a$;

        \h (iv)\,  $g(1) \,=\, h(2) \,=\, b$ and $g(2) \,=\, h(1) \,=\, a$.

\noindent In Cases~(i) and~(iii) Equations~$({\ast})_{2}$ and~$({\ast}{\ast})_{2}$ are trivially correct;
   for instance, in Case~(iii) these equations become
        \begin{displaymath}
        f(b) + f(a) \,=\, f(b) + f(a) \mbox{ and } f(b) {\cdot} f(a) \,=\, f(b) {\cdot} f(a),
        \end{displaymath}
    respectively.
    Likewise, in Cases~(ii) and~(iv) Equations~$({\ast})_{2}$ and~$({\ast}{\ast})_{2}$ are true because of the standard Commutative Laws for Addition and Multiplication, i.e., Axiom~A1.
    For instance, in Case~(ii) these equations become
        \begin{displaymath}
        f(a) + f(b) \,=\, f(b) + f(a) \mbox{ and } f(a) {\cdot} f(b) \,=\, f(b) {\cdot} f(a).
        \end{displaymath}
    Thus Equations~$({\ast})_{2}$ and~$({\ast}{\ast})_{2}$ hold, independent of the choice of set $X$ with exactly two elements.


        Next, suppose that $k{\in}A$, with $k\,\,{\geq}\,\,2$.
    Consider a set $X$ with exactly $k+1$ elements, and let $g$ and $h$ be bijections of ${\NN}_{k+1}$ onto $X$.


        \underline{Case A} Suppose that $g(k+1) \,=\, h(k+1) \,=\, u$, and let $Y \,=\, X{\setminus}\{u\}$.
    Then it is clear that $Y$ is a set with exactly $k\,\,{\geq}\,\,2$ elements, and that the restrictions $\hat{g}$ and $\hat{h}$ of $g$ and $h$ to ${\NN}_{k}$ are bijections of ${\NN}_{k}$ onto $Y$.
    Thus, by the induction hypothesis that $k$ is in $A$, it follows that Equations~$({\ast})_{k}$ and~$({\ast}{\ast})_{k}$ hold for the set $Y$ and the bijections $\hat{g}$ and $\hat{h}$. That is,
        \begin{displaymath}
        f(\hat{g}(1)) + f(\hat{g}(2)) + \,{\ldots}\,+f(\hat{g}(k)) \,=\, 
        f(\hat{h}(1)) + f(\hat{h}(2)) + \,{\ldots}\,+f(\hat{h}(k)).
        \end{displaymath}
    Since $\hat{g}(j) \,=\, g(j)$ and $\hat{h}(j) \,=\, h(j)$ for all $j$ in ${\NN}_{k}$,
    one can write instead
        \begin{displaymath}
        f(g(1)) + f(g(2)) + \,{\ldots}\,+f(g(k)) \,=\, 
        f(h(1)) + f(h(2)) + \,{\ldots}\,+f(h(k))
        \end{displaymath}
    Since, by hypothesis, $g(k+1) \,=\, h(k+1)$, it follows from all this that
        \begin{displaymath}
        (f(g(1)) + f(g(2)) + \,{\ldots}\,+f(g(k)))+f(g(k+1)) \,=\, 
        (f(h(1)) + f(h(2)) + \,{\ldots}\,+f(h(k)))+f(h(k+1))
        \end{displaymath}
        However, by Definition~\Ref{DefB10.30} one also has
        \begin{displaymath}
        f(g(1)) + f(g(2)) + \,{\ldots}\,+ f(g(k)) + f(g(k+1)) \,=\,
        (f(g(1)) + f(g(2)) + \,{\ldots}\,f(g(k))) + f(g(k+1))
        \end{displaymath}
    and
        \begin{displaymath}
        f(h(1)) + f(h(2)) + \,{\ldots}\,+ f(h(k)) + f(h(k+1) \,=\,
        (f(h(1)) + f(h(2)) + \,{\ldots}\,f(h(k))) + f(h(k+1)).
        \end{displaymath}
    It follows that
        \begin{displaymath}
        f(g(1)) + f(g(2)) + \,{\ldots}\,+f(g(k))+f(g(k+1)) \,=\,
        f(h(1)) + f(h(2)) + \,{\ldots}\,+f(h(k))+f(h(k+1)).
        \end{displaymath}
    That is, Equation~$({\ast})_{k+1}$ holds for these $g$ and $h$. A similar argument shows that in this case Equation~$({\ast}{\ast})_{k+1}$ also holds.

\V

        \underline{Case B} Suppose that $g(k+1) \,\,{\neq}\,\, h(k+1)$. The difficulties in this case are primarily organizational, not conceptual, so it helps to introduce some {\em ad~hoc} notation.

        Thus, for convenience, set $u \,=\, g(k+1)$ and $v \,=\, h(k+1)$; likewise, set $S \,=\, f(g(1)) + f(g(2)) + \,{\ldots}\,+f(g(k+1))$ and $T \,=\, f(h(1)) + f(h(2)) + \,{\ldots}\,+ f(h(k+1))$.
    In addition, let $U \,=\, X{\setminus}\{u\}$, $V \,=\, X{\setminus}\{v\}$ and $W \,=\, X{\setminus}\{u,v\}$.
    Since $X$ has $k+1$ elements, including $u$ and $v$, and since $u \,\,{\neq}\,\, v$,
    it follows that $U$ and $V$ have exactly $k$ elements, while $W$ has exactly $k-1$ elements; and since $k\,\,{\geq}\,\,2$, it follows that $W$ is not empty.
    Let ${\alpha}:{\NN}_{k-1} \,{\rightarrow}\, W$ be a bijection, and set $P \,=\, f({\alpha}(1)) + f({\alpha}(2)) + \,{\ldots}\, + f({\alpha}(k-1))$.
    Next, define maps ${\beta}:{\NN}_{k} \,{\rightarrow}\, U$ and ${\gamma}:{\NN}_{k} \,{\rightarrow}\, V$ by the rules
        \begin{displaymath}
        {\beta}(j) \,=\, {\gamma}(j) \,=\, {\alpha}(j) \mbox{ for $1\,\,{\leq}\,\,j\,\,{\leq}\,\,k-1$}; \h {\beta}(k) \,=\, v; \h {\gamma}(k) \,=\, u.
        \end{displaymath}
    It is clear that ${\beta}$ and ${\gamma}$ are bijections of ${\NN}_{k}$ onto $U$ and $V$, respectively.
    It follows from the definition of `repeated addition' (and the definition of ${\beta}$ in terms of ${\alpha}$) that
        \begin{displaymath}
        f({\beta}(1)) + f({\beta}(2)) + \,{\ldots}\, + f({\beta}(k)) \,=\, P + f(v);
        \end{displaymath}
    likewise,
        \begin{displaymath}
        f({\gamma}(1)) + f({\gamma}(2)) + \,{\ldots}\,+ f({\gamma}(k)) \,=\, P+ f(u).
        \end{displaymath}
    Furthermore, it is clear that the restriction of the bijection $g$ to ${\NN}_{k}$ is a bijection of ${\NN}_{k}$ onto $U$;
    likewise, the restriction of $h$ to ${\NN}_{k}$ is a bijection of ${\NN}_{k}$ onto $V$.
    Now the induction hypothesis on $k$, combined with the equations obtained above, implies that
        \begin{displaymath}
        f(g(1)) + f(g(2)) + \,{\ldots}\, + f(g(k)) \,=\, P + f(v) \mbox{ and }
    f(h(1)) + f(h(2)) + \,{\ldots}\, + f(h(k)) \,=\, P + f(u).
        \end{displaymath}
    It then follows from the definition of repeated addition, together with the fact that $g(k+1) \,=\, u$, that
        \begin{displaymath}
        f(g(1)) + f(g(2)) + \,{\ldots}\, + f(g(k)) + f(g(k+1)) \,=\, (P+f(v)) + f(u).
        \end{displaymath}
    Likewise, using $h(k+1) \,=\, v$ one gets
        \begin{displaymath}
        f(h(1)) + f(h(2)) + \,{\ldots}\, + f(h(k)) + f(h(k+1)) \,=\, (P+f(u)) + f(v).
        \end{displaymath}
    However, by the ordinary Commutative and Associative Laws for Addition one gets
        \begin{displaymath}
        (P+f(u)) + f(v) \,=\, P+(f(u) + f(v)) \,=\, P+ (f(v)+f(u)) \,=\, (P+f(v)) + f(u).
        \end{displaymath}
    Combining all these facts then yields
        \begin{displaymath}
        f(g(1)) + f(g(2)) + \,{\ldots}\, + f(g(k)) + f(g(k+1)) \,=\, 
        f(h(1)) + f(h(2)) + \,{\ldots}\, + f(h(k)) + f(h(k+1)).
        \end{displaymath}
    It follows that $k+1$ is also in $A$. Thus, by Mathematical Induction, $A \,=\, {\NN}$, and the desired result follows.

\V

        The corresponding proof for multiplication is similar and is left as an exercise.
}%\EndSkip
%-------------------
%------------------
\StartSkip{ %% PROBABLY CAN DROP THIS
        \underline{Case 2} Suppose that $g(k+1) \,\,{\neq}\,\, h(k+1)$.
    Let $u \,=\, g(k+1)$ and $v \,=\, h(k+1)$.
    It follows, from the fact that $h$ is a bijection of $\{1,2,\,{\ldots}\,k,k+1\}$ onto $X$,
    that $v$ must be a member of the set $Y \,=\, X{\setminus}\{u\}$. Thus, since $g$ is also a bijection, there exists a unique $i$ in $\{1,2,\,{\ldots}\,k\}$ such that $v \,=\, g(i)$.
    Now let ${\sigma}:\{1,2,\,{\ldots}\,k\} \,{\rightarrow}\, Y$ be the function given by the rule
        \begin{displaymath}
        {\sigma}(r) \,=\, \left\{
        \begin{array}{ll}
        g(r) & \mbox{if $1\,\,{\leq}\,\,r\,\,{\leq}\,\,k-1$ and $r \,\,{\neq}\,\, i$} \\
        g(i) & \mbox{if $r \,=\, k$} \\
        g(r) & \mbox{if $r \,=\, i$}
        \end{array}
                                    \right.
        \end{displaymath}
    It is easy to verify that ${\sigma}$ is a bijection of $\{1,2,\,{\ldots}\,k\}$ onto $Y$ such that ${\sigma}(k) \,=\, v$.
    Now apply the induction hypothesis to the set $Y$ and the bijections $\hat{g} \,=\, g|_{\{1,2,{\cdot}k\}}$ and ${\sigma}$ to get
        \begin{displaymath}
        f(g(1))+f(g(2))+\,{\ldots}\,+f(g(k-1))+f(g(k)) \,=\, 
        f({\sigma}(1))+f({\sigma}(2))+\,{\ldots}\,+f({\sigma}(k-1))+f({\sigma}(k)).
        \end{displaymath}
    Thus by Definition~\Ref{DefB10.30} one gets
        \begin{displaymath}
        f(g(1))+f(g(2))+\,{\ldots}\,+f(g(k))+f(g(k+1)) \,=\, 
        (f({\sigma}(1))+f({\sigma}(2))+\,{\ldots}\,+f({\sigma}(k))) + f(g(k+1))
        \end{displaymath}
    Next, by Definition~\Ref{DefB10.30} again, one has
        \begin{displaymath}
        f({\sigma}(1))+f({\sigma}(2))+\,{\ldots}\,+f({\sigma}(k-1))+f({\sigma}(k)) \,=\, 
        (f({\sigma}(1))+f({\sigma}(2))+\,{\ldots}\,+f({\sigma}(k-1)))+f({\sigma}(k)).
        \end{displaymath}
    Thus
        \begin{displaymath}
        (f({\sigma}(1))+f({\sigma}(2))+\,{\ldots}\,+f({\sigma}(k))) + f(g(k+1))
     \,=\, 
        ((f({\sigma}(1))+f({\sigma}(2))+\,{\ldots}\,+f({\sigma}(k-1)))+f({\sigma}(k))) + f(g(k+1)) \,=\, 
        \end{displaymath}
        \begin{displaymath}
(f({\sigma}(1))+f({\sigma}(2))+\,{\ldots}\,+f({\sigma}(k-1))) + (f({\sigma}(k)) + f(g(k+1))),
        \end{displaymath}
    where the last equation uses the Associative Law for Addition. However, one also  has $f({\sigma}(k)) + f(g(k+1)) \,=\, f(g(k+1))+f({\sigma}(k))$. Combine this with the preceding results to get
        \begin{displaymath}
        (f({\sigma}(1))+f({\sigma}(2))+\,{\ldots}\,+f({\sigma}(k-1))) + (f({\sigma}(k) + f(g(k+1)))) \,=\, 
        \end{displaymath}
        \begin{displaymath}
        (f({\sigma}(1))+f({\sigma}(2))+\,{\ldots}\,+f({\sigma}(k-1))) + (f(g(k+1)) + f({\sigma}(k))) \,=\, 
        \end{displaymath}
        \begin{displaymath}
    (f({\sigma}(1))+f({\sigma}(2))+\,{\ldots}\,+f({\sigma}(k-1)) + f(g(k+1))) + f({\sigma}(k)).
        \end{displaymath}
    Use Definition~\Ref{DefB10.30} again, together with the preceding results, to get
        \begin{displaymath}
        f(g(1))+f(g(2))+\,{\ldots}\,+f(g(k-1))+f(g(k))+f(g(k+1)) \,=\, 
    f({\sigma}(1))+f({\sigma}(2))+\,{\ldots}\,+f({\sigma}(k-1)) + f(g(k+1)) + f({\sigma}(k)).
        \end{displaymath}
    Define a new map ${\tau}:\{1,2,\,{\ldots}\,k,k+1\} \,{\rightarrow}\, X$ by the rule
        \begin{displaymath}
        {\tau}(j) \,=\, \left\{
        \begin{array}{ll}
        {\sigma}(j) & \mbox{if $j \,=\, 1,2,\,{\ldots}\,k-1$} \\
        g(k+1)      & \mbox{if $j \,=\, k$} \\
        {\sigma}(k) & \mbox{if $j \,=\, k+1$}
        \end{array}
                                \right.
        \end{displaymath}
    It is easy to see that ${\tau}$ is a bijection of $\{1,2,\,{\ldots}\,k,k+1\}$ onto $X$.
    In particular, one has
        \begin{displaymath}
        f({\sigma}(1))+f({\sigma}(2))+\,{\ldots}\,+f({\sigma}(k-1)) + f(g(k+1)) + f({\sigma}(k)) \,=\, 
    f({\tau}(1)) + f({\tau}(2)) + \,{\ldots}\,+ f({\tau}(k)) + f({\tau}(k+1)).
        \end{displaymath}
    Since ${\tau}(k+1) \,=\, {\sigma}(k) \,=\, h(k+1)$, it is clear that ${\tau}$ and $h$ are bijections for which Case~(1) holds.
    Thus one can write
        \begin{displaymath}
        f({\tau}(1)) + f({\tau}(2)) + \,{\ldots}\,+ f({\tau}(k)) + f({\tau}(k+1)) \,=\, 
        f(h(1))+ f(h(2)) + \,{\ldots}\,+ f(h(k)) + f(h(k+1)).
        \end{displaymath}
    It now follows that
        \begin{displaymath}
        f(g(1))+f(g(2))+\,{\ldots}\,+f(g(k-1))+f(g(k))+f(g(k+1)) \,=\, 
        f(h(1))+ f(h(2)) + \,{\ldots}\,+ f(h(k)) + f(h(k+1));
        \end{displaymath}
    that is, Equation~$({\ast})_{k+1}$ holds for this $g$ and $h$ as well.
    A similar argument shows that Equation~$({\ast}{\ast})_{k+1}$ also holds.

        In any event, $k$ being in $A$ implies $(k+1)$ is in $A$, so (by the Principle of Mathematical Induction) $A \,=\, {\NN}$.
    Thus, the desired result holds for all $k$ in ${\NN}$.


\V
\V

}%%\ENDSKIP
%--------------------

%--------------------
\StartSkip{

            \subsection{\small{\bf Definition}}
            \label{DefB10.50}

        Let $X$ be a finite nonempty set with exactly $k\,\,{\geq}\,\,2$ elements, and let $f:X \,{\rightarrow}\, {\RR}$ be a real-valued function whose domain contains $X$ as a subset.

\V

       (1) The {\bf sum of the function values of $f$ over $X$} is the number $\sum_{X} f$ given by
        \begin{displaymath}
       \sum_{X} f \,=\, f(g(1)) + f(g(2)) + \,{\ldots}\,+ f(g(k)),
        \end{displaymath}
    where $g$ is any bijection of $\{1,2,\,{\ldots}\,k\}$ onto $X$.

\V

        (2) The {\bf product of the function values of $f$ over $X$} is the number $\prod_{X} f$ given by
        \begin{displaymath}
      {\prod}_{X} f \,=\, f(g(1)) {\cdot} f(g(2)) {\cdot} \,{\ldots}\,{\cdot} f(g(k)).
        \end{displaymath}

\V

        (3) If $X$ is a singleton set, $X \,=\, \{c\}$, then it is convenient to set ${\sum}_{X} f \,=\, {\prod}_{X} f \,=\, f(c)$.
    Likewise, it is convenient to write $\sum_{{\emptyset}} f \,=\, 0$ and ${\prod}_{{\emptyset}} f \,=\, 1$ for every function $f$.


\V

            \subsection{\small{\bf Remarks}}
            \label{RemrkB10.53}

\V

\hspace*{\parindent}(1) The conventions that $\sum_{{\emptyset}} f \,=\, 0$ and ${\prod}_{{\emptyset}} f \,=\, 1$ do not conflict with the requirement that the domain of a function must be a nonempty set.
    Indeed, in the preceding definition it is required only that the set $X$ over which the sum and product are to be taken be a {\em subset} of the domain of the function $f$.
    The empty set fulfills that requirement automatically.

\V

        (2) The preceding theorem shows that the expressions ${\sum}_{X} f$ and ${\prod}_{X} f$ depend only on $f$ and $X$,
    but not on the specific choice of bijection $g$; that is, they do not depend on the order in which one adds or multiplies the values of $f$.
    For this reason one often refers to the expressions of the form ${\sum}_{X} f$ and ${\prod}_{X} f$ as {\bf unordered sums} and {\bf unordered products}.
    In contrast, the repeated sums and products described in Definition~\Ref{DefB10.30} are then called {\bf ordered sums} and {\bf ordered products}.

        Note that is the {\em expressions} -- that is, the manner in which the sums and products are written down -- that are being distinguished as either `ordered' or `unordered' here, not the {\em values} assigned to these expressions;
    indeed, the main conclusion of the preceding theorem is that the values are the same.

%% TEMPORARY REFERENCE ~\Ref{ChaptG}
        In Chapter~G, however, we extend these ideas to sums and products of {\em infinitely many} numbers.
    In that context it turns out that the values which the `ordered' and `unordered' approaches assign do {\em not} have to be the same;
    that is, the `commutative law' has exceptions for infinite sums and products.

\V

        (3) The main result of the preceding theorem can be rephrased to say that the
    `ordered' and `unordered' approaches yield the same results for sums and products of finitely many numbers.

\V

        (4) In the special case $X \,=\, {\NN}_{k}$ the notations for the two types of sums take the form ${\sum}_{{\NN}_{k}} f$ (unordered sum) and $\sum_{j=1}^{k} f(j)$ (ordered sum).

\V
\V

        The associative laws for addition and multiplication also have general versions.

\V

            \subsection{\small{\bf Theorem} (Generalized Associative Laws for Addition and Multiplication)}
            \label{ThmB10.60}

        Let $f:X \,{\rightarrow}\, {\RR}$ be a real-valued function defined on a nonempty finite set $X$ with exactly $k$ elements.
    Let $C_{1}$, $C_{2}$,\,{\ldots}\,$C_{r}$ be nonempty subsets of $X$ that are mutually disjoint and whose union is $X$.
    Then
        \begin{equation}
        \label{EqnB.20A}
        {\sum}_{X} f \,=\, ({\sum}_{C_{1}} f) + ({\sum}_{C_{2}}) f + \,{\ldots}\, + ({\sum}_{C_{r}} f)
        \end{equation}
    and
        \begin{equation}
        \label{EqnB.20B}
        {\prod}_{X} f \,=\, ({\prod}_{C_{1}} f){\cdot}({\prod}_{C_{2}} f){\cdot}\,{\ldots}\,{\cdot}({\prod}_{C_{r}} f).
        \end{equation}
 
\V

        {\bf Proof}\, Let $A$ be the set of all $r$ in ${\NN}$ for which Equation~\Ref{EqnB.20A} is true.

        Clearly $1{\in}A$; indeed, if $r \,=\, 1$ then $C_{r} \,=\, C_{1} \,=\, X$, and the condition to be proved reduces to
    ${\sum}_{X} f \,=\, {\sum}_{C_{1}} f$, which is true because $C_{1} \,=\, X$.

        Next, suppose that $r \,=\, 2$, and suppose that $C_{1}$ and $C_{2}$ are nonempty mutually disjoint subsets of $X$ such that $X \,=\, C_{1}\,{\cup}\,C_{2}$.
    For convenience let $Y \,=\, C_{1}$ and $Z \,=\, C_{2}$.
    Let $p$ be the number of points in $Y$, and let $y_{1}$, $y_{2}$,\,{\ldots}\,$y_{p}$ be these points.
    Likewise, let $q$ be the number of points of $Z$, and let $z_{1}$, $z_{2}$,\,{\ldots}\,$z_{q}$ be these points.
    By Part~(c) of Theorem~\Ref{ThmA15.30}, one then has $p+q \,=\, k$.
    Define $g:{\NN}_{k} \,{\rightarrow}\, X$ by the rule
        \begin{displaymath}
        g(j) \,=\,
        \left\{
        \begin{array}{ll}
        y_{j}    & \mbox{if $1\,\,{\leq}\,\,j\,\,{\leq}\,\,p$} \\
        z_{j-p}  & \mbox{if $p+1\,\,{\leq}\,\,j\,\,{\leq}\,\,k$} \,=\, p+q.
        \end{array}
        \right.
        \end{displaymath}
    Then it is clear that $g$ is a bijection of ${\NN}_{k}$ onto $X$.
    To simplify the notation, let us write $x_{j} \,=\, g(j)$ for all $j$ in ${\NN}_{k}$.
    Thus one has
        \begin{displaymath}
        x_{1} \,=\, y_{1}, x_{2} \,=\, y_{2},\,{\ldots}\,x_{p} \,=\, y_{p},x_{p+1} \,=\, z_{1}, x_{p+1} \,=\, z_{2},\,{\ldots}\,x_{k} \,=\, x_{p+q} \,=\, z_{q}.
        \end{displaymath}
    By definition one has
        \begin{displaymath}
        {\sum}_{X} f \,=\, S_{k}(f(x_{1}),f(x_{2}),\,{\ldots}\,f(x_{k})),
        \end{displaymath}
    where $S_{k}$ is as in Theorem~\Ref{ThmB10.27}.
    From the recursive properties of the functions $S_{1}$, $S_{2}$,\,{\ldots}\,$S_{k}$ given in that theorem, one has
        \begin{displaymath}
         {\sum}_{X} f \,=\, S_{k}(f(x_{1}),f(x_{2}),\,{\ldots}\,f(x_{k}))\,=\, S_{k-1}(f(x_{1}),f(x_{2}),\,{\ldots}\,f(x_{k-1})) + f(x_{k}) \,=\,
         \end{displaymath}
         \begin{displaymath}
          S_{k-1}(f(x_{1}),f(x_{2}),\,{\ldots}\,f(x_{k-1})) + S_{1}(f(x_{k})).
        \end{displaymath}
    Now apply the same argument to $S_{k-1}$ to get
        \begin{displaymath}
        {\sum}_{X} f
    \,=\, \left(S_{k-2}(f(x_{1}),\,{\ldots}\,f(x_{k-2})) + f(x_{k-1})\right) + S_{1}(f(x_{k}))
    \,=\,
    \]
    \[
    S_{k-2}(f(x_{1}),\,{\ldots}\,f(x_{k-2})) + \left(f(x_{k-1}) + S_{1}(f(x_{k})\right))
     \,=\,
     \]
     \[
      S_{k-2}(f(x_{1}),\,{\ldots}\,f(x_{k-2})) + \left(S_{1}(f(x_{k}))+f(x_{k-1})\right)
    \,=\,
    \]
    \[
    S_{k-2}(f(x_{1}),\,{\ldots}\,f(x_{k-2})) + S_{2}(f(x_{k}),f(x_{k-1})).
        \end{displaymath}
    Note that second and third equations are just applications of the associative and commutative laws, respectively, while the other equations reflect the recursive properties of the functions $S_{1}$, $S_{2}$,\,{\ldots}\,$S_{k}$.
    Continue this process until it has been done $q$ times. It is  clear that one finally gets
        \begin{displaymath}
        {\sum}_{X} f \,=\, S_{k-q}(f(x_{1}),f(x_{2}),\,{\ldots}\,f(x_{p})) + S_{q}(f(x_{k}),f(x_{k-1}),\,{\ldots}\,f(x_{p+1})) \,=\, 
        \]
        \[
        S_{p}(f(y_{1}),\,{\ldots}\,f(y_{p})) + S_{q}(f(z_{k}),f(z_{k-1}),\,{\ldots}\,f(z_{1})).
        \end{displaymath}
    In light of the definitions of ${\sum}_{S_{1}} f$ and ${\sum}_{S_{2}} f$, combined with the fact that the General Commutative Law holds, one gets
        \begin{displaymath}
        {\sum}_{X} f \,=\, {\sum}_{Y} f + {\sum}_{Z} f \,=\, {\sum}_{C_{1}} f + {\sum}_{C_{2}} f.
        \end{displaymath}
    In other words, $r \,=\, 2$ is in the set $A$.

        Next, suppose that $r{\in}A$, with $r\,\,{\geq}\,\,2$, and suppose that $C_{1}$, $C_{2}$,\,{\ldots}\,$C_{r}$, $C_{r+1}$ are mutually disjoint nonempty subsets of $X$ whose union is $X$.
    Let $Y \,=\, C_{1}\,{\cup}\,C_{2}\,{\cup}\,\,{\ldots}\,\,{\cup}\,C_{r}$ and $Z \,=\, C_{r+1}$.
    Then the fact that $2$ is in $A$ implies that
        \begin{displaymath}
        {\sum}_{X} f \,=\, {\sum}_{Y} f + {\sum}_{Z} f.
        \end{displaymath}
    And the induction hypothesis that $r$ is in $A$ implies that
        \begin{displaymath}
        {\sum}_{Y} f \,=\, {\sum}_{C_{1}} f + {\sum}_{C_{2}} f + \,{\ldots}\,+ {\sum}_{C_{r}} f.
        \end{displaymath}
    Combining these facts with the definition of repeated sums, one finally obtains
        \begin{displaymath}
        {\sum}_{X} f \,=\, \left({\sum}_{C_{1}} f + {\sum}_{C_{2}} f + \,{\ldots}\,+ {\sum}_{C_{r}} f\right) + {\sum}_{C_{r+1}} f \,=\, 
    {\sum}_{C_{1}} f + {\sum}_{C_{2}} f + \,{\ldots}\,+ {\sum}_{C_{r}} f + {\sum}_{C_{r+1}} f.
        \end{displaymath}
    In other words, $r+1$ is also in $A$. Now the induction is complete, and $A \,=\, {\NN}$ so Equation~\Ref{EqnB.20A} is valid.

        The proof of Equation~\Ref{EqnB.20B} is similar, and is left as an exercise.

\V
\V


        {\bf Example} Suppose that $X \,=\, \{a,b,c\}$ is a set with exactly three elements.
    Let $C_{1} \,=\, \{a\}$ and $C_{2} \,=\, \{b,c\}$.
    Then Equation~\Ref{EqnB.20A} takes the form
        \begin{displaymath}
        {\sum}_{X} f \,=\, {\sum}_{C_{1}} f + {\sum}_{C_{2}} f;
        \end{displaymath}
    that is,
        \begin{displaymath}
        {\sum}_{X} f \,=\, f(a) + (f(b)+f(c)).
        \end{displaymath}
    Likewise, if one applies Equation~\Ref{EqnB.20A} to the sets $C_{1}' \,=\, \{a,b\}$ and $C_{2}' \,=\, \{c\}$, one gets
        \begin{displaymath}
        {\sum}_{X} f \,=\, {\sum}_{C_{1}'} f + {\sum}_{C_{2}'} f \,=\, (f(a)+f(b)) + f(c).
        \end{displaymath}
    In particular,
        \begin{displaymath}
        f(a) + (f(b)+f(c)) \,=\, (f(a)+f(b))+f(c).
        \end{displaymath}
    If one sets $x \,=\, f(a)$, $y \,=\, f(b)$ and $z \,=\, f(c)$, then this  result takes the more familiar form
        \begin{displaymath}
        x+(y+z) \,=\, (x+y)+z.
        \end{displaymath}

        Similar applications of Equation~\Ref{EqnB.20B} imply
        \begin{displaymath}
        f(a){\cdot}(f(b){\cdot}f(c)) \,=\, (f(a){\cdot}f(b)){\cdot}f(c)
        \end{displaymath}
    In other words, the simplest nontrivial case of this theorem reduces to the usual Associative Laws for Addition and Multiplication.
    It is for this reason the the results of Theorem~\Ref{ThmB10.60} are called `{\em Generalized} Associative Laws'.

\V
\V

            \subsection{\small{\bf Example}}
            \label{ExampB10.70}

        Consider the equation
        \begin{displaymath}
        1+(4+1)+(3+2) \,=\, 1+1+2+3+4 \h ({\ast})
        \end{displaymath}
    Proving this directly from the axioms could be time consuming. Here is how to get it from the preceding theorems.

        First, note that there are $5$ terms in the expression on the left, so let $X$ be a set with exactly $5$ elements.
    To be definite, let $X \,=\, \{a,b,c,d,e\}$. Define $f:X \,{\rightarrow}\, {\RR}$ by the rule $f(a) \,=\, 1$, $f(b) \,=\, 4$, $f(c) \,=\, 1$, $f(d) \,=\, 3$, $f(e) \,=\, 2$.
    Then note that
        \begin{displaymath}
        X \,=\, C_{1}\,{\cup}\,C_{2}\,{\cup}\,C_{3},
        \end{displaymath}
    where $C_{1} \,=\, \{a\}$, $C_{2} \,=\, \{b,c\}$, $C_{3} \,=\, \{d,e\}$.
    Note that the left side of Equation~$({\ast})$ equals
        \begin{displaymath}
        ({\sum}_{C_{1}} f)+ ({\sum}_{C_{2}} f) + ({\sum}_{C_{3}} f).
        \end{displaymath}
    Likeswise,
        \begin{displaymath}
        {\sum}_{X} f \,=\, f(a) + f(b) + f(c) + f(d) + f(e) \,=\, 1+4+1+3+2 \,=\, 1+1+2+3+4,
        \end{displaymath}
    where the last equation follows from the General Commutative Law for Addition.
    The desired equation now follows by applying the Generalized Associative Law.


\V
\V

            \subsection{\small{\bf Remark}}
            \label{RemrkB10.80}

        The careful reader may be bothered by the fact that the right side of Equation~\Ref{EqnB.20A} is written as an `ordered sum', while the left side is an `unordered sum';
    see Remark~\Ref{RemrkB10.53}~(1) for the meanings of these  phrases.
    This (minor) aesthetic flaw can easily be fixed by observing that the sets $C_{1}$, $C_{2}$,\,{\ldots}\,$C_{r}$ discussed in Theorem~\Ref{ThmB10.60}
    form a {\em partition} of the original set $X$; see Definition~\Ref{DefA50.85}~(1).
    More precisely, let ${\cal F} \,=\, \{C_{1},\,{\ldots}\,C_{r}\}$; then ${\cal F}$ is the partition in question.
    This suggests the following reformulation of Theorem~\Ref{ThmB10.60}; the simple proof is left as an exercise for the reader.

\V

            \subsection{\small{\bf Theorem} (Alternate Formulation of the Generalized Associative Laws)}
            \label{ThmB10.90}

        Let $f:X \,{\rightarrow}\, {\RR}$ be a real-valued function defined on a nonempty finite set $X$ with exactly $k$ elements.
    Let ${\cal F}$ be a partition of $X$, and define a function $\hat{f}:{\cal F} \,{\rightarrow}\, {\RR}$ by the rule
        \begin{displaymath}
        \hat{f}(C) \,=\, {\sum}_{C} f \mbox{ for each $C$ in the family ${\cal F}$}.
        \end{displaymath}
    Then
        \begin{equation}
        \label{EqnB.30A}
        {\sum}_{X} f \,=\, {\sum}_{{\cal F}} \hat{f}.
        \end{equation}

        Likewise, let $\tilde{f}:{\cal F} \,{\rightarrow}\, {\RR}$ be given by the rule
        \begin{displaymath}
        \tilde{f}(C) \,=\, {\prod}_{C} f \mbox{ for each $C$ in ${\cal F}$}.
        \end{displaymath}
    Then
        \begin{equation}
        \label{EqnB.30B}
        {\prod}_{X} f \,=\, {\prod}_{{\cal F}} \tilde{f}.
        \end{equation}

\V
\V

            \subsection{\small{\bf `Real-life' Example}}
            \label{ExampB10.95}

        \underline{The Story Line} A certain person, whom we call `Pat', owns a chain of three stores in Chicago.
    The following table shows the net profit for each store during the six-month period January~1 through June~30 of a certain year:
        \begin{displaymath}
        \begin{array}{c|rrrrrr}  \hline
        \mbox{Month}   &
  \mbox{Jan} & \mbox{Feb} & \mbox{Mar} & \mbox{Apr} & \mbox{May} & \mbox{Jun} \\
        \mbox{Store A} &
       1213  &   1502     &    1101    &    987     &    322     &  -206      \\
        \mbox{Store B} &
       -433  &   -106     &     224    &    783     &   1200     &  1305      \\
        \mbox{Store C} &
        213  &    714     &     949    &    851     &    770     &   312      \\
        \end{array}
        \end{displaymath}

        \underline{Problem} Determine the net profit that Pat received from the chain of stores during this period.

        \underline{Solution} First note that the entire  situation can be  formulated along the lines of the previous discussion.
    Indeed, let $X$ be the set of all ordered pairs $(u,v)$ where $u$ is one of the three store letters $A$, $B$, $C$, and $v$ is one of the six months Jan, Feb, Mar, Apr, May, Jun.
    Next, define $f:X \,{\rightarrow}\, {\RR}$ by the rule $f(u,v)$ is the net profit of Store~$u$ during Month~$v$.
    Then it is clear that the number Pat wishes to know is ${\sum}_{X} f$. 
    This quantity is, by its nature, an `unordered sum', since there is no uniquely natural way to list out the $18$ numbers of the table to form a single ordered sum.
    However there are two obvious ways to `partition' the data in the table:

        \underline{Partition by `Store'} Let $S_{A}$ be the subset of $X$  corresponding to the six data points associated with Store~A. That is
        \begin{displaymath}
        S_{A} \,=\, \{(A,\mbox{Jan}), (A,\mbox{Feb}),\,{\ldots}\,(A,\mbox{Jun})).
        \end{displaymath}
    Likewise, let $S_{B}$ and  $S_{C}$ denote the subsets of $X$ corresponding to Stores~B and~C, respectively.
    Clearly the sets $S_{A}$, $S_{B}$ and $S_{C}$ form a partition ${\cal F} \,=\, \{S_{A},S_{B},S_{C}\}$ of $X$.
    Note that the corresponding function $\hat{f}:{\cal F} \,{\rightarrow}\, {\RR}$ is then given by
        \begin{displaymath}
        \hat{f}(S_{A}) \,=\, {\sum}_{S_{A}} f \,=\, \mbox{ the net profit of Store~A},
        \end{displaymath}
    and likewise for $\hat{f(S_{B})}$ and $\hat{f}(S_{C})$.
    Theorem~\Ref{ThmB10.90} then takes the form
        \begin{displaymath}
        {\sum}_{X} f \,=\, {\sum}_{{\cal F}} \hat{f}.
        \end{displaymath}
    This is then interpreted as saying that the net profit over the period for the entire chain is the sum of the profits of the individual stores over that period.

        In terms of the `table' notation used here: ${\sum}_{{\cal F}} \hat{f}$ calculates the sum of the entries of the table `row-by-row'.

\V

        \underline{Partition by `Month'} Let $T_{\mbox{Jan}}$ be the subset of $X$ corresponding to the three data points associated with the month of January.
    That is,
        \begin{displaymath}
        T_{\mbox{Jan}} \,=\, \{(A,\mbox{Jan}), (B,\mbox{Jan}), (C,\mbox{Jan})\}.
        \end{displaymath}
    Likewise, let $T_{\mbox{Feb}}$,\,{\ldots}\,$T_{\mbox{Jun}}$ denote the subsets of $X$ corresponding to February, March etc.
    Clearly the family ${\cal G}$, given by
        \begin{displaymath}
        {\cal G} \,=\, \{T_{\mbox{Jan}}, T_{\mbox{Feb}}, T_{\mbox{Mar}},
        T_{\mbox{Apr}}, T_{\mbox{May}}, T_{\mbox{Jun}}\},
        \end{displaymath}
    forms a second partition of $X$.
    Now define $f^{\#}:{\cal G} \,{\rightarrow}\, {\RR}$ by the rule
        \begin{displaymath}
        f^{\#}(T_{\mbox{Jan}}) f \,=\, {\sum}_{T_{\mbox{Jan}}} \,=\, \mbox{ the sum of the net profits from each of the three stores for January},
        \end{displaymath}
    and likewise for the other five months.
    In this case Theorem~\Ref{ThmB10.90} takes the form
        \begin{displaymath}
        {\sum}_{X} f \,=\, {\sum}_{{\cal G}} f^{\#}.
        \end{displaymath}
    This is then interpreted as saying that the net profit of the chain over the given six-month period is equal to the sum of the net profits for each of these months of the chain.

        In terms of the `table' notation used here: ${\sum}_{{\cal G}} f^{\#}$ calculates the sum of the entries of the table `column-by-column'.

        \underline{Practical Note} It is clear that the quantities ${\sum}_{{\cal F}} \hat{f}$ and ${\sigma}_{{\cal G}} f^{\#}$ must equal each other, since they are both equal to ${\sum}_{X} f$.
    Acountants use the fact that adding row-by-row ought to produce the same results as adding column-by-column as a way to (partially) verify the accuracy of their calculations.

\V
\V

        {\bf Remark} The formulation of the `General Associative Law' in Theorem~\Ref{ThmB10.90}, i.e., in terms of partitions,
    may seem artificial.
    %% TEMPORARY REFERENCE ~\Ref{ChaptG}
    However, we need to use an analog of this formulation in our treatment of `infinite sums' in Chapter~G.
    Also, such `partition' formulations appear frequently in other branches of advanced mathematics.

\V
\V

        The Generalized Commutative and Associative Laws can be used to prove the following facts which, although simple, are surprisingly useful.

\V

        \subsection{\small{{\bf Theorem}}}
        \label{ThmB10.100}

\V

\hspace*{\parindent}(a) Let $a$ and $b$ be real numbers. If $x_{1}$, $x_{2}$,\,{\ldots}\, $x_{k}$, are real numbers, then
        \begin{displaymath}
        b-a \,=\, (b-x_{k}) + (x_{k}-x_{k-1}) + (x_{k-1}-x_{k-2}) + \,{\ldots}\, + (x_{2}-x_{1}) + (x_{1}-a).
        \end{displaymath}

\V

        (b) Let $c$ and $d$ be nonzero real numbers. If $y_{1}$, $y_{2}$,\,{\ldots}\, $y_{k}$ are nonzero real numbers, then
        \begin{displaymath}
        \frac{d}{c} \,=\, \left(\frac{d}{x_{k}}\right){\cdot} 
                          \left(\frac{x_{k}}{x_{k-1}}\right){\cdot}
                          \left(\frac{x_{k-1}}{x_{k-2}}\right){\cdot}
        \,{\ldots}\,
                          \left(\frac{x_{2}}{x_{1}}\right){\cdot}
                          \left(\frac{x_{1}}{a}\right)
        \end{displaymath}

\V

        {\bf Proof}

\V

        (a) For convenience set $x_{0} \,=\, a$ and $x_{k+1} \,=\, b$, so the equation to be proved takes the form
        \begin{displaymath}
        x_{k+1}-x_{0} \,=\, (x_{k+1}-x_{k}) + (x_{k}-x_{k-1}) + (x_{k-1}-x_{k-2}) + \,{\ldots}\, + (x_{2}-x_{1}) + (x_{1}-x_{0}) \h ({\ast})
        \end{displaymath}
    Note that the expression on the right side of Equation~$({\ast})$ involves $2k+2$ indexed quantities:
        \begin{displaymath}
        x_{0}, x_{1},\,{\ldots}\,x_{k},x_{k+1}, -x_{1},\,{\ldots}\,-x_{k}
        \end{displaymath}
    (Recall that a term such as $x_{2}-x_{1}$ really is an addition, namely $x_{2} + (-x_{1})$.)
    There does not appear to be a completely obvious choice of labeling set $X$ and labeling function $f$ for this situation.
    Based on the order in which the terms are written on the right side of Equation~$({\ast})$,
    we choose $X \,=\, \{0,1,2,\,{\ldots}\,2k+1\}$ as the labeling set, and define the labeling function $f:X \,{\rightarrow}\, {\RR}$ by the rule
        \begin{displaymath}
        f(j) \,=\, \left\{
        \begin{array}{rl}
        x_{k+1-j} & \mbox{if $0\,\,{\leq}\,\,j\,\,{\leq}\,\,k$} \\
       -x_{2k+1-j} & \mbox{if $k+1\,\,{\leq}\,\,j\,\,{\leq}\,\,2k+1$}
        \end{array}
                            \right.
        \end{displaymath}
    This labeling corresponds to writing the numbers that appear in the desired sum in the following order:
        \begin{displaymath}
        x_{k+1}, x_{k}, x_{k-1},\,{\ldots}\,x_{2},x_{1}, -x_{k}, -x_{k-1},\,{\ldots}\,-x_{2}, -x_{1}, -x_{0}.
        \end{displaymath}
    Now let $C_{0}$, $C_{2}$,\,{\ldots}\,$C_{k}$ be the subsets of $X$ that correspond under $f$ to indices which appear in the differences in the parentheses on the right side of~$({\ast})$:
        \begin{displaymath}
        C_{0} \,=\, \{0,k+1\}, \h C_{1} \,=\, \{1,k+2\}, \h C_{2} \,=\, \{2, k+3\}, \h  \,{\cdots}\, C_{k-1} \,=\, \{k-1, 2k\}, \h C_{k}  \,=\, \{k,2k+1\}
        \end{displaymath}
    The general rule is $C_{j} \,=\, \{j, k+1+j\}$ for $0\,\,{\leq}\,\,j\,\,{\leq}\,\,k$.
    Note that $f(j) + f(k+1+j) \,=\, x_{k+1-j} + (-x_{k-j}) \,=\, x_{k+1-j}-x_{k-j}$.
    Thus the right side of Equation~$({\ast})$ equals
        \begin{displaymath}
        {\sum}_{C_{0}} f + {\sum}_{C_{1}} f + \,{\ldots}\, + {\sum}_{C_{k}} f.
        \end{displaymath}
    Since the sets $C_{0}$, $C_{1}$,\,{\ldots}\,$C_{k}$ are disjoint nonempty subsets of $X$ whose union is $X$, it then follows from the Generalized Associative Law for Addition that the right side of Equation~$({\ast})$ equals ${\sum}_{X} f$.

        Next, define new subsets $C_{0}'$, $C_{1}'$,\,{\ldots}\,$C_{k}'$ of $X$ as follows:
        \begin{displaymath}
        C_{0}' \,=\, \{0,2k+1\}, \h C_{1}' \,=\, \{1,k+1\}, \h C_{2}' \,=\, \{2,k+2\},\,{\ldots}\,C_{k}' \,=\, \{k,2k\}.
        \end{displaymath}
    Much as above, one sees that $f(0)+f(2k+1) \,=\, x_{k+1} - x_{0} \,=\, b-a$, $f(1)+f(k+1) \,=\, x_{k}-x_{k} \,=\, 0$, $f(2)+f(k+2) \,=\, x_{k-1}-x_{k-1} \,=\, 0$,\,{\ldots}\,$f(k)+f(2k) \,=\, x_{1}-x_{1} \,=\, 0$.
    Thus the sum
        \begin{displaymath}
        {\sum}_{C_{0}'} f + {\sum}_{C_{1}'} f + \,{\ldots}\,+{\sum}_{C_{k}'} f 
        \end{displaymath}
    equals the sum $(b-a) + 0 + 0 + \,{\ldots}\,+ 0$; that is, the value is~$b-a$, which of course is the {\em left} side of  Equation~$({\ast})$.
    But it is clear that the sets $C_{0}'$, $C_{1}'$,\,{\ldots}\, $C_{k}'$ are also nonempty mutually disjoint subsets of $X$ whose union is $X$.
    Thus the Generalized Associative Law for Addition applies once again to imply that the left side of Equation~$({\ast})$ also equals ${\sum}_{X} f$.


        Since, as just been shown, both sides of Equation~$({\ast})$ equal the same quantity, namely ${\sum}_{X} f$,
    it follows that the two sides of this equation equal each other; which is a fancy way of saying that the equation is true.

\V

        (b) The proof of this part is similar, and is left as an exercise.


\V
\V

        {\bf Remark} These equations should bring back happy memories from high-school algebra:
    they form the basis for the classic `Add-and-Subtract' Trick (Part~(a)) and the `Multiply-and-Divide Trick' (Part~(b)).

\V
\V


        The preceding results keep addition and multiplication separated. The next result combines both operations.

\V

            \subsection{\small{\bf Theorem} (Generalized Distributive Law)}
            \label{ThmB10.110}

\V

        Suppose that $f_{1},f_{2},\,{\ldots}\,f_{m}:X \,{\rightarrow}\, {\RR}$ are real-valued functions defined on a nonempty finite set $X$,
    and that $c_{1}$, $c_{2}$,\,{\ldots}\,$c_{m}$ are real numbers. Then:
        \begin{equation}
        \label{EqnB.10}
        {\sum}_{X} (c_{1}f_{1} + c_{2}f_{2} + \,{\ldots}\,+ c_{m}f_{m}) \,=\, 
    c_{1}{\cdot}{\sum}_{X} f_{1} + c_{2}{\cdot}{\sum}_{X} f_{2} + \,{\ldots}\,+ c_{m}{\cdot}{\sum}_{X} f_{m}
        \end{equation}
        In particular, one has as the following: ${\sum}_{X} (-f) \,=\, -{\sum}_{X} f$.

\V

        The simple proof is left as an exercise.

\V

        To see how this result generalizes the usual Distributive Law (see Axiom~A3),
    consider the special case in which $m \,=\, 1$ and the set $X$ has exactly two elements: $X \,=\, \{a,b\}$.
    Then on the left side of the equation one has
        \begin{displaymath}
        {\sum}_{X} c_{1}f_{1} \,=\, c_{1}f_{1}(a) + c_{1}f_{1}(b),
        \end{displaymath}
    while on the right side one has
        \begin{displaymath}
        c_{1}{\sum}_{X} f_{1} \,=\, c_{1}(f_{1}(a)+f_{1}(b)).
        \end{displaymath}
    The resulting  equality $c_{1}f_{1}(a) + c_{1}f_{1}(b) \,=\, c_{1}(f_{1}(a)+f_{1}(b))$ is the Distributive Law.

\V
\V

        The preceding calculations illustrate an important feature of proving well-known facts directly from the axioms:
    the process, although certainly instructive, can be quite tedious.
    It is also quite annoying, since we are proving results that we have been using, sometimes unconsciously, almost all our lives.
    From this point on, however, we shall follow the usual custom and normally leave such low-level proofs to the reader.
    Sometimes these proofs will be omitted without comment, sometimes with a blithe statement such as `Now simplify to get \,{\ldots}\, '.
    In any event, the reader is left the task of filling in the gaps in such calculations, often by invoking the Generalized Commutative, Associative and Distributive Laws.
    

\V
\V



\begin{quotation}
{\footnotesize \underline{Pedagogical Comment}
    The axioms listed above all involve standard algebraic facts about real numbers that everyone has known -- and used, often without realizing it -- since grade school.
    Because of that familiarity, there is a tendency to think of these axioms as `obvious' or even `trivial';
    Chapter Quote~$1$ suggests a reason for this tendency.

        Nevertheless, the rather bland presentation of these axioms does hide some nonobvious facts.
    For example, consider the following equation:
        \begin{displaymath}
        25350{\times}47 \,=\, 325{\times}3666 \h ({\ast})
        \end{displaymath}
    The odds are high that most people would not find this equation as being `obviously true';
    indeed, most would have to verify it by simply carrying out the indicated multiplications and noting that each ends up equaling~$1191450$.
    However, one easily checks that $25350 \,=\, 325{\cdot}78$ and $3666 \,=\, 78{\cdot}47$,
     so that Equation~$({\ast})$ is simply a rewriting of the following special case of the Associative Law for Multiplication:
        \begin{displaymath}
        (325{\cdot}78){\cdot}47 \,=\, 325{\cdot}(78{\cdot}47)
        \end{displaymath}
    If the special case $({\ast})$ of this Associative Law is not `obvious', then probably the general Associative Law should be even less `obvious'.

        So why do we accept Axiom~A2 as `obvious'? Almost certainly {\em not} because
    we have tried out this axiom on dozens of triples $x$, $y$ and $z$ and verified that it works, much as we just did with Equation~$({\ast})$.
    No, the likely answer is that we accepted this axiom simply because in grade  school arithmetic `Teacher said it is so.'
}%EndFootNoteSize
\end{quotation}

\V
\V
}%\EndSkip
%-------------------
%------------------
\StartSkip{
        The next result is sometimes of use.

\V


            \subsection{\small{\bf Theorem}}
            %\label{ThmB20.45}

        Suppose that $C\,>\,0$.
    Then there exists a number $B\,>\,0$ such that if $M\,>\,B$ then
        \begin{displaymath}
        \frac{1}{M}\,<\,C\,<\,M.
        \end{displaymath}

\V

        The simple proof is left to the reader as an exercise. However, be careful:
    it is easy to let the notation of algebra fool you. Does {\em your} solution work, for instance, when $C \,=\, 1/2$?
}%\EndSkip MAKE THIS AN EXERCISE?
%-----------------

%------------------
\StartSkip{
\V
\V

        Inequalities of the form $a\,<\,b$ or $b\,>\,a$ are often referred to as {\bf strict inequalities},

        The negation of the statement `$x$ is less than $y$' is the statement `$x$ is \underline{not} less than $y$'; this is sometimes written symbolically as $x \, \not < \, y$.
    However, in light of `Trichotomy' (Property~(a) above), the statement `$x$ is not less than $y$' is equivalent, 
    for real numbers, to the compound statement `{\bf $x$ is greater than $y$ or $x$ is equal to, $y$}';
    symbolically, $x\,\,{\geq}\,\,y$. This latter notation is almost always used instead of $x \, \not < \, y$; its spoken version is usually abbreviated to `$x$ is greater than, or equal to, $y$'.
    Likewise, one normally formulates the negation of the statement `$x\,>\,y$' as $x\,\,{\leq}\,\,y$',
    which in spoken form becomes `$x$ is less than, or equal to, $y$', instead of $x\, \not > \,y$.

        To clarify the distinction, one sometimes refers to the relations $x\,\,{\leq}\,\,y$  and $x\,\,{\geq}\,\,y$  as  {\bf weak inequalities}, since each allows the possibility that $x$ might actually equal $y$.
    In much the same way, one sometimes refers to the relations $x\,<\,y$  and $x\,>\,y$ as {\bf strict inequalities}, since they do {\em not} allow the possibility of equality.
   One could with equal justice refer to these as {\bf strong} inequalities, to contrast with the `weak inequalities' terminology above;
   it appears that such usage is not common in analysis.

        In a similar manner, it is easy to see that the negation of the statement `$x\,\,{\leq}\,\,y$' is equivalent to `$x\,>\,y$',
    and the negation of the statement `$x\,\,{\geq}\,\,y$' is equivalent to '$x\,<\,y$'.

        In analogy with the notation introduce in Part~(b) of Theorem~\Ref{ThmB20.40},
    it is convenient to allow strings of inequalities that contain both weak and strict inequalities,
    as long as all of them are of the same type; that is, all are either $<$ or $\,\,{\leq}\,\,$, or all are either $\,>\,$ or $\,\,{\geq}\,\,$.
    For example, one allows strings such as
        \begin{displaymath}
        x\,\,{\leq}\,\,y\,<\,z\,<\,w\,\,{\leq}\,\,u\,<\,v
        \end{displaymath}
    The meaning of this string is that each of the inequalities connecting consecutive pairs of numbers is valid.
    However, as usual one should avoid stringing together inequalities of opposite type, such as $\,\,{\leq}\,\,$ with $\,\,{\geq}\,\,$ or $\,>\,$.


\V

        The next results summarize the main properties of the binary relations $\,\,{\leq}\,\,$ and $\,\,{\geq}\,\,$.

\V

            \subsection{\small{\bf Theorem}}
            \label{ThmB20.60}

\V

        Throughout this theorem the quantities $x$, $y$, $z$ and $w$ are real numbers.

\V

        (a) A necessary and sufficient condition for $x$ to equal $y$ is that $x\,\,{\leq}\,\,y$ and $y\,\,{\leq}\,\,x$.

\V

        (b) (Transitivity) Suppose that $x\,\,{\leq}\,\,y$ and $y\,\,{\leq}\,\,z$.
    Then $x\,\,{\leq}\,\,z$.
    Moreover, one has $x \,=\, z$ if, and only if, $x \,=\, y$ and $y \,=\, z$.

        More generally, let $n$ be a natural number such that $n\,\,{\geq}\,\,3$,
    and suppose that $x_{1}$, $x_{2}$, $x_{3}$, \,{\ldots}\,$x_{n}$ are real numbers such that each of the following inequalities hold:
        \begin{displaymath}
        x_{1}\,\,{\leq}\,\,x_{2}; \,x_{2}\,\,{\leq}\,\,x_{3};
    \,\,{\ldots}\,
        x_{n-2}\,\,{\leq}\,\,x_{n-1};\, x_{n-1}\,\,{\leq}\,\,x_{n};
        \end{displaymath}
    more briefly, $x_{k}\,\,{\leq}\,\,x_{k+1}$ for each index $n \,=\, 1,2,\,{\ldots}\,n-1$.
    Then for each pair of indices $i$ and $j$ such that $1\,\,{\leq}\,\,i\,<\,j\,\,{\leq}\,\,n$ one has $x_{i}\,\,{\leq}\,\,x_{j}$.
    \underline{Note} One indicates this by then writing
        \begin{displaymath}
        x_{1}\,\,{\leq}\,\,x_{2}\,\,{\leq}\,\,\,{\ldots}\,x_{n-1}\,\,{\leq}\,\,x_{n}.
        \end{displaymath}
    Finally, if this last condition holds, then a necessary and sufficient condition to have $x_{i} \,=\, x_{j}$
    for some indices $i$ and $j$ such that $i\,<\,j$ is that $x_{i} \,=\, x_{k}$ for all $k \,=\, i, i+1, \,{\ldots}\,j$.

\V

        (c) (Additivity) If $x\,\,{\leq}\,\,y$ and $z\,\,{\leq}\,\,w$, then $x+z\,\,{\leq}\,\,y+w$.
    Moreover, one has $x+z \,=\, y+w$ if, and only if, $x \,=\, y$ and $z \,=\, w$.


\V

        (d) (Negativity) If $x\,\,{\leq}\,\,y$ then $-y\,\,{\leq}\,\,-x$.
    Moreover, one has $-y \,=\, -x$ if, and only if, $x \,=\, y$.

\V

        (e) (Multiplicity) Suppose that $x\,\,{\leq}\,\,y$.

        \h (i) If $u$ is a positive real number, then $ux\,\,{\leq}\,\,uy$;  equality occurs if, and only if, $x \,=\, y$.

        \h (ii) If $u$ is a negative real number then $uy\,\,{\leq}\,\,ux$; equality occurs if, and only if, $x \,=\, y$.

\V

        (f) (Reciprocity) Suppose that $x\,\,{\leq}\,\,y$.

        \h (i) If $x$ is positive, then $y$ is also positive;
    furthermore,  ${\displaystyle \frac{1}{y}\,\,{\leq}\,\,\frac{1}{x}}$.

        \h (ii) If $y$ is negative then $x$ is also negative; furthermore, ${\displaystyle \frac{1}{y}\,\,{\leq}\,\,\frac{1}{x}}$.


\V
        (g) Let $c$ be a real number. Then $|c|\,\,{\geq}\,\,0$. Furthermore, $|c| \,=\, 0$ if, and only if, $c \,=\, 0$.

\V

        (h) If in Parts~(a) through (f) above one replaces every occurance of the symbol $\,\,{\leq}\,\,$ by the symbol $\,\,{\geq}\,\,$, then the resulting statements are also true.

\V

        {\bf Proof}\, Left as an exercise.
}%\EndSkip
%-------------------

\VV

%-------------------------
\StartSkip{
        {\bf Remark} It may appear silly to use two notations, $\,<\,$ and $\,>\,$, for essentially one idea;
    indeed, it is clear that in principle only one of these notations is needed.
    In practice, however, there is a good reason,
    rooted in the way languages work, for allowing both notations.

        \underline{Example}: Consider the following sentences:
\VA

        \h (i)\, The real number $1$ is positive.

        \h (ii) The real number $-1$ is negative.
\VA

\noindent In each case the subject of the sentence, i.e., the thing that the sentence is {\em about}, is a certain real number;
    in (i) it is the number~$1$, while in~(ii) it is the number~$-1$.
    Of course one could write equivalent sentences using the symbols $\,>\,$ and $\,<\,$:
        \begin{displaymath}
        \mbox{(i) } 1\,>\,0 \h \mbox{(ii) } -1\,<\,0
        \end{displaymath}
    If, however, one were to eliminate, say, $\,<\,$ as being `redundant', then the inequality $-1\,<\,0$ would have to be replaced by $0\,>\,-1$.
    This last expression would be spoken as `$0$ is less than $1$', which, in ordinary usage,
    is a sentence that asserts something about the number~$0$, not about~$1$; thus, this version slightly distorts the original emphasis.


            \subsection{\small{\bf Remarks on Strings of Inequalities}}
            \label{RemrkB20.50}

\hspace*{\parindent}
        (1) The statement `$x\,<\,y$ and $y\,<\,z$' in the Transitivity Property (Part~(b) of Theorem~\Ref{ThmB20.40}) is normally written in a more compact form:
        \begin{displaymath}
        x\,<\,y\,<\,z
        \end{displaymath}
    More generally, if $x_{1}$, $x_{2}$, $x_{3}$, \,{\ldots}\, $x_{n-1}$, $x_{n}$ are real numbers, then the expression
        \begin{displaymath}
        x_{1}\,<\,x_{2}\,<\, x_{3}\,<\,\,{\ldots}\,\,<\,x_{n}
        \end{displaymath}
    is an abbreviation of the compound statement
        \begin{displaymath}
       ` x_{1}\,<\,x_{2} \mbox{ and } x_{2}\,<\,x_{3} \mbox{ and } \,{\ldots}\, \mbox{ and } x_{n-1}\,<\,x_{n}'.
        \end{displaymath}
    It follows from the Transitivity Property for $\,<\,$ that if $x_{1}\,<\,x_{2}\,<\, x_{3}\,<\,\,{\ldots}\,\,<\,x_{n}$,
    then for each $i$ and $j$ such that $1\,\,{\leq}\,\,i\,<\,j\,\,{\leq}\,\,k$ one has $x_{i}\,<\,x_{j}$.

        Similar results hold when one replaces one or more of the symbols $\,<\,$ in the preceding results by the weaker inequality $\,{\leq}\,$; see Exercise~(\ref{ChaptB}~-~26) at the end of this chapter.

\V

        (2) Similar combinations involving $\,>\,$ and $\,{\geq}\,$ can be formed, and the transitivity property likewise exploited.
    However, it is considered bad writing style to combine, for example, $\,>\,$ in the same string of inequalities with $\,<\,$. For instance, the string of inequalities $x\,<\,y\,>\,z$ certainly makes sense.
    indeed, it says the same as the compound statement `$x\,<\,y$ and $y\,>\,z$', or,
    equivalently, `$x\,<\,y$ and $z\,y\,z$'; more briefly, `$x, z\,<\,y$'. The two latter formulations are much easier to read, whereas the expression $x\,<\,y\,>\,z$ does not combine well with `Transitivity'.

}%\EndSkip
%-------------------
%----------------------------------------------------
\StartSkip{
            \subsection{\small{\bf Corollary} (Properties of `Distance' in ${\RR}$)}
            %\label{CorB20.66}

\V

        Let $d_{{\RR}}:{\RR}{\times}{\RR} \,{\rightarrow}\, {\RR}$ denote the `distance in ${\RR}$' function described in Definition~\Ref{DefB20.10}.

\V

        (a) (Positivity) If $a$ and $b$ are real numbers with $a \,\,{\neq}\,\, b$, then $d_{{\RR}}(a,b)\,>\,0$.
    However, if $a \,=\, b$ then $d_{{\RR}}(a,b) \,=\, 0$.

\V

        (b) (Symmetry) If $a$ and $b$ are real numbers then $d_{{\RR}}(a,b) \,=\, d_{{\RR}}(b,a)$.

\V

        (c) (The Basic Distance Triangle Inequality) If $a$, $b$ and $c$ are real numbers, then
        \begin{equation}
        \label{IneqB.36A}
        d_{{\RR}}(a,c)\,\,{\leq}\,\,d_{{\RR}}(a,b) + d_{{\RR}}(b,c).
        \end{equation}

\V

        (d) (The Extended Distance Triangle Inequality) Suppose that $a$ and $b$ are real numbers. Then for every choice of $k$ real numbers $c_{1}$, \,{\ldots}\, $c_{k}$ one has
        \begin{equation}
        \label{IneqB.36B}
        d_{{\RR}}(a,b)\,\,{\leq}\,\,d_{{\RR}}(a,c_{1}) + d_{{\RR}}(c_{1},c_{2}) + \,{\ldots}\, + d_{{\RR}}(c_{k-1},c_{k}) + d_{{\RR}}(c_{k},b).
        \end{equation}
    Moreover, one gets the case of `equality' in Inequality~\Ref{IneqB.36B} if, and only if, either $a\,\,{\leq}\,\,c_{1}\,\,{\leq}\,\,c_{2}\,\,{\leq}\,\,\,{\ldots}\,\,\,{\leq}\,\,c_{k}\,\,{\leq}\,\,b$ or $b\,\,{\leq}\,\,c_{k}\,\,{\leq}\,\,c_{k-1}\,\,{\leq}\,\,\,{\ldots}\,\,\,{\leq}\,\,c_{1}\,\,{\leq}\,\,a$.

\V

        (e) (The Distance/Magnitude Inequality) Suppose that $a$ and $b$ are real numbers.
    Then
        \begin{equation}
        \label{IneqB.36C}
        d_{{\RR}}(|a|,|b|)\,\,{\leq}\,\,d_{{\RR}}(a,b).
        \end{equation}
    That is, the distance between the magnitudes of two numbers is no bigger than the distance between the numbers themselves.

\V

        The simple proof, which makes repeated use of Theorem~\Ref{ThmB20.65}, is left as an exercise for the reader.


\V
\V

            \subsection{\small{\bf Remarks}}
            \label{RemrkB20.67}
\V

        \hspace*{\parindent}(1) The name `Magnitude--Interval Equalities' reminds us that the inequalities relate the magnitude $|x-c|$ and $M$ with the intervals $[-M+c,M+c]$ and $(-M+c,M+c)$.

\V

        (2) The name `Triangle Inequality' associated with these results is traditional.
    It comes from the analogous result in the study of sides of a in two-dimensional Euclidean geometry:
    If $a$, $b$ and $c$ are the lengths of the sides of a triangle in the Euclidean plane,
    then the sum of any two of these lengths is at least as large as the third length.
    (Equality can occur only in the case of `degenerate' triangles, for which all three vertices lie on the same line segment.)

\V

        (3) In contrast to the `Triangle' terminology, the `Distance Inequality' terminology used in Corollary~\Ref{CorB20.66} makes good sense,
    even in the context of the real numbers.
    Unfortunately, the more common usage is to refer to `Triangle Inequality' for those distance results as well.
    In particular, the title `Distance/Magnitude Inequality' for Part~(e) of the corollary is {\em not} at all standard.

}%\EndSkip
%-----------------------
%----------------------------
\StartSkip{
        Up to now it has been assumed in {\ThisText} that the reader is familiar with the standard decimal notation for integers,
    and this assumption continues to hold. However, it is useful for later discussions to formally define at least the decimal digits as real numbers.

        \subsection{\small{{\bf Definition}}}
        \label{DefB25.55}\IndA{decimal digits}

\V

        The {\bf decimal digits} are the real numbers $0$, $1$, $2$, $3$, $4$, $5$, $6$, $7$, $8$ and~$9$ given by as follows:
    First, $0$ and $1$ are the usual additive and multiplicative units of the real number system.
    The remaining decimal digits are then obtained, using the ordinary addition of real numbers, by
        \begin{displaymath}
        2 \,=\, 1+1; \h 3 \,=\, 2+1; \h 4 \,=\, 3+1; \h 5 \,=\, 4+1; \h
        6 \,=\, 5+1; \h 7 \,=\, 6+1; \h 8 \,=\, 7+1; \h 9 \,=\, 8+1
        \end{displaymath}
    Furthermore, when dealing with decimal representations, the symbol $10$ denotes the real~number~$9+1$.
}%\EndSkip
%---------------

%---------------------
\StartSkip{
%%% 
\begin{quotation}
{\footnotesize \underline{\Note}\IndB{\notes}{on ${\NN}$ as an inductive subset of ${\RR}$} (on ${\NN}$ as an inductive subset of ${\RR}$):
        The preceding result shows that it is particularly easy to derive the basic algebraic properties of ${\ZZ}$ and ${\QQ}$ by treating them as subsets of ${\RR}$ as above.
    Many modern texts in real analysis go one step further and derive the properties of ${\NN}$ itself by defining this set directly as a subset of ${\RR}$.
    That is, in contrast to {\TheseNotes}, such texts do {\em not} treat the natural numbers as a primitive concept that comes logically prior to that of the real numbers.
    Here is how they are able to do this.

\V

        {\bf Definition}
        %\subsection{\small{{\bf Definition}}}
        %\label{DefB25.60}

\V

\hspace*{\parindent}(1) A subset $X$ of ${\RR}$ is said to be an {\bf inductive subset} provided it satisfies the following two conditions:

        \h (i)\, The number $1$ is an element of $X$

        \h (ii) If $k$ is any element of $X$, then $k+1$ is also an element of $X$.

\V

        (2) Let ${\cal F}_{i}$ be the family of all inductive subsets of ${\RR}$.
    Then the intersection of this family is called the {\bf inductively-defined set of natural numbers}, and is denoted by the symbol ${\NN}_{i}$.

\V

        {\bf Remark} It is clear that there do exist inductive subsets of ${\RR}$, and thus that the family ${\cal F}_{i}$ is nonempty;
    for example, ${\RR}$ itself is clearly an inductive subset of ${\RR}$, as is the set of all positive real numbers.

\V

        {\bf Theorem}
        %\subsection{\small{{\bf Theorem}}}
        %\label{ThmB25.70}

\V

\hspace*{\parindent}(a) The set ${\NN}_{i}$ satisfies the Principle of Mathematical Induction.
    More precisely, if $A$ is any subset of ${\NN}_{i}$ such that $1{\in}A$ and $k$ in $A$ implies that $k+1$ is in $A$, then $A \,=\, {\NN}_{i}$.

\V

        (b) The sets ${\NN}_{r}$ and ${\NN}_{i}$ described in the preceding paragraphs are the same: ${\NN}_{i} \,=\, {\NN}_{r}$.

\V

        {\bf Proof}

\V

        (a) The hypotheses on $A$ imply that $A$ is an inductive subset of ${\RR}$, and thus $A$ is a member of the family ${\cal F}_{i}$.
    Thus, since (by definition) ${\NN}_{i}$ is the intersection of all the members of ${\cal F}_{i}$,  it follows from the definition of `intersect' that every element of ${\NN}_{i}$ must also be an element of $A$; that is, ${\NN}_{i} \,{\subseteq}\, A$.
    However, one also has $A \,{\subseteq}\, {\NN}_{i}$ by hypothesis. The fact that $A \,=\, {\NN}_{i}$ now follows.

\V

        (b) This follows easily from the fact that each of the sets ${\NN}_{r}$ and ${\NN}_{i}$ satisfy the Principle of Mathematical Induction.

\V

        {\bf Remark} Texts which follow this `inductive subset' approach to the natural numbers then have to show that the basic facts for such numbers hold; 
    for example, that the subset is closed under addition and multiplication in ${\RR}$.
    They would also do essentially what we carried out in Appendix~A to derive the usual laws for natural numbers.
    Finally, they would define the integers and the rational numbers, much as we have done here, in terms of ${\NN}_{i}$.

        It is largely a matter of taste whether one starts with the natural numbers and only later embeds them into the real numbers (as we do in {\TheseNotes}),
    or starts with the natural numbers already treated as elements of ${\RR}$.
}%EndFootnotesize
\end{quotation} 
%##
}%\EndSkip
%------------------------
%-------------------------
\StartSkip{
        The phrasing of many results can be simplified by using the following terminology.

\V

            \subsection{\small{\bf Definition}}
            \label{DefB20.70}

\V

\hspace*{\parindent}
        (1) Let $c$ be a real number. Then the {\bf positive part of $c$}\IndBD{positive part}{positive part of a number} is the number $c^{+}$ given by
        \begin{displaymath}
        c^{+} \,=\, \left\{
        \begin{array}{ll}
        c & \mbox{if $c\,\,{\geq}\,\,0$} \\
        0 & \mbox{if $c\,<\,0$}
        \end{array}
                                \right.
        \end{displaymath}
    Likewise, the {\bf negative part of $c$}\IndBD{negative part}{negative part of a number} is the number $c^{-}$ given by
        \begin{displaymath}
        c^{-} \,=\, \left\{
        \begin{array}{rl}
        0 & \mbox{if $c\,>\,0$} \\
       -c & \mbox{if $c\,\,{\leq}\,\,0$}.
        \end{array}
                    \right.
        \end{displaymath}

\V

        (2) More generally, let $f:X \,{\rightarrow}\, {\RR}$ be a real-valued function whose domain is a nonempty set $X$.
Then the {\bf positive part of $f$}\IndBD{positive part}{positive part of a function}, denoted $f^{+}$, and the {\bf negative part of $f$}\IndBD{negative part}{negative part of a function}, denoted $f^{-}$, are the functions with domain $X$ given by
        \begin{displaymath}
        f^{+}(x) \,=\, \left(f(x)\right)^{+} \mbox{ and } f^{-}(x) \,=\, \left(f(x)\right)^{-} \mbox{ for all $x$ in $X$}.
        \end{displaymath}
    (Note that the numbers $\left(f(x)\right)^{+}$ and $\left(f(x)\right)^{-}$ appearing on the right side of the preceding equations are defined by Part~(1), using $c \,=\, f(x)$.)


\V
\V

            \subsection{\small{\bf Examples}}
            \label{ExampB20.80}


\V

\hspace*{\parindent}(1) If $c \,=\, 2$ then $c^{+} \,=\, 2$, $c^{-} \,=\, 0$.

\V

        (2) If $c \,=\, -2$ then $c^{+} \,=\, 0$, $c^{-} \,=\, 2$.

\V

        (3) If $c \,=\, 0$ then $c^{+} \,=\, c^{-} \,=\, 0$.

\V

        (4) Let $f:{\RR} \,{\rightarrow}\, {\RR}$ be given by $f(x) \,=\, 1-x^{2}$ for all $x$ in ${\RR}$.
    Then one easily sees that
        \begin{displaymath}
        f^{+}(x) \,=\, \left\{
        \begin{array}{cl}
        1-x^{2} & \mbox{if $-1\,\,{\leq}\,\,x\,\,{\leq}\,\,1$} \\
          0     & \mbox{if $x\,<\,-1$ or $x\,>\,1$}
        \end{array}
                                    \right.
        \end{displaymath}
    and
        \begin{displaymath}
        f^{-}(x) \,=\, \left\{
        \begin{array}{cl}
          0      & \mbox{if $-1\,\,{\leq}\,\,x\,\,{\leq}\,\,1$} \\
       x^{2} - 1 & \mbox{if $x\,<\,-1$ or $x\,>\,1$}
        \end{array}
                                    \right.
        \end{displaymath}
    The reader is encouraged to sketch the graphs of $f$, $f^{+}$ and $f^{-}$ in this case.

\V
\V

            \subsection{\small{\bf Remarks}}
            \label{RemrkB20.90}

\V

\hspace*{\parindent}
        (1) It may seem strange that one calls $c^{+}$ the `positive' part of of $c$, since $c^{+}$ need not be positive;
    it might seem more reasonable to call $c^{+}$ the `nonnegative part' of $c$.

\V

        (2) It should seem even stranger, then, to call $c^{-}$ the `negative part' of $c$, since $c^{-}$ is {\em never} negative!

\V

        (3) Finally, it is not at all clear in what sense $c^{+}$ and $c^{-}$ are `parts' of $c$.

\V

        (4) Similar observations can be made about the functions $f^{+}$ and $f^{-}$.

\V

        The simplest way to respond to the objections implicit in these remarks is to hide behind the curtain of authority:
    these definitions are completely standard and are used throughout analysis, so one should simply learn -- and accept -- them.

\V
\V

        The next result gives the basic properties of the numbers $c^{+}$ and $c^{-}$.

\V

            \subsection{\small{\bf Theorem}}
            \label{ThmB20.100}

        Let $c$ be a real number. Then:

\V

        (a) $c^{+} \,=\, {\max}\,\{c,0\}, \mbox{ and } c^{-} \,=\, {\max}\,\{-c,0\}$.
    In particular, $c^{+}\,\,{\geq}\,\,0$ and $c^{-}\,\,{\geq}\,\,0$.

\V

        (b) $c \,=\, c^{+} - c^{-}$, \mbox{ and } $|c| \,=\, c^{+} + c^{-}$.
    In particular, one has  $-c^{-}\,\,{\leq}\,\,c\,\,{\leq}\,\,c^{+}$.


\V

        (c) ${\displaystyle c^{+} \,=\, \frac{|c|+c}{2}}$
    and ${\displaystyle c^{-} \,=\, \frac{|c|-c}{2}}$.

\V

        (d) If $a$ and $b$ are real numbers then $0\,\,{\leq}\,\,(a+b)^{+}\,\,{\leq}\,\,a^{+}+b^{+}$ and $0\,\,{\leq}\,\,(a+b)^{-}\,\,{\leq}\,\,a^{-}+b^{-}$.

\V

        \underline{Proof}

\V

        (a) Suppose that $c\,\,{\geq}\,\,0$. Then $c^{+} \,=\, c$ (by definition of $c^{+}$), and ${\max}\,\{c,0\} \,=\, c$ (by definition of $\max$);
    thus $c^{+} \,=\, \max\,\{c,0\}$ when $c\,\,{\geq}\,\,0$.
    Similarly, suppose that $c\,<\,0$. Then $c^{+} \,=\, 0$, and  ${\max}\,\{c,0\} \,=\, 0$; thus, $c^{+} \,=\, \max\,\{c,0\}$ when $c\,<\,0$, too.

       As for $c^{-}$, suppose first that $c\,>\,0$; then $c^{-} \,=\, 0$. Also, $-c\,<\,0$, so ${\max}\,\{-c,0\} \,=\, 0$.
    Thus $c^{-} \,=\, {\max}\,\{-c,0\}$. Similarly, if $c\,\,{\leq}\,\,0$ then $c^{-} \,=\, -c$. Also $-c\,\,{\geq}\,\,0$, so ${\max}\,\{-c,0\} \,=\, -c$.
    Thus, $c^{-} \,=\, {\max}\,\{-c,0\}$ in this case as well.

        The inequalities $c^{+}\,\,{\geq}\,\,0$ and $c^{-}\,\,{\geq}\,\,0$ follow easily.

\V

        (b) If $c\,\,{\geq}\,\,0$ then $c^{+}-c^{-} \,=\, c-0 \,=\, c$;
    also $c^{+}+c^{-} \,=\, c+0 \,=\, c \,=\, |c|$.
    Likewise, if $c\,<\,0$ then $c^{+}-c^{-} \,=\, 0-(-c) \,=\, c$; also $c^{+}+c^{-} \,=\, 0-c \,=\, -c \,=\, |c|$.

        If $c \,=\, 0$ then $c^{+} \,=\, c^{-} \,=\, 0$, and $|c| \,=\, 0$.
    Thus $c^{+}-c^{-} \,=\, 0-0 \,=\, 0 \,=\, c$ and $c^{+}+c^{-} \,=\, 0+0 \,=\, 0 \,=\, |c|$, as required.

        Since $c^{-}\,\,{\geq}\,\,0$, the equation $c \,=\, c^{+}-c^{-}$ implies that $c^{+}\,=\,c+c^{-}\,\,{geq}\,\,c$; thus, $c\,\,{\leq}\,\,c^{+}$.
    Likewise, since $c^{+}\,\,{\geq}\,\,0$, it follows from the same equation that $-c^{-} \,=\, c-c^{+}\,\,{\leq}\,\,c$.
    Combining these results yields the desired inequality.
    

\V

        (c) It follows from Part~(b) that
        \begin{displaymath}
        |c| + c \,=\, (c^{+}+c^{-}) + (c^{+}-c^{-}) \,=\, (c^{+}+c^{+}) + (c^{-}-c^{-}) \,=\, 2c^{+}.
        \end{displaymath}
    Likewise,
        \begin{displaymath}
        |c| - c \,=\, (c^{+}+c^{-}) - (c^{+}-c^{-}) \,=\, (c^{+}-c^{+}) + (c^{-}+c^{-}) \,=\, 2c^{-}.
        \end{displaymath}
    The desired result follows easily.

\V

        (d) The simple proof is left as an exercise.

\V

            \subsection{\small{\bf Corollary}}
            \label{CorB20.105}
       Let $f:X \,{\rightarrow}\, {\RR}$ be a real-valued function defined on a nonempty set~$X$. Then:

\V

        (a) $f^{+}(x) \,=\, {\max}\,\{f(x),0\}, \mbox{ and } c^{-} \,=\, {\max}\,\{-f(x),0\}$ for all $x$ in~$X$.
    In particular, the functions $f^{+}$ and $f^{-}$ are nonnegative on~$X$.

\V

        (b) $f \,=\, f^{+} - f^{-}$, \mbox{ and } $|f| \,=\, f^{+} + f^{-}$.
    In particular, one has  $-c^{-}\,\,{\leq}\,\,c\,\,{\leq}\,\,c^{+}$.


\V

        (c) ${\displaystyle f^{+} \,=\, \frac{|f|+f}{2}}$
    and ${\displaystyle f^{-} \,=\, \frac{|f|-f}{2}}$.

\V

%        (d) If $a$ and $b$ are real numbers then $0\,\,{\leq}\,\,(a+b)^{+}\,\,{\leq}\,\,a^{+}+b^{+}$ and $0\,\,{\leq}\,\,(a+b)^{-}\,\,{\leq}\,\,a^{-}+b^{-}$.

\V

        The simple proof is left as an exercise.
}%\EndSkip
%--------------------------

\V
\V


%----------------------------
\StartSkip{

        The preceding ideas can be used to simplify the statement of Theorem~\Ref{ThmB20.25A}.

\V

            \subsection{\small{\bf Theorem}}
            \label{ThmB20.110}

        Suppose that $f:X \,{\rightarrow}\, {\RR}$ is a real-valued function defined on a finite set $X$.
    Let $f^{+}:X \,{\rightarrow}\, {\RR}$ and $f^{-}:X \,{\rightarrow}\, {\RR}$ denote, respectively, the positive and negative parts of $f$ on $X$.
    Then

\V

        (a) ${\sum}_{X} f^{+}\,\,{\geq}\,\,0$, with equality if, and only if, $f(x)\,\,{\leq}\,\,0$ for all $x$ in $X$.
    Likewise, ${\sum}_{X} f^{-}\,\,{\leq}\,\,0$, with equality if,
    and only if, $f(x)\,\,{\geq}\,\,0$ for all $x$ in $X$.

\V

        (b) The set $X_{f;+}$ defined in Theorem~\Ref{ThmB20.25A} is nonempty if, and only if, ${\sum}_{X} f^{+}\,>\,0$.
    Likewise, the set $X_{f;-}$ is nonempty if, and only if, ${\sum}_{X} f^{-}\,<\,0$.

\V

        (c) Equation~\Ref{EqnB.25} can be put into the following simpler form:
        \begin{equation}
        \label{EqnB.60}
        {\sum}_{X} f \,=\, {\sum}_{X} f^{+} - {\sum}_{X} f^{-}
        \end{equation}
        Likewise, Equation~\Ref{EqnB.25A} can be put into the form
        \begin{equation}
        \label{EqnB.65}
        {\sum}_{X} |f| \,=\, {\sum}_{X} f^{+} + {\sum}_{X} f^{-}
        \end{equation}

\V

        The simple proofs are left as an exercise.

\V
\V


            \subsection{\small{\bf Remarks}}
            \label{RemrkB20.120}

\V

\hspace*{\parindent}
        (1) In light of the preceding result, Remark~\Ref{RemrkB20.25B} can be summarized more succinctly as follows:

        When faced with computing a sum that involves the possibility of terms of mixed signs,
    it is often useful to reduce the calculation to sums of nonnegative terms, together with at most one subtraction,
    using Equation~\Ref{EqnB.60}.

\V

        (2) One advantage of Theorem~\Ref{ThmB20.110}, compared to Theorem~\Ref{ThmB20.25A},
    is that in Equations~\Ref{EqnB.60} and~\Ref{EqnB.65}, all the sums taken are over the same nonempty set $X$.

}%\EndSkip
%------------------------------
%-------------------------------------------------
\StartSkip{

            \subsection{\small{Lemma}}
            \label{LemmaB30.08CC}

\V

        Let $X$ be a nonempty set of numbers which is bounded above. Let $U_{X}$ be the set of upper bounds of~$X$;
    note that the hypothesis that $X$ is bounded above is equivalent to asserting that the set $U_{X}$ being nonempty.
    A necessary and sufficient condition for the set $X$ to have a supremum $B$ is that the set $U_{X}$ have a least element~$C$,
    in the sense of Definition~\Ref{DefB30.60}; that is, $X$ has a least upper bound. Furthermore, when this occurs one has $B \,=\, C$.

\V

        {\bf Proof} Suppose that $X$ has a supremum; call it~$B$. Then, by Part~(1) of Definition~\Ref{DefB30.08A}, $B$ is in the set~$U_{X}$.
    Furthermore, if $y\,<\,B$, then by Part~(2) of the same definition there exists $x{\in}X$ such that $y\,<\,x$;
    in particular, if $y\,<\,B$ then $y$ is {\em not} an upper bound of~$X$. Thus $B$ is the least element of~$U_{X}$, as required.

        The converse can be proved by reversing the steps of the preceding argument.

\V

        The preceding lemma ensures the equivalence of the Supremum Principle with the following principle.

\V
}%\EndSkip
%---------------------
%-------------------------
\StartSkip{

            \subsection{\small{Lemma}}
            \label{LemmaB30.08FF}

\V

        Suppose that $X$ is a nonempty set of numbers which is bounded below. Let $L_{X}$ be the set of lower bounds of~$X$.
    Then a necessary and sufficient condition for the set $X$ to have an infimum $b$ is that the set $L_{X}$ have a greatest element~$c$,
    in the sense of Definition~\Ref{DefB30.60}. Furthermore, when this occurs one has $b \,=\, c$.
}%\EndSkip
%%---------------------------------------------------

%------------------------------------------
\StartSkip{

            \label{RemrkB30.08H}
\V

        (1) The phrases `{\em the} supremum' and `{\em the} infimum' used in the preceding definitions
    suggest that the numbers $B$ and $b$ satisfying the given conditions, if they exist, are unique.
    It is an easy exercise to check that this is, indeed, correct.

\V

        (2) The nouns `supremum' and `infimum' come from the Latin words for `highest one' and `lowest one', respectively.
    Because of this origin, the plurals of these words are sometimes written as in Latin, as `suprema' and `infima',
    and sometimes in the manner of ordinary English, as `supremums' and `infimums'.
    The reader should expect to find both forms in the mathematical literature.

\V

        (3) The words `maximum' and `minimum', found in Definition~\Ref{DefB30.60},
    are also Latin in origin, and one often finds their plurals written as `maxima' and `minima'.
    More importantly for the current discussion, these words have nearly the same meaning as `supremum' and `infimum': `greatest' and `least', respectively.
    This fact often causes confusion, because there is a subtle difference in the way these words are used in mathematics.
    Precisely, the technical definitions of $\max\,X$ and $\min\,X$ require that these numbers be elements of the set~$X$,
    whereas the definitions of ${\sup}\,X$ and ${\inf}\,X$ allow the possiblility that these numbers might {\em not} be elements of~$X$.
    Geomtrically speaking: suppose that one wishes to discuss the right endpoint of a nonempty set $X$ of numbers.
    If it is known for certain that this endpoint is actually a member of the set~$X$, then one is allowed to refer to it as $\max\,\,X$;
    but if its membership status is unknown, so that it may or may not be a member of the set~$X$, then use ${\sup}\,X$.
    Similar comments apply to the uses of `$\min X$' and ${\inf}\,X$.

\V

        (5) In his pamphlet of the year $1817$ referred to above, Bolzano stressed
    this subtle distinction between `maximum of a set' ($\max\,X$) and `right endpoint of a set' (${\sup}\,X$).
    In particular, he stated that even some well-known mathematicians of his era were led into errors by failing to recognize this distinction.
    (Of course Bolzano did not use the modern formulations seen here.)
}%\EndSkip
