% M140AB_A.TeX  Notes for `Single-Variable Analysis': Chapter 

%
% Revised: 01/20/2017 Encoding: Western ASCII
%



                  \chapter{Preliminaries; Elementary Set Theory; Functions}
                  \label{ChaptA}


        \underline{Quotes for Chapter~\Ref{ChaptA}}\IndB{chapter quotes}{for Chapter~\Ref{ChaptA} (Preliminaries; Elementary Set Theory; Functions)}:

\V

\begin{quotation}
{\footnotesize

        (1) `I shall not today attempt further to define [it], and perhaps I could never succeed in intelligibly doing so. But I know it when I see it, \,{\ldots}\, .'

        (Potter Stewart, Associate Justice of the U.S. Supreme Court, in his written opinion on the 1964 case of `Jacobellis {\em vs} Ohio'.)\IndA{Stewart, Justice Potter}\IndD{Jacobellis {\em vs} Ohio}{Stewart, Justice Potter}

        Remark: The reader may wish to look up this case to find out what the `it' was that Justice Stewart had such difficulty defining.
`
\V

        (2) `I hate definitions.'

        (Spoken by Mrs. Felix Lorraine, a character in the novel `Vivian Grey' by Benjamin Disraeli, later to become Prime Minister of the United Kingdom.)\IndA{Disraeli, Benjamin}
    % Bartlett p.434 #13

\V

        (3) `\,{\ldots}\,first in war, first in peace, and first in the hearts of his countrymen.'

        (From the eulogy, by `Light-Horse' Harry Lee, on the death of President George Washington.)

\V

        (4) `When we've been there ten thousand years, bright shining as the sun, we've no less days to sing God's praise then when we first begun'.\IndA{Amazing Grace verse}

        (Anonymous text often included as an additional verse of the well-known hymn {\em Amazing Grace} by John Newton;
    it appears in the novel `Uncle Tom's Cabin' by Harriet Beecher Stow.)
%Page 231 of my computer version of Volume 2 of the novel.

}%EndFootNoteSize
\end{quotation}

\V
\V

        
                \section{Preliminary Remarks}\IndB{ZZ Sections}{\Ref{SectA05} Preliminary Remarks for Chapter~\Ref{ChaptA}} \IndA{preliminary remarks for Chapter~\Ref{ChaptA}}
                        \label{SectA05}

\V
\V

       \h \underline{Basic Structure of This Work}

\V

        \h \h (1) In what follows, we refer to this work as `{\bf {\ThisText}}'\IndA{\ThisText}; note the italics.

\V

        \h \h (2) The `{\bf main body}' of {\ThisText},\IndA{main body of {\ThisText}} consists of a number of chapters,
    enumerated by Roman numerals (I, II, III, etc.) In addition, there are several appendices, enumerated by capital letters (A, B, etc).
    Each chapter and appendix ends with exercises. % NEED EXERCISES WITH THE APPENDICES

\V

        \h \h (3) The appendices expand on topics which appear in the main body of {\ThisText}. Many of these topics are of the type that every mathematician should know.
    However, one can read the main body, and carry out the corresponding exercises, independently of the appendices.

\V

        \h \h (4) Inserted into the exposition are certain `\Notes', outside the strictly {\em logical} flow of the discussion,
    which attempt to give insight into the topic at hand. Many of these `\Notes' are historical in nature; some allow the author to express personal mathematical opinions which can be safely ignored by the reader; and some provide connections with pedagogy.
    (Those who study the type of analysis presented here often become teachers of calculus themselves.)


    \underline{Remark} The `\Notes' are indented and printed in a smaller font to make it easier for the reader to skip over them if so desired;
    in a sense, they play the role of footnotes. In particular, they are not needed for a purely logical treatment of the subject,
    and they are not referred to in the main body, the appendices to the main body, or the exercises of {\ThisText}.
    Nevertheless, it is recommended that they be read, at least when first learning the material.


\VV

       \h \underline{Prerequisites for Reading {\ThisText}}

\V

      \h \h (1) Anyone reading {\ThisText} should certainly know, from elementary-school arithmetic,
    the basic properties of the natural numbers $1, 2, 3, \,{\ldots}\,$, the integers $0,  \,{\pm}\, 1,  \,{\pm}\, 2,  \,{\pm}\, 3, \,{\ldots}\,$,
    and the rational numbers (quotients of integers with nonzero denominators). For sake of completeness some of these properties are further discussed in appendices.

\V

      \h \h (2) In addition, the reader should also be familiar with the {\em real} numbers, again from elementary-school arithmetic.
    In contrast to the situation which holds for the integers and the rational numbers, however, to understand modern analysis
    it is necessary to delve much more deeply into the foundations of the real-number system than was possible in elementary arithmetic.
    Indeed, the body of Chapter~\Ref{ChaptB} is devoted to a careful axiomatic description of the real-number system.
    As is usually the case with such axiomatic approaches, this description does not actually say what real numbers `are',
    in any philosophical sense, only how to use them properly.

\V

      \h \h (3) It is assumed that the readers of {\ThisText} have already taken a standard course in elementary (single-variable) calculus;
    in particular, that they are familiar with the few simple proofs which normally appear in such a course,
    such as the derivations of the product and quotient rules for differentiation, and the proof via Rolle's Theorem of the standard formulation of the Mean-Value Theorem.
    In order to avoid simply repeating these proofs exactly as was already presented in elementary calculus,
    our Chapter~\Ref{ChaptE} (`Differential Calculus')  takes the opportunity to approach some of these topics in a way which provides different insights.
    For example, in Chapter~\Ref{ChaptE} we of course prove the fact that that a function with positive derivative on an interval $I$ is strictly increasing on~$I$,
    but without using, or even mentioning, the Mean-Value Theorem; the resulting proof seems more direct than the standard one in calculus.
    Where appropriate, the standard approaches are also reviewed, but usually in the exercises.


\V

      \h \h (4) One who had not first taken elementary calculus could, in principle, understand the content of {\ThisText},
    since all the definitions and theorems stated in the main body are carefully presented using ideas appearimg earlier here, and the corresponding proofs are rigorous.
    However, such a reader would lack the motivating examples and applications which play such an important role in elementary calculus,
    but which traditionally are omitted from texts at our level. Indeed, a major goal of real analysis is to build a logical foundation under the already-known results of elementary calculus,
    so that errors which crept into calculus by the beginning of the nineteenth century can be avoided.
    On occasion it may be useful to refer to some topics from calculus, usually within clarifying examples, before they are `officially' treated in the body of the text.
    A reader lacking  the appropriate calculus background at that stage may simply ignore such examples.

\VV

%%%
\begin{quotation}
{\footnotesize \underline{\Note}\IndB{\notes}{on Definitions, Theorems and Proofs} (on definitions, theoreme and proofs)

\V

        As is mentioned above, the exposition of analysis found in {\TheseNotes} attempts to be rigorous.
    This means that definitions should be carefully formulated, theorems should be stated fully, and proofs should be logically complete.
    Since {\TheseNotes} may be the first extensive encounter with rigorous mathematics for some readers,
    it is useful to make a few comments.

\V

      \h \h (1) The role of a `definition' is to express the meaning of a concept in terms of concepts which are already understood.
    Normally these older concepts are themselves defined in terms of concepts which are older~yet.
    It is clear, however, that at some point one must stop looking back, and simply accept some `primitive' concepts as being `already known',
    without providing definitions of them.
    Such a primitive concept is often handled along the lines of Justice Potter Stewart's famous confession;
    see Chapter Quote~(1) at the start of this chapter.


        \underline{Warning}: Different authors may describe the same concept using different definitions.

\VA

       \h \h (a) \underline{Example} Consider the following statements:

        \h \h \h `An even number is an integer of the form $2\,k$, where $k$ is some integer.'

        \h \h \h `An odd number is an integer which is not an even number.'

        \h \h \h `An odd number is an integer of the form $2\,k -1$, where $k$ is some integer.'

        \h \h \h `An even number is an integer which is not an odd number.'

\VA

\noindent Each of these statements happens to be true; but {\em why} are they true?

        Nearly everyone would say that the first statement is true `by definition',
    since most authors {\em define} the meaning of `even number' with this statement.
    From that point of view, one cannot {\em prove} the first statement, since it simply provides the meaning of the phrase `even number'.
    Likewise, some authors use the second statement as the definition of `odd number', so for such an author it is also true `by definition';
    in this case, the third statement would then be a theorem which needs to be proved.
    In contrast, some authors use the third statement as the definition of `odd number', and for them {\em it} becomes true `by definition',
    while the second statement becomes a theorem to be proved.
    Finally, an author who uses the third statement as the definition of `odd number' might well use the fourth statement as the definition of `even number', 
    in which case the first statement would need to be proved as a theorem.

         In particular, to give a logical treatment of a topic it is important to know which statements are taken as the definitions, and which are not:
    the former are automatically true (`by definition'!), while the latter require proof.
    Unfortunately, some authors are rather vague about which statements are their definitions, and which are their theorems.
    In {\TheseNotes} the convention is that when words or phrases are being defined they appear in boldface,
    and, most of the time, in a paragraph explicitly labeled as a definition.
    However, on occasion it is pedagogically useful to start with a `primitive' or `preliminary' definition of a concept,
    and then give an `improved' definition later as circumstances change. In {\TheseNotes} auch situations are noted explicitly and explained.

        The question of which formulation of a concept is chosen as the definition is largely a matter of the judgement and taste of the author.
    Thus, while one cannot argue that an author's definition is `false', one {\em can} claim that the author used bad taste in choosing to use it and not another,
    or that the author's definition is `nonstandard', or that the author's definition is not equivalent to one's own favorite.

        Sometimes different authors use the same words for slightly different ideas.
    For example, some authors define the the smallest natural number to be~$1$, while others define it to be~$0$;
    see the discussion in Example~\Ref{ExampA10.06} below.


\VA

      \h \h  (b) A related issue arises especially in the {\em construction} of important mathematical objects.
    Namely, authors may give the same name to -- and treat the same way --  objects which are of completely different types.
    For example, in elementary arithmetic the standard way to construct the integer $-2$ is to simply prefix the natural number $2$ with the minus sign.
    The modern approach, in contrast, defines $-2$ to be a certain infinite collection of pairs of natural numbers; see Appendix~B.


\V

      \h  (2) A `Theorem' is a mathematical statement which asserts that, under appropriate circumstances (namely, when certain `hypotheses' are satisfied)
    then something else must also be true (namely the `conclusions' of the theorem).
    Sometimes words such as `Proposition', `Lemma' or `Corollary' are used in place of `Theorem' to break the monotony,
    or to show the logical dependence of one statement on the other; but they are all theorems.
    When stating theorems, all hypotheses and conclusions should be formulated very precisely.
    Likewise, when applying a theorem to a later situation, it is equally important
    to check carefully that its hypotheses are satisfied and that its conclusions are being used correctly.

        Another feature of theorems in mathematics is the frequent use of {\em names} for theorems,
    such as `The Pythagorean Theorem' (in geometry) or `The Mean-Value Theorem' (in elementary calculus) . In {\TheseNotes} we attempt to name as many of the important theorems as possible, 
    especially those which have names that are in common use. The main reason is for ease of reference: it is more meaningful to say, for example,
    that a given proof uses `the Mean-Value Theorem' than it is to say that the proof uses `Theorem~\Ref{ThmE50.40}'.
    Of course this use of names, instead of theorem numbers, becomes even more important in mathematical discussions outside the context of a given source.
    Unfortunately, as with definitions, mathematicians sometimes apply the same name to different theorems, so some caution is needed.

\V

      \h  (3) Many texts include a brief discussion on 'Logic' or `Proofs'.
    Such discussions often include the introduction of the formalism of `symbolic logic',
    which can make `logic' appear to be purely mathematical -- even mechanical -- and unrelated to ordinary experience.
    The approach taken in {\TheseNotes}, in contrast, treats `logic' as primarily a linguistic phenomenon:
    what constitutes a correct logical argument in mathematics is really the same as for a logical argument in, say, history or the law.
    That is, the correctness of an argument consists primarily in using {\em words} properly and precisely, and not just symbols.
    In particular, as happens with learning ordinary language, one develops the skill for producing logical arguments by encountering
    -- and ultimately mimicking -- many examples of such arguments. When reading proofs in {\TheseNotes}, for instance,
    the beginner should go carefully through the arguments -- don't simply `scan' over them.
    To help, many of the early proofs are given in excruciating detail, so read each detail.
    With experience, less and less needs to be included in the printed proof, and the reader can be expected to fill the gaps.
    On occasion in {\ThisText} there will be a discussion, often within a {\Note}, about logical arguments, to help less experienced readers.

\V

    \h (4) The most common format for writing rigorous mathematical exposition nowadays is the so-called {\bf Definition-Theorem-Proof style}\IndA{Definition-Theorem-Proof style}:
    first give one or more definitions of important concepts; then state theorems about those concepts; finally prove those theorems.
    Such an exposition can be very clean, but it puts great burdens on readers to figure out where any of this comes from and what it means to them.
    For example, in real-life mathematics, `definitions' usually appear on the scene only after the importance of the underlying idea is already clear,
    and all one needs is to express it clearly in words and give it a name. That is, `definitions' normally do {\em not} appear first chronologically in the development of mathematics.

\V


    \h  (5) It is the experience of many teachers of elementary calculus that most of their students believe that
    the {\em words} which appear in their calculus textbooks form an optional part of the course; this includes definitions and statements of theorems.
    For example, if, at the end of such a course, the teacher asks the students to give the definition of `derivative'
    -- arguably the most fundamental concept of the subject, and one whose definition was actually used repeatedly throughout the course  --
    the result is often a wall of blank stares.
}%EndFootnotesize
\end{quotation} 
%## 



                        \section{Basic Set Theory}\IndB{ZZ Sections}{\Ref{SectA10} Basic Set Theory}
                        \label{SectA10}


        In the last hundred and fifty years or so mathematics has become increasingly abstract and axiomatic.
    This process has been greatly facilitated by the use of set theory as a common language.
    The present section is devoted to a quick review of the basics of that theory. The treatment here is informal --
    some authors use the word `naive' -- to contrast it with more formal axiomatic approaches that study the foundations of the subject.
    In particular, the `set theory' developed in {\TheseNotes} is a tool for organizing the study of analysis, and not a goal in itself.

\VV


        The primitive concept needed for our treatment of basic set theory is that of a {\bf collection of objects}.
    In particular, we do not define here what is meant by either an {\em object} or by a {\em collection};
    instead, we assume that these these are `primitive concepts' which fall under Justice Stewart's dictum of `I know it when I see it'.

\V

            \subsection{\small{\bf Definition}}
            \label{DefA10.05}\IndB{set theory}{definition of `set'}

\V

\hspace*{\parindent}(1) A {\bf set} is a collection of objects, thought of as a single object in its own right.

        \underline{Note} The phrase `thought of an object in its own right' is crucial:
    it implies that whatever the primitive concept of `object' means, and whatever the primitive concept of `collection' means,
    anything which is a `collection of objects', i.e., a `set', is itself an `object',
    and therefore can be used in the formulation of new `collections of objects'; in particular, sets of sets.

        One frequently uses the word {\bf family}\IndBD{set theory}{family} instead of the word `set'.
     In {\TheseNotes} the use of `family' is normally restricted to sets whose elements are themselves sets of objects;
    thus, we may refer to a `{\em family} of sets' instead of a `{\em set} of sets'.

\V

        (2) If $X$ is a set of objects, then the objects which form the collection $X$ are called the
    {\bf elements of $\Bfm{X}$}\IndBD{set theory}{elements}; they are also called {\bf points of $\Bfm{X}$}\IndBD{set theory}{points} and {\bf members of $\Bfm{X}$}\IndBD{set theory}{members}.
    If $b$ is a member of $X$ then one also says that {\bf $\Bfm{b}$ belongs to $\Bfm{X}$} or that {\bf $\Bfm{b}$ is in $\Bfm{X}$};
    the standard shorthand notation for any of these statements is $b{\in}X$.
    Likewise, if $c$ is an object which is {\em not} a member of the collection $X$,
    one says that {\bf $\Bfm{c}$ is not an element of $\Bfm{X}$}, etc, and one writes $c\not\in X$.

\V
\V

%%% 
\begin{quotation}
{\footnotesize \underline{\Note}\IndB{\notes}{on set theory} (on set theory): The theory of sets, as a distinct branch of mathematics, was initially founded by the German mathematician Georg Cantor\IndBD{set theory}{Cantor, Georg} in the 1870's.
    It is worth noting that this very abstract theory grew out of Cantor's work on Fourier series,
    a subject which plays a vital role in quite concrete applied mathematics.
    Fortunately, one does not have to know anything about Fourier series to understand the main ideas of Cantor's set theory.
}%EndFootnotesize
\end{quotation} 
%##

\V
\V

        \underline{Some Nonmathematical Sets}

\V

        (1) The set whose elements are the letters
        \begin{displaymath}
        A,B,C,D,E,F,G,H,I,J,K,L,M,N,O,P,Q,R,S,T,U,V,W,X,Y,Z
        \end{displaymath}
    is called the (English) {\bf alphabet}.
    More precisely, it is the set of upper-case letters, to contrast it from the corresponding set of lower-case letters.
    Note that in mathematics one often uses letters from this alphabet, or from the alphabet of some other language,
    in particular Greek, as the names or symbols for certain mathematical objects.
    In that context one normally treats the upper-case and lower-case versions of a given letter as denoting different objects.

\V

        (2) The set consisting of all the United States senators as of January~1, 2000,
    is an object in its own right: the US~Senate (as of that date), denoted here by the letter~$S$. Its elements are the individual senators.

        This example illustrates the significance of the phrase `thought of as an object in its own right' appearing in Definition~\Ref{DefA10.05}.
    Indeed, as an object in its own right, the Senate $S$ can have properties appropriate to the type of object it is.
    For example, the Senate, as a (finite) set of objects, has a `membership size': there are 100~members (senators).
    In contrast, an element of the set~$S$ (i.e., an individual senator) has `party affiliation'; for example, `independent'.
    Note that the property `membership size' does not apply to an individual senator, nor does the property `party affiliation' apply to the Senate as a whole.


\V

        (3) Consider the set whose elements are the Greek letter ${\alpha}$, the country Australia, and the emperor Napoleon Bonaparte.
    Each of the three elements of this set is, individually, of considerable significance;
    but the set itself, thought of as an object in its own right, appears to be of little interest (except, possibly, as an example of a set of little interest).

\V
\V

            \subsection{\small{\bf Some Standard Mathematical Sets and Their Symbols}}
            \label{ExampA10.06}

\V


        In contrast to the preceding `nonmathematical' sets, the following sets {\em are} of considerable importance for us;
    the symbols used here are fairly standard in mathematics, and appear throughout~{\TheseNotes}.

\V

        (a) The symbol ${\NN}$ denotes the set of all {\bf natural numbers};\IndA{natural numbers}.
    These are the numbers used in the process of `counting' which one learns as children.
    Indeed, they are often called the {\bf counting numbers}\IndBD{natural numbers}{counting numbers}.
    In the body of {\ThisText} we treat the concept of these numbers, and the corresponding basic properties,
    as `primitive' concepts: we know them when we see them, but do not define them further.
    However, we also follow the usual custom and identify intuitively whatever `primitive' notion of `natural number' we have with
    `strings of finite decimals expressions': $1$, $2$, $3$, \,{\ldots}\,$100$, $101$, and so on; keep in mind, however, that historically the decimal notation arose much later.

        \underline{Warning} Despite the antiquity of these numbers, the terminology used for them is far from universal even today.
    For example, in areas such as computer science it is customary to include~$0$ as the `initial' natural number;
    what most mathematicians call `natural numbers' (i.e., starting with $1$) might in such areas be referred to as {\bf counting numbers}\IndBD{natural numbers}{counting numbers}.
    Good arguments can be made for or against either usage. (For example, try replacing the word
    `first' with the word `zero-th' throughout Chapter Quote~(3) at the start of this chapter.)
    In any event, the choice of which usage to follow is mainly one of taste, convenience, and the conventions within the particular field of study.

\V

        (b) The symbol ${\ZZ}$ denotes the set of all integers, i.e., the numbers $0$,  $\,{\pm}\, 1$, $ \,{\pm}\, 2$, \,{\ldots}\,.
    There appears to be universal agreement on what numbers constitute this set, and nearly universal agreement on the use of the symbol ${\ZZ}$.
    (The use of this symbol comes from the German word `{\bf Z}ahl', which means `number'.)

\V

        (c) The symbol ${\QQ}$ denotes the set of all rational numbers (i.e., {\bf Q}uotients of integers).

\V

        (d) The symbol ${\RR}$ denotes the set of all {\bf R}eal numbers.

\V

        (e) It is convenient to list here the standard notations for a few more important sets of numbers.

        \h If $k$ is a natural number, then ${\NN}_{k}$ denotes the set of all natural numbers~$m$ such that $1\,\,{\leq}\,\,m\,\,{\leq}\,\,k$.

        \h In contrast to the preceding, if $k$ is a natural number, then ${\ZZ}_{k}$ stands for the set of integers $m$ such that $0\,\,{\leq}\,\,m\,\,{\leq}\,\,k-1$.

        \h The symbols ${\ZZ}^{+}$, ${\QQ}^{+}$ and ${\RR}^{+}$ denote the sets of positive integers, positive rational numbers,
    and positive real numbers, respectively. In particular, one has ${\NN} \,=\, {\ZZ}^{+}$.

        \h Let $a$ and $b$ be real numbers such that $a\,<\,b$. The {\bf closed interval with endpoints $\Bfm{a}$ and \Bfm{b}}\IndBD{intervals in ${\RR}$}{closed intervals},
    denoted $[a,b]$, is the set of all real numbers $x$ such that $a\,\,{\leq}\,\,x\,\,{\leq}\,\,b$.
    The corresponding {\bf open interval}\IndBD{intervals in ${\RR}$}{open intervals} is the set $(a,b)$ whose members are the real numbers $x$ such that $a\,<\,x\,<\,b$.
    The corrsponding {\bf half open intervals} $[a,b)$ and $(a,b]$ are defined analogously.

        \underline{Remark} The symbols ${\NN}$, ${\ZZ}$, ${\QQ}$ and ${\RR}$ are stylized versions of the ordinary upper-case letters
    $N$, $Z$, $Q$ and $R$, respectively, and in {\TheseNotes} are used only to refer to the indicated fundamental sets of numbers.
    In contrast, the `unstylized' versions, $N$, $Z$, $Q$ and $R$, are also used frequently in {\TheseNotes}, but {\em never} to refer to these sets.

\V
        In Appendix~A the interested reader can find an axiomatic development of the arithmetic of the natural numbers.
    However, the treatment found in that appendix is not needed to understand the main body of {\ThisText}.
    In particular, it is assumed that the reader is already familiar with the standard arithmetic (addition, multiplication and,
    where appropriate, division) of these numbers, as well as the their standard order properties (greater than, less than).

\VV

%%% 
\begin{quotation}
{\footnotesize \underline{\Note}\IndB{\notes}{on the `natural number' terminology} (on the `natural number' terminology):
An obvious way to avoid the ambiguity of what which numbers ought to be called `natural numbers' (see the `Warning' above)
    is to use the standard symbol ${\ZZ}^{+}$, which stands for `the set of positive integers', in place of the symbol ${\NN}$,
    and to use the phrase `positive integer' instead of `natural number'. Indeed, many authors do just that, despite the fact that the former expression is longer than the latter: more letters, more syllables.
    We avoid the `positive integer' terminology, at least at this early stage, because it introduces an anachronism into the discussion:
    if one wants to {\em define} ${\NN}$ to be ${\ZZ}^{+}$, one needs to know in advance what the set ${\ZZ}$ is.
    Historically speaking, however, the `counting' numbers $1$, $2$, $3$, \,{\ldots}\, came long before the number $0$ or the negative numbers,
    and thus long before it would make sense to talk about the `{\em positive} integers'.
    Of course for a long time `number' simply meant what we now call `natural number'. The need for the prefix `natural' arose, one presumes,
    from the introduction of new numbers which were originally thought to be `unnatural', such as negative numbers.
}%EndFootnotesize
\end{quotation} 
%##

\VV


            \subsection{\small{\bf Remarks}}
            \label{RemrkA10.07}


        A good deal of terminology and notation has developed in mathematics around the concept of `set'.

\V

        (1) Frequently a set is denoted by explicitly listing its elements, or by providing some other more-or-less explicit description of its elements.
    For instance, if $Y$ is the set consisting of all the even natural numbers, then one can write
        \begin{displaymath}
        Y  \,=\,  \{2, 4, 6, 8,\,{\ldots}\,\}  \,=\, \{2\,k: k  \,=\,  1,2,3, \,{\ldots}\, \} \,=\, \{2\,k: k{\in}{\NN}\}.
        \end{displaymath}
    In the first expression for $Y$, the reader is expected to figure out from the pattern that is setting up that the set consists of `all even natural numbers';
    likewise, in the second expression, the reader is expected to realize that the quantity $k$ runs over all the natural numbers, so that the expression $2k$ runs over all the even natural numbers.
    The third expression is technically the clearest, although it does require that the reader remember the definition of the symbol ${\NN}$;
    or, failing that, be willing to look up its definition.
    
        Note that in this so-called `{\bf set-builder notation}'\IndB{set theory}{set builder notation}
    the braces \,\{\, and \,\}\, are used as `delimiters', in the sense that they tell where the description of the set begins and ends.

\V

        (2) If $X$ is a set, then, as is stated in Definition~\Ref{DefA10.05}, $X$ can be viewed as a single object in its own right.
    As a consequence, it is possible to form new sets whose elements are themselves sets.
    For instance, suppose that $X \,=\, \{1,2,3,4,5\}$ while $Y \,=\, \{10, 11, 12\}$.
    Let $Z$ be the set whose elements are the objects $X$ and $Y$;
    that is,
        \begin{displaymath}
        Z \,=\, \{X,Y\} \,=\, \{\{1,2,3,4,5\},\{10,11,12\}\}.
        \end{displaymath}
    Notice that the set $Z$ has precisely two elements, namely the set $X$ and the set $Y$, thought of as objects in their own right.
    In particular, $Z$ is {\em not} the set $\{1,2,3,4,5,10,11,12\}$, which has precisely eight elements.

\V

        (3) The statement `A set is a collection of objects' in Definition~\Ref{DefA10.05}
    may make it appear that every set must have more than one member, since the word `objects' here is a plural noun.
    In reality, however, mathematicians allow the title `set' to be applied to smaller collections as well:

       \h (a) Let $c$ be an object. Then the set $X \,=\, \{c\}$, whose only element is the object $c$, is said to be a {\bf singleton set}\index{singleton set}.
    Likewise, if $b$ and $c$ are objects such that $b\,{\neq}\,c$, then one calls the set $\{b,c\}$ a {\bf doubleton set}\index{doubleton set}.

       \h (b) Let $X$ be defined as `the set of all natural numbers whose square is negative'.
    Of course, there are no such numbers, so this `set' has no elements at all!
    Nevertheless, it is useful to allow such a set into the theory, as will become clear.
    This set with no elements is called the {\bf empty set}\IndBD{set theory} {empty set (${\emptyset}$)} and is denoted by the symbol ${\emptyset}$.
    Note that this example may suggest that the empty set is a set of natural numbers; however, see Example~\Ref{ExampA10.09}~(3) below.

\V


        (4) The special case in which $X$ a singleton set $\{c\}$, thought of as an object in its own right, is worth separate mention.
    Authors frequently treat the set $\{c\}$ and original object $c$ interchangeably,
    as if they were the same object; otherwise stated, they `identify' the set $\{c\}$ with the object $c$.
    Of course, equating these objects is incorrect, since the object $\{c\}$ is a set, whose only element is the object $c$, while the object $c$ is not.
    Usually the context makes clear what is really meant, and no confusion results.
    Nevertheless, is is considered good manners to warn the reader when such an {\bf abuse of notation}\IndA{abuse of notation}
    (as identifications like these are usually called) is being used.

\VV


        In general, any set which arises `naturally' in mathematics consists of objects that are, in some sense,
    `mathematical objects' that are `related' to each other; for example, each element of the set ${\QQ}$ is a ratio of integers.
    Indeed, a major part of mathematics consists of studying the properties which arise from the relations which hold between elements of specific sets.
    Nevertheless, in set theory there is no requirement that the elements of a set be related to each other in any way other than have been grouped into the same set.
    The only purely set-theoretic issue is whether an object is in the set or not. This fact is sometimes expressed as the following principle:

\V

            \subsection{\small{\bf Fundamental Principle (The Axiom of Extension)}}\IndA{axiom of extension}
            \label{PrinA10.08}

        A set is completely determined by its elements. More precisely: The set $X$ and the set $Y$ are equal,
    i.e., they are the same object, if, and only if, they have exactly the same members;
    that is, every object in $X$ is also an element of $Y$, and every object in $Y$ is also an element of~$X$.

\V

        The preceding `Fundamental Principle' is not a `theorem' of set theory; instead, it is really just a clarification of the definition.
    The name `Axiom of Extension' (or, sometimes, `Axiom of Extensionality') comes from more formal treatments of set theory.

        This princple may seem too obvious to need statement, but there is real content to it.
    For instance, it implies that the {\em manner} in which one describes a set is irrelevant.
    It also implies that {\em how one uses} the elements of a set is irrelevant to which set is involved.

            \subsection{\small{\bf Examples}}
            \label{ExampA10.09}


         \h (1) Let $X \,=\, \{1,2,3\}$, let $Y \,=\, \{3,2,1\}$, and let $Z \,=\, \{1,3,2,2,1,1,3\}$.
    The {\em lists} of numbers used to describe $X$, $Y$ and $Z$ are not the same -- the order is different, and in the case of $Z$ the list has repetitions;
    That is, the given {\em descriptions} of these sets are all different.
    Nevertheless, the sets $X$, $Y$ and $Z$ are the equal.
    For instance, the numbers $1$, $2$ and $3$ are clearly in the set $Z$, and equally clearly no other object is in $Z$.
    Thus, $Z$ has precisely the same elements as the set $X$, so $Z \,=\, X$. Likewise one sees that $X \,=\, Y \,=\, Z$.

\V

        (2) Let $X$ be the set of all real numbers $x$ such that $-1\,\,{\leq}\,\,x\,\,{\leq}\,\,1$,
    and let $Y$ be the set of all numbers of the form ${\sin}\,x$ for $x$ in ${\RR}$.
    It should be clear to the reader that $X \,=\, Y$; of course this assumes that the reader recalls certain specific facts from high-school trigonometry.

\V

        (3) Let $X$ be the set of all real numbers $x$ such that $x^{2} \,=\, -2$,
    and let $Y$ be the set of all live dinosaurs in the San Diego Zoo as of January~1,~2000.
    It is clear from these definitions that $X$ is a set of numbers, while $Y$ is a set of animals.
    Since no number is an animal and no animal is a number, at first glance it would appear that these sets could not possibly be equal.
    However, these sets do have exactly the same elements, in the sense that there is no element of $X$ which is not in $Y$,
    and there is no element of $Y$ which is not in $X$.
    Thus, $X \,=\, Y$; in fact, both $X$ and $Y$ equal the empty set ${\emptyset}$ discussed earlier.
    This illustrates the fact that there is only one `empty set', which is why we can refer to {\em the} empty set and can use a fixed symbol, ${\emptyset}$, to denote it.


\VV

            \subsection{\small{\bf Definition}}
            \label{DefA10.095}

\V

\hspace*{\parindent} (1) Suppose that $X$ and $Y$ are sets, and suppose further that every element of $X$ is also an element of $Y$.
    One then says that {\bf $\Bfm{X}$ is a subset of $\Bfm{Y}$}\IndBD{set theory}{subset}; in symbols, $X \,{\subseteq}\, Y$.
    This relationship between $X$ and $Y$ is also written $Y \,{\supseteq}\, X$; in words: `{\bf $\Bfm{Y}$ is a superset of $\Bfm{X}$}'\IndBD{set theory}{superset}.

\V

        (2) If $X{\subseteq}Y$ but $X \,\,{\neq}\,\, Y$ then one says that $X$ is a {\bf proper subset}\IndC{set theory}{subset}{proper subset} of $Y$;
    the phrase `proper superset'\IndC{set theory}{superset}{proper superset} is defined analogously.
    For example, the empty set ${\emptyset}$ is a subset of {\em every} set $X$, and is a proper subset of every nonempty set.

\V

        \underline{Warning on Notation}: Some math texts use the symbols ${\subset}$ and ${\supset}$ for what we write here as ${\subseteq}$ and ${\supseteq}$, respectively.
    Unfortunately, many other math texts use the same symbols, ${\subset}$ and ${\supset}$, to refer to {\em proper} subsets and supersets, respectively.
    Because of this, we avoid the use of ${\subset}$ and ${\supset}$ in {\TheseNotes}.
    If there is a need to indicate explicitly that $X$ is a {\em proper} subset of $Y$, or, equivalently, $Y$ is a {\em proper} superset of $X$,
    then we use the unambiguous notations $X\,\subsetne\,Y$ and $Y\,\supsetne\,X$.

\V
\V

        It is convenient to formulate the `Axiom of Extension' in terms of the `subset' relation.



\V

            \subsection{\small{\bf Theorem}}
            \label{ThmA10.10}

        Let $X$ and $Y$ be sets. A necessary and sufficient condition for these sets to be equal, i.e., for the relation $X \,=\, Y$ to hold, is that $X \,{\subseteq}\, Y$ and $Y \,{\subseteq}\, X$;
    equivalently, $Y \,{\supseteq}\, X$ and $X \,{\supseteq}\, Y$.

\V

        The (trivial) proof, which consists of recalling the meaning of the notations $ \,{\subseteq}\, $ and $\,{\supseteq}\, $, is left to the reader.

\V
\V

        Let us continue the very informal discussion of `sets', given above, but  now in the more formal `Definition-Theorem-Proof' style.
    The first definition describes some standard ways of constructing new sets from old.

\V

        \underline{Two Notes on Language}:

\V

        (1)\IndA{inclusive `or' {\em vs} exclusive `or'}\IndA{exclusive `or' {\em vs } inclusive `or'} In the following definition,
    as elsewhere in {\TheseNotes}, we follow the standard convention in mathematical writing and use the `inclusive' sense of the word `or'.
    For example, to say that `an element $c$ is a member of either the set $X$ or the set $Y$'
    does {\em not} preclude the possibility that $c$ could be a member of both sets.
    This contrasts the usage in ordinary (i.e., nonmathematical) English, in which the `or' is often used in the `exclusive' sense:

        `Do your homework or you won't get to watch television.'

\noindent This usually implies that you {\em will} get to watch~TV if, in fact, you do your homework.

\V

        (2) There is another problem in English usage which appears both within and outside of mathematics: the ambiguous indefinite article.
    \IndA{ambiguous indefinite article}

        \h \underline{Example} Consider the following questions:

        \h \h (1) `Does Kim have an apple?'

        \h \h (2) `Does the quadratic equation $x^{2} - 4 \,=\, 0$ have a solution?'

\noindent In both questions the use of the indefinite articles `{\em an}' and `{\em a}' is ambiguous. For example, in Question~(1),
    is the questioner asking whether Kim has {\em exactly} one apple, or whether Kim has {\em at least} one apple?
    Likewise, in Question~(2), is the questioner asking whether the equation has {\em exactly} one solution, or whether it has {\em at least} one solution?


        Experience suggests that in mathematical writing the meaning of the indefinite articles `{\em an}' and~`{\em a}' is used is to mean `at least one'.
    In any event, the obvious way to avoid such ambiguity is to append phrases such as `at least one' or `exactly one', as appropriate.
        
\V
\V


            \subsection{\small{\bf Definition}}
            \label{DefA10.15}

\hspace*{\parindent} Let $X$ and $Y$ be sets.

\V

        (1) The {\bf complement of $\Bfm{X}$ in $\Bfm{Y}$}\IndBD{set theory}{complement of one set in another},
    denoted $Y{\setminus}X$, is the set whose elements are precisely those members of $Y$ which are {\em not} members of $X$;
    the symbol `$\,{\setminus}\,$' is sometimes pronounced `minus' in the present context.

\V

        (2) The {\bf union of $\Bfm{X}$ and $\Bfm{Y}$}\IndBD{set theory}{union of sets}, denoted $X{\cup}Y$, is the set whose elements are precisely those objects which belong either to $X$ or to $Y$;
    the symbol ${\cup}$ is pronounced `union' or `cup'.
    (As was stated in the  `Note' above, we use the `inclusive or' here, so that an object which is an element of both $X$ and $Y$ is also an element of $X{\cup}Y$.)

        Similarly, let $k$ be a natural number, and let $X_{1}$, $X_{2}$, \,{\ldots}\,$X_{k}$ be sets.
    Then the  `union' of these sets is the set $X_{1}{\cup}X_{2}{\cup}\ \,{\cdots}\, {\cup} X_{k}$ whose elements are those objects which belong to {\em at least one} of the sets $X_{1}$, \,{\ldots}\,$X_{k}$.
    Such unions are also denoted by expressions such as ${\displaystyle {\bigcup}_{j=1}^{k} X_{j}}$.


\V

        (3) The {\bf intersection of $\Bfm{X}$ and $\Bfm{Y}$}\IndBD{set theory}{intersection of sets}, denoted $X{\cap}Y$, is the set whose elements are precisely those objects which belong to {\em both} $X$ and $Y$;
    the symbol ${\cap}$ is pronounced `intersection' or `cap'.
    If $X\,{\cap}\,Y \,=\, {\emptyset}$, then the sets $X$ and $Y$ are said to be {\bf disjoint}\IndBD{set theory}{disjoint sets}

        Similarly, if $X_{1}$, $X_{2}$, \,{\ldots}\,$X_{k}$ are sets then their  `intersection' is the set $X_{1}{\cap}X_{2}{\cap}\ \,{\cdots}\, {\cap} X_{k}$ whose elements are those objects which belong to {\em each} of the sets $X_{1}$, \,{\ldots}\,$X_{k}$.
    Such intersections are also denoted by expressions such as ${\displaystyle {\bigcap}_{j=1}^{k} X_{j}}$.

\V

        (4) More generally, let ${\cal A}$ be a nonempty family of sets;
	that is, ${\cal A}$ is a nonempty set such that each element of ${\cal A}$ is itself a set;
    we allow the empty set ${\emptyset}$ itself to be an element of the family~${\cal A}$.
    Then the {\bf union of the family $\Bfm{{\cal A}}$}, denoted by ${\bigcup}\,{\cal A}$,
    is the set $Z$ such that an object $x$ is an element of $Z$ if, and only if, $x$ is an element of {\em at least one} set belonging to the family ${\cal A}$.
    Similarly, the {\bf intersection of the family $\Bfm{{\cal A}}$}, denoted by ${\bigcap}\,{\cal A}$,
    is the set $W$ such that an object $x$ is an element of $W$ if, and only if  $x$ is an element of {\em each} set belonging to the family ${\cal A}$.

        It is possible to assign meanings to the union and intersection of the {\em empty} family of sets, but some subtle complications arise.
    We never need to consider the union or intersection of the empty family of sets in {\TheseNotes}, which allows us to ignore those complications.

        {\bf Alternate Notation}: The sets ${\bigcup}\, {\cal A}$ and ${\bigcap}\, {\cal A}$ are often denoted by symbols such as
    ${\bigcup}_{X{\in}{\cal A}}\,X$ and ${\bigcap}_{Y{\in}{\cal A}}\,Y$, in analogy to the notations ${\displaystyle {\bigcup}_{j=1}^{k} X_{j}}$ and ${\displaystyle {\bigcap}_{j=1}^{k} X_{j}}$ used in Parts~(2) and~(3) above.

        Important Special Case: Suppose that ${\cal A} \,=\, \{X_{1},X_{2},\,{\ldots}\,X_{j},\,{\ldots}\,\}$, where the quantity $j$ ranges over the set ${\NN}$ of all natural numbers.
    Then it is customary to denote the union and intersection of this family by expressions such as ${\bigcup}_{j=1}^{{\infty}} X_{j}$ and ${\bigcap}_{j=1}^{{\infty}} X_{j}$, respectively.

\V

        (5) Let ${\cal A}$ be a nonempty family of sets, as in Part~(4) above.
The sets in this family are said to be {\bf mutually disjoint}
    \IndBD{set theory}{mutually-disjoint family of sets} provided that if $X$ and $Y$ are elements of the family ${\cal A}$ such that $X \,\,{\neq}\,\, Y$,
    then $X\,{\cap}\,Y \,=\, {\emptyset}$. In particular, this property certainly holds if the family ${\cal A}$ has exactly one element.


\V

        \underline{Note}
    If $k \,=\, 1$, then, by convention, ${\displaystyle {\bigcup}_{j=1}^{k} X_{j}}$ and ${\displaystyle {\bigcap}_{j=1}^{k} X_{j}}$ both equal $X_{1}$.

\VV


%% MAKE NEXT (SKIPPED) EXAMPLE INTO AN EXERCISE
\StartSkip{
            \subsection{\small{\bf Example}}
            \label{ExampA10.20}
\hspace*{\parindent}
    (1) For each $j \,=\, 1,2,3,\,{\ldots}\,$ let $X_{j} \,=\, \{x \mbox{ in } {\RR}: x\,\,{\geq}\,\,j\}$.
    Then it is easy to see that
        \begin{displaymath}
        {\bigcup}_{j=1}^{{\infty}} X_{j} \,=\, X_{1} \mbox{ and } 
        {\bigcap}_{j=1}^{{\infty}} X_{j} \,=\, {\emptyset}
        \end{displaymath}
    Indeed, let ${\cal A}$ be the family consisting of the sets $X_{j}$ for $j \,=\, 1,2,\,{\ldots}\,$.
    Then ${\bigcup}_{j=1}^{{\infty}} X_{j}$ and ${\bigcap}_{j=1}^{{\infty}} X_{j}$ are alternative expressions for the union and intersection (respectively) of the family ${\cal A}$.

        First, suppose that $x{\in}X_{1}$. Then $x$ is certainly an element of at least one element of the family ${\cal A}$, namely $X_{1}$.
    Thus $x$ is an element of the union of the family ${\cal A}$.
    Conversely, suppose that $x{\in}{\bigcup}_{j=1}^{{\infty}} X_{j}$.
    Then $x$ is an element of at least one of the sets $X_{j}$.
    For that $j$ it follows, by definition of the set $X_{j}$, that $x$ is a real number such that $x\,\,{\geq}\,\,j$.
    Since $j\,\,{\geq}\,\,1$, and $x\,\,{\geq}\,\,j$, it follows that $x$ is a real number such that $x\,\,{\geq}\,\,1$, and thus (by the definition of the set $X_{1}$) $x{\in}X_{1}$.

        In summary: Every element of $X_{1}$ is an element of ${\bigcup}_{j=1}^{{\infty}} X_{j}$, and vice-versa.
    Thus, by the Fundamental Principle of Set Theory, the sets $X_{1}$ and ${\bigcup}_{j=1}^{{\infty}} X_{j}$ are equal, as claimed.

        In a similar manner, suppose that the set ${\bigcap}_{j=1}^{{\infty}} X_{j}$ is nonempty, and let $x$ be an element of this intersection.
    Then, by the definition of the intersection of the family ${\cal A}$, the object $x$ must be an element of {\em each} of the sets $X_{j}$.
    In particular, by the definition of the set $X_{j}$ this means that $x$ must be a real number such that $x\,\,{\geq}\,\,j$, and this must be true for each natural number $j$.
    However, one knows from grade-school arithmetic that there is no number which has this property.
    More precisely, given the number $x$, it is known that there exist natural numbers $k$ such that $k\,>\,x$.
    That is, assuming that ${\bigcap}_{j=1}^{{\infty}} X_{j} \,\,{\neq}\,\, {\emptyset}$ leads to a contradiction.
    Thus, ${\bigcap}_{j=1}^{{\infty}} X_{j}$ must be the empty set, as claimed.
}%\EndSkip

\VV

        The next results summarize a few of the properties associated with the preceding definitions.
    The proofs of these results are easy, so most of them are left as exercises.

\V
\V

            \subsection{\small{\bf Theorem}}
            \label{ThmA10.25}

\hspace*{\parindent}
        (a) Let $X$ and $Y$ be sets. Then

        \h (i)\, $Y{\setminus}X$ is a subset of $Y$; written symbolically, $(Y{\setminus}X)\,{\subseteq}\,Y$.

        \h (ii) Equality occurs in (i) (that is, one has $Y{\setminus}X \,=\, Y$) if, and only if, $X{\cap}Y \,=\, {\emptyset}$.

\V

        (b) Let $X$, $Y$ and $Z$ be sets. If $X \,{\subseteq}\, Y$ and $Y \,{\subseteq}\, Z$, then $X \,{\subseteq}\, Z$.

        Note: Because of this last fact, it is convenient to use the notation $X \,{\subseteq}\, Y \,{\subseteq}\, Z$
    as an abbreviation for the compound hypothesis `$X \,{\subseteq}\, Y$ and $Y \,{\subseteq}\, Z$' stated in this result.

\V

        (c) Let $X$ be a set. Then
        \begin{displaymath}
         (i)\,\, {\emptyset} \,{\subseteq}\, X \,{\subseteq}\, X; \h
         (ii)\,\, X{\cup}{\emptyset} \,=\, X; \h
         (iii)\,\,  X{\cap}{\emptyset} \,=\, {\emptyset}; \h
         (iv)\, \, X{\setminus}{\emptyset} \,=\, X.
        \end{displaymath}
    Furthermore, a necessary and sufficient condition for the statement `$X \,{\subseteq}\, {\emptyset}$' to be true is that $X \,=\, {\emptyset}$.

\V

        (d) Let $X$ be a set. Then $X\,{\cap}\,X \,=\, X\,{\cup}\,X \,=\, X$.

\V

        (e) (`Commutative Laws for Union and Intersection') Let $X$ and $Y$ be sets. Then
        \begin{displaymath}
        X{\cup}Y \,=\, Y{\cup}X \mbox{ and } X{\cap}Y \,=\, Y{\cap}X.
        \end{displaymath}

\V

        (f) (`Associative Laws for Union and Intersection') Let $X$, $Y$ and $Z$ be sets.
    Then
        \begin{displaymath}
        (X{\cup}Y){\cup}Z \,=\, X{\cup}(Y{\cup}Z) \mbox{ and } (X{\cap}Y){\cap}Z \,=\, X{\cap}(Y{\cap}Z).
        \end{displaymath}
    More precisely, one has
        \begin{displaymath}
        (X{\cup}Y){\cup}Z \,=\, X{\cup}(Y{\cup}Z) \,=\, X\,{\cup}\,Y\,{\cup}\,Z \mbox{ and } (X{\cap}Y){\cap}Z \,=\, X{\cap}(Y{\cap}Z) \,=\, X\,{\cap}\,Y\,{\cap}\,Z,
        \end{displaymath}
    where $X\,{\cup}\,Y\,{\cup}\,Z$ and $X\,{\cap}\,Y\,{\cap}\,Z$ are as described in the preceding definition.

\V

        (g) Let $X$ and $Y$ be sets. Then $X{\cup}Y \,=\, Y$ if, and only if, $X$ is a subset of $Y$.
    Likewise, $X{\cap}Y \,=\, X$ if, and only if, $X$ is a subset of $Y$.

\V

        (h) Let $X$ and $Y$ be sets. Then $Y{\setminus}(Y{\setminus}X) \,=\, X{\cap}Y$.
    In particular, a necessary and sufficient condition for the equation $Y{\setminus}(Y{\setminus}X) \,=\, X$ to hold is that $X$ be a subset of $Y$.
    Likewise, a necessary and sufficient condition for the equation $Y \,=\, (Y{\setminus}X)\,{\cup}\,X$ to be true is that $X$ be a subset of $Y$.

\V
\V

        {\bf Partial Proof} All the parts of this theorem are easy to prove, usually by simply using the definitions.
    Let us carry out the proof for Part~(a). To save some writing, let $Z \,=\, Y{\setminus}X$ throughout this proof.

        \underline{Proof of Part~(i) of (a)}: By the definition of `complement' (see Part~(a) of Definition~\Ref{DefA10.15}),
    the set $Z$ consists of those elements of $Y$ which are {\em not} in $X$.
    In particular, every element of $Z$ is also an element of $Y$, and thus (by the definition of `subset') $Z$ is a subset of $Y$.

        \underline{Proof of Part~(ii) of (a)}: For convenience let us break up the proof into two parts.

        \underline{The `if' portion of Statement (ii)}: 
    Suppose that $X{\cap}Y \,=\, {\emptyset}$, and let $c$ be any element of $Y$.
    Clearly such $c$ cannot be an element of $X$; for if it were, then it would be in both $X$ and $Y$, hence (by definition of `intersection') in $X\,{\cap}\,Y$,
    contradicting the hypothesis above that $X{\cap}Y \,=\, {\emptyset}$.
    Thus every such $c$ is an element of $Z$; that is, $Y \,{\subseteq}\, Z$.
    Now combine this with the result of Part~(i), together with Theorem~\Ref{ThmA10.10},
    to conclude that that $Y \,=\, Z$, i.e., $Y \,=\, Y{\setminus}X$, as claimed.

        \underline{The `only if' portion of Statement (ii)}: Suppose that $Y \,=\, Y{\setminus}X$.
    It follows from this equation that if $c$ is any element of $Y$ then $c$ is also an element of $Y{\setminus}X$, and thus, in particular, $c$ is {\em not} an element of $X$.
    Thus no element of $Y$ is also in $X$, hence $X{\cap}Y \,=\, {\emptyset}$, as claimed.

\V


%%% 
\begin{quotation}
{\footnotesize \underline{\Note} (on proofs)\IndB{\notes}{on proofs}: The proofs given above are not difficult;
    but they do have some features that are worth a little extra discussion, especially for readers having limited experience with rigorous mathematics.

\V

        (1)\IndA{if, and only if formulation} The proof of Part~(ii) of~(a) is broken into the `if' portion and the `only if' portion.
	This reflects the fact that there are really two substatements which combine to give the full meaning of Statement~(ii):

    \h (ii)$_{{\alpha}}$ `One has $Y{\setminus}X \,=\, Y$ {\bf if} $X\,{\cap}\,Y \,=\, {\emptyset}$; and

    \h (ii)$_{{\beta}}$ `One has $Y{\setminus}X \,=\, Y$ {\bf only if} $X\,{\cap}\,Y \,=\, {\emptyset}$'.

\noindent As the proof given above indicates, each of these substatements is a logical implication in which something is assumed (`the hypothesis'),
    from which something else is deduced (`the conclusion'):
    
\VA

    \h (ii)$_{{\alpha}}$ `If $X\,{\cap}\,Y \,=\, {\emptyset}$ (hypothesis), then $Y{\setminus}X \,=\, Y$ (conclusion)'

    \h  (ii)$_{{\beta}}$ `If $Y{\setminus}X \,=\, Y$ (hypothesis), then $X\,{\cap}\,Y \,=\, {\emptyset}$ (conclusion)

\VA

\noindent Note that each of these substatements is simply the converse of the other.
    The complete Statement~(ii) simply asserts that both of these substatements are simultaneously true:

\VA

    \h    (ii) `If $X\,{\cap}\,Y \,=\, {\emptyset}$, then $Y{\setminus}X \,=\, Y$; and, conversely,
    if $Y{\setminus}X \,=\, Y$, then $X\,{\cap}\,Y \,=\, {\emptyset}$.'

\VA

        Why would a mathematics text use the original `if, and only if' phrasing  of Statement~(ii) when the second phrasing is less likely to cause confusion?
    Simple: The original phrasing takes up less space.

        In mathematics the phrase `if, and only if,' appears so frequently that it is treated almost as a single word: `if-and-only-if';
    indeed, many authors use the written abbreviation `iff' (pronounced `if-and-only-if', not `ifffffff') for this phrase.
    In {\TheseNotes}, however, we always write out the full phrase
    to emphasize that whenever this phrase appears
    it indicates that {\em two} separate statements are under consideration, and separate proofs are needed for each.

\V

        (2)\IndA{necessary and sufficient formulation}  In a similar manner, the phrase `necessary and sufficient condition'  appears frequently in mathematics.
    For instance, in Part~(h) of the preceding theorem the presence of this phrase means that the statement there really breaks into two substatements:

\VA

        \h `A {\em necessary} condition for $Y{\setminus}(Y{\setminus}X) \,=\, X$ to hold is that $X$ be a subset of $Y$.'

        \h `A {\em sufficient} condition for $Y{\setminus}(Y{\setminus}X) \,=\, X$ to hold is that $X$ be a subset of $Y$.'

\VA

\noindent A complete proof of (h), then, would consist of proving both of these substatements.
    Note that the `condition' referred to in each of these substatements is the phrase `$X$ be a subset of $Y$'.
    (The actual condition would normally be stated by itself as `$X$ is a subset of $Y$'; it is cast into the subjunctive voice in the statement of the theorem because of the rules of English grammar.)

        Many students in math courses get almost as confused about the distinction between `necessary' and `sufficient' as they are about `if' {\em vs} `only if'.
    They usually believe that the reason this confusion is because the context is a math course, and that mathematicians think differently from regular folks.
    In reality, however, the issue is one of understanding the use of such words in ordinary language.
    For example, consider the following statements:

        \h `A {\bf necessary} condition to get your first driver's license in California is to pass the written test.'

        \h `A {\bf sufficient} condition to get your first driver's license in California is to pass the written exam.'

\noindent Clearly, the second statement is not correct: passing the written exam is not enough; you also need to pass the driving test.
    In contrast, the first statement is true; indeed, passing the written exam is needed before you are even allowed to take the driving test.

\V

        (3) Some readers may wonder why the proof of Part~(a) starts out by assigning the symbol $Z$ to the set $Y{\setminus}X$;
    indeed, some might worry that there is something mystic going on which they are missing, because they would not have thought of starting that way.
    The explanation, however, is both benign and boring:
    The author realized, while doing the first draft of the proof, that the expression $Y{\setminus}X$ would need to be referred to repeatedly, 
    so that the slight extra work of introducing the symbol $Z$ in the final drafts would save enough typing to be worth the effort.

        The main point of interest, however, is the fact that the proofs require the readers to know the meanings of all the words and phrases that appear in it!
    (You might be surprised how often it happens in math courses that students cannot do a problem simply because they don't know what the words mean, and it does not occur to them to look up those meanings.)
    Sometimes this requirement, namely that the readers are expected to know the definitions of the terms, is made explicit;
    for example, in the proof of Part~(i) of~(a) the reader is told directly that the definitions of `complement' and `subset' are relevant.

        In the rest of the proof of Part~(ii) of~(a), however, the requirement of knowing what the words mean is implicit.
    For instance, in the proof of the `only if' portion of (ii) the argument that $c$ is not in $X{\cap}Y$ uses the definition of `intersection':
    since $c$ can't be in $X$, it can't be in both $X$ and $Y$ simultaneously and thus
    (here's where the definition of `intersection' gets used) it can't be in $X{\cap}Y$.

        Normally the instruction, `Know the definitions of the words that appear!', is left unstated; but it is always understood to hold.

\VA

        \underline{Moral of this Story}:

      \h  (a) You need to know the precise definition of everything you deal with in mathematics; in particular: `When in doubt, look it up'.
    Similarly, you are expected to know the precise statements of the theorems which you may need to use.

      \h  (b) You should expect to write up more than one draft of your work in math courses before handing it in to be graded.
    In doing so, you may find it useful to introduce new notation, or even new terminology, to simplify the job of your readers.
}%EndFootnotesize
\end{quotation} 
%##

%------------------AAA
\StartSkip{ 


            \subsection{\small{\bf Three Important Principles in ${\NN}$}}
            \label{PrinA10.11}



        As is indicated at the beginning of this section, a major goal in modern mathematics is to formulate the basic concepts and facts in terms of set theory.
    This includes even older results which were well understood before set theory and its terminology were introduced.
    What follows is an important example of converting an older formulation to a more modern one using `sets' terminology.

\VV


\V

        The next result reformulates this Principle, as well as a couple of its near relatives, in terms of sets.
%}%EndFootnotesize
%\end{quotation}


\VV


            \subsection{\small{\bf Three Important Principles in ${\NN}$}}
            \label{PrinA10.11}

\V

\hspace*{\parindent} (1) {\bf The Principle of Mathematical Induction}
    \IndB{natural numbers}{mathematical induction, principle of}\IndD{mathematical induction}{natural numbers}
    \IndD{principle of mathematical induction}{natural numbers}
    Suppose that $A$ is a set of natural numbers such that the following conditions hold:

        \h (i)\, (Initial Step) $1{\in}A$.

        \h (ii) (Induction Step) If $k$ is any element of ${\NN}$ such that $k{\in}A$, then $(k+1){\in}A$.

\noindent \underline{Conclusion} $A \,=\, {\NN}$.

\V

        (2) \underline{Preliminary Remark} Many students of mathematics, even fairly advanced ones, find the preceding principle difficult to understand.
    The next result, which is logically equivalent to the induction principle, seems easier for such students to comprehend.

        \h {\bf The Least-Natural-Number Principle}\IndBD{natural numbers}{least natural number, principle of}
    Suppose that $B$ is a nonempty subset of ${\NN}$. Then the set $B$ has a least member.
    That is, there is a (unique) natural number $m$ such that $m$ is an element of $B$, and $m\,\,{\leq}\,\,k$ for every number $k$ in $B$.

        \underline{Note} Many authors refer to this result as the
    {\bf Well-Ordering Principle}\IndA{well-ordering principle}, or sometimes the {\bf Well-Ordering Principle in ${\NN}$}.

\V

        (3) \underline{Preliminary Remark} The set ${\NN}$ itself illustrates the fact that a nonempty subset of ${\NN}$ need not have a greatest element.
    Indeed, no matter how large a given natural number $n$ might be, there is always a larger one; for example, $n+1$.
    Nevertheless, there is still something useful one can say on this issue.

        \h  {\bf The Greatest-Natural-Number Principle}\IndBD{natural numbers}{greatest natural number, principle of}
    Suppose that $C$ is a nonempty subset of ${\NN}$ which is {\bf bounded in~${\NN}$},
    \IndB{bounded, unbounded}{subsets of ${\NN}$}
    in the sense that there exists a number $q$ in ${\NN}$ such that $q\,\,{\geq}\,\,k$ for all $k$ in $C$.
    Then there exists a unique natural number $n$ such that $n$ is an element of $C$, and $n\,\,{\geq}\,\,k$ for all $k$ in $C$.
    The number $n$ is called the {\bf greatest element of $\Bfm{C}$}.

\VV

        {\bf Example} Consider the statement, mentioned above:
    `If $k$ is a natural number, then the sum of the first $k$ natural numbers equals~${\displaystyle \frac{k\,(k+1)}{2}}$.'
    To convert this to the modern set-theoretic formulation, let $A$ be the set of natural numbers $k$ for which the conclusion holds.
    Then the claim that the given statement is true is equivalent to the set-theoretic statement that $A \,=\, {\NN}$.
    The standard inductive proof of the original statement then reduces to checking that Steps (i) and~(ii) above hold for~$A$.

        In {\ThisText} we normally carry out the translation of induction arguments into such a set-theoretic formulation.

\VV

        The next result provides slight extensions of the preceding three principles; the simple proofs are left as exercises. %% EXERCISE?

\VV



            \subsection{\small{\bf Three Important Principles in ${\ZZ}$}}
            \label{PrinA10.11B}

\V

\hspace*{\parindent} (1) {\bf The Principle of Mathematical Induction in ${\ZZ}$}
    \IndB{integers}{mathematical induction in ${\ZZ}$, principle of}
    Let $m$ be an integer, and suppose that $A$ is a set of integers such that the following conditions hold:

        \h (i)\, (Initial Step) $m{\in}A$.

        \h (ii) (Induction Step) If $k$ is any integer such that $k{\in}A$, then $(k+1){\in}A$.

\noindent \underline{Conclusion} Every integer $k$ such that $k\,\,{\geq}\,\,m$ is in the set~${\ZZ}$.

\V

        (2) {\bf The Least-Integer Principle}\IndBD{integers}{least integer, principle of}
    Suppose that $B$ is a nonempty subset of the set ${\ZZ}$ which is bounded below,
    in the sense that there exists a number $p$ in ${\ZZ}$ such that $p\,\,{\leq}\,\,k$ for all $k$ in $B$.
    Then there exists a unique integer $m$ such that $m$ is an element of $B$, and $m\,\,{\leq}\,\,k$ for all $k$ in~$B$.
    The integer $m$ is called the {\bf least element of $\Bfm{B}$}.

\V

        (3) {\bf The Greatest-Integer Principle}\IndBD{integers}{greatest integer, principle of}
    Suppose that $C$ is a nonempty subset of ${\ZZ}$ which is {\bf bounded above},
    in the sense that there exists a number $q$ in ${\ZZ}$ such that $q\,\,{\geq}\,\,k$ for all $k$ in $C$.
    Then there exists a unique integer $n$ such that $n$ is an element of $C$, and $n\,\,{\geq}\,\,k$ for all $k$ in $C$.
    The number $n$ is called the {\bf greatest element of $\Bfm{C}$}.


\VV


\begin{quotation}
{\footnotesize \underline{\Note} (on preferring the name 'Least-Natural-Number Principle')\IndB{\notes}{on preferring the name 'least-natural-number principle'}:
        The name used in {\ThisText} for the principle in question is definitely not standard; a much more common name for it is `The Well-Ordering Principle'.
    The root of the latter name is a much deeper result, also called `The Well-Ordering Principle', which arises in set theory;
    roughly speaking, this deeper result states that if $X$ is a nonempty set, then there exists a notion of
    `less~than' on $X$ relative to which every nonempty subset of $X$ has a least element;
    alternatively, there exists a notion of `greater~than' on $X$ relative to which every nonempty subset of $X$ has a greatest element.
    This is a pure `existence' theorem which gives no clue on how to find orderings with the given property.
    The use of the name `Well-Ordering Principle' for the restricted result for natural numbers given above does, therefore, make a certain amount of sense.
    However, this result is also very similar to three of the other results given above,
    namely the `Greatest-Natural-Number Principle', the `Least-Integer Principle' and the `Greatest Integer Principle'.
    None of these last results concerns a property enjoyed by {\em all} nonempty  subsets of a given set,
    since they all require the subset to be `bounded' in one sense or another. Our choice of terminology emphasizes the similarity of these four results.
}%EndFootnotesize
\end{quotation}

\VV

        The next result is a useful variant of the Principle of Mathematical Induction,
    and could also be considered to be a `well-known result', so that its proof would not be needed.
    We include a proof here to illustrate how to use the Greatest-Natural-Number Principle.

\V

    \underline{Reminder} If $k{\in}{\NN}$, then ${\NN}_{k}$ is the set of all natural numbers $j$ such that $1\,\,{\leq}\,\,j\,\,{\leq}\,\,k$. In particular, ${\NN}_{1}$ is the singleton set~$\{1\}$.

\V

            \subsection{\small {\bf Theorem} (The Strong Principle of Mathematical Induction)}\IndBD{natural numbers}{mathematical induction, strong principle of}
            \label{ThmA20.04A}

        Suppose that $A$ is a subset of ${\NN}$ such that the following conditions hold:

        \h (i)\, (Initial Step) ${\NN}_{1} \,{\subseteq}\, A$.

        \h (ii) (Induction Step) If $k$ is any element of ${\NN}$ such that ${\NN}_{k} \,{\subseteq}\, A$, then ${\NN}_{k+1} \,{\subseteq}\, A$.

        \underline{Conclusion} $A \,=\, {\NN}$.

\V

        {\bf Proof}\, (by contradiction) Suppose that there is a subset $A$ of ${\NN}$ satisfying Conditions~(i) and~(ii) above,
    but $A \,\,{\neq}\,\, {\NN}$. Let $C$ be the set of all $k$ in ${\NN}$ such that ${\NN}_{k} \,{\subseteq}\, A$.
    Since, by the Initial Step, one has ${\NN}_{1} \,{\subseteq}\, A$, it follows that $1{\in}C$ and thus $C \,\,{\neq}\,\, {\emptyset}$.
    Likewise, by the `contradiction hypothesis' that $A \,\,{\neq}\,\, {\NN}$, there must exist $q$ in ${\NN}$ such that $q \not \in A$.
    It is clear that that if $k{\in}C$ then $k\,<\,q$ and thus the set $C$ is bounded in~${\NN}$.
    It follows from the Greatest-Natural Number Principle that $C$ has a greatest element; call it~$m$.
    It follows from the definition of the (nonempty) set $C$ that ${\NN}_{m} \,{\subseteq}\, A$.
    Because of Condition~(ii), it then follows that ${\NN}_{m+1} \,{\subseteq}\, A$, hence $(m+1){\in}C$.
    This contradicts the fact that $m$ is supposed to be the {\em largest} element of~$C$.

\V

        \underline{Remarks} (1) Since ${\NN}_{1} \,=\, \{1\}$, Condition~(i) is simply a fancy way of stating that $1$ is an element of the set~$A$.
    In contrast, when $k\,\,{\geq}\,\,2$, Condition~(ii) is a stronger hypothesis than the corresponding Induction Step in the regular version of the Principle of Mathematical Induction.

\V

        (2) It is a useful exercise to construct an alternate proof of the preceding result based on the Least-Natural-Number Principle.

% WRITE UP THIS EXERCISE

                                                                                                                                                                         
}%\EndSkip

%\StartSkip{ % SectA11
                        \section{Some Properties of the Set ${\NN}$ of Natural Numbers}\IndB{natural numbers}{some properties of ${\NN}$}\IndB{ZZ Sections}{\Ref{SectA11} Some Properties of the Set ${\NN}$}
                        \label{SectA11}


        As is mentioned earlier in this Chapter, a major goal in modern mathematics is to formulate the basic concepts and facts in terms of set theory.
    This includes even older results which were well understood before set theory and its terminology were introduced.

\V


        One of the most important facts about natural numbers is the classic Principle of Mathematical Induction.
        The discussion below formulates this Principle, as well as a couple of its near relatives, in terms of sets.


\begin{quotation}
{\footnotesize \underline{\Note} (on the classic formulation of the Principle of Mathematical Induction)\IndB{\notes}{on the classic formulation of the Principle of Mathematical Induction}:
    The Principle in question was classically formulated, without referring to sets, along the following lines:

\V

        For each natural number $k$ let $S(k)$ denotes a statement which involves the natural number~$k$. Suppose that:

\VA

        \h (i)\, Statement $S(1)$ is true.

        \h (ii) For every natural number $k$ the truth of Statement $S(k)$ implies the truth of Statement~$S(k+1)$.

\VA

\noindent Then $S(k)$ is true for {\em every} natural number~$k$.

        \underline{Remark} The texts which use this statement of the Principle usually provide
    a few examples of what the phrase `statement which involves the natural number~$k$' signifies; a common example is the statement

\VA

        \h `If $k$ is a natural number, then the sum of the first $k$ natural numbers equals~${\displaystyle \frac{k\,(k+1)}{2}}$.'

\VA

\noindent However, they usually don't define the meaning of `a statement which involves the natural number~$k$' any further,
    leaving it as a primitive concept for which `I'll know it when I see~it'.
}%\EndFootNoteSize}
\end{quotation}


\VV


            \subsection{\small{\bf Three Important Principles in ${\NN}$}}
            \label{PrinA10.11}

\V

\hspace*{\parindent} (a) {\bf The Principle of Mathematical Induction}
    \IndB{natural numbers}{mathematical induction, principle of}\IndD{mathematical induction}{natural numbers}
    %\IndD{principle of mathematical induction}{natural numbers}
    Suppose that $A$ is a set of natural numbers such that the following conditions hold:

        \h (i)\, (Initial Step) $1{\in}A$.

        \h (ii) (Induction Step) If $k$ is any element of ${\NN}$ such that $k{\in}A$, then $(k+1){\in}A$.

\noindent \underline{Conclusion} $A \,=\, {\NN}$.

\V

        (b) {\bf The Least-Natural-Number Principle}\IndBD{natural numbers}{least natural number, principle of}
    Suppose that $B$ is a nonempty subset of ${\NN}$. Then the set $B$ has a least member.
    That is, there is a (unique) natural number $m$ such that $m$ is an element of $B$, and $m\,\,{\leq}\,\,k$ for every number $k$ in $B$.

\V

        (c) {\bf The Greatest-Natural-Number Principle}\IndBD{natural numbers}{greatest natural number, principle of} Suppose that $C$ is a nonempty subset of ${\NN}$
    which is {\bf bounded above in~${\NN}$},\IndB{bounded, unbounded}{subsets of ${\NN}$} in the sense that there exists a number $q$ in ${\NN}$ such that $q\,\,{\geq}\,\,k$ for all $k$ in $C$.
    Then the set $C$ has a greatest element.
 That is, there exists a (unique) natural number $n$ such that $n$ is an element of $C$, and $n\,\,{\geq}\,\,k$ for all $k$ in $C$.

\V


        {\bf Remark}\,It is conventional to accept these Principles on faith, with primary emphasis given to Principle~(a).
    However, many students of mathematics, even fairly advanced ones, find Principles (b) and (c) easier to understand than the original Induction Principle~(a).
    In fact, it is not hard to show that each of these principles implies the other two. We illustrate one such proof below.

\V

        {\bf Proof that Principle (b) Implies Principle (a)} We assume here that the basic properties of ${\NN}$ known from elementary-school arithmetic.

        Suppose that Principle~(b) is true, and let $A$ be a subset of ${\NN}$ which satisfies Hypotheses (i) and~(ii) of Principle~(a).
    Now suppose, on the contrary, that this $A$ does not also satisfy the conclusion of Principle~(a); that is, suppose that $A \,\,{\neq}\,\, {\NN}$,
    then the set $B \,=\, {\NN}\,{\setminus}\,A$ is a nonempty subset of~${\NN}$. Let $m$ be the minimum element of $B$ whose existence is guaranteed by Principle~(b).
    Clearly Hypothesis~(i) of Principle~(a) implies that $1$ is not in $B$, so $m\,>\,1$. Then $m-1$ is an element of ${\NN}$ less than $m$ so that $m-1$ cannot be in $B$, hence $(m-1){\in}A$.
    But then Hypothesis~(ii) implies that $m \,=\, (m-1)+1$ is also in~$A$, contrary to the construction of $m$ as the smallest element of~$B$. That is, Principle~(a) is true.
    %EXERCISE: Do the other implications

\V

        {\bf Remark}\,Many authors refer to Principle~(b) above as the
    {\bf Well-Ordering Principle}\IndA{well-ordering principle}, or sometimes the {\bf Well-Ordering Principle in ${\NN}$}.
    The {\Note} below explains the preference in {\TheseNotes} for using the nonstandard name `Least-Natural-Number Principle'.


\VV


\begin{quotation}
{\footnotesize \underline{\Note} (on preferring the name 'Least-Natural-Number Principle')\IndB{\notes}{on preferring the name 'least-natural-number principle'}:
        The name used in {\ThisText} for the principle in question is definitely not standard; a much more common name for it is `The Well-Ordering Principle'.
    The root of the latter name is a much deeper result, called `The Well-Ordering Theorem', which arises in advanced set theory, but which normally is not described in this more elementary situation;
    roughly speaking, this deeper result states that if $X$ is an arbitrary nonempty set, then there exists a notion of an `ordering' $\,<\,$.
    or `less~than', on $X$ relative to which every nonempty subset of $X$ has a least element;
equivalently,
    there exists a notion of $\,>\,$, or `greater~than', on $X$ relative to which every nonempty subset of $X$ has a greatest element.
    Under such an ordering the set $X$ is said to be `well ordered'. The principle under discussion then translates to say that the set ${\NN}$,
    under its standard order of `less than', is `well ordered'. Singling out this one example to assign the name `Well-Ordering Principle',
    however, without explaining the origin of the phrase `well ordering', seems pointless, especially when the name `Least-Natural-Number Principle' actually reminds one of the content of Principle~(b).

        A second reason for preferring the nonstandard name `Least-Natural-Number Principle'
    is that it complements the name `Greatest-Natural-Number Principle'. The latter principle is {\em not} a special case of the `Well-Ordering Principle',
    not even in the alternate formulation given above, because it requires the additional `bounded above' hypothesis.
}%EndFootnotesize
\end{quotation}

\VV

        The next result is a useful variant of the Principle of Mathematical Induction, and could also be considered to be a `well-known result', so that its proof would not be needed.
    We include a proof here to illustrate the use of the Greatest-Natural-Number Principle.

\V

    \underline{Reminder} If $k{\in}{\NN}$, then ${\NN}_{k}$ is the set of all natural numbers $j$ such that $1\,\,{\leq}\,\,j\,\,{\leq}\,\,k$. In particular, ${\NN}_{1}$ is the singleton set~$\{1\}$.

\V

            \subsection{\small {\bf Theorem} (The Strong Principle of Mathematical Induction)}\IndBD{natural numbers}{mathematical induction, strong principle of}
            \label{ThmA20.04A}

        Suppose that $A$ is a subset of ${\NN}$ such that the following conditions hold:

        \h (i)\, (Initial Step) ${\NN}_{1} \,{\subseteq}\, A$.

        \h (ii) (Induction Step) If $k$ is any element of ${\NN}$ such that ${\NN}_{k} \,{\subseteq}\, A$, then $(k+1){\in}A$.

        \underline{Conclusion} $A \,=\, {\NN}$.

\V

        {\bf Proof}\, (by contradiction) Suppose that there is a subset $A$ of ${\NN}$ satisfying Conditions~(i) and~(ii) above,
    but $A \,\,{\neq}\,\, {\NN}$. Let $C$ be the set of all $k$ in ${\NN}$ such that ${\NN}_{k} \,{\subseteq}\, A$.
    Since, by the Initial Step, one has ${\NN}_{1} \,{\subseteq}\, A$, it follows that $1{\in}C$ and thus $C \,\,{\neq}\,\, {\emptyset}$.
    Likewise, by the `contradiction hypothesis' that $A \,\,{\neq}\,\, {\NN}$, there must exist $q$ in ${\NN}$ such that $q \not \in A$.
    It is clear that that if $k{\in}C$ then $k\,<\,q$ and thus the set $C$ is bounded above in~${\NN}$. It follows from the Greatest-Natural Number Principle that $C$ has a greatest element; call it~$m$.
    It follows from the definition of the (nonempty) set $C$ that ${\NN}_{m} \,{\subseteq}\, A$.
    Because of Condition~(ii), it then follows that $(m+1){\in}C$, and thus ${\NN}_{m+1} \,=\, {\NN}_{m}\,{\cup}\,\{m+1\} \,{\subseteq}\, A$, hence $(m+1){\in}C$.
    This contradicts the fact that $m$ is supposed to be the {\em largest} element of~$C$.

\V

        \underline{Remarks} (1) Since ${\NN}_{1} \,=\, \{1\}$, Condition~(i) is simply a fancy way of stating that $1$ is an element of the set~$A$.
    In contrast, when $k\,\,{\geq}\,\,2$, Condition~(ii) is a stronger hypothesis than the corresponding Induction Step in the regular version of the Principle of Mathematical Induction.

\V

        (2) It is a useful exercise to show that the Strong Induction Principle implies the regular Induction Principle. % EXERCISE

\V

        The terminology introduced next should be familiar from elementary-school arithmatic.


            \subsection{\small{\bf Definition}}
            \label{DefA20.04B}

\hspace*{\parindent} (1) A natural number $k$ is said to be a {\bf composite number}\IndBD{natural numbers}{composite numbers} provided it can be expressed, in at least one way,
    as the product $k \,=\, i{\cdot}j$ of two natural numbers $i$ and $j$ such that $i\,\,{\geq}\,\,2$ and $j\,\,{\geq}\,\,2$.

\V


        (2) A noncomposite number greater than $1$ is called a {\bf prime number}\IndBD{natural numbers}{prime numbers}.
\V

        {\bf Remarks} (1) The requirements $i\,\,{\geq}\,\,2$ and $j\,\,{\geq}\,\,2$ on the factors $i$ and $j$ is to ensure that we consider only {\em nontrivial} factorizations of~$k$;
    indeed, {\em every} natural number $m$ admits the `trivial' factorizations $m \,=\, m{\cdot}1 \,=\, 1{\cdot}m$. Note that one also has $i\,\,{\leq}\,\,k-1$ and $j\,\,{\leq}\,\,k-1$.

\V

        (2) Because of the trivial nature of the number $1$ as a factor, it is conventional to separate the noncomposite numbers into two types: the number~$1$, and all other noncomposite numbers.
    One result of this is that the number $1$ is, by convention, not considered to be a prime number, so that $2$ is the smallest prime number.
    This convention makes the phrasing of some results about natural numbers a little easier; for example, Theorem~\Ref{ThmA20.04D} below.

\V

            \subsection{\small{\bf Lemma}}
            \label{LemmaA20.04C}

\V

        Every composite number can be expressed as the product of two or more factors, each factor being a prime number.

\V

        {\bf Proof}\,  Let $A$ be the set of all natural numbers $k$ such that at least one of the following statements is true:

        \h  (i)\,\, $k \,=\, 1$.

        \h (ii)\, $k$ is a prime number.

        \h (iii) $k$ is the product of two or more prime factors.

\noindent The statement to be proved is then equivalent to showing that $A \,=\, {\NN}$.
    We use the Strong Principle of Mathematical Induction to prove this last equality.

        \underline{Initial Step} Note that $1{\in}A$, by definition of $A$, hence ${\NN}_{1} \,{\subseteq}\, A$.

        \underline{Inductive Step} Suppose that $k$ is an element of ${\NN}$ such that ${\NN}_{k} \,{\subseteq}\, A$.
    Clearly $k+1 \,=\, 1$ is an impossibility, so there are two possibiities:

       \h (a) $k+1$ is a prime number. In this case $k+1$ is in $A$ by the definition of $A$.

       \h (b) $k+1$ is {\em not} a prime number. Then $k+1$ must be a composite number, so $k+1 \,=\, m{\cdot}n$ for some natural numbers $m$ and $n$ satisfying $2\,\,{\leq}\,\,m\,\,{\leq}\,\,k$ and $2\,\,{\leq}\,\,n\,\,{\leq}\,\,k$.
    In particular, by the induction hypothesis that `${\NN}_{k} \,{\subseteq}\, A$', one sees that both $m$ and $n$ are in $A$.
    Since $m\,>\,1$ it follows that $m$ is either a prime number or a product of primes; likewise $n$ is either a prime or a product of primes.
    It then follows that $k+1 \,=\, m{\cdot}n$ is also a product of primes, as required, so $k+1$ is in $A$ in this case as well.

        Now the Strong Principle of Mathematical Induction implies that $A \,=\, {\NN}$, as required.

\V

        \underline{Note} The statement of this Lemma could have been accepted here as a `well-known fact' and the proof omitted.
    The real reason for including a proof is to illustrate how to use the Strong Principle of Mathematical Induction.
    It is instructive to try to prove the preceding result using only the the original (`weak') form of the Principle of Mathematical Induction.

\V

            \subsection{\small{\bf Theorem} (Unique-Prime-Factorization Theorem)}\IndBD{natural numbers}{unique-prime-factorization theorem}
            \label{ThmA20.04D}

\V


        If $n$ is a natural number and $n\,\,{\geq}\,\,2$ then either $n$ is a prime, or $n$ can be expressed, in exactly one way, as a product
        \begin{displaymath}
        n \,=\, p_{1}{\cdot}p_{2}{\cdot}\,{\ldots}\,{\cdot}p_{m},
        \end{displaymath}
    where $m\,\,{\geq}\,\,2$ and $p_{1}$, $p_{2}$,\,{\ldots}\,$p_{m}$ are primes such that 
    $1\,<\,p_{1}\,\,{\leq}\,\,p_{2}\,\,{\leq}\,\,\,{\ldots}\,\,\,{\leq}\,\,p_{m}$.

\V

        The proof of this (well-known) result is left as an exercise. (It follows easily from Lemma~\Ref{LemmaA20.04C}.)

% CONSTRUCT THE EXERCISE

\V

        \underline{Remarks} (1) This result is often called the {\bf Fundamental Theorem of Arithmetic}.\IndA{fundamental theorem of arithmetic}

\V

        (2) In the preceding result, if $p$ is a prime number such that either $n \,=\, p$
    (in the case $n$ is a prime) or $p$ is one of the factors $p_{1}$, $p_{2}$,\,{\ldots}\,$p_{m}$ (if $n$ is not a prime),
    then one calls $p$ a {\bf prime factor of $\Bfm{n}$}



\VV

        The Unique-Prime-Factorization Theorem above has many consequences in arithmetic;
    for example, it can be used to characterize those natural numbers which are squares of {\em rational} numbers. More generally, one has the following result.

\V

            \subsection{\small{\bf Theorem}}
            \label{ThmA20.05A}

\V

        Let $n$ and $m$ be natural numbers. If there is a positive {\em rational} number $r$ such that $r^{m} \,=\, n$,
    then $r$ is actually a natural number.

\V

        {\bf Proof} Suppose that $r$ is of the form $r \,=\, j/k$, where $j$ and $k$ are natural numbers, and $r^{m} \,=\, n$.
    Without loss of generality one can assume that the prime factorizations of $j$ and $k$ have no prime factors in common.
    (Indeed, by canceling out any such factors in the division $j/k$, one gets $r \,=\, j'/k'$ where $j'$ and $k'$ have no prime factors in common.)
    If $k \,=\, 1$ then $r \,=\, j$, a natural number, as claimed. Thus assume that $k\,\,{\geq}\,\,2$, so that $j\,\,{\geq}\,\,2$ as well, since $n\,\,{\geq}\,\,1$.
    Then one has $j^{m} \,=\, r^{m}\,k^{m} \,=\, n\,k^{m}$. If $k\,\,{\geq}\,\,2$,
    then either $k$ is itself a prime number $p$ or else $k$ has at least one prime factor~$p$.
    It follows easily from the Unique-Prime-Factorization Theorem that $p$ is a prime factor of $n\,k^{m}$, hence of $j^{m}$, hence of $j$ itself,
    contrary to the hypothesis that $j$ and $k$ have no prime factors in common. It follows that $k \,=\, 1$, and the desired result follows.

            \subsection{\bf Examples}
            \label{ExampA20.05B}

\V

\hspace*{\parindent} (1) There is no rational number $r$ such that $r^{2} \,=\, 2$. Indeed, if such $r$ existed, it could be chosen so that $r\,>\,0$,
    and thus it would follow from the preceding result that $2$ is the square of some natural number, which is obviouly not true: note that $1^{2} \,=\, 1\,<\,2$, while $j^{2}\,>\,2$ if $j\,\,{\geq}\,\,2$.

\V

        (2) There is no rational number $r$ such that $r^{3} \,=\, 10$. Indeed, it is clear that any such $r$ must be positive,
    and thus by the preceding theorem $10$ would the cube of some natural number. But one computes that
    $1^{3} \,=\, 1$, $2^{3} \,=\, 8$ and $j^{3}\,\,{\geq}\,\,27$ for all $j\,\,{\geq}\,\,3$. The claim follows.

%}%\EndSkip SectA11


                        \section{Ordered Tuples; Cartesian Products of Sets}                        
                        \label{SectA12}\IndB{ZZ Sections}{\Ref{SectA12} Ordered Tuples; Cartesian Products}


        {\bf Introduction} The process of strengthening the logical foundations of mathematics, begun in the late nineteenth century,
    has evolved into the modern situation in which everything ultimately is reduced to set theory.
    This reduction means that any deep foundational issues can be passed off to the set theorists and logicians to deal with.

        One simple concept, used in many important constructions in mathematics, is that of an `ordered pair' of objects.
    For example, in the elementary analytical geometry of the Euclidean plane, one identifies a (geometric) point $P$ in that plane
    with an ordered pair~$(x,y)$ of real numbers, where the first number $x$ denotes the abscissa of $P$ and the second $y$ denotes its ordinate (relative to given coordinate axes).
    (The use of the words `first' and `second' in this context reflects the `order' of this ordered pair.) Likewise, in the next section we define the vital concept of `function' in terms of sets of ordered pairs.

        In order to comply with the spirit of `reduce everything to set theory', the concept of `ordered pair' should be also be defined purely in terms of sets.
    Such a definition was given by Wiener in~1912, and simplified by Kuratowski in~1921; we present the Kuratowski definition of `ordered pair' in Appendix~B.
    For the present section, however, we treat the concept of `ordered pair' as a primitive concept: one knows it when one sees it.

        In a similar manner, it is convenient to accept as primitive the concepts of ordered triples, ordered quadruples, ordered quintuples, ordered sextuples, ordered septuples, and so on.
    More generally, if $k$ is a natural number, then we treat as `primitive' the concept of an {\bf ordered $\Bfm{k}$-tuple}\IndBD{ordered tuples}{ordered $k$-tuples}\IndBD{ordered tuples}{tuples}
    $(x_{1},x_{2},\,{\ldots}\,x_{k})$ of objects, in which the `order' is indicated here by the conventional left-to-right listing of the objects.
    (Of course, the concept of `left-to-right listing' is taken here as primitive: you know it -- literally -- when you see it.
    It is closely related to the primitive concept of `chronological order': one speaks the name $x_{1}$ first, then $x_{2}$, and so on.)
    For instance, in the ordered $3$-tuple (triple) $(2, 4, -1)$ of numbers, the first entry is $2$, the second is $4$, and the third is $-1$.
    Likewise, in the ordered $3$-tuple $(2,3,2)$ the first entry is $2$, the second is $3$, and the third is $2$ again.

\V

        (2) In {\ThisText} the phrase `ordered $k$-tuple' is often abbreviated to `$k$-tuple'; likewise, if $k$ is understood from the context, $k$-tuple' may be abbreviated to `tuple'.


\V

        (3) The case $k \,=\, 1$ is special. The primitive concept of an ordered $1$-tuple $(x)$ is that it is simply the single object $x$ itself; of course there is no real `order' in this situation.
    In Appendix~B, however, we develop the concept of `tuple' from other, more primitive, concepts. With that treatment the $1$-tuple $(x)$ is technically {\em not} the same object as the original object~$x$ itself.
    Nevertheless, even in that more modern treatment one often ends up identifying the $1$-tuple $(x)$ with the original object~$x$; no confusion seems to result.


\VV

        \subsection{\bf Remarks}
        \label{RemrkA12.10}

 \hspace*{\parindent} (1) The main feature of the primitive notion of `ordered pair' is that two ordered pairs, $(a,b)$ and $(c,d)$,
    are equal if, and only if, both of the equations $a \,=\, c$ and $b \,=\, d$ hold. Note that if $a \,\,{\neq}\,\, b$ then this feature implies that $(a,b) \,\,{\neq}\,\, (b,a)$.
    In contrast, Principle~\Ref{PrinA10.08}, the `Axiom of Extension', implies that the corresponding {\em sets}, namely $\{a,b\}$ and $\{b,a\}$ are equal.
    In particular the `obvious idea' to identify the primitive concept of `ordered pair $(a,b)$' with the set $\{a,b\}$,
    fails to reflect the `main feature' described above and thus is unsuitable as a set-theoretic characterization of the primitve concept.

        Likewise, the main feature of the primitive notion of `ordered $k$-tuple' is that two such $k$-tuples of objects, $(x_{1}, x_{2},\,{\ldots}\,x_{k})$ and $(y_{1}, y_{2},\,{\ldots}\,y_{k})$,
    are equal if, and only if, $x_{j} \,=\, y_{j}$ for each $j \,=\, 1, 2, \,{\ldots}\,k$.

\V

        (2) Depending on the context, the notation $(a,b)$ can be ambiguous. For example,
    it may refer to the ordered pair $(a,b)$, formed by objects $a$ and $b$, as above.
    But if $a$ and $b$ are real numbers such that $a\,<\,b$, then it may denote an open interval in~${\RR}$, a very different idea. This ambiguity normally causes no difficulty in a given context,
    and it can be avoided easily by using clarifying phrases, such as `the ordered pair $(a,b)$' or `the open interval $(a,b)$' as needed.

\VV

%%%
\begin{quotation}
{\footnotesize \underline{\Note}\IndB{\notes}{on the `tuple' terminology } (on the `tuple' terminology)
The use of the ending `tuple' in `$k$-tuple' comes from ordinary English, where analogous words are `singleton', `pair', triple', `quadruple', `quintuple', `sextuple', `septuple', `octuple' and so on;
    `tuple' is the generic ending for such formations once the first few special cases are passed.
}%EndFootNoteSize
\end{quotation}
%##

        It turns out in modern mathematics that {\em collections} of ordered tuples are important.

\V

            \subsection{\small{\bf Definition} (Cartesian Products of Sets)}
            \label{DefA12.30}\IndBD{set theory}{Cartesian products of sets}

  \hspace*{\parindent} (1) Let $(A,B)$ be an ordered pair of nonempty sets.
    The {\bf Cartesian Product of $\Bfm{A}$ with $\Bfm{B}$}
    is the set $A{\times}B$ consisting of all ordered pairs $(a,b)$ with $a{\in}A$ and $b{\in}B$.
    That is, an object $p$ is an element of the set $A{\times}B$ if, and only if,
    there exists an element $a$ in $A$ and an element $b$ in $B$ such that $p\,=\,(a,b)$.

        (2) More generally, let $k$ be a natural number such that $k\,\,{\geq}\,\,2$,
    and let $(X_{1}, X_{2},\,{\ldots}\,X_{k})$ be an ordered $k$-tuple of nonempty sets.
    Then the corresponding {\bf Cartesian Product \Bfm{X_{1}{\times}X_{2}{\times}\,{\ldots}\,{\times}X_{k}}}
    is the set of all ordered $k$-tuples of the form $(x_{1}, x_{2},\,{\ldots}\,x_{k})$
    such that for each $j \,=\, 1,2,\,{\ldots}\,k$ the object $x_{j}$ is an element of the set $X_{j}$.
    The sets $X_{1}$, $X_{2}$,\,{\ldots}\,$X_{k}$ are called the {\bf factors} of this Cartesian product.

        If any of the sets $X_{1}$,\,{\ldots}\,$X_{k}$ equals the empty set, one sets $X_{1}{\times}X_{2}{\times}\,{\ldots}\,{\times}X_{k} \,=\, {\emptyset}$.

        (3) If there is a set $Y$ such that $X_{j} \,=\, Y$ for all $j \,=\, 1,2,\,{\ldots}\,k$,
    then one usually writes $Y^{k}$ instead of $X_{1}{\times}X_{2}{\times}\,{\ldots}\,{\times}X_{k}$.
    For example, one usually writes $Y^{4}$ instead of $Y{\times}Y{\times}Y{\times}Y$.


\V

        \underline{Remarks} (1) The symbol ${\times}$ is usually pronounced `cross' in English; thus, for example, the expression $A{\times}B$ would be spoken `$A$~{\em cross}~$B$'.

\V

        (2) The use of the word `product' in this context is because the `cross' notation is also used in elementary arithmetic to denote the ordinary product of numbers.
    This also explains the `exponential notation' $Y^{k}$ used above: it mimics the exponential notation used in arithmetic.
    However, there is no further algebraic theory associated with the `product' used in `Cartesian product'.

\V

        (3) The word `Cartesian' is capitalized here because it derives from a proper name; namely, from the second name of Ren\'{e} Des{\bf cartes}, the founder of modern analytic geometry.

\VV

        \subsection{\small{{\bf Examples}}}
        \label{ExampA12.40}

\hspace*{\parindent}
    (1) Let $A \,=\, \{1,2,3\}$ and $B \,=\, \{2,4\}$. Then it is clear that
        \begin{displaymath}
        A{\times}B \,=\, \{(1,2), (1,4), (2,2), (2,4), (3,2), (3,4)\}.
        \end{displaymath}
    Indeed, each of the ordered pairs listed on the right side of the preceding equation is certainly in the set $A{\times}B$,
    since in each case the first entry is in the set $A$ while the second is in $B$.
    Conversely, it is clear from the way these pairs are organized here that for every possible first entry (i.e., $1$, $2$ and $3$) the two possible second entries have been used.
    Thus, no element of $A{\times}B$ is missing from the right side.

\V

        (2) The standard plane from high-school analytic geometry can be identified with ${\RR}{\times}{\RR}$, the set of all ordered pairs of real numbers. This set is usually written as~${\RR}^{2}$.

\V

        (3) If $A$ and $B$ are nonempty sets such that $A \,\,{\neq}\,\, B$, then clearly $A{\times}B \,\,{\neq}\,\, B{\times}A$.
    For example, suppose that $a$ is an element of $A$ which is not in $B$. Let $b$ be an element of $B$.
    Then the ordered pair $(a,b)$ is in the set $A{\times}B$ but not in the set $B{\times}A$.

        In contrast, if $A \,\,{\neq}\,\, B$ but one of the sets $A$ or $B$ is empty,
    then one does have $A{\times}B \,=\, B{\times}A$, since in this case both Cartesian products are, by definition, equal to the empty set.

\V
\V

\StartSkip{
        The main application of the concept of Cartesian products in {\TheseNotes} is to the general study of `functions';
    this extensive study begins in the next section.
    As a prelude to that study, however, and as a quick way to illustrate the usefulness of Cartesian products,
    we end the current section with a brief discussion on the following topic:  what does it mean to say that sets $A$ and $B$ have equally many elements?

\V

\begin{quotation}
{\footnotesize \underline{\Note} (on defining `equally many elements')\IndB{\notes}{on defining `equally many elements'}:
    The solution to this problem seems very easy if the sets $A$ and $B$ are both finite:
    simply count the number of elements in each set, and if the numbers agree, then the sets have equally many elements.
    However, in modern mathematics one is forced to study sets which have {\em infinitely many} elements, and in such cases `counting' may not even make sense.
    Fortunately, there is a way of determining when two sets have equally many elements which, even in the case of finite sets, is older than the idea of `counting', and this older method is what can be used.

        \underline{Example} Anthropologists tell us that there were primitive societies whose concept of `number' was restricted to `one', `two' and `many'.
    Suppose that the king of such a society needs to know whether there are as many spears available in storage as there are warriors;
    could he do so? The answer is `Yes': he could tell the warriors to each take one spear from storage;
    if, after this, every warrior has one spear, and there are no spears left over, then the king knows that there are equally many spears as warriors.
    Note that this process does not involve `counting' the number of spears and the number of warriors; indeed the king probably cannot count that high.
    It is simply a matter of `pairing off' spears and warriors, so that each spear is carried by one warrior, and each warrior holds one spear.

\VA

        The preceding suggests a way of determining whether two sets $A$ and $B$, possibly infinite, have equally many elements:
    if it is possible to `pair off' the elements of the sets, so that each element of $A$ gets paired with exactly one element of $B$,
    and each element of $B$ gets paired with exactly one element of $A$, then the sets have equally many elements.
}%EndFootnotesize
\end{quotation}

        \subsection{\small{\bf Definition}}
            \label{DefA12.70}\IndBD{cardinality}{complete pairings}

        Let $(A,B)$ be an ordered pair of nonempty sets.

        (1) A {\bf complete pairing of $A$ with $B$} is a subset $F$ of the Cartesian product $A{\times}B$ which has the following properties:

        \h \underline{Pairing Condition (i)} For each element $a$ in $A$ there is a unique element $b$ in $B$ such that $(a,b){\in}F$;

        \h \underline{Pairing Condition (ii)} For each $b$ in $B$ there is a unique $a$ in $A$ such that $(a,b){\in}F$.

\noindent If an ordered pair $(a,b)$ is an element of a complete pairing $F$, then one also says that {\bf $a$ is paired with $b$ by $F$}.

\V

        (2) One says that {\bf $A$ has equally many elements as $B$}, or, using more modern terminology,
    that {\bf $A$ has the same cardinality as $B$},
    provided there exists at least one complete pairing of $A$ with $B$.

\V

        (3) Let $k$ be a natural number, and recall that ${\NN}_{k}$ denotes the set of all natural numbers $m$ such that $1\,\,{\leq}\,\,m\,\,{\leq}\,\,k$.
    One says that a set $A$ {\bf has cardinality $k$}, or that {\bf $A$ has (exactly) $k$ elements},
    provided that $A$ has the same cardinality as the set ${\NN}_{k}$; in symbols, $\# (A)\,=\,k$.
    (The qualifier `exactly' is normally omitted unless needed for clarity; for example,
    in ordinary English usage the statement `John has two brothers' might be interpreted as `John has {\em at least} two brothers'.)


        (4) In the preceding one assumes that the sets $A$ and $B$ are both nonempty.
    It is convenient to extend these definitions to situations involving the empty set~${\emptyset}$.
    Thus, one says that the empty set ${\emptyset}$ has `cardinality $0$', or that it has `$0$ elements' (or that is has `no elements').

\V

        (5) A set $A$ is said to be a {\bf finite set}\IndBD{cardinality}{finite sets} if either $A \,=\, {\emptyset}$, or there exists a natural number $k$ such that $A$ has exactly $k$ elements.
    All other sets are said to be {\bf infinite sets}\IndBD{cardinality}{infinite sets}.

\V

\begin{quotation}
{\footnotesize \underline{\Notes} (on the counting process)\IndB{\notes}{on the counting process}:
    
        (1) Parts~(3) and~(4) of the preceding definition contain the essence of the concept of `counting out' the elements of a finite set $A$;
    of course, they assume -- as we have been doing throughout this chapter -- that the reader is already familiar with the set~${\NN}$ of natural numbers.
    However, the phrasing makes it sound like one must somehow first come up with the appropriate number $k$,
    and then determine an appropriate complete pairing of ${\NN}_{k}$ with $A$.
    In practice, however, the process is a bit more subtle.
    For example, suppose that we wish to `count out' a large, but finite, collection $A$ of marbles in an urn.
    (Why an urn, and not a large box? Basically: It's a tradition in mathematics to use urns -- often Greek urns -- for counting problems.)
    Reach into the urn, pull out a marble while saying `one', and set that marble aside (outside the urn, of course).
    Then reach into the urn again, pull out another marble while saying `two', and set the new marble aside.
    Keep doing this until the marbles run out.
    The last number $k$ spoken in this process is the number of marbles originally in the urn,
    and the process of pulling out marbles establishes the complete pairing of $A$ with ${\NN}_{k}$.
    In particular, the value of $k$ is established only at the end of the `counting' process, as is the corrresponding complete pairing~$F$.

\V

        (2) The counting process described above uses the infinite set ${\NN} \,=\, \{1,2,3,\,{\ldots}\,99, 100, 101,\,{\ldots}\,\}$ as a `standard comparison set for counting'.
    In contrast, a couple of millenia ago, Julius Caesar probably would have used the set $\{I, II, III, \,{\ldots}\, XCIX, C, CI, \,{\ldots}\,\}$ as his `standard comparison set' for counting counting out the Roman legions.
    In any event, every such `standard comparison set' for counting enjoys the following properties:

        \h (a) There is a systematic procedure for going from one element of the comparison set to the next higher element.
    For instance, in the set ${\NN}$ the procedure can be stated simply:
    `Add~$1$ to the given element to get the next higher one'.
    To see just how systematic, and well-known, this procedure is, consider the following {\em extremely} large element of ${\NN}$:
        \begin{displaymath}
        37182946822901028333009155404045373779925111110382238549871179999.
        \end{displaymath}
    If this is the first time you are reading this section, then the probability is high that you have never encountered this gigantic number before.
    Indeed, it is so large that relatively few people could actually {\em speak} its name.
    (In the United States its name would start `$37$~vigintillion\,{\ldots}\,'; in Europe it would start `$37$~decilliard\,{\ldots}\,.)
    Nevertheless, what you learned as a child provides all you need to know to write down the next higher natural number; try to do so before reading further.

\V
\V

        You should get
        \begin{displaymath}
        37182946822901028333009155404045373779925111110382238549871180000.
        \end{displaymath}
    (This is one of the great features of the Arabic numerals. Had the original number been expressed in Roman numerals, the result might well have been less simple.)
    The process used in obtaining the successor of the given giant number can be thought of as `adding $1$'.
    However, it is likely that most people would simply look at the digits of the original number and write down the answer directly, without really doing `addition' as such.

        \h (b) By starting with the natural number~$1$ (or, if you insist on using $\hat{{\NN}}$ instead of ${\NN}$, starting with~$0$),
    and repeating the procedure discussed in (a), one eventually obtains every element of the comparison set.

\noindent It turns out that Properties~(a) and~(b) allow one to uniquely construct the other properties of the standard comparison set,
    such as the meaning of `greater than' as well as the operations of addition and multiplication.
    The details are discussed in Appendix~A.
}%EndFootnotesize
\end{quotation}

\V

        \subsection{\small{\bf Remark}}
            \label{RemrkA12.80}

        In ordinary language usage, one would think of the statements `$A$ has the same cardinality as $B$' and `$B$ has the same cardinality as $A$'
    (see Part~(2) of the preceding definition) as mere rephrasings of each other,
    so that one could say that they `mean' the same thing even without knowing the nature of the subject matter.
    In reality, however, the usage here is technical, not that of `ordinary language', and the two statements are subtly different.
    Indeed, the first statement means (by Definition~\Ref{DefA12.70}) that there exists a subset $F$ of $A{\times}B$ satisfying the pairing conditions for $A$ with $B$,
    while the second statement means (also by the same definition) that there exists a subset $G$ of $B{\times}A$ satisfying the pairing conditions for $B$ with $A$.
    Since $A{\times}B$ and $B{\times}A$ need not be the same sets -- indeed, they may have no points in common --
    there is no reason to expect that $F \,=\, G$. Thus, to show that the first statement {\em implies} the second,
    one should use the existence of the complete pairing $F$ of $A$ with $B$ to construct a corresponding complete pairing $G$ of $B$ with $A$.
    The obvious choice is to define $G$ by the rule
        \begin{displaymath}
        G \,=\, \{(b,a): (a,b){\in}F\}
        \end{displaymath}
    It is easy to see that $G$ is a complete pairing of $B$ with $A$; we call it the {\bf reversed complete pairing}
    \IndBD{cardinality}{reversed complete pairings}\IndC{cardinality}{complete pairings}{reversed complete pairings} associated with $F$.
    It is clear that $F$ is also the reversed complete pairing associated with~$G$.
}%\EndSkip

                        \section{Functions in Mathematics}
                        \label{SectA30}\IndB{ZZ Sections}{\Ref{SectA30} Functions in Mathematics}

    It can be argued that the single most important concept in modern mathematics is that of `function'.
    Although the word `function' has many nonmathematical meanings in ordinary English, in {\TheseNotes} we refer to its role as a technical mathematical term.

        The inception of the mathematical usage of this word is generally attributed to Leibniz in the late seventeenth century.
    Over the next couple of centuries the concept of `function' evolved greatly, often through the requirements of applications of mathematics to the sciences.
    The study of this evolution can be found in many books, and provides many insights into how mathematics actually develops in the real world.
    In the discussion below we consider only the very final stages of this evolution.

\V

        \underline{Preliminary Discussion} Let us remind ourselves of the somewhat informal approach to the function concept,
    as is taught nowadays in many elementary math courses, and then follow the evolution of this concept to its formal definition.

\V

        Near the beginning of most modern calculus texts one finds a definition that looks very much like this:

\V

        `A {\em function} is a rule which assigns to each element $x$ of a set $A$ a definite element $y$ of a set $B$.
    If $f$ is such a function and $x$ is an element of $A$, then we denote by $f(x)$ the element $y$ in $B$ which the rule $f$ assigns to~$x$,
    and we call it the {\em value} of the function $f$ at the element~$x$; that is, $y \,=\, f(x)$.'

\V

        For most purposes this definition is quite adequate. The obvious issue, of what one means by a `rule' and by `assigns',
    is handled by Justice Stewart's dictum,  `I know it when I see it'. However, a deeper analysis of the meanings of these words can get fairly complicated.
    For example, consider the following `rules' for defining the values of a pair of real-valued functions $f$ and $g$ of a real variable:
        \begin{displaymath}
        f(x) \,=\, (x+1)^{3} - x^{3} + 3\,x^{2}; \h g(x) \,=\, 1 - 3\,x \h ({\ast})
        \end{displaymath}
    If one thinks of the word `rule' to mean a list of instructions for what to do to the number~$x$ to obtain the corresponding value of the function,
    then these are clearly different `rules'; for example, the first `rule' requires computing the cube of $x$ while the second does not.
    Nevertheless it is easy to see, using basic laws of algebra, that $f(x) \,=\, g(x)$ for every number~$x$.
    In calculus one treats $f$ and $g$ to represent `the same function', even though they are not given by `the same rule'.
    Note that this is not an isolated phenomenon: it is clear that {\em every} function
    which one encounters in calculus can be described in multiple ways using different `rules'.

        There is a simple cure for this ambiguity, also given in the calculus texts, which comes from the concept of the `graph' of a function.
    Indeed, recall from calculus that if $f$ is a real-valued function of a real variable,
    then one defines the {\em graph} of $f$ to be the set of points $(a,b)$ in ${\RR}{\times}{\RR}$ such that $f$ is defined at $a$, and $b \,=\, f(a)$.
    Note that with this graphical interpretation the phrase `assigns to each element $a$ of a set $A$ a definite element $b$ of a set $B$' can be clarified:
    it means that if $(a,b_{2})$ and $(a,b_{2})$ are both points of the graph of $f$, then $b_{1} \,=\, b_{2}$.
    Conversely one can identify directly those subsets of ${\RR}{\times}{\RR}$ which can be viewed as graphs of functions.
    More precisely, suppose that $G$ is a nonempty subset of ${\RR}{\times}{\RR}$ which passes the following
    {\bf Restricted Vertical-Line Test}:\IndBD{functions}{restricted vertical-line test}
        \begin{displaymath}
        \mbox{If $(a,b)$ and $(a,c)$ are elements of $G$, then $b \,=\, c$.} 
        \end{displaymath}
    Speaking geometrically: every vertical line in the $x\,y$-plane which intersects
    the set $G$ does so in exactly one point; hence the name `Vertical-line Test'.
    The function $f$ associated with such a set $G$ then can be described as follows:

        (i)\,The domain $A$ of $f$ consists of all numbers $x$ in ${\RR}$ such that for some real number $y$ the ordered pair $(x,y){\in}G$.

        (ii) The `rule' for $f$ is that for each $x$ in the domain of $f$, $f(x)$ is the unique number $y$ such that $(x,y){\in}G$.

\VA

        {\bf Remark} The word `restricted' is used here because it applies only to real-valued functions of a single real variable.
    

\V

        The formal definition of `function' which follows incorporates the major features of the preceding discussion,
    except that the `rule' formulation is replaces by the `graph' concept, and the sets $A$ and $B$ can be sets of objects of any type, not just real numbers. 

\V
\V

            \subsection{\small{\bf Definition}}
            \label{DefA30.10}\IndB{functions}{classical ordered-pairs definition}

\V

\hspace*{\parindent} (1) Let $A$ and $B$ be nonempty sets of objects. Then a {\bf function with domain~$\Bfm{A}$\IndB{functions}{domain of a function}
    and values in the target $\Bfm{B}$}\IndB{functions}{target of a function} is a subset $f$ of the
    Cartesian product $A{\times}B$ which satisfies the following {\bf Extended Vertical-Line Test}\IndBD{functions}{extended vertical-line test}:


\V

        \h For every object $x$ in the set $A$ there is exactly one object $y$ in the set $B$ such that the ordered pair $(x,y)$ is an element of the set~$f$.

\V

\noindent One calls $y$ the {\bf value of $\Bfm{f}$ at $\Bfm{x}$}
    \IndBD{functions}{value of a function at a point} and says that {\bf $\Bfm{f}$ assumes the value $\Bfm{y}$ at~$\Bfm{x}$}\IndBD{functions}{assumes a value at a point}.
    The standard notation for this (unique) $y$ is $f(x)$, pronounced (in English)  `$f$-of-$x$' (`eff-of-eks'). One also says that
    the function $f$ {\bf maps the set $\Bfm{A}$ into the set $\Bfm{B}$}.\IndBD{function}{maps (as a verb)}

\V

        (2) A {\bf function in the classical sense} is a set of ordered pairs of the type described in Part~(1).

\V

        (3) Suppose that $f$ is a function with domain~$A$. If $x$ is a point of the domain $A$,
    then one says that {\bf \Bfm{f} is defined at~\Bfm{x}}\IndBD{functions}{defined at a point}.
    Likewise, if $S$ is a nonempty subset of~$A$, then one says that {\bf $\Bfm{f}$ is defined on the set~$\Bfm{S}$}\IndBD{functions}{defined on a set}


%% SEE APOSTOL FOR EXAMPLE OF A TEXT USING "DEFINED ON A SET" THIS WAY.

\V

        (4) Let $f$ be a function with domain $A$ and values in a set $B$, as above, and let $S$ be a nonempty subset of~$A$.

        \h (a) One says that the function $f$ is {\bf one-to-one on~$\Bfm{S}$}\IndBD{functions}{one-to-one on a set}
    provided whenever $x_{1}$ and $x_{2}$ are elements of $S$ such that $f(x_{1}) \,=\, f(x_{2})$, then $x_{1} \,=\, x_{2}$.

        \h (b) Likewise, one says that {\bf \Bfm{f} maps the $S$ onto the set $\Bfm{B}$}\IndBD{functions}{maps onto a set}
    provided that every element $y$ in $B$ can be expressed in the form $y \,=\, f(x)$ for some element $x$ in $S$.

        \underline{Note} Condition (a) can be reformulated as: for every $y$ in $B$ there is {\em at most} one $x$ in $A$ such that $f(x) \,=\, y$.
    Likewise, Condition~(b) can be reformulated as: for every $y$ in $B$ there is {\em at least one} $x$ in $A$ such that $f(x) \,=\, y$.

\VV


        \subsection{\small{\bf Remarks}}
        \label{RemrkA30.12}

\hspace*{\parindent} (1) If the set $f$ is a function in the sense of Part~(2) above, then it completely determines the points of the corresponding domain~$A$:
        \begin{displaymath}
        A \,=\, \{x: \mbox{ there exists an ordered pair in the set $f$ whose first entry is $x$}\} \h ({\ast})
        \end{displaymath}
    In contrast, the set $f$, by itself, has only partial information about the target set~$B$.
    More precisely, let $B_{0} \,=\, \{y: \mbox{ there exists an ordered pair in the set $f$ whose second entry is $y$}\}$.
    Then any superset of $B_{0}$ can play the role of~$B$.

        The preceding observation raises the question of whether one needs to include explicit mention of the sets $A$ and $B$ in the definition of `function'.
    Indeed, why not simply define a `function' to be a nonempty set of ordered pairs of objects, with no restriction on the type of objects involved?
    The answer is that such an approach involves the concept of the `set of all objects',
    a concept which leads to serious logical difficulties; see, for example, the treatment of `Russell's Paradox' in Appendix~B.

\V

        (2) Since functions are defined above to be certain types of sets of ordered pairs,
    it follows from the Axiom of Extension, i.e., Principle~\Ref{PrinA10.08}, that two functions $f$ and $g$ are the same function if, and only if,
    as sets they have exactly the same elements. When combined with Equation~$({\ast})$ in the preceding remark,
    one obtains the following classic formulation for the equality of two functions $f$ and $g$:
    \IndBD{functions}{equality of functions -- classic formulation}

\VA

        \h (i)\,$f$ and $g$ have the same domain; and

        \h (ii) for every $x$ in this common domain one has $f(x) \,=\, g(x)$.

\VA

\noindent This set-theoretic formulation avoids the ambiguity of the `A function is a Rule such that ...' formulation.
    Nevertheless, in specific cases we may describe the function, i.e., the set $f$ of ordered pairs,
    using an explicit `rule' showing how, for each $x$ in the domain of $f$, to obtain $f(x)$ from $x$.

\V

        (3) Depending on the context, mathematicians often use words such as {\bf map}\IndBD{functions}{map (as a noun)}, {\bf mapping}\IndBD{functions}{mapping}, {\bf operation}\IndBD{functions}{operation},
    {\bf operator}\IndBD{functions}{operator} and {\bf transformation}\IndBD{functions}{transformation} in place of `function'.
    Also, the convention in {\TheseNotes} is that both $A$ and $B$ need to be nonempty; in other words, we don't admit the concept of the `empty function'.
    This restriction is for convenience; but it should be noted that in certain other parts of mathematics the empty function {\em is} allowed.

\V

        (4) The statement `$f$ is defined on the set $S$', in Part~(2) of the preceding definition,
    allows the possibility that $f$ is also defined at points not in~$S$; that is, it allows $S$ to be a proper subset of the domain $A$ of~$f$.
    In contrast, some authors define this statement to mean that $S$ is the (full) domain of $f$, so that if $x\not \in S$, then $f(x)$ makes no sense.
    The situation is actually a bit more complicated: some of the authors who require that $S$ be the (full) domain do, on occasion,
    and without stating that they are deviating from their usual convention, allow $S$ to be a proper subset of that domain.

%% Example: Baby Rudin 3rd Ed identifies `is defined on' with `domain'

%% EXAMPLE In defining the definite integral \int_{a}^{b} f(x)\,dx, such
%% authors may imply that f is a function whose full domain is [a,b].
%% But in that case, when they do the addition formula for integrals, namely
%% \int_{a}^{b} f = \int_{a}^{c} f + \int_{c}^{b} f, with a<c<b, they
%% ought to have used the restrictions of f to [a,c] and [c,b]. They don't.

\VV

        Many authors prefer an approach to `functions' in terms of ordered pairs, as above, but in which the target $B$ is also specified uniquely,
    not just the domain~$A$; indeed, in certain parts of mathematics, such as Algebraic Topology, fixing the target of a function is of great importance.
    One obvious approach would be to always use the set $B_{0}$ described in Remark~(1) above.  
    However, that choice turns out to be much too restrictive, especially when considering simultaneously more than one function with the same domain.

        The following well-known device allows one to include references to a specific target $B$ without conflicting with Definition~\Ref{DefA30.10}.

\VV

        {\bf The Arrow Notation for Functions}\IndBD{functions}{arrow notation for functions}
    Assume that $f$ is a function which is defined on a nonempty set $S$ and has values in a set $B$, as described in Definition~\Ref{DefA30.10} above.
    (In particular, recall that `is defined on $S$' means that the nonempty set $S$ is a subset of the full domain $A$ of~$f$.)
    One often abbreviates this assumption in symbols using the following {\bf arrow notation}:
        \begin{displaymath}
        f:S \,{\rightarrow}\, B;
        \end{displaymath}
    in words: `$f$ maps\IndBD{functions}{map (as a verb)} the set $S$ into $B$'.

\VV

        The arrow notation provides a simple way to provide a more modern definition of `function' in which the target set is completely specified.

\V

            \subsection{\small{\bf Definition}}
            \label{DefA30.20A}\IndB{functions}{modern ordered-pairs definition}

\V

         (1) An expression of the form $f:S \,{\rightarrow}\, B$,
    where $S$, $B$ and $f$ are as above, is called a {\bf function diagram}\IndBD{functions}{function diagrams}. 
    The condition for two such diagrams, $f:S \,{\rightarrow}\, B$ and $g:T \,{\rightarrow}\, C$, to be equal as diagrams
    is that $S \,=\, T$, $B \,=\, C$, and $f(x) \,=\, g(x)$ for each $x$ in~$S$, where each equation is in the sense of Principle~\Ref{PrinA10.08}, the Axiom of Extension.

\V

        (2) A {\bf function in the modern sense} is a function diagram $f:A \,{\rightarrow}\, B$, as in Part~(1) above,
    in which the set $A$ is the domain of~$f$. The set $B$ in this diagram is then called the {\bf codomain}\IndBD{functions}{codomain of a function} of the given function.

\V

            \subsection{\small{\bf Remarks}}
            \label{RemrkA30.22}

\hspace*{\parindent} (1) Many texts define `function in the modern sense' to  be an ordered pair $(U,f)$ in which $U$ is an ordered pair $(A,B)$ of nonempty sets,
    and $f$ is a subset of $A{\times}B$ which satisfies the Extended Vertical-Line Test. This approach is obviously equivalent to the `function diagram' approach just described.

\V

        (2) If the given context makes clear which function diagram is under consideration,
    we shall often abbreviate `the function diagram $f:A \,{\rightarrow}\, B$' to `the function $f:A \,{\rightarrow}\, B$', or even more briefly to `the function~$f$'.
    In such a context it still makes sense to refer to the set $B$ as `the codomain of the function~$f$', since the underlying function diagram $f:A \,{\rightarrow}\, B$ is understood.

\V

        (3) Similarly, the context should make it clear whether the word `function'
    is being used in the `classical sense' of Definition~\Ref{DefA30.10} or in the `modern sense' of Definition~\Ref{DefA30.20A}.
    Note that some authors use the `classical' definition, some the `modern' definition, so it is useful to be familiar with both formulations.
    However, since most authors focus on only one of these formulations, they usually do not include the adjectives `classical' or `modern' as we do here.

\V

        (4) On occasion it is convenient to use the notation $S\stackrel{f\,\,\,\,\,}{{\longrightarrow}\,B}$ as a substitute for the standard
    $f:S \,{\rightarrow}\, B$; for example, see the treatment of `composition' below, in which one strings together a pair of function diagrams.

\VV

        The `function diagram' concept can be used to clarify some other terminology.

            \subsection{\small{\bf Definition}}
            \label{DefA30.20B}
\V


        A function diagram $f:S \,{\rightarrow}\, B$ is said to be an {\bf injection}\IndBD{functions}{injections}
    provided the function $f$ is one-to-one on the set~$S$, in the sense of Part~(4\,a) of Definition~\Ref{DefA30.10}.

        Likewise, the diagram is said to be a {\bf surjection}
    \IndBD{functions}{surjections}
    provided $f$ maps the set $S$ onto the set~$B$, in the sense of Part~(4\,b) of the same definition.

        A function diagram which is both an injection and a surjection is called a {\bf bijection}\IndBD{functions}{bijections}.
    If $f:A \,{\rightarrow}\, B$ is a bijection, then one says that elements $a$ in $A$ and $b$ in $B$
    {\bf correspond under $\Bfm{f}$}\IndBD{functions}{corresponding elements under a bijection} provided $b \,=\, f(a)$.



        \subsection{\small{\bf Some Examples of Functions}}
        \label{ExampA30.25}

\V

\hspace*{\parindent}(1) The standard algebraic functions and transcendental functions used in calculus should be familiar.
    The `algebraic' functions include polynomial functions and rational functions (i.e., ratios of polynomial functions).
    The `transcendental' functions include the standard exponential, logarithmic and trigonometric functions.

\V

        (2) Less well known, perhaps, but even simpler, are the following real-valued functions, both with domain $A \,=\, {\RR}$,
    named after mathematicians of the nineteenth century:

        \h (i)\, The {\bf Dirichlet Function}\IndC{functions}{special functions}{Dirichlet function} is the function $F_{\mbox{Diri}}:{\RR} \,{\rightarrow}\, {\RR}$ given by the rule
        \begin{displaymath}
        F_{\mbox{Diri}}(x) \,=\, \left\{
        \begin{array}{ll}
        1 & \mbox{if $x$ is a rational number} \\
        0 & \mbox{if $x$ is an irrational number}
        \end{array}
            \right.
        \end{displaymath}

        \h (ii) The {\bf Thomae Function}\IndC{functions}{special functions}{Thomae function} is the function $F_{\mbox{Thom}}:{\RR} \,{\rightarrow}\, {\RR}$ given by the rule
        \begin{displaymath}
        F_{\mbox{Thom}}(x) \,=\, \left\{
        \begin{array}{ll}
        1 & \mbox{if $x \,=\, 0$} \\
        1/q & \mbox{if $x$ is a nonzero rational number $p/q$, with $p$ in ${\ZZ}$ and $q$ in ${\NN}$ being in lowest terms} \\
        0 & \mbox{if $x$ is an irrational number}
        \end{array}
            \right.
        \end{displaymath}
    These function are used mainly as `exotic examples' in various contexts.

\V

        (3) Let $f:A \,{\rightarrow}\, B$ be a function diagram. One says that {\bf $\Bfm{f}$ is constant on $\Bfm{A}$} if there exists an element $c$ of $B$ such that $f(x) \,=\, c$ for every $x$ in~$A$.
    If, in addition, $A$ is the full domain of $f$, then one says that {\bf $\Bfm{f}$ is the constant function on $\Bfm{A}$ with value $\Bfm{c}$}.\IndC{functions}{special functions}{constant functions}\IndBD{special functions}{constant functions}

\V

        (4) Let $A$ be a nonempty set, and let $f:A \,{\rightarrow}\, A$ be the function, with domain and codomain both equal to $A$, given by the rule $f(x) \,=\, x$ for all $x{\in}A$.
    (Equivalently, $f$ is the subset of $A{\times}A$ consisting of all the ordered pairs of the form $(x,x)$ with $x{\in}A$.)
    This function is called {\bf the identity function on $A$}\IndC{functions}{special functions}{identity function}\IndBD{functions}{identity function},
    and is usually denoted by the symbol $I_{A}$; if the set $A$ remains fixed throughout a discussion, the notation may be simplified to $I$.
    It is clear that the map $I_{A}:A \,{\rightarrow}\, A$ is a bijection, in the sense of Definition~\Ref{DefA30.20B}.

        Similarly, let $A$ be a nonempty set, and let $B$ be a superset of~$A$; that is, $A \,{\subseteq}\, B$.
    Define the function diagram ${\iota}_{A;B}:A \,{\rightarrow}\, B$, with domain $A$ and codomain~$B$, by the rule
        \begin{displaymath}
        {\iota}_{A;B}(x) \,=\, x \mbox{ for all $x$ in $A$}.
        \end{displaymath}
    This function is called the {\bf inclusion of $\Bfm{A}$ into $\Bfm{B}$}.\IndC{functions}{special functions}{inclusion function}\IndBD{functions}{inclusion function}
    (The symbol `${\iota}$' is the lower-case Greek letter `iota', which corresponds to the English letter {\em i}.)

        Note that the domain of the function ${\iota}_{A;B}$ is the same as the domain of the identity function $I_{A}$ considered above.
    In addition, $I_{A} \,{\subseteq}\, A{\times}A$ and ${\iota}_{A;B} \,{\subseteq}\, A{\times}B$ are the same sets of ordered pairs.
    Thus under the `classical' formulation of `function', one has $I_{A} \,=\, {\iota}_{A;B}$.
    However, under the modern `function-diagram' formulation, they are different functions if $A$ is a proper subset of~$B$.

\V

        (5) Let $A$ be a nonempty set, and let $S$ be a subset of $A$, possibly empty.
    Then the {\bf characteristic function associated with the subset $\Bfm{S}$ of $\Bfm{A}$}\IndC{functions}{special functions}{characteristic functions} is the function ${\chi}_{A;S}:A \,{\rightarrow}\, \{0,1\}$, with domain $A$ and with values in the doubleton set~$\{0,1\}$,
    given by the rule
        \begin{displaymath}
        {\chi}_{A;S}(x) \,=\, \left\{
        \begin{array}{ll}
        1 & \mbox{if $x$ in $A$ is an element of $S$}           \\
        0 & \mbox{if $x$ in $A$ is {\em not} an element of $S$}
        \end{array}
        \right.
        \end{displaymath}

        \underline{Remarks} (i) The symbol `${\chi}$' is the lower-case version of the ancient Greek letter `chi', usually pronounced `kai', and which corresponds (roughly) to the English `k' sound.


        (ii) If, as is often the case, the context makes clear which domain $A$ is under consideration, it is customary to omit reference to it and write simply ${\chi}_{S}$; indeed, some texts use this concept only when $A \,=\, {\RR}$.

        (iii) The phrase `characteristic function' is used in certain other branches of mathematics with an unrelated meaning.
    Because of this, some authors use the phrase {\bf indicator function}\IndD{indicator functions}{special functions}\IndC{functions}{special functions}{indicator functions}
    instead of `characteristic function' for the concept defined here; and some use notations such as $1_{S}$ instead of ${\chi}_{S}$.

\V

        (6) Let $P \,=\, (a,c)$ and $Q \,=\, (b,d)$ be points in~${\RR}{\times}{\RR}$, with $a\,<\,b$.
    Define $g:[a,b] \,{\rightarrow}\, {\RR}$ to be the real-valued function, with domain the closed interval $[a, b]$, given by the rule
        \begin{displaymath}
        g(x) \,=\, c + \left(\frac{d-c}{b-a}\right)(x-a)
\mbox{ for $a\,\,{\leq}\,\,x\,\,{\leq}\,\,b$}
        \end{displaymath}
    In terms of the `ordered pairs' definition of functions, $g$ is the set of all ordered pairs $(x,y)$ in ${\RR}{\times}{\RR}$ of the form ${\displaystyle \left(x,c + \left(\frac{d-c}{b-a}\right)(x-a)\right)}$ with $a\,\,{\leq}\,\,x\,\,{\leq}\,\,c$.
    Speaking geometrically, $g$ is a function whose graph in the $(x,y)$-plane is the straight line segment joining the points $P$ and $Q$.
    The function $g$ described here is called the {\bf linear interpolation\IndBD{functions}{linear interpolation between two points} between $\Bfm{P}$ and~$\Bfm{Q}$}.

\V

        (7) In elementary calculus one is often taught about {\bf step functions}.\IndC{functions}{special functions}{step functions}
    The most common example of such a function given in calculus texts is the so-called {\bf postage-stamp function}.\IndC{functions}{special functions}{postage stamp function}
    For example, in the year $2013$ the cost of mailing a first-class letter within the United States is given by the following table:
        \begin{displaymath}
        \begin{array}{ll}
        \mbox{Weight of Letter (in ounces)} & \mbox{Mailing Cost (in USD)} \\
        0.0\,<\,w\,\,{\leq}\,\,1.0 & \mbox{\$0.46}     \\
        1.0\,<\,w\,\,{\leq}\,\,2.0 & \mbox{\$0.66}     \\
        2.0\,<\,w\,\,{\leq}\,\,3.0 & \mbox{\$0.86}     \\
        3.0\,<\,w\,\,{\leq}\,\,3.5 & \mbox{\$1.00}
        \end{array}
        \end{displaymath}
    (Anything heavier falls into a different category of mail.)

        Associated with this table is the function $f:(0,3.5] \,{\rightarrow}\, {\RR}$ given by the rule
        \begin{displaymath}
        f(x) \,=\, \left\{
        \begin{array}{rl}
        0.46 & \mbox{if $0.0\,<\,x\,\,{\leq}\,\,1.0$} \\
        0.66 & \mbox{if $1.0\,<\,x\,\,{\leq}\,\,2.0$} \\
        0.86 & \mbox{if $2.0\,<\,x\,\,{\leq}\,\,3.0$} \\
        1.00 & \mbox{if $3.0\,<\,x\,\,{\leq}\,\,3.5$}
        \end{array}
                        \right.
        \end{displaymath}

%---------------------------- EXERCISE?
\StartSkip{
        {\bf EXERCISE}\,The Dirichlet function $F_{\mbox{Diri}}:{\RR} \,{\rightarrow}\, {\RR}$
    is the characteristic function ${\chi}_{{\QQ}}$ of the set of rational numbers (viewed as a subset of the real numbers).
    Likewise, the relation between the Dirichlet function and the Thomae function $F_{Thom}$ is this:
        \begin{displaymath}
        F_{Diri} \,=\, {\chi}_{S}{\circ}F_{Thom}, 
        \end{displaymath}
    where $S$ is the set of positive real numbers. The verification of this is
}%\EndSkip
%---------------------------

\VV

        The following terminology and notation is used throughout modern mathematics.

\V

        \subsection{\small{\bf Definition}}
        \label{DefA30.26A}\IndBD{functions}{inverse of a bijection}

\V

        Suppose that the function $f:A \,{\rightarrow}\, B$ is a bijection.
    Then the corresponding {\bf inverse function} $f^{-1}:B \,{\rightarrow}\, A$ is given by the following rule:
        \begin{displaymath}
        \mbox{If $y{\in}B$, then $f^{-1}(y)$ is the unique element $x$ in $A$ such that $f(x) \,=\, y$.}
        \end{displaymath}

\V

        {\bf Example} Let $A$ be the set of all real numbers $x \,\,{\neq}\,\, 1$, and let $B$ be the set of all real numbers $y \,\,{\neq}\,\, 2$.
    Define the function $f$ with domain $A$ by the rule $f(x) \,=\, {\displaystyle \frac{2\,x-1}{x-1}}$ for all $x$ in~$A$.
    It is easy to see that $f$ maps $A$ onto $B$, and that the function diagram $f:A \,{\rightarrow}\, B$ is a bijection.
    Indeed, if $y$ is a real number of the form $(2\,x-1)/(x-1)$, then
        \begin{displaymath}
        y\,(x-1) \,=\, 2\,x-1, \mbox{ hence } (y-2)\,x \,=\, y-1, \mbox{ and thus } x \,=\, \frac{y-1}{y-2}.
        \end{displaymath}
    This implies that if $x \,\,{\neq}\,\, 1$ then $y \,=\, f(x) \,\,{\neq}\,\, 2$, so $f$ maps $A$ into~$B$.
    Further, the calculation implies that if $y \,\,{\neq}\,\, 2$ then there is a unique $x$ in $A$ for which $y \,=\, f(x)$, so that the function $f$ is one-to-one.
    Thus, $f$ maps $A$ onto~$B$, so that $f:A \,{\rightarrow}\, B$ is a bijection.
    Finally, the calulation implies that the inverse $f^{-1}:B \,{\rightarrow}\, A$ is given by the formula $f^{-1}(y) \,=\, {\displaystyle \frac{y-1}{y-2}}$.

\VV


        \subsection{\small{\bf Theorem}}
        \label{ThmA30.26B}

\V

        Suppose that $f:A \,{\rightarrow}\, B$ is a bijection, and let $f^{-1}:B \,{\rightarrow}\, A$ be the corresponding inverse function. Then:

\V

        (a) The set $f^{-1} \,{\subseteq}\, B{\times}A$ is given by the rule
        \begin{displaymath}
        f^{-1} \,=\, \mbox{ the set of all ordered pairs $(b,a)$ such that $(a,b){\in}f$}.
        \end{displaymath}

\V

        (b) The function diagram $f^{-1}:B \,{\rightarrow}\, A$ is also a bijection.

\V

        (c) The inverse of the bijection $f^{-1}:B \,{\rightarrow}\, A$ is the original bijection $f:A \,{\rightarrow}\, B$.
    In symbols: $(f^{-1})^{-1} \,=\, f$.

\V

        The simple proof is left as an exercise.

%% EXERCISE??


\VV

        Associated with a function $f$ from $A$ to $B$ are various subsets of $A$ and $B$, along with corresponding notation and terminology.

            \subsection{\small{\bf Definition}}
            \label{DefA30.15}

        Throughout this definition $f:A \,{\rightarrow}\, B$ is a function with domain $A$ and codomain~$B$.

\V

        (1) Let $S$ be a subset of $A$. Then one associates, with the function $f$ and set $S$, a subset of $B$, denoted $f[S]$, given by the rule
        \begin{displaymath}
        f[S] \,=\, \{f(x):x{\in}S\}.
        \end{displaymath}
    In words: the set $f[S]$ consists precisely of those elements $y$ in $B$ such that $y \,=\, f(x)$ for at least one element of~$S$.
    One calls the set $f[S]$ the {\bf image\IndBD{functions}{image of a set under a function} of the set $\Bfm{S}$ under the map $\Bfm{f}$}.
    Note that if $S \,=\, {\emptyset}$ then $f[S] \,=\, {\emptyset}$.

        The special set $f[A]$, i.e., the image of the (full) domain of $f$ under $f$,
    is called simply the {\bf image of the function $\Bfm{f}$}\IndB{functions}{image of a function};
    the elements of this set are precisely the values of the function~$f$.

\V

        (3) Similarly, let $U$ be a subset of $B$.
    Then one associates with $f$ and $U$ a subset of $A$, denoted by $f^{-1}[U]$ and given by the rule
        \begin{displaymath}
        f^{-1}[U] \,=\, \{x{\in}A: f(x){\in}U\}.
        \end{displaymath}
    In words: $f^{-1}[U]$ is the set of all $x$ in $A$ such that $f(x){\in}U$. 
The set $f^{-1}[U]$ is called the {\bf inverse image of $\Bfm{U}$
    under $\Bfm{f}$}\IndB{functions}{inverse image of a set};
the word {\bf preimage}\IndBD{functions}{preimages} is often used in place of the phrase `inverse image'.
    Note, in particular, that $f^{-1}[{\emptyset}] \,=\, {\emptyset}$.

\V
\V

%%%
\begin{quotation}
{\footnotesize \underline{\Notes} (on function notation and terminology)\IndB{\notes}{on function notation and terminology}:

\V

        (1) Many texts write $f(S)$ instead of the notation $f[S]$ used above;
    that is, they surround the symbol $S$ with parentheses,~(\, and~), instead of with brackets,~[\, and~]\,.
    Likewise, they write $f^{-1}(U)$ instead of the notation $f^{-1}[U]$ used above.

        The most obvious problem with the `parentheses' notation $f(S)$ is that it can conflict with the notation $f(x)$,
    used for the value of the function at a point $x$ of the domain of $f$. Normally this `abuse of notation' does not cause any confusion;
    but there are situations in which it could. For instance, let $A$ be the doubleton set $\{1,\{1\}\}$ and let $B$ be the singleton set~$\{1\}$.
    Define $f:A \,{\rightarrow}\, B$ by the rule $f(1) \,=\, 1$, $f(\{1\}) \,=\, 1$.
    Note that the set $S \,=\, \{1\}$ is simultaneously an {\em element} of $A$ and a {\em subset} of $A$.
    Viewing $S$ as an {\em element} of $A$, one has, using the normal `$f(x)$' notation, $f(S) \,=\, 1$; viewing $S$ as a {\em subset} of $A$, one has,
    using the bracket notation, $f[S] \,=\, \{\{f(1)\}\} \,=\, \{1\}$.
    However, using parentheses for both situations leads to the confusion of writing simultaneously
    $f(S) \,=\, 1$, when $S$ is thought of as an element of~$A$, and $f(S) \,=\, \{1\}$, when $S$ is thought of as a subset of~$A$.

\V

        (2) The notation for the inverse image has, under certain circumstances, a second ambiguity.
    Indeed, if $f:A \,{\rightarrow}\, B$ is a bijection, then the symbol $f^{-1}$
    is used to denote the inverse function associated with $f$; see Definition~\Ref{DefA30.26A}.
    In this case the notation $f^{-1}[U]$ makes sense for every subset $U$ of~$B$ as the image under the function $f^{-1}$ of the subset $U$ of $B$.
    Fortunately, this set happens to be the same as the inverse image, in the sense of Part~(2) of the preceding definition,
    of the set $U$ under the original map~$f$.

\V

        (3) Some authors use the terminology `range of $f$' instead of the phrase `image of $f$' used above.
    In contrast, some other authors use the word `range' for what we refer to as `target'. For that reason, we do not use `range' in either sense in {\ThisText}.
}%EndFootnotesize
\end{quotation} 
%##

\V
\V

                        \section{New Functions from Old Functions}
                        \label{SectA35}\IndB{ZZ Sections}{\Ref{SectA35} New Functions from Old Functions}

        There are many ways of defining new functions in terms of other functions. One of the simplest is given next.

\VV


        \subsection{\small{\bf Definition}}
        \label{DefA30.127}
        

\hspace*{\parindent} (1) Suppose that $f$ is a function with domain $A$ and values in a set~$B$, as described in Definition~\Ref{DefA30.10} above.
    If $S$ is a {\em nonempty} subset of $A$, then one associates with $f$ and $S$ a new function~$g$, with domain $S$ and values in~$B$,
    called the {\bf restriction of $\Bfm{f}$ to the subset~$S$}\IndBD{functions}{restriction of a function}. It is given by the rule
        \begin{displaymath}
        g(x) \,=\, f(x) \mbox{ for all $x{\in}S$}.
        \end{displaymath}
    In this context one also refers to the function $f$ as {\bf an extension}\IndBD{functions}{extension of a function} of $g$ to the set~$A$.

\V

        (2) The standard notation for the restriction of the function $f$ to the subset $S$ is $f|_{S}$.


\VV

        {\bf Remark} We use the phrase `{\em an} extension of $g$ to the set $A$' above
    because usually $g$ can be viewed as the restriction to $S$ of a function with domain $A$ in more than one way.
    The exceptions are when $S \,=\, A$ or $B$ is a singleton set.

\VV

        The next construction appears frequently in elementary calculus, although usually in not so general form.

\V

          \subsection{\small{{\bf Definition} (Composition of Functions)}}
                  \label{DefA30.130}\IndBD{functions}{composition of functions}

        Suppose that $f:A \,{\rightarrow}\, B$ and $g:C \,{\rightarrow}\, D$ are function diagrams such that $f[A] \,{\subseteq}\, C$; that is, for each $x$ in $A$ one has $f(x){\in}C$ and thus in the domain of~$g$. 
    Then the {\bf composition of $\Bfm{g}$ with $\Bfm{f}$} is the function $g{\circ}h:A \,{\rightarrow}\, D$ gien by the rule
        \begin{displaymath}
        (g{\circ}h)(x) \,=\, g(f(x)) \mbox{ for all $x{\in}A$} \h ({\ast})
        \end{displaymath}
    In symbols: $h \,=\, g{\circ}f$; the symbol~${\circ}$ is often pronounced `of', or, sometimes, `circle' in this context.

\V

        \subsection{\small{{\bf Remarks}}}
        \label{RemrkA30.140}

\V

\hspace*{\parindent} (1) The notation `${\circ}$' for the composition $g{\circ}f$ is used to make one think of a kind of `multiplication' of the function $g$ with the function~$f$.
    In this case one refers to $g$ as the `left factor' and $f$ as the `right factor' in the expression~$g{\circ}f$.
    In contrast to the `product ${\times}$ used in the Cartesuan productThis `multiplication'

        The order in which the factors $g$ and $f$ appear in the expression $g{\circ}f$ is very important.
    Indeed, it is possible for the composition $g{\circ}f$ to be defined, while the composition $f{\circ}g$ is not.
    Even if $g{\circ}f$ and $f{\circ}g$ both make sense, they need not be equal.
    (That is, the operation of composition need not satisfy the `Commutative Law'.)
    See the examples below for illustrations of these facts.

\V

        (2) Some texts - especially those used in elementary calculus -- allow a slightly more general definition of `composition'.
    The key is the defining equation $(g{\circ}f)(x) \,=\, g(f(x))$:
    these texts allow the domain of $g{\circ}f$ to be the set of all $x$ for which this expression makes sense (provided this set is nonempty). More precisely:

\V
        \underline{Alternate Definition of Composition}:\IndC{functions}{compositions}{alternate definition}
        Suppose that $f:A \,{\rightarrow}\, B$ and $g:C \,{\rightarrow}\, D$ are function diagrams. Let $S \,=\, \{x{\in}A: f(x){\in}C\}$; that is, $S \,=\, f^{-1}[B\,{\cap}\,C]$.
    If the set $S$ is nonempty, then the composition of $g$ with $f$ is the function
    $p:S \,{\rightarrow}\, D$ given by $p(x) \,=\, g(f(x))$ for all $x{\in}S$.

\V

        In {\TheseNotes} we follow the original version given above (Definition~\Ref{DefA30.130}). However,
    most of the results concerning composition can be easily modified to work just as well with this alternate definition.

\VV

        \subsection{\small{{\bf Examples}}}
        \label{ExampA30.150}

\hspace*{\parindent}
        (1) Let $A \,=\, \{1,2,3\}$, $B \,=\, \{4,5,6\}$ and $C \,=\, \{40,50,60\}$.
    Define $f:A \,{\rightarrow}\, B$ by the rule $f(x) \,=\, x+3$ for $x{\in}A$, and define $g:B \,{\rightarrow}\, C$ by the rule $g(y) \,=\, 10y$ for $y{\in}B$.
    It is easy to see that the composition $g{\circ}f:A \,{\rightarrow}\, C$ is defined and is given by the rule
        \begin{displaymath}
        (g{\circ}f)(1) \,=\, g(1+3) \,=\, g(4) \,=\, 40; \h
        (g{\circ}f)(2) \,=\, g(2+3) \,=\, g(5) \,=\, 50; \h
        \end{displaymath}
        \begin{displaymath} 
       (g{\circ}f)(3) \,=\, g(3+3) \,=\, g(6) \,=\, 60
        \end{displaymath}

        In contrast, the expression $f{\circ}g$ does not make sense here. (Do you see why?)

\V

        (2) Let $A \,=\, \{1,2,3\}$ as before, and let $f:A \,{\rightarrow}\, A$ and $g:A \,{\rightarrow}\, A$ be given by
        \begin{displaymath}
        f(1) \,=\, 2, \h f(2) \,=\, 3, \h f(3) \,=\, 1
        \h \mbox{ and } \h
        g(1) \,=\, 1, \h g(2) \,=\, 3, \h g(3) \,=\, 2.
        \end{displaymath}
    Clearly $g{\circ}f:A \,{\rightarrow}\, A$ and $f{\circ}g:A \,{\rightarrow}\, A$ are both defined and have the same domain, namely $A$ (because $A \,=\, B \,=\, C$).
    However, one readily computes that
        \begin{displaymath}
        (g{\circ}f)(2) \,=\, g(f(2)) \,=\, g(3) \,=\, 2,
        \mbox{ while }
        (f{\circ}g)(2) \,=\, f(g(2)) \,=\, f(3) \,=\, 1.
        \end{displaymath}
    Since $g{\circ}f$ and $f{\circ}g$ do not have the same value at some point of their common domain, they cannot be the same function.

\V

        (3) The preceding example illustrates the following fact:

        \begin{displaymath}
        \mbox{the equation $g{\circ}f \,=\, f{\circ}g$ is not always correct.} \h ({\ast})
        \end{displaymath}
    \underline{Warning} Some students go on to (mis)interpret Statement~$({\ast})$ as meaning
        \begin{displaymath}
        \mbox{the equation $g{\circ}f \,=\, f{\circ}g$ is always not correct.} \h ({\ast}{\ast})
        \end{displaymath}
        - note how the word `always' has subtly shifted to the left of the `not' in the second version.
    That is, they interpret the original statement as meaning that `for all $f$ and $g$, the function $g{\circ}f$ is {\em never} equal to~$f{\circ}g$.
    This second interpretation is {\em not} what Statement~$({\ast})$ says; indeed, the phrase `not always correct' allows the possibility that the equation is `sometimes correct, sometimes incorrect'.
    This second interpretation, Statement~$({\ast}{\ast})$, is wrong.
    For instance, let $A \,=\, \{1,2,3\}$ as above,  but now let $f:A \,{\rightarrow}\, A$ and $g:A \,{\rightarrow}\, A$ be given by
        \begin{displaymath}
        f(1) \,=\, 2, \h f(2) \,=\, 3, \h f(3) \,=\, 1
        \mbox{ and }
        g(1) \,=\, 3, \h g(2) \,=\, 1, \h g(3) \,=\, 2.
        \end{displaymath} 
    The reader is invited to verify that $g{\circ}f \,=\, f{\circ}g \,=\, I_{A}$ in this case.

\V
\V


%%% 
\begin{quotation}
{\footnotesize \underline{\Note}\IndB{\notes}{on the left-to-right bias} (on the left-to-right bias)\IndBD{\notes}{left-to-right bias}:
    This is a good place to discuss a phenomenon which pervades mathematics, but is rarely mentioned;
    namely, a bias in favor of reading mathematical expressions from left to right.

\V

        {\bf Examples}


        (1) Consider the statements

        \h (a) `George Washington was the first president of the United States.'

        \h (b) `The first president of the United States was George Washington.'

\noindent Superficially, it appears that these statements contain exactly the same information and thus are interchangable; and in a sense this is correct.
    However, there is a subtle difference: Statement~(a) is `about' George Washington,
    because `George Washington' comes first, since English is read left-to-right; in contrast, Statement~(b) is `about' the office of the presidency.
    For example, Statement~(a) would be the better response to the question `Who was George Washington?',
    while Statement~(b) would be the better response to the (very different) question `Who was the first president of the United States?'

\V

        (2) Similarly, consider the inequalities $\sqrt{2}\,<\,2$ and $2\,>\,\sqrt{2}$. 
    Technically speaking, they contain exactly the same information about the relation between the numbers $2$ and~$\sqrt{2}$.
    Psychologically speaking, however, there is a subtle difference in focus: because of the left-to-right nature of written English,
    the first inequality is a statement `about' the number $\sqrt{2}$ -- written as an English sentence, it says `the square root of $2$ is less than~$2$';
    while the second is a statement `about' the number~$2$, namely `$2$ is greater than~$\sqrt{2}$'.
    It is possible that mathematicians felt the need to introduce {\em two} symbols for essentially the same idea,
    namely $\,<\,$ and $\,>\,$, in order to allow symbolically for this subtle difference of focus.
    Similar remarks can be made concerning the `duplicative' notations $ \,{\subseteq}\, $ and $ \,{\supseteq}\, $.

\V

        (3) Sometimes mathematicians need to be a little devious to write down exactly what they mean.
    For instance, the (compound) inequality $1\,<\,\sqrt{2}\,<\,2$ has the same mathematical content as the sentence `$\sqrt{2}$ is between $1$ and $2$';
    but the sentence form makes it clearer that the object of interest is the square root.
    In contrast, the symbolic form is really an abbreviation of the pair of inequalities $1\,<\,\sqrt{2}$ and $\sqrt{2}\,<\,2$.
    The first `about' the number~$1$, because we read `$1$' first; likewise, the second is `about' the number~$\sqrt{2}$.
    Some mathematicians get around this, while still using symbolism, by writing $\sqrt{2}\,{\in}\,(1,2)$,
    to emphasize the fact that desired (compound) statement is `about' the number~$\sqrt{2}$.
    Of course this formulation requires the reader to decode the `member of' symbol ${\in}$ and the `open interval' notation $(1,2)$.

        Note that the ambiguity in the `focus' illustrated here does not disappear by simply replacing $\,<\,$ with~$\,>\,$.

\V

        (4) The `left-to-right' bias appears in equations. For instance, the so-called Quadratic Formula, from elementary algebra, for the solutions of equations of the form $ax^{2}+bx+c \,=\, 0$, is always written
        \begin{displaymath}
        x \,=\, \frac{-b  \,{\pm}\, \sqrt{b^{2} - 4a\,c}}{2\,a},
        \end{displaymath}
    never
        \begin{displaymath}
        \frac{-b  \,{\pm}\, \sqrt{b^{2} - 4a\,c}}{2\,a} \,=\, x,
        \end{displaymath}
    even though the equations have the same content. The first equation tells us,
    because of the left-to-right bias, that the equation is `about' the unknown~$x$.

\V

        (5) Sometimes the `left-to-right' bias causes true difficulties. For instance,
    in multivariable calculus one encounters expressions such as ${\displaystyle \frac{{\partial}^{2}z}{{\partial}y{\partial}x}}$.
    If one asks students to carry out the partial derivatives `in the order indicated',
    many will do the $y$-derivative first, because it appears on the left.
    Of course, the notation really means that the $x$-differentiation should be carried out first.
    It is fortunate for such students that normally `mixed partials are equal'.

        Incidently, notice that the widely-used `subscript' notation for partial derivatives is in accordance with the `left-to-right' bias, and thus does not share this problem:
        \begin{displaymath}
        \frac{{\partial}^{2}z}{{\partial}y{\partial}x} \,=\, z_{xy}
        \end{displaymath}

\V

        (6) A similar problem occurs with the definition of `composition'. Thus, consider functions $A \stackrel{f}{ \,{\rightarrow}\, }B$ and $B  \stackrel{g}{ \,{\rightarrow}\, }C$.
    The use of the `right arrow' $ \,{\rightarrow}\, $ here reflects the `left-to-right' bias;
    indeed, one rarely encounters the notation $B \stackrel{f}{ \,{\leftarrow}\, }A$.
    It becomes even clearer if one writes the corresponding function diagram
        \begin{displaymath}
       A \stackrel{f}{ \,{\rightarrow}\, } B \stackrel{g}{ \,{\rightarrow}\, } C
        \end{displaymath}
    Many students look at this and then write the corresponding composition as $f{\circ}g$,
    to match the `left-to-right' order seen above, instead of the (correct) order $g{\circ}f$.
    Unlike the `mixed partials' situation described in the preceding example, however,
    the error here is much more serious, since usually it is {\em not} the case that $f{\circ}g \,=\, g{\circ}f$.
}%EndFootnotesize
\end{quotation} 
%##

\VV

        \subsection{\small{{\bf Theorem (Basic Facts about Composition)}}}
        \label{ThmA30.160}

\hspace*{\parindent}
        (a) Let $f:A \,{\rightarrow}\, B$ be a map with domain $A$.
    Then the compositions $f{\circ}I_{A}$ and $I_{B}{\circ}f$ are both defined, and
        \begin{displaymath}
        f{\circ}I_{A} \,=\, I_{B}{\circ}f \,=\, f.
        \end{displaymath}
    (The symbols $I_{A}$ and $I_{B}$ denote the identity functions on the sets $A$ and $B$, respectively.)

\V

        (b) Let $f:A \,{\rightarrow}\, B$, $g:B \,{\rightarrow}\, C$, and $h:C \,{\rightarrow}\, D$ be maps with domains $A$, $B$ and $C$, respectively.
    Then the compositions $(h{\circ}g){\circ}f:A \,{\rightarrow}\, D$ and $h{\circ}(g{\circ}f):A \,{\rightarrow}\, D$ are both defined, and they are equal:
        \begin{displaymath}
        (h{\circ}g){\circ}f \,=\, h{\circ}(g{\circ}f).
        \end{displaymath}
    Stated briefly: `The Associative Law for Composition is valid'.

\V

        (c) Suppose that $f:A \,{\rightarrow}\, B$ is a bijection, and let $f^{-1}:B \,{\rightarrow}\, A$ be the inverse map; see Definition~\Ref{DefA30.26A}.
    Then $f^{-1}{\circ}f \,=\, I_{A}$ and $f{\circ}f^{-1} \,=\, I_{B}$.

\V

        (d) A necessary and sufficient condition for a map $f:A \,{\rightarrow}\, B$ to be a bijection from $A$ onto $B$ is that there exist maps $g:B \,{\rightarrow}\, A$ and $h:B \,{\rightarrow}\, A$ such that
        \begin{displaymath}
        g{\circ}f \,=\, I_{A} \mbox{ and } f{\circ}h \,=\, I_{B}.
        \end{displaymath}
    If such maps $g$ and $h$ exist, then $g \,=\, h \,=\, f^{-1}$.

\V

        (e) If $f:A \,{\rightarrow}\, B$ and $g:B \,{\rightarrow}\, C$ are bijections from $A$ onto $B$ and from $B$ onto $C$, respectively,
    then their composition $g{\circ}f:A \,{\rightarrow}\, C$ is a bijection from $A$ onto $C$.
    Furthermore, the inverse map $(g{\circ}f)^{-1}:C \,{\rightarrow}\, A$ is given by the formula
        \begin{displaymath}
        (g{\circ}f)^{-1} \,=\, f^{-1}{\circ}g^{-1}.
        \end{displaymath}


\V
\V

        {\bf Partial Proof}:

    (a) The reader should be able to do this.

\V

        (b) The fact that both compositions are defined, and both have domain $A$ and have values in $C$,
    follows directly from the definition of `composition'.
    To see that the equation is satisfied, note first that if $x$ is in $A$ then
        \begin{displaymath}
        ((h{\circ}g){\circ}f)(x) \stackrel{(1)}{ \,=\, } (h{\circ}g)(f(x)) \stackrel{(2)}{ \,=\, } 
    h(g(f(x)))  \stackrel{(3)}{ \,=\, } h((g{\circ}f)(x))
     \stackrel{(4)}{ \,=\, } (h{\circ}(g{\circ}f))(x).
        \end{displaymath}
    Indeed, Equation~(1) follows from the definition of the composition $p{\circ}f$, where $p \,=\, h{\circ}g$.
    Likewise, Equation~(2) reflects the definition of $h{\circ}g$, Equation~(3) uses the definition of $g{\circ}f$, and Equation~(4) comes from the definition of $h{\circ}q$ where $q \,=\, g{\circ}f$.
    Thus the maps $(h{\circ}g){\circ}f$ and $h{\circ}(g{\circ}f)$ not only have the same domain, but they also assume the same value as each other for each point of that domain.
    In other words, they are the same map, as claimed.

\V


        (c) The simple proof is left as an exercise.

\V

        (d) \underline{The `Sufficient' Part of (d)}: Suppose that maps $g$ and $h$ with the indicated properties exist.

       \h (i) Since $g{\circ}f \,=\, I_{A}$, it follows that $f$ is one-to-one on $A$.
    Indeed, suppose that $x_{1}$ and $x_{2}$ are points of $A$ such that $f(x_{1}) \,=\, f(x_{2})$.
	Apply the function $g$ to each side of this last equation to get $g(f(x_{1})) \,=\, g(f(x_{2}))$.
    From the definitions of `composition' and `identity map',  plus the hypothesis $g{\circ}f \,=\, I_{A}$, one then sees that
        \begin{displaymath}
        x_{1} \,=\, I_{A}(x_{1}) \,=\, (g{\circ}f)(x_{1}) \,=\, g(f(x_{1})) \,=\, g(f(x_{2})) \,=\, (g{\circ}f)(x_{2}) \,=\, I_{A}(x_{2}) \,=\, x_{2}.
        \end{displaymath}
    That is, if $f(x_{1}) \,=\, f(x_{2})$ then $x_{1} \,=\, x_{2}$, which means that $f$ is one-to-one, as claimed.

        \h (ii) Since $f{\circ}h \,=\, I_{B}$ it follows that $f$ maps $A$ {\em onto} $B$.
    Indeed, let $y$ be any element of $B$, and note that
        \begin{displaymath}
        y \stackrel{(1)}{ \,=\, } I_{B}(y) \stackrel{(2)}{ \,=\, } (f{\circ}h)(y) \stackrel{(3)}{ \,=\, } 
    f(h(y)).
        \end{displaymath}
    Equation~(1) simply repeats the definition of the identity map $I_{B}$; Equation~(2) restates the hypothesis $f{\circ}h \,=\, I_{B}$;
    Equation~(3) uses the definition of `composition'.
    In any event, one now has $y \,=\, f(x)$ for at least one $x{\in}A$, namely $x \,=\, h(y)$.
    It follows that $f$ is a surjection of $A$ onto $B$.%

        Since, as has just been shown, $f$ is maps $A$ one-to-one onto $B$, it follows that $f$ is a bijection, as claimed.
    To see that $g \,=\, h \,=\, f^{-1}$,
 note first that the equation $g{\circ}f \,=\, I_{A}$ implies
        \begin{displaymath}
        f^{-1} \stackrel{(1)}{ \,=\, }  I_{A}{\circ}f^{-1} \stackrel{(2)}{ \,=\, } 
    (g{\circ}f){\circ}f^{-1} \stackrel{(3)}{ \,=\, } 
    g{\circ}(f{\circ}f^{-1}) \stackrel{(4)}{ \,=\, } 
    g{\circ}I_{B} \stackrel{(5)}{ \,=\, } 
    g,
        \end{displaymath}
    so that $g \,=\, f^{-1}$, as claimed.
    Indeed, Equation~(1) follows from Part~(a) of this theorem, Equation~(2) uses the hypothesis about $g$, Equation~(3) uses the `Associative Law for Composition',
    Equation~(4) uses the results of Part~(c) of this theorem, and Equation~(5) uses Part~(a) of this theorem again.

        A similar argument shows that $h \,=\, f^{-1}$.


        \underline{The `Necessary' Part of (d)}: If $f$ is a bijection, simply set $g \,=\, h \,=\, f^{-1}$.
    The fact that $g$ and $h$ have the desired properties follows easily from the results of Part~(c) of this theorem.

\V

        (e) This result can be easily proved directly from the definitions of the various concepts which appear in it;
    the reader is encouraged to carry out such a proof.

\VV

        It frequently happens that the most convenient way to describe a function is in terms of its restrictions
    (in the sense of Definition~\Ref{DefA30.127}) to a suitable family of subsets of its domain.
    The next result makes this precise.

\V

        \subsection{\small{{\bf Theorem} (The Union-of-Functions Theorem)}}
        \label{ThmA30.27}\IndBD{functions}{union of functions theorem}

        Let $A$ and $B$ be nonempty sets, and let ${\cal S}$ be a family of nonempty subsets of $A$ whose union is~$A$.
    For each set $S$ in the family ${\cal S}$ let $f_{S}:S \,{\rightarrow}\, B$ be a function with domain $S$ and with values in $B$.
    Let ${\cal F} \,=\, \{f_{S}: S{\in}{\cal S}\}$ be the corresponding family of functions.
    Then a necessary and sufficient condition for there to exist a function $g:A \,{\rightarrow}\, B$
    such that for each $S$ in ${\cal S}$ one has $f_{S} \,=\, g|_{S}$ is the following {\bf consistency condition}:

\VA
        \h If $S_{1}$ and $S_{2}$ are elements of ${\cal S}$ such that $S_{1} \,\,{\neq}\,\, S_{2}$ and $S_{1}\,{\cap}\,S_{2} \,\,{\neq}\,\, {\emptyset}$,
    then $f_{S_{1}}(x) \,=\, f_{S_{2}}(x)$ for all $x$ in $S_{1}\,{\cap}\,S_{2}$.

\VA

\noindent When this consistency condition is satisfied, the resulting function $g$ is unique;
    more precisely, $g$ is the union of the family ${\cal F}$.
    (Recall that, by definition, $g$ is a subset of $A{\times}B$ while each $f_{S}$ is a subset of $S{\times}B \,{\subseteq}\, A{\times}B$, so this union makes sense.)

\V

         The simple proof is left as an exercise.

%% ASSIGN AN EXERCISE

\V

        \subsection{\small{{\bf Definition}}}
        \label{DefA30.28}

        The function $g$ obtained above is called the {\bf union of the functions in the family $\Bfm{{\cal F}}$}\IndBD{functions}{union of functions}.

\V
\V

        {\bf Remark} The name `Union-of-Functions Theorem' for this result is not standard.

\V


        \subsection{\small{{\bf Examples of Functions Described as Unions}}}
        \label{ExampA30.29}

\V

\hspace*{\parindent}(1) The function $g:{\RR} \,{\rightarrow}\, {\RR}$ given by  the rule
        \begin{displaymath}
        g(x) \,=\, 
        \left\{
        \begin{array}{rl}
        x & \mbox{if $x\,\,{\geq}\,\,0$} \\
       -x & \mbox{if $x\,\,{\leq}\,\,0$}
        \end{array}
                    \right.
        \end{displaymath}
    is called  the {\bf Absolute-Value Function}; the corresponding quantity $g(x)$ is usually denoted by the symbol $|x|$,
    although many computer languages and programs (e.g., spreadsheets) use the notation $\mbox{abs}\,(x)$ instead.

    \underline{Note} The construction of this function is of the type described in the preceding theorem.
    Indeed, let $S_{1} \,=\, \{x{\in}{\RR}: x\,\,{\geq}\,\,0\}$ and $S_{2} \,=\, \{x{\in}{\RR}: x\,\,{\leq}\,\,0\}$,
    and define $f_{S_{1}}:S_{1} \,{\rightarrow}\, {\RR}$ and $f_{S_{2}}:S_{2} \,{\rightarrow}\, {\RR}$ by the rules
        \begin{displaymath}
        f_{S_{1}}(x) \,=\,  x \mbox{ for all $x{\in}S_{1}$}, \h
        f_{S_{2}}(x) \,=\, -x \mbox{ for all $x{\in}S_{2}$}
        \end{displaymath}
    Note that $S_{1}\,{\cap}\,S_{2} \,=\, \{0\}$ and that $f_{S_{1}}(0) \,=\, f_{S_{2}}(0) \,=\, 0$,
    so the preceding result applies with ${\cal S} \,=\, \{S_{1},S_{2}\}$ and ${\cal F} \,=\, \{f_{S_{1}},f_{S_{2}}\}$ to get the function $g \,=\, \mbox{abs}$.

        Of course, this is not the only way to express the function $g$ as the union of simpler functions.
    For instance one could chose instead $S_{1} \,=\, \{x{\in}{\RR}: x\,>\,0$, $S_{2} \,=\, \{x{\in}{\RR}: x\,<\,0\}$ and $S_{3} \,=\, \{0\}$;
    now define $f_{S_{j}}:S_{j} \,{\rightarrow}\, {\RR}$, for $j \,=\, 1,2,3$, by
        \begin{displaymath}
        f_{S_{1}}(x) \,=\,  x \mbox{ for $x{\in}S_{1}$}, \h
        f_{S_{2}}(x) \,=\, -x \mbox{ for $x{\in}S_{2}$}, \h
        f_{S_{3}}(0) \,=\, 0.
        \end{displaymath}
    The corresponding family ${\cal S} \,=\, \{S_{1}, S_{2}, S_{3}\}$ automatically satisfies the consistency condition since,
    in this case $S_{i}\,{\cap}\,S_{j} \,\,{\neq}\,\, {\emptyset}$ only when $i \,=\, j$.

        {\bf Remark} It would have been slightly simpler to use the notation $f_{j}$ instead of $f_{S_{j}}$.
    Henceforth we shall normally make such simplifications when they cannot cause confusion.

\V


        (2) The Dirichlet function $F_{\mbox{Diri}}$ (see Example~\Ref{ExampA30.25}~(3) above) is the union of two constant functions.
    More precisely, let $S_{1}$ be the set of all rational numbers and let $S_{2}$ be the set of all irrational numbers.
    Define $f_{1}:S_{1} \,{\rightarrow}\, {\RR}$ to be the constant function on $S_{1}$ with value~$1$,
    and let $f_{2}:S_{2} \,{\rightarrow}\, {\RR}$ be the constant function on $S_{2}$ of value~$0$.
    Then $F_{\mbox{Diri}}$ is the union (in the sense of Definition~\Ref{DefA30.28}) of $f_{1}$ and $f_{2}$.
    (Note that $S_{1}\,{\cap}\,S_{2} \,=\, {\emptyset}$, so the consistency condition is automatically satisfied.)

\V

        (3) Let $I \,=\, [a,b]$ be a closed interval in ${\RR}$. For some $m$ in ${\NN}$ let
    $P_{0} \,=\, (a_{0},b_{0})$, $P_{1} \,=\, (a_{1},b_{1})$,\,{\ldots}\,$P_{m-1} \,=\, (a_{m-1},b_{m-1})$, $P_{m} \,=\, (a_{m},b_{m})$
    be points in ${\RR}{\times}{\RR}$ such that  $a \,=\, a_{0}\,<\,a_{1}\,<\,a_{2}\,<\,\,{\ldots}\,\,<\,a_{m} \,=\, b$.
    For each $j \,=\, 0,\,{\ldots}\,,m-1$ let $S_{j} \,=\, [a_{j},a_{j+1}]$.
    Now define $g_{j}:S_{j} \,{\rightarrow}\, {\RR}$ to be the linear interpolation between $P_{j}$ and $P_{j+1}$ (see Example~\Ref{ExampA30.25}~(4)).
    It is easy to verify that the family ${\cal G} \,=\, \{g_{1},g_{2},\,{\ldots}\,g_{k}\}$ satisfies the consistency condition, so that the union of these functions is also a function; call it~$g$.
    The function $g$ is called the {\bf piecewise-linear interpolation
\IndBD{functions}{piecewise-linear interpolation}
through the points $\Bfm{P}_{0}$, $\Bfm{P}_{1}$,\,{\ldots}\,$\Bfm{P}_{m}$}.

        \underline{Special Case}: Suppose that $f:[a,b] \,{\rightarrow}\, {\RR}$ is a real-valued function with domain $[a,b]$,
    and that the numbers $b_{0}$, $b_{1}$m\,{\ldots}\,$b_{m}$ above satisfy $b_{j} \,=\, f(a_{j})$ for each $j \,=\, 0,1,\,{\ldots}\,m$;
    that is, $P_{j} \,=\, (a_{j}, f(a_{j}))$. Then one calls the corresponding piecewise-linear function $g$
    described as above a {\bf piecewise-linear interpolant of the function~$\Bfm{f}$}.

        The $m+1$ points $a_{0}$, $a_{1}$,\,{\ldots}\,$P_{m}$ described above the {\bf nodes}\IndC{functions}{piecewise-linear interpolation}{nodes} 
    associated with this interpolation construction. These nodes are said to be {\bf equally spaced}
    provided the differences $a_{1}-a_{0}$, $a_{2}-a_{1}$,\,{\ldots}\,$a_{m}-a_{m-1}$ are equal;
    more precisely, provided $a_{j+1}-a_{j} \,=\, (b-a)/m$ for each $j \,=\, 0,1,\,{\ldots}\,m-1$.

        {\bf Remarks} (1) Suppose that $f:[a,b] \,{\rightarrow}\, {\RR}$ is a real-valued function with domain~$[a,b]$.
    Then it is an easy exercise to show that for each $m$ in ${\NN}$ there is exactly one piecewise-linear interpolant
    of $f$ on $[a,b]$ having exactly $m+1$ equally spaced nodes.
%% EXERCISE

\V
\V

        We finish this section by discussing briefly the functions of main interest in real analysis, namely functions {\bf real-valued functions};
    that is, functions $f:X \,{\rightarrow}\, {\RR}$ from some domain $X$ (which need not be part of ${\RR}$) with values in ${\RR}$.
    The special nature of the target ${\RR}$  allows these functions to be combined algebraically to form new functions.

\V

        \subsection{\small{{\bf Definition}}}
        \label{DefA30.200}

        Let $f:X_{1} \,{\rightarrow}\, {\RR}$ and $g:X_{2} \,{\rightarrow}\, {\RR}$ be real-valued functions whose domains are the sets $X_{1}$ and $X_{2}$, respectively.
    Let $X_{3} \,=\, X_{1}\,{\cap}\,X_{2}$, and assume that $X_{3} \,\,{\neq}\,\, {\emptyset}$.

\V

        (1) The {\bf sum of $\Bfm{f}$ and $\Bfm{g}$} is the function $f+g:X_{3} \,{\rightarrow}\, {\RR}$ given by the rule
        \begin{displaymath}
        (f+g)(x) \,=\, f(x)+g(x) \mbox{ for all $x$ in $X_{3}$}.
        \end{displaymath}
    Similarly, the {\bf difference of $\Bfm{f}$ and $\Bfm{g}$} is the function $f-g:X_{3} \,{\rightarrow}\, {\RR}$ given by the rule
        \begin{displaymath}
        (f-g)(x) \,=\, f(x) - g(x) \mbox{ for all $x$ in $X_{3}$}.
        \end{displaymath}

\V

        (2) The {\bf product of $\Bfm{f}$ and $g$} is the function $f{\cdot}g:X_{3} \,{\rightarrow}\, {\RR}$ given by the rule
        \begin{displaymath}
        (f{\cdot}g)(x) \,=\, (f(x)){\cdot}(g(x)) \mbox{ for all $x$ in $X_{3}$}
        \end{displaymath}
\V
        (3) Let $X_{4}$ be the set of all points $x$ in $X_{3}$ at which $g(x) \,\,{\neq}\,\, 0$, and assume $X_{4} \,\,{\neq}\,\, {\emptyset}$.
    Then the {\bf quotient of $\Bfm{f}$ by $\Bfm{g}$} is the function $f/g:X_{4} \,{\rightarrow}\, {\RR}$ given by the rule
        \begin{displaymath}
        \left(\frac{f}{g}\right)(x) \,=\, \frac{f(x)}{g(x)} \mbox{ for all $x$ in $X_{4}$}.
        \end{displaymath}


\StartSkip{
        In addition to the real-valued functions discussed above, the following type of function, often non-real valued, is of importance.

\V

        \subsection{\small{{\bf Definition ($k$-tuples)}}}
        \label{DefA30.30}

        Let $X$ be a nonempty set and let $k$ be a natural number.

        (1) A {\bf  $\Bfm{k}$-tuple in $\Bfm{X}$}\IndBD{tuples}{$k$-tuples} is a function with domain ${\NN}_{k}$ and values in $X$.
    (Recall that ${\NN}_{k}$ denotes the set of all $j$ in ${\NN}$ such that $1\,\,{\leq}\,\,j\,\,{\leq}\,\,k$.)
    The set of all $k$-tuples in $X$ is denoted by~$X^{k}$. This set is called the {\bf \Bfm{k}-fold Cartesian product of~$\Bfm{X}$}
    \IndBD{Cartesian products}{$k$-fold}

\V

        (2) If $g:{\NN}_{k} \,{\rightarrow}\, X$ is a $k$-tuple in~$X$, so that in accordance with Definition~\Ref{DefA30.10} above $g$ is the set
    $\{(1,g(1)), (2,g(2)),\,{\ldots}\,(k,g(k))\}$, one normally writes $g$ more informally
    (and more briefly) as the ordered list $(g(1), g(2),\,{\ldots}\,g(k))$.

\V

        (3) A {\bf tuple in \Bfm{X}} is an object which is a member of $X^{k}$ for some $k$ in ${\NN}$.

\V

        (4) Suppose that $X_{1}$, $X_{2}$,\,{\ldots}\,$X_{k}$ are nonempty subsets of the given set~$X$.
    Then $X_{1}{\times}X_{2}{\times}\,{\ldots}\,{\times}X_{k}$ is the set of  all the $k$-tuples
    $g:{\NN}_{k} \,{\rightarrow}\, X$ in $X^{k}$ such that $g(j){\in}X_{j}$ for each $j$ in~${\NN}_{k}$.

        If any of the sets $X_{j}$, $1\,\,{\leq}\,\,j\,\,{\leq}\,\,k$, is empty, then one sets $X_{1}{\times}\,{\ldots}\,X_{k}$ equal to the empty set.

\VV

        \underline{Remarks} (1) Note that a $2$-tuple in~$X$, as given by the preceding definition,
    is {\em not} an ordered pair in~$X$ as described as a `primitive concept'  in Section~\Ref{SectA12} above.
    Indeed, if $g:{\NN}_{2} \,{\rightarrow}\, X$ is a $2$-tuple, the notation given in the preceding definition uses the abbreviation
    $g \,=\, (g(1),g(2))$ in place of the more correct $g \,=\, \{(1,g(1)), (2,g(2))\}$.
    That is, this notation identifies the $2$-tuple $g \,=\, \{(1,g(1)), (2,g(2))\}$ with the `primitive' ordered pair $(g(1),g(2))$.
    Using this conventional identification does not appear to cause any difficulties, and it is certainly convenient.
    Henceforth we follow this convention, of identifying (primitive) ordered pairs and $2$-tuples without further comment.


\V

        (2) The case $k \,=\, 1$ is also special. Indeed, the elements of $X^{1}$ are, by definition of `function from ${\NN}_{1}$ to $X$',
    precisely the (singleton) sets of ordered pairs of the form $\{(1,c)\}$ with $c$ in~$X$.
    Because of this, it is conventional to identify the set $X^{1}$ with the set $X$ itself.
    We normally observe this convention as well in {\TheseNotes}.

\V

        (3) As mentioned in the preceding definition, the usual convention is to write a $k$-tuple $g:{\NN}_{k} \,{\rightarrow}\, X$ as an `ordered list':
        \begin{displaymath}
        g \,=\, (g(1),g(2),\,{\ldots}\,g(k))
        \end{displaymath}
    Indeed, because of this many authors refer to `{\em ordered} $k$-tuples' instead of the briefer `$k$-tuples'.
    We use both terminologies interchangeably in {\ThisText}.
    (Note that in certain branches of mathematics one also finds the notion of {\em un}ordered tuples. We never have reason to consider that concept here.)

\V

        (4) The (primitive) concept of an `ordered list' is even older than that of `function',
    and the convention for such lists is to use subscripts instead of `function values'. Thus, one might write
        \begin{displaymath}
        g \,=\, (g_{1},g_{2},\,{\ldots}\,g_{k}),
        \end{displaymath}
    where $g_{j}$ is an alternate notation for $g(j)$. Even more likely, however, would be to introduce subscripted letters;
    for instance, one might set $y_{j} \,=\, g(j)$ for each $j$ in ${\NN}_{k}$, and then write
        \begin{displaymath}
        g \,=\, (y_{1},y_{2},\,{\ldots}\,y_{k}).
        \end{displaymath}
    Once again, in {\TheseNotes} we generally bow to custom and use such subscripted variables.
    Note, however, that this notation can cause confusion. For instance, consider a $4$-tuple $h$ given as the followed ordered list:
        \begin{displaymath}
        h \,=\, (y_{1},y_{3},y_{4}, y_{2}).
        \end{displaymath}
    In this case the subscripts do not accurately describe the underlying function $h:{\NN}_{4} \,{\rightarrow}\, X$.
    Indeed, from the `ordered list' conventions, one has
        \begin{displaymath}
        h(1) \,=\, y_{1}, \h h(2) \,=\, y_{3}, \h h(3) \,=\, y_{4}, \h h(4) \,=\, y_{2}.
        \end{displaymath}

\V

        (5) Of particular importance for multivariable real analysis are the $k$-tuples $g:{\NN}_{k} \,{\rightarrow}\, X$ for which the target space $X \,=\, {\RR}$; that is, {\em real}-valued tuples
    In this case one refers to the corresponding set ${\RR}^{k}$, whose elements are the ordered $k$-tuples of real numbers,
    as the {\bf Euclidean space of dimension $\Bfm{k}$}.
    Such $k$-tuples are often called {\bf $\Bfm{k}$-dimensional vectors}, and many texts use a special notation involving bold-face letters or an `arrow' notation to visually inform the reader of the nature of these objects.


\V

        (6) Readers familiar with linear algebra or matrix theory will recall that if $A$ is an $m$-by-$n$ matrix of real numbers,
    then $A$ determines a function $T_{A}:{\RR}^{n} \,{\rightarrow}\, {\RR}^{m}$ by the rule
        \begin{displaymath}
        T_{A}(\Vect{x}) \,=\, A{\cdot}\Vect{x} \mbox{ for all vectors $\Vect{x}$ in ${\RR}^{n}$}.
        \end{displaymath}
    In this expression, the $n$-dimensional vector $\Vect{x}$ is thought of as an $n$-by-$1$ matrix (i.e., a column vector),
    and the `dot' denotes the standard `multiplication of  matrices'; the `output' $\Vect{y} \,=\, A{\cdot}\Vect{x}$ is an $m$-dimensional vector.
    One calls the resulting function $T_{A}$ the {\bf linear transformation determined by $\Bfm{A}$}\IndC{functions}{special functions}{linear transformations}.


\V
\V

%%% 
\begin{quotation}
{\footnotesize \underline{\Notes} (on the `tuples' terminology)\IndB{\notes}{on the `tuples' terminology}:

\V

        The use of the ending `tuple' in `$n$-tuple' comes from ordinary English, where analogous words are `singlet' `doublet', triplet', `quadruple', `quintuple', `sextuple', `septuple', and so on;
    the `tuple' is the `generic' ending for such formations once the first few cases are passed.

        Even within mathematics the standard usage is different for small values of $n$.
    For example, an ordered $2$-tuple is normally referred to as `an ordered pair', and an ordered $3$-tuple is usually called `an ordered triple.'

}%EndFootnotesize
\end{quotation} 
%##
}%\EndSkip

\V
\V
 
\StartSkip{
%%% 
\begin{quotation}
{\footnotesize \underline{\Note} (on sketchy proofs)\IndB{\notes}{on sketchy proofs}: The careful reader has noticed that at various places in {\TheseNotes} some claims are made without a proof being provided, or with perhaps just a sketchy proof;
    for instance, in Example~(7) above it is claimed that $Q^{-1}(Y) \,=\, A{\times}Y$.
    Such omissions are very common in mathematical writing, and the reason is mainly educational:
    Examples are usually provided so the reader can better understand some definition or theorem under discussion;
    but the real understanding comes by the reader working out the omitted details so the reader can understand how the example does, in fact, illustrate the issue in question.
    Likewise, if an author omits some steps in a proof, then the reader is expected to work out those details. Doing so increases understanding.

    (There is an old saying in mathematics: `One should read a math text with paper and pencil in hand to fill in the missing steps.'
    Or, as is expressed in another old saying: `A math book is not a novel.')
}%EndFootnotesize
\end{quotation} 
%##
}%\EndSkip

\StartSkip{

\V
\V

        Let us return to the general theory of functions.

        \subsection{\small{{\bf Definition}}}
        \label{DefA30.40}

        Suppose that $f$ is a function with domain $A$ and whose values lie in $B$. Let $S$ be a nonempty subset of $A$.

\V

        \index{injection}\IndD{one-to-one}{injection}(a) One says that the map $f$ is {\bf one-to-one on $\Bfm{S}$}, or that $f$ is {\bf injective on $\Bfm{S}$},
    provided that for every pair of elements $x_{1}$ and $x_{2}$ in $S$ such that $x_{1} \,{\neq}\, x_{2}$ one has $f(x_{1}) \,{\neq}\, f(x_{2})$;
    equivalently, provided that for $x_{1}$ and $x_{2}$ in $S$ the equation $f(x_{1}) \,=\, f(x_{2})$ implies the equation $x_{1} \,=\, x_{2}$.

        If $f$ is injective on its full domain $A$, then one says that $f$ is a {\bf one-to-one map} or that $f$ is an {\bf injection}.

\V

        \index{surjection}\IndD{onto}{surjection}(b) Let $T$ be a subset of the target set $B$.
    One says that $f$ maps $S$ {\bf onto $\Bfm{T}$}, or that $f$ is a {\bf surjection of $\Bfm{S}$ onto $\Bfm{T}$} provided $f[S] \,=\, T$;
    equivalently, provided that for every $y{\in}T$ there exists at least one $x{\in}S$ such that $f(x) \,=\, y$.


\V

        \index{bijections}(c) Suppose that $f$, $S$ and $T$ are as above, and suppose that $f$ is both one-to-one on $S$ {\em and} $f$ maps $S$ onto $T$.
    Then one says that {\bf $\Bfm{f}$ maps $\Bfm{S}$ bijectively onto $\Bfm{T}$}, or that {\bf $\Bfm{f}$ is a bijection from $\Bfm{S}$ onto $\Bfm{T}$}.
    (Intuitively speaking: `{\bf bi}jection' = `{\bf in}jection' + `{\bf sur}jection';
    the `bi' in `bijection' of course refers to the fact that it involves the two types of `jections'.)

\V

        \subsection{\small{{\bf Remark}}}
        \label{RemrkA30.45}

        It is common in certain contexts to refer to, say, `the surjection $f:S \,{\rightarrow}\, T$', or `the bijection $f:S \,{\rightarrow}\, T$'.
    In such contexts it should be understood that a particular target set, $T$, is singled out,
    and that it would be improper to replace $T$ in such a context by a proper superset.

\V
\V

        \subsection{\small{{\bf Examples}}}
        \label{ExampA30.50}

\V

\hspace*{\parindent}
        (1) Let $f:{\RR} \,{\rightarrow}\, {\RR}$ be the real-valued function, with domain ${\RR}$,
    given by the rule $f(x) \,=\, {\sin}\,x$ for all $x{\in}{\RR}$; thus, $f$ is the standard `sine' function from freshman calculus.
    It is clear from basic trigonometry that the function $f$ is not one-to-one;
    that is, it is not injective.
    For example, one knows that $f(0) \,=\, f(2{\pi}) \,=\, 0$, so the function $f$ cannot be injective.

        It is equally clear that $f$ does not map the domain ${\RR}$ onto the target set ${\RR}$.
    Indeed, it is well known that the inequalities $-1\,{\leq}\,{\sin}\,x\,{\leq}\,1$ hold for all $x{\in}{\RR}$; thus, for instance, the number $2$ is not in $f[{\RR}]$.

\V

        (2) Let $B$ be the set of all real numbers $y$ such that $-1\,{\leq}\,y\,{\leq}\,1$,
    and let $g:{\RR} \,{\rightarrow}\, B$ be the function, with domain ${\RR}$, given by the rule $g(x) \,=\, {\sin}\,x$.
    It is clear that this function $g$ is the same as the function $f$ in the preceding example: They have the same domain and the same `formula'.
    It is also clear that $g$ is {\em not} one-to-one; the same proof as above works here.
    In contrast to the results in the preceding example, however, it follows from well-known trig facts that the function $g$ {\em does} map ${\RR}$ onto the target space $B$.

\V

\underline{Remark}: The results of these first two examples illustrate the fact that the use of the words `onto' and `surjection' (and thus the word `bijection') makes sense only if the `target space' is specified;
    the same function may fail to be `surjective' with one choice of target, and be `surjective' with another.
    In many math texts the reader is expected to pick out from the context which target set the text's author has in mind.

\V

        (3) Let $A$ be the set of all real numbers $x$ such that $-{\pi}/2\,{\leq}\,x\,{\leq}\,{\pi}/2$,
    and let $h:A \,{\rightarrow}\, {\RR}$ be the function with domain $A$ given by the rule $h(x) \,=\, {\sin}\,x$ for all $x{\in}A$.
    Thus, $h \,=\, f|_{A}$, where $f:{\RR} \,{\rightarrow}\, {\RR}$ is the function discussed in Example~(1) above.
    It is shown in calculus that the function $h$ is one-to-one.
    Of course it is {\em not} a surjection onto ${\RR}$, but it {\em is} a surjection onto the set $B$ in Example~(2).

}%\EndSkip

\VV

\StartSkip{
        The next results could be thought of as simply more example of bijections, but they are important enough to deserve separate treatment.

\V

        \subsection{\small{{\bf Theorem}}}
        \label{ThmA30.55}

\V

        Let $A$ and $B$ be nonempty sets. Then $A$ has the same cardinality as~$B$,
    in the sense of Definition~\Ref{DefA12.70}, if, and only if, there exists a bijection of $A$ onto~$B$.


        {\bf Proof} Suppose that $F$ is a complete pairing of $A$ with $B$.
    Then $F$ is a bijection of the set $A$ onto the set $B$.
    Indeed, Pairing Condition~(i) of Definition~\Ref{DefA12.70} is simply the statement that $F$ is a function with domain $A$ and values in $B$,
    in the sense of Definition~\Ref{DefA30.10}.
    Moreover, the statement that an ordered pair $(a,b)$ is an element of $F$ means, in the usual function notation, that $b \,=\, F(a)$.


        Likewise, Pairing Condition~(ii) can be reformulated as two statements about the function $F$:

       \h For every $b$ in $B$ there is {\em at least one} $a$ in $A$ such that $F(a) \,=\, b$; that is, the function $F$ maps $A$ {\em onto} $B$;

        \h For every $b$ in $B$ there is {\em at most one} $a$ in $A$ such that $F(a) \,=\, b$;
    that is, the function $F$ is one-to-one on~$A$.

\noindent In other words, Pairing Condition~(ii) says that $F$, whose nature as a function with domain $A$ and values in $B$
    is guaranteed by Pairing Condition~(i), is actually a bijection from $A$ onto $B$.

        Conversely, suppose that $F:A \,{\rightarrow}\, B$ is a bijection of $A$ onto $B$; in particular, $F$ is a subset of $A{\times}B$.
    Then by the reversing the steps of the first half of this proof one sees that $F$ is a complete pairing f $A$ with~$B$, as required.

}%\EndSkip

\StartSkip{

\V
\V

        \subsection{\small{{\bf Theorem}}}
        \label{ThmA30.60}

        Suppose that $C$ is an infinite subset of ${\NN}$. Then:

\V

        (a) There exists a unique order-preserving\IndC{functions}{special functions}{order-preserving} bijection ${\Psi}_{C}:{\NN} \,{\rightarrow}\, C$ of ${\NN}$ onto $C$.
    (By `order preserving' is meant that if $i$ and $j$ are in ${\NN}$ and $i\,<\,j$, then ${\Psi}_{C}(i)\,<\,{\Psi}_{C}(j)$.)

\V

        {\bf Proof}\,  The `uniqueness' part follows by a simple `Mathematical Induction' argument.
    Indeed, suppose that ${\Psi}_{1}:{\NN} \,{\rightarrow}\, C$ and ${\Psi}_{2}:{\NN} \,{\rightarrow}\, C$ are both order-preserving bijections of ${\NN}$ onto~$C$.
    Let $A$ be the set of natural numbers $k$ such that ${\Psi}_{1}(j) \,=\, {\Psi}_{2}(j)$ for all $j$ in ${\NN}_{k}$.
    Let $c_{1}$ denote the least element of the nonempty set $C$; see the `Least-Natural-Number Principle' in Theorem~\Ref{PrinA10.11}.
    Then the `bijection' hypothesis implies that $c_{1}$ is in the image of both ${\Psi}_{1}$ and ${\Psi}_{2}$,
    and it is clear, by the `order-preserving' hypothesis, that the smallest element of ${\NN}$ must be mapped to the smallest element of $C$.
    That is, one must have ${\Psi}_{1}(1) \,=\, {\Psi}_{2}(1) \,=\, c_{1}$. In particular, $1{\in}A$.
    Next, suppose that $k{\in}A$, and let $c_{j} \,=\, {\Psi}_{1}(j)$ for $1\,\,{\leq}\,\,j\,\,{\leq}\,\,k$;
    note that ${\Psi}_{2}(j) \,=\, c_{j}$ for such $j$ by the definition of the set $A$.
    Let $C_{k} \,=\, C\,{\setminus}\,\{c_{1},c_{2},\,{\ldots}\,c_{k}\}$.
    Then $C_{k}$ is nonempty (because otherwise $C$ would equal the finite set $\{c_{1},c_{2},\,{\ldots}\,c_{k}\}$,
    contrary to the hypothesis that $C$ is an infinite subset of ${\NN}$). Let $c_{k+1}$ denote the least element of the set $C_{k}$.
    Then arguing as above one sees that ${\Psi}_{1}(k+1) \,=\, {\Psi}_{2}(k+1) \,=\, c_{k+1}$, so that clearly $(k+1){\in}A$.
    The Principle of Mathematical Induction (see Theorem~\Ref{PrinA10.11}) now implies that $A \,=\, {\NN}$, and thus the functions ${\Psi}_{1}$ and ${\Psi}_{2}$ are equal, as claimed.

     The preceding argument also tells one how to construct the desired bijection ${\Psi}_{C}$:
    First, define ${\Psi}_{C}(1)$ be the least element of the set $C$; and if ${\Psi}_{C}(1)$, ${\Psi}_{C}(2)$,\,{\ldots}\,${\Psi}_{C}(k)$
    have already been defined, define ${\Psi}_{C}(k+1)$ to be the least element of the set $C\,{\setminus}\,\{{\Psi}_{C}(1),\,{\ldots}\,{\Psi}_{C}(k)\}$.
    It is clear that that the function ${\Psi}_{C}$ constructed here satisfies the `order-preserving' requirement and that ${\Psi}_{C}(k)\,\,{\geq}\,\,k$ for all $k$ in ${\NN}$.
    in particular, it follows that ${\Psi}_{C}$ is an injection. It is also clear that ${\Psi}_{C}$ maps ${\NN}$ {\em into} the set $C$.
    To see that it also maps ${\NN}$ {\em onto} $C$, and thus is a bijection of ${\NN}$ onto $C$,
    let $b$ be any element of the set $C$. If $b \,=\, c_{1}$, the smallest element of $C$,
    then certainly $b{\in}{\Psi}_{C}[{\NN}]$, since $c_{1} \,=\, {\Psi}_{C}(1)$.
    Thus assume that $b\,>\,c_{1}$, and let $D$ be the set of all $c$ in ${\Psi}_{C}[{\NN}]$ such that $c\,<b$.
    The set $D$ is nonempty, since $c_{1}\,<\,b$; and clearly $d\,<\,b$ for all $d$ in $D$.
    Thus by the `Greatest-Natural-Number Principle' (see Theorem~\Ref{PrinA10.11}) the set $D$ has a greatest element; call it~$n$.
    Since every element of $D$ is in ${\Psi}_{C}[{\NN}]$, it follows that there exists $k$ in ${\NN}$ such that $n \,=\, {\Psi}_{C}(k)$.
    It follows from the `order-preserving' property that $b{\in}C\,{\setminus}\,\{{\Psi}_{C}(1),\,{\ldots}\,{\Psi}_{C}(n)\}$,
    and thus, by the definition of ${\Psi}_{C}(k+1)$, one has $b\,\,{\geq}\,\,{\Psi}_{C}(k+1)$.
    However, one cannot have $b\,>\,{\Psi}_{C}(k+1)$, since that would imply that ${\Psi}_{C}(k+1)$ is in the set $D$,
    contrary to the fact that ${\Psi}_{C}(k)$ is the greatest element of $D$. It follows that $b \,=\, {\Psi}_{C}(k+1)$, and thus $b{\in}{\Psi}_{C}[{\NN}]$.
    In particular, the function ${\Psi}_{C}$ maps ${\NN}$ {\em onto} $C$, as required.
    

\V

        \subsection{\small{{\bf Definition}}}
        \label{DefA30.70}

        If $C$ is an infinite subset of ${\NN}$ then the map ${\Psi}_{C}:{\NN} \,{\rightarrow}\, C$ described above is called the {\bf canonical bijection of ${\NN}$ onto $\Bfm{C}$}\index{canonical bijection}.
    The number ${\Psi}_{C}(k)$ is called the {\bf $\Bfm{k}$-th smallest element of $\Bfm{C}$}.

\V


        \subsection{\small{{\bf Remarks}}}
        \label{RemrkA30.80}

\V

\hspace*{\parindent}(1) The terminology `canonical bijection', and the notation ${\Psi}_{C}$ for this bijection, are convenient;
    but they are \underline{not} standard in the mathematical literature. Indeed, it is likely that they are used this way only in {\TheseNotes}.


\V

        (2) The method used to construct the canonical bijection ${\Psi}_{C}$ given above is an example of what is called a {\bf recursive definition}\index{recursive definitions}.
    That is, it describes the value of ${\Psi}_{C}(m)$ in terms of the values ${\Psi}_{C}(j)$ for $j\,\,{\leq}\,\,m-1$,
    and not directly in terms of $m$ itself. This technique of defining functions on ${\NN}$ is both powerful and popular,
    and is used freely throught {\TheseNotes}. In order to speed up the exposition,
    the justification for this technique is postponed to Appendix~B.


\V
\V

        Associated with a bijection is a related function which `reverses' the effect of the bijection.

        \subsection{\small{{\bf Definition}}}
        \label{DefA30.110}

        Suppose that $f:A \,{\rightarrow}\, B$ is function, with domain $A$, which is a bijection from the set $A$ onto the set $B$.
    Then the corresponding {\bf inverse map} $f^{-1}:B \,{\rightarrow}\, A$ is the function, with domain $B$, defined by the rule
        \begin{displaymath}
        \mbox{If $y$ is an element of $B$, then $f^{-1}(y)$ is the unique element $x$ of $A$ such that $f(x) \,=\, y$}.
        \end{displaymath}

\V

        \subsection{\small{{\bf Examples}}}
         \label{ExampA30.120}

\hspace*{\parindent}
        (1) Let ${\RR}^{+}$ denote the set of all positive real numbers, and let $f:{\RR}^{+} \,{\rightarrow}\, {\RR}^{+}$ be given by the formula $f(x) \,=\, x^{2}$.
    It is obvious that $f$ is a bijection from ${\RR}^{+}$ to ${\RR}^{+}$, and it is easy to verify that $f^{-1}:{\RR}^{+} \,{\rightarrow}\, {\RR}^{+}$ is the function given by $f^{-1}(y) \,=\, \sqrt{y}$, the `positive square-root function'.

\V

        (2) Let $f:{\RR} \,{\rightarrow}\, {\RR}^{+}$ denote the standard exponential function from calculus, given by the formula $f(x) \,=\, e^{x}$.
    Then it is well-known that $f$ is a bijection from ${\RR}$ to ${\RR}^{+}$.
    The corresponding inverse function $f^{-1}:{\RR}^{+} \,{\rightarrow}\, {\RR}$ is the standard natural logarithm function, ${\ln}$.

\V

        (3) The standard `inverse trig functions' from calculus give other useful examples of inverse functions in the context of freshman calculus.
    The reader is encouraged to pick up a calculus text and review the definitions of these functions.

\V

        (4) Suppose that $f:A \,{\rightarrow}\, B$ is a bijection of $A$ onto $B$ and $g:C \,{\rightarrow}\, D$ is a bijection of $C$ onto~$D$.
    Then the ordered pair $(f,g)$ determines a corresponding bijection $f{\times}g:A{\times}C \,{\rightarrow}\, B{\times}D$ of the Cartesian product $A{\times}C$ onto the Cartesian product $B{\times}D$.
    The rule is
        \begin{displaymath}
        (f{\times}g)(c,d) \,=\, (f(c), g(d)) \mbox{ for all $(c,d)$ in $A{\times}C$}.
        \end{displaymath}
    The simple proof that $f{\times}g$ is a bijection and that $(f{\times}g)^{-1} \,=\, f^{-1}{\times}g^{-1}$, is left as an exercise.

\V

        (5) Let $A$ and $B$ be nonempty sets, and let $A{\times}B_{K}$ denote the `Kuratowski' version of the Cartesian product of $A$ with $B$;
    see Definition~\Ref{DefA12.30}.
    Likewise, let $A{\times}B$ denote the version of the Cartesian product introduced in Definition~\Ref{DefA30.30}.
    Then there is a natural bijection $F:A{\times}_{K}B \,{\rightarrow}\, A{\times}B$ of $A{\times}_{K}B$ onto $A{\times}B$.

\V

        (6) Suppose that $F$ is a complete pairing of a nonempty set $A$ with a set $B$, in the sense of Definition~\Ref{DefA12.70}.
    It is noted in Example~\Ref{ExampA30.50}~(4) above that $F$ is a bijection of $A$ onto $B$.
    It is easy to see that the corresponding inverse function $F^{-1}$, viewed as a complete pairing $F^{-1} \,{\subseteq}\, B{\times}_{K}A$ of $B$ with $A$, is given by the rule
        \begin{displaymath}
        (b,a){\in}F^{-1} \mbox{ if, and only if, } (a,b){\in}F.
        \end{displaymath}
    In other words, $F^{-1}$ is the `reversed complete pairing' associated with $F$; see Remark~\Ref{RemrkA12.80}.

\V

          \subsection{\small{{\bf Remark}}}
                  \label{RemrkA30.125}

\hspace*{\parindent}Suppose that $f:A \,{\rightarrow}\, B$ is a function with domain $A$ and values in $B$.
    If $U$ is a subset of $B$, we have defined the symbol $f^{-1}[U]$ to mean the set of all $x$ in $A$ such that $f(x){\in}U$;
    see Definition~\Ref{DefA30.10}.
    Note that in this context the function $f$ need not be an injection, so the symbol $f^{-1}$ does not refer to `the inverse of $f$', in the sense of Definition~\Ref{DefA30.40}.
    However, if $f$ does happen to be a bijection of $A$ onto $B$, then the inverse map $f^{-1}:B \,{\rightarrow}\, A$ does make sense, as does the symbol $f^{-1}[U]$.
    However, in this new context the meaning of $f^{-1}[U]$ is as the image of the set $U$ under the map~$f^{-1}$.

        In other words, there is a possible conflict between the notation $f^{-1}[U]$, thought of as the `preimage of $U$ with respect to the function $f$', 
    and the same notation, thought of as the `image of $U$ under the inverse map $f^{-1}$', when $f$ is a bijection.
    Fortunately, the set $f^{-1}[U]$ turns out to be the same under either viewpoint when $f$ is a bijection,
    so normally this conflict of the notation $f^{-1}$ causes no difficulties.

        Note, however, when $f^{-1}$ denotes the inverse of a bijection from $A$ to $B$,
    then when $y$ is an element of $B$ one can consider $f^{-1}(y)$ and $f^{-1}[\{y\}]$.
    The former is an {\em element} of $A$, the other is a {\em subset} of $A$. In this case one {\em does} sometimes encounter some confusion,
    since many authors use parentheses for both situations, and many such authors write $f^{-1}(y)$ (an {\em element} in $A$)
    when they mean $f^{-1}(\{y\})$ (a {\em subset} of $A$).


\V
\V

        In most of the examples of functions given so far, the `rule' which defines the value of the function at each point of its domain has been given fairly explicitly.
    There are many situations in analysis, however, when one needs to know that a suitable function exists, but an explicit `rule' cannot be found.
    In such situations the following fact often can be invoked.

\V

        \subsection{\small{{\bf The Axiom of  Choice}}}
        \label{AxiomA30.170}\IndA{axiom of choice}

        Let $Y$ be a nonempty set, and let ${\cal F}$ be a nonempty family of nonempty subsets of $Y$.
    Then there exists at least one function $c:{\cal F} \,{\rightarrow}\, Y$ such that one has $c(S){\in}S$ for each set $S$ in the family ${\cal F}$.
    Such a function $c$ is called a {\bf choice function}
    \IndB{axiom of choice}{choice functions}\IndC{functions}{special functions}{choice functions}
    for the family~${\cal F}$.

\V

        In {\TheseNotes} we follow the usual custom in analysis and allow free use of this axiom.

\V
\V

%%% 
\begin{quotation}
{\footnotesize \underline{\Notes} (on the Axiom of Choice)\IndB{\notes}{on the Axiom of Choice}:

\V

        (1) The reason for the names `Axiom of {\em Choice}' and `{\em choice} function' is clear.
    Indeed, the `rule' for the function $f$ described in this axiom can be phrased intuitively as:

        \h For each set $S$ in the family ${\cal F}$, the function $c$ `chooses' an element from $S$.

\V

        (2) Some authors require, in their formulation of this axiom,
    that the sets in the family ${\cal F}$ be mutually disjoint; that is, if $S_{1}$ and $S_{2}$ are in ${\cal F}$ and $S_{1} \,\,{\neq}\,\, S_{2}$,
    then $S_{1}\,{\cap}\,S_{2} \,=\, {\emptyset}$.
    However, it is easy to show that the version of the axiom use here is equivalent to the one given in such texts.

\V

        (3) Many people find the Axiom of Choice to be fairly innocuous, even obvious.
    Nevertheless, for some years after its introduction to set theory, by Zermelo in~1904,
    it was the source of considerable controversy in the mathematical community.
    Part of that controversy came from the results that could be proved using it.
    One of the most spectacular is the following result, due to Banach and Tarski (1924):

        Let $X$ be a solid sphere in ${\RR}^{3}$ of radius $R\,>\,0$.
    Then it is possible to decompose $X$ into six disjoint subsets and to reassemble these six pieces, using only rigid motions in ${\RR}^{3}$, to form a sphere of radius $2\,R$.

        Recall that a `rigid motion' in ${\RR}^{3}$ consists of a rotation followed by a translation and possibly a reflection through a plane.
    In particular, rigid motions in ${\RR}^{3}$ preserve volumes. Thus the Banach-Tarski {\em appears} to be saying that one can decompose the sphere $X$ into six disjoint subsets,
    transform each of these sets into a new set, of equal volume as the original set it came from,
    so that the union of the new sets has {\em larger} volume than the original sphere!

        If this latter interpretation were what the Banach-Tarski theorem actually says,
    then the result truly would be paradoxical, and thus justify the name `
\IndAA{Banach-Tarski paradox}' which is normally given to the theorem.
    In reality, however, what the theorem does show is that the sets into which the process divides the original sphere cannot be assigned a reasonable notion of `volume',
    where by `reasonable' one includes the requirement that rigid motions should not change that volume.
    Banach and Tarski make clear that a key to proving this result is the use of the Axiom of Choice.

\V

        (4) The controversy associated with the Axiom of Choice is restricted to the case in which the family ${\cal F}$ is infinite.
    No one (well, hardly anyone) objects to a proof in which only finitely many choices are to be made.

        For instance, if in a proof one says `Let $x_{0}$ be a point of the nonempty set $X$', this is not viewed as an application of the Axiom of Choice.
}%EndFootnotesize
\end{quotation}
%##

\V
\V
    
         To illustrate the use of the Axiom of Choice, let us prove the following simple relation between the existence of surjections and the existence of injections between sets.

\V

        \subsection{\small{{\bf Theorem}}}
        %\label{ThmA30.190}

        Let $A$ and $B$ be nonempty sets. Then a necessary and sufficient condition for there to exist an injective map from $A$ into $B$ is that there exist a surjective map from $B$ onto $A$.

\V

        {\bf Proof}\, 

\V

        (a) \underline{The `Necessary' Part} Suppose that there does exist at least one injection from $A$ into $B$,
    and let $f:A{\rightarrow}B$ be such a map.
    Let $C$ denote the image $f[A]$ of the map $f$, and let $a_{0}$ be a fixed element of $A$.
    Define $g:B{\rightarrow}A$ by the rule
        \begin{displaymath}
        g(b) \,=\,
                      \left\{
    \begin{array}{l}
\mbox{ the unique $a{\in}A$ such that $f(a) \,=\, b$ if $b{\in}C$;} \\
    \mbox{ $a_{0}$ if $b \not \in C$.}
    \end{array}
    \right.
        \end{displaymath}
    It is clear that $g$ is a well-defined function from $B$ {\em into} $A$. To see that $g$ maps $C$, and thus $B$, {\em onto} $A$,
    note that (by hypothesis) $f$ is an injection on $A$, and thus $f$ is a {\em bijection} of $A$ onto its image $C$.
    Moreover, it is clear that the restriction $g|_{C}$ of $g$ to $C$ is the corresponding inverse map $f^{-1}:C \,{\rightarrow}\, A$.
    In particular, $g|_{C}$, and thus $g$ itself, maps $C$ {\em onto} $A$.

\V

        (b) \underline{The `Sufficient' Part} Suppose that there exists at least one surjective map of $B$ onto $A$, and let $g:B{\rightarrow}A$ be such a map.
    For each $a$ in $A$ let $B_{a} \,=\, g^{-1}[\{a\}]$; that is, $B_{a}$ consists of all points $b$ of $B$ such that $g(b) \,=\, a$.
    Then each set $B_{a}$ is nonempty, because of the hypothesis that $g$ maps $B$ {\em onto} $A$. Also, if $a_{1}$ and $a_{2}$ are points of $A$ such that $a_{1} \,\,{\neq}\,\, a_{2}$, then the fact that $g$ is a  {\em function} implies that $B_{a_{1}}\,{\cap}\,B_{a_{2}} \,=\, {\emptyset}$. (Do you see why?)
 
        Now let ${\cal F}$ be the family of all the sets $B_{a}$ with $a$ in $A$.
    By the Axiom of Choice, there exists a choice function for this family; let $c:{\cal F} \,{\rightarrow}\, B$ be such a function.
    Finally, let $f:A{\rightarrow}B$ be the map given by the rule
        \begin{displaymath}
    f(a) \,=\, c\left(B_{a}\right) \mbox{ for each $a$ in $A$}.
        \end{displaymath}
    The fact that $f$ is one-to-one on $A$ now follows easily from the fact, mentioned above,
    that $B_{a_{1}}\,{\cap}\,B_{a_{2}} \,=\, {\emptyset}$ if $a_{1} \,\,{\neq}\,\, a_{2}$.

}%\EndSkip

\VV

\StartSkip{

\V

        By its very definition, a binary operation on a set $A$ acts only on {\em pairs} of objects in the set $A$.
    Nevertheless, it is quite common in mathematics to encounter expressions which involve multiple appearances of binary operations.
    For example, consider the following expressions involving binary operations acting on natural numbers:
        \begin{displaymath}
        (i)\, \,  (a+b){\cdot}(c+d); \h
        (ii)\,     a{\cdot}b + c{\cdot}d; \h
        \end{displaymath}

        In Expression~$(i)$ the multiplication obviously cannot be carried out unless one first determines the values of the two factors $a+b$ and $c+d$;
    it does not matter which of these sums is computed first, but the presence of the parentheses makes it easy to organize the calculation.

        Expression $(ii)$, in contrast, involves no parentheses. Nevertheless, one is expected to realize that this expression is shorthand for
    $(a{\cdot}b) + (c{\cdot}d)$, and not, say, $a{\cdot}(b + (c{\cdot}d))$.
    How do we know that the expression means this? Because such facts were drilled into our brains
    by our algebra teachers under the heading of `Precedence of Operators'. \IndBD{operations/operators}{precedence of operations}
    These rules include, for example:

\VA

        \h `First evaluate any expressions which appear inside parentheses, starting with the inmost such expressions if they are nested;
    then carry out multiplications before additions. In cases of expressions of equal precedence, normally carry them out left to right.'

\VA
}%\EndSkip

%----------------
\StartSkip{

        (4) Let $A$ be a subset of ${\NN}$, possibly empty; and as usual let ${\chi}_{A}:{\NN} \,{\rightarrow}\, \{0,1\}$
    denote the characteristic function associated with this subset of ${\NN}$ (see Example~\Ref{ExampA30.25}).
    The function ${\chi}_{A}$ is thus an example of an infinite sequence with values in the doubleton set $\{0,1\}$.
    Otherwise stated, one can identify the elements of the power set ${\cal P}({\NN})$ with ordered infinite sequences of the form $(b_{1}, b_{2},\,{\ldots}\,b_{k},\,{\ldots}\,)$ in which each entry is either $0$ or~$1$.
    For instance, the empty subset of ${\NN}$ corresponds to the sequence $(0,0,\,{\ldots}\,0,\,{\ldots}\,)$;
    the subset of even numbers corresponds to the sequence $(0,1,0,1,\,{\ldots}\,)$;
    the finite subset $\{1,2,4,6\}$ corresponds to the sequence $(1, 1, 0, 1, 0, 1, 0, \,{\ldots}\,0, \,{\ldots}\,)$; and so on.

\V

        (3) Let ${\xi} \,=\, (1,0,2,0,3,0,4,0,\,{\ldots}\,)$ be the sequence discussed in the preceding example.
    One can get new sequences from ${\xi}$ by deleting some of the terms from the original ordered list,
    leaving the terms which remain in their original order.
    Of course, one must be careful to not delete {\em too} many terms from the original list: we need to keep infinitely many terms.
    What results  from this procedure is also an infinite ordered list; that is, an infinite sequence.

        For instance, if one deletes from ${\xi}$ the terms of even order (i.e., the terms $x_{k}$ with $k$ even), one obtains the new sequence
        \begin{displaymath}
        {\zeta} \,=\, (1,2,3,\,{\ldots}\,).
        \end{displaymath}
    The $k$-th term of this new sequence is $k$ for each $k$ in ${\NN}$; in the `function' viewpoint, ${\zeta}(k) \,=\, k$ for each $k$ in ${\NN}$.

        Likewise, if one deletes from ${\xi}$ the terms of odd order, one obtains the new sequence
        \begin{displaymath}
        {\tau} \,=\, (0,0,0,\,{\ldots}\,),
        \end{displaymath}
    all of whose terms equal $0$; in the function viewpoint, ${\tau}(k) \,=\, 0$ for all $k$ in ${\NN}$.

        Note that the sequence ${\zeta}$ above is equally well determined by knowing which terms of ${\xi}$ which are {\em not} deleted.
    Indeed, if one simply erases the even-order terms from the list ${\xi} \,=\, (1,0,2,0,3,0,4,0,\,{\ldots}\,)$
    (as well as the corresponding commas, which are there mainly to clarify the notation), one is left with the ordered list
        \begin{displaymath}
        (1, \h 2, \h 3, \h 4, \h \,{\ldots}\,)
        \end{displaymath}
    That is, the key to the sequence ${\zeta}$ is to know which terms of ${\xi}$ are {\em retained} in the construction process.
    In the case of ${\zeta}$, the retained terms are the odd-order terms of ${\xi}$.

        Likewise, the correct way to think about the sequence ${\tau}$ is that it comes from retaining the {\em even}-order terms of ${\xi}$.

\V

        (4) Let $X \,=\, \{0,1\}$ be the doubleton set whose entries are the integers `zero' and~`one'.
    Then every infinite sequence ${\xi}:{\NN} \,{\rightarrow}\, X$ is the the characteristic function of some subset $A_{{\xi}}$ of ${\NN}$;
    namely, $A_{{\xi}} \,=\, \{k{\in}{\NN}: {\xi}(k) \,=\, 1\}$.
    Conversely, every subset of ${\NN}$ is of the form $A_{{\xi}}$ for a unique sequence with values in this set $X$.


\V
\V

        {\bf Subsequences}\IndBD{sequences}{subsequences}

\VV

    The process illustrated in Example~(3) above, namely, forming a new sequence by deleting/retaining terms of an old sequence,
    is used frequently in analysis.
    Because this process is important, and beginners sometimes find the related notations confusing, it is worthwhile to first discuss the general process in the context of infinite ordered lists.
    The `official' discussion, in terms of functions defined on ${\NN}$ is  given after that.

    Let ${\xi} \,=\, (x_{1},x_{2},\,{\ldots}\,)$ be an infinite sequence in a set $X$; here ${\xi}$ is thought of as an ordered list.
    Suppose that one wishes to form a new infinite sequence ${\zeta} \,=\, (z_{1},z_{2},\,{\ldots}\,)$ from ${\xi}$ by deleting certain terms from ${\xi}$, 
    but retaining infinitely many terms.
    Let $A$ denote the set of indices $k$ in ${\NN}$ corresponding to the terms of ${\xi}$ that are to be retained;
    of necessity, $A$ must then be an infinite subset of ${\NN}$. Then the `subsequence' ${\zeta}$ can be described as follows:

\VA

        \h (i)\, The terms of the list ${\zeta}$ are precisely the terms $x_{k}$ of the original list ${\xi}$ for which $k{\in}A$.

        \h (ii) If $i$ and $j$ are elements of the set $A$ such that $i\,<\,j$, then $x_{i}$ appears {\em before} $x_{j}$ in the ordered list ${\zeta}$.

\VA

\noindent In other words, the terms of the original sequence ${\xi}$ which are `retained'
    in the construction of the `subsequence' ${\zeta}$ are kept in their original order.

\V

        The translation of the preceding into the official `function' approach is based on the following results.

\V

        \subsection{\small{{\bf Definition}}}
        \label{DefA40.40}

\hspace*{\parindent}(1) Suppose that ${\xi}:{\NN} \,{\rightarrow}\, X$ is a sequence in a nonempty set~$X$.
    Let ${\Psi}_{A}:{\NN} \,{\rightarrow}\, A$ be the canonical bijection associated with an infinite subset~$A$ of ${\NN}$; see Theorem~\Ref{ThmA30.60}.
    Then ${\zeta} \,=\, {\xi}{\circ}{\Psi}_{A}:{\NN} \,{\rightarrow}\, X$ is the {\bf subsequence of ${\xi}$ associated with the set 
    $A$}\IndBD{sequences}{subsequence associated with an infinite subset of ${\NN}$}. In {\ThisText} it denoted ${\xi}_{A}$.


\V

        (2) Conversely, a sequence ${\zeta}:{\NN} \,{\rightarrow}\, X$ is said to be {\bf a subsequence of ${\xi}$} provided there exists an infinite subset $A$ of ${\NN}$ such that ${\zeta} \,=\, {\xi}_{A}$.

\V

        (3) Suppose that ${\xi}:{\NN} \,{\rightarrow}\, X$ is an infinite sequence of elements of a nonempty set $X$.
    A sequence ${\tau}:{\NN} \,{\rightarrow}\, X$ is said to be a {\bf \underline{sub}subsequence of $\Bfm{{\xi}}$}
    provided there exists a subsequence ${\zeta}$ of ${\xi}$ such that ${\tau}$ is a subsequence of ${\zeta}$.
    One also refers to such ${\tau}$ as a {\bf subsequence of order $2$ of (the original sequence) $\Bfm{{\xi}}$}.
    It then becomes convenient to refer to the subsequence ${\zeta}$ as a {\bf subsequence of order~$1$ of~$\Bfm{{\xi}}$},
and to ${\xi}$ itself as a {\bf subsequence of order~$0$ of~$\Bfm{{\xi}}$}.

\V

       (4)\IndBD{sequences}{subsequences of arbitrary order}
    More generally, suppose that the concept of `subsequence of order $m$ of a sequence ${\xi}$' has been defined.
    Then a sequence ${\tau}$ is said to be a {\bf subsequence of order $m+1$ of $\Bfm{{\xi}}$}
    provided there exists a subsequence ${\zeta}$ of order $m$ of ${\xi}$ such that ${\tau}$ is a subsequence of~${\zeta}$.

\V
\V

        \subsection{\small{{\bf Examples}}}
        \label{ExampA40.80}

\V

\hspace*{\parindent}
        (1) It is clear that every sequence is a subsequence of itself.
    Indeed, note that ${\Psi}_{N} \,=\, I_{{\NN}}$, the identity map on ${\NN}$.
    Thus
        \begin{displaymath}
        {\xi} \,=\, {\xi}{\circ}I_{{\NN}} \,=\, {\xi}_{{\NN}}.
        \end{displaymath}
    By repeating this argument, one also sees that for every $m$ in ${\NN}$ the sequence ${\xi}$ is a subsequence of order $m$ of itself.

\V

        (2) It follows easily from the result in Remark~(1) that if ${\zeta}$ is a subsequence of ${\xi}$,
    then, for every $m$ in ${\NN}$ ${\zeta}$ is a subsequence of ${\xi}$ of order $m$.

\V

        (3) Let $X$ be the finite set $\{1,2,3,4\}$; that is, $X \,=\, {\NN}_{4}$; and let ${\xi} \,=\, (x_{1}, x_{2},\,{\ldots}\,x_{k},\,{\ldots}\,)$ be the sequence in $X$ given by the list
        \begin{displaymath}
        {\xi} \,=\, (1,2,3,4,1,2,3,4,1,2,3,4,\,{\ldots}\,),
        \end{displaymath}
    where the obvious pattern repeats indefinitely.

        If one interprets the sequence ${\xi}$ to be a function ${\xi}:{\NN} \,{\rightarrow}\, X$, then
        \begin{displaymath}
        {\xi}(1) \,=\, 1, \h {\xi}(2) \,=\, 2, \h {\xi}(3) \,=\, 3, \h {\xi}(4) \,=\, 4, \h {\xi}(5) \,=\, 1, \h {\xi}(6) \,=\, 2,
        \end{displaymath}
    and so on.

        Now let $A$ be the set of all natural numbers $m$ of the form $m \,=\, 2+3k$ for $m$ in ${\NN}$. Thus,
        \begin{displaymath}
        A \,=\, \{5, 8, 11, 14, 17, 20, 23, 26\,{\ldots}\,\},
        \end{displaymath}
    and one has ${\Psi}_{A}(k) \,=\, 2+3k$ for all $k$ in ${\NN}$.
    The correponding subsequence ${\zeta} \,=\, {\xi}_{A} \,=\, {\xi}{\circ}{\Psi}_{A}$ is given by
        \begin{displaymath}
        {\zeta} \,=\, {\xi}_{A} \,=\, ({\xi}(5),{\xi}(8),{\xi}(11),{\xi}(14),{\xi}(17),\,{\ldots}\,) \,=\, 
    (1,4,3,2,1,4,3,2,1,4,3,2,\,{\ldots}\,)
        \end{displaymath}
    Note that with this choice of $A$ one gets the sequence ${\zeta}$ from the original sequence ${\xi}$
    by keeping the terms $x_{m}$ with index $m$ of the form $m \,=\, 2+3\,k$, while `deleting' from~${\xi}$ the terms $x_{m}$ with $m$ {\em not} of this form.

        Now let $B \,=\, \{2,4,6,8,\,{\ldots}\,\}$ be the set of even natural numbers; note that ${\Psi}_{B}(k) \,=\, 2k$ for all $k$ in ${\NN}$.
    Then the corresponding subsequence of ${\zeta}$ is
        \begin{displaymath}
        {\tau} \,=\, {\zeta}_{B} \,=\, (4,2,4,2,4,2,\,{\ldots}\,).
        \end{displaymath}
    Viewed this way, ${\tau}$ is a subsequence of ${\zeta}$ and thus a \underline{sub}subsequence of the original sequence~${\xi}$.
    Of course, ${\tau}$ can also be viewed directly as a (first-order) subsequence of~${\xi}$ itself.
    That is, there is an infinite subset $C$ of ${\NN}$ such that ${\tau} \,=\, {\xi}_{C}$;
    indeed, because of the repetitive nature of the terms in the original sequence~${\xi}$, there are many such subsets of~${\NN}$.
    Probably the most obvious choice is $C_{1} \,=\, \{4, 6, 8, 10, \,{\ldots}\,(2+2\,n),\,{\ldots}\,\}$,
    for which one has ${\Psi}_{C_{1}}(n) \,=\, 2+2\,n$ for each $n$ in~${\NN}$. A second choice of the set~$C$,
    at first not so obvious, is $C_{2} \,=\, \{8, 14, 20, 26, \,{\ldots}\,2+6\,m,\,{\ldots}\,\}$.
    The choice $C_{1}$

\V

        (4) Let ${\xi} \,=\, (x_{1},x_{2},\,{\ldots}\,)$  be an infinite sequence in a nonempty set $X$, and let ${\zeta} \,=\, (z_{1},z_{2},\,{\ldots}\,)$ be a subsequence of ${\xi}$.
    Then there exists an infinite subset $A$ of ${\NN}$ such that ${\zeta} \,=\, {\xi}{\circ}{\Psi}_{A}$.
    In terms of the familiar `index' notation, one can write
        \begin{displaymath}
        {\zeta} \,=\, (x_{k_{1}},x_{k_{2}},\,{\ldots}\,),
        \end{displaymath}
    where $k_{j} \,=\, {\Psi}_{A}(j)$ for each $j$ in ${\NN}$.
    By the properties of the function ${\Psi}_{A}$, one sees that the indices $k_{1}$, $k_{2}$,\,{\ldots}\, satisfy the condition
        \begin{displaymath}
        1\,\,{\leq}\,\,k_{1}\,<\,k_{2}\,<\,\,{\ldots}\,
        \end{displaymath}
    Conversely, if natural numbers $k_{1}$, $k_{2}$,\,{\ldots}\,are chosen so that $1\,\,{\leq}\,\,k_{1}\,<\,k_{2}\,<\,\,{\ldots}\,$,
    then these numbers determine an infinite subset $A$ of ${\NN}$, namely $A \,=\, \{k_{1},k_{2},\,{\ldots}\,\}$.
    This subset then determines a corresponding subsequence of ${\xi}$, namely ${\xi}_{A}$.
    This `index' approach to subsequences is the standard one for those whose think of a sequence as an infinite ordered list.

\V

        (5) Whereas each infinite subset $A$ of ${\NN}$ determines a unique subsequence of a given sequence ${\xi}$, the converse is not true.
    That is, it is possible to have ${\xi}_{A} \,=\, {\xi}_{B}$  for infinite subsets $A$ and $B$ of ${\NN}$ for which $A \,\,{\neq}\,\, B$.
    Consider, for instance, the constant sequence ${\xi} \,=\, (0,0,0,\,{\ldots}\,)$ in ${\RR}$.
    It is clear that if $A$ is {\em any} infinite subset of ${\NN}$, then ${\xi}_{A} \,=\, {\xi}$.

        In contrast, if, when viewed as a function ${\xi}:{\NN} \,{\rightarrow}\, X$, the sequence ${\xi}$ is one-to-one,
    then it is easy to see that ${\xi}_{A} \,=\, {\xi}_{B}$ implies $A \,=\, B$.

\V

        (6) The `index' notation for subsequences can become unwieldy, especially when one is forced to consider subsequences of order two or higher.
    For instance, let ${\xi} \,=\, (x_{1},x_{2},\,{\ldots}\,)$ be a sequence, 
and suppose that ${\zeta} \,=\, (z_{1},z_{2},\,{\ldots}\,)$ is the subsequence ${\xi}_{A}$ of ${\xi}$ associated with a certain infinite subset $A$ of ${\NN}$.
    Then for each $j$ in ${\NN}$ one has $z_{j} \,=\,x_{k_{j}}$, where $k_{j} \,=\, {\Psi}_{A}(j)$.
    Likewise, if ${\tau} \,=\, (t_{1},t_{2},\,{\ldots}\,)$ is the subsequence ${\zeta}_{C}$, then $t_{i} \,=\, z_{j_{i}}$ where $j_{i} \,=\, {\Psi}_{C}(i)$.
    Combining these results, one gets the following expression for the typical term $t_{i}$ of ${\tau}$ in terms of the terms $x_{k}$ of the original sequence ${\xi}$:
        \begin{displaymath}
        t_{i} \,=\, x_{j_{i}} \,=\, x_{{\Psi}_{A}({\Psi}_{C}(i))} \mbox{ for all $i$ in ${\NN}$}.
        \end{displaymath}
    The `index' notation for the corresponding subsubsequence of ${\xi}$ would be written out as
        \begin{displaymath}
        (x_{k_{j_{1}}}, x_{k_{j_{2}}},x_{k_{j_{3}}},\,{\ldots}\,).
        \end{displaymath}
    Many students have difficulty in decoding such triple-subscripted quantities.
    Of course, the `index' notation gets even harder to decipher for subsequences of order higher than the second.

\VV

        {\bf Remark} It has been observed above that a sequence ${\tau}$ being  a subsequence of order $m$
    of a sequence ${\xi}$ is not an intrinsic property of ${\tau}$; indeed, if ${\tau}$ is a subsequence of ${\xi}$, then it is a subsequence of any order~$m$.
    The significance instead is `how ${\tau}$ is being thought of' in relation to ${\xi}$ in a given context.
    More precisely, it is the relations between the indices which characterize these relations.
    The next definition makes this more concrete.
\VV

        \subsection{\small{{\bf Definition}}}\IndBD{sequences}{subsequence structures}
        \label{DefA40.45}

\V

        Let $m$ be a natural number. A {\bf subsequence structure of order \Bfm{m}} is an ordered $m$-tuple $(A_{1}, A_{2},\,{\ldots}\,A_{m})$
    of infinite subsets of ${\NN}$ such that $A_{1} \,{\supseteq}\, A_{2} \,{\supseteq}\, \,{\ldots}\, \,{\supseteq}\, A_{m}$.
    Similarly, a {\bf subsequence structure of infinite order} is an infinite sequence $(A_{1}, A_{2},\,{\ldots}\,A_{m},\,{\ldots}\,)$
    of infinite subsets of ${\NN}$ such that for each $k$ in ${\NN}$ one has $A_{k} \,{\supseteq}\, A_{k+1}$.

\V

        {\bf Remark} Although the type of structure defined here appears frequently in conjunction with the next lemma,
    the phrase `subsequence structure', as used here, is definitely not standard.

\VV


        \subsection{\small{{\bf Lemma}}}
        \label{LemmaA40.50}

\V

        Suppose that ${\cal A} \,=\, (A_{1}, A_{2},\,{\ldots}\,A_{m},\,{\ldots}\,)$
    is a subsequence stucture of infinite order, as described in the preceding definition.
    Then there exists an infinite subset $B$ of ${\NN}$ such that if one expresses $B$ in the standard form
    $B \,=\,\{n_{1}, n_{2}, \,{\ldots}\,n_{k},\,{\ldots}\,\}$ with $n_{k}\,<\,n_{k+1}$ for all~$k$,
    then for each $k$ the element $n_{k}$ lies in each of the sets $A_{j}$ for $1\,\,{\leq}\,\,j\,\,{\leq}\,\,k$.

\V

        {\bf Proof} Let $n_{1}$ be any element of the set $A_{1}$. Since $A_{2}$ is an infinite subset of $A_{1}$,
    there exist infinitely many elements $n$ in $A_{2}$ such that $n_{1}\,<\,n$; let $n_{2}$ be any such~$n$;
    note that $n_{2}{\in}A_{1}$ because $A_{2} \,{\subseteq}\, A_{1}$. Continuing this way, suppose that
    $n_{1}$, \,{\ldots}\,$n_{k}$ have been chosen so that $n_{j}{\in}A_{j}$ for each $j$ such that $1\,\,{\leq}\,\,j\,\,{\leq}\,\,k$,
    and $n_{1}\,<\,n_{2}\,<\,\,{\ldots}\,\,<\,k_{m}$.
    Since $A_{k+1}$ is an infinite subset of $A_{k}$, there exists $n$ in $A_{k+1}$ such that
    $n\,>\,n_{k}$ (and thus $n\,>\,n_{j}$ for each $j \,=\, 1,2,\,{\ldots}\,k$). Let $n_{k+1}$ be any such number.
    This process then defines the set $B \,=\, \{n_{1}, n_{2},\,{\ldots}\,n_{k},\,{\ldots}\,\}$ with the desired properties.

\V

        \subsection{\small{{\bf Definition}}}\IndBD{sequences}{subsequence selector sets}
        \label{DefA40.60}

\V

        A set $B$ constructed from an infinite-order subsequence structure ${\cal A}$ as above is called a
    {\bf subsequence selector~set derived from~$\Bfm{\cal A}$}.

\V

        {\bf Remarks} (1) The `subsequence selector set' terminology is {\em definitely} nonstandard.

\V

       \h (2) Many texts consider `sequences' only later in their development, after the introduction of the axioms for the real numbers.
    However the ideas and facts about infinite subsets of ${\NN}$ presented here involve only basic properties of the set ${\NN}$ of natural numbers,
    properties which we accept as `primitive' in {\ThisText}. No futher analysis of them is needed.

\V

        \subsection{\small{{\bf Example}}} 
        \label{ExampA40.70}

        Let ${\xi} \,=\, (x_{1}, x_{2}, \,{\ldots}\,x_{n}, \,{\ldots}\,)$ be a sequence of real numbers in the unit interval $[0,1]$.
    Assign to each number $x_{n}$ its nonending decimal expansion of the form $0.d_{1}\,d_{2}\,\,{\ldots}\,d_{k}\,\,{\ldots}\,$,
    where each $d_{j}$ is a decimal digit, i.e., a natural number in the set $\{0,1,2,3,4,5,6,7,8,9\}$.
    Define a corresponding sequence of infinite subsets $A_{1}$, $A_{2}$ \,{\ldots}\, of ${\NN}$ as follows:

    (1) Since there are only finitely many decimal digits, at least one of these digits
    must appear as the first digit of $x_{n}$ for infinitely many values of $n$; let $d_{1}$ be the smallest such digit,
    and let $A_{1}$ be the set of $n$ in ${\NN}$ such that $d_{1}$ is the first decimal digit of $x_{n}$.


       (2) Similarly, there exists a decimal digit which appears as the second decimal digit of $x_{n}$ for infinitely many $n$ in $A_{1}$;
    let $d_{2}$ be the smallest such digit, and let $A_{2}$ be the set of all $n$ in $A_{1}$ such that the second digit of $x_{n}$ is $d_{2}$.
    Clearly $A_{2}$ is a subset of~$A_{1}$, so that if $n{\in}A_{2}$ then the first two decimal digits of $x_{n}$ are $d_{1}$ and $d_{2}$, respectively.

       (3) Continuing this way, one gets a sequence of infinite subsets $A_{1}$, $A_{2}$,\,{\ldots}\, of ${\NN}$,
    with $A_{k+1} \,{\subseteq}\, A_{k}$ for all $k$, and a corresponding infinite sequence of decimal digits $d_{1}$, $d_{2}$,\,{\ldots}\,
    such that if $n$ is an element of $A_{k}$ then the first $k$ decimal digits of $x_{n}$ are $d_{1}$, $d_{2}$,\,{\ldots}\,$d_{k}$, respectively.
    Clearly the sequence ${\cal A} \,=\, (A_{1}, A_{2},\,{\ldots}\,)$ is an infinite-order subsequence structure.

        Let $c$ be the real number in $[0,1]$ with the decimal representation $c \,=\, 0.d_{1}\,d_{2}\,\,{\ldots}\,d_{n}\,\,{\ldots}\,$,
    and let $B \,=\, \{n_{1}, n_{2},\,{\ldots}\,\}$, with $n_{n}\,<\,n_{k+1}$ for all~$k$, be a subsequence selector set derived from~${\cal A}$.
    Then it is easy to see that $|c-s_{n_{k}}|\,<\,1/10^{k}$ for all~$k$. Speaking intuitively,
    the number $c$ can be `approximated arbitrarily closely' by the terms of a subsequence of the original sequence~${\sigma}$.


        {\bf Remark} Unlike the situation for natural numbers, we accept statements concerning {\em real} numbers in this chapter only provisionally,
    to smooth the exposition and to provide useful examples. In particular, the result obtained in the preceding example
    should be viewed only for its ability to illustrate the concepts of `sequence structure of infinite-order subsequence structures'
    and the corresponding idea of `subsequence selector sets'. Indeed, the fact obtained here,
    when made suitably rigorous later on, is a restricted formulation of an important result in analysis called
    the {\bf Bolzano-Weierstrass Theorem for Sequences}\IndBD{Bolzano, Bernhard (1781-1848)}{restricted Bolzano-Weierstrass theorem}.


\V
\V

        It has been noted above that a \underline{subsub}sequence of a sequence ${\xi}$ can also be thought of as a \underline{sub}sequence of ${\xi}$.
    The next result makes this more precise.

\V

        \subsection{\small{{\bf Theorem}}}
        \label{ThmA40.90}

\V

        Let ${\xi}:{\NN} \,{\rightarrow}\, X$ be an infinite sequence of elements in a nonempty set $X$.
    Suppose that ${\tau}$ is a subsubsequence of ${\xi}$, and let $A$ and $C$ be infinite subsets of ${\NN}$ such that ${\tau} \,=\, {\zeta}_{C}$, where ${\zeta} \,=\, {\xi}_{A}$.
    Then ${\tau} \,=\, {\xi}_{B}$, where $B \,=\, \left({\Psi}_{A}{\circ}{\Psi}_{C}\right)[{\NN}]$.

\V

        \underline{Proof} The simple proof is left as an exercise.
}%\EndSkip
%---------------

        \section{The Cardinality of Sets}
                        \label{SectA15}\IndB{ZZ Sections}{\Ref{SectA15} The Cardinality of Sets}

        One of the major advances made by Cantor in his theory of sets is his analysis of the concept of the `number of elements of an infinite set'.
    The special case of a set have equally many elements as the set ${\NN}$ of natural numbers plays a particularly important role in analysis,
    so we focus on that case in the main body of {\ThisText}. In Appendix~B we consider Cantor's theory in more generality.



\V

\begin{quotation}
{\footnotesize \underline{\Note} (on sets having equally many elements)\IndB{\notes}{on sets having equally many elements}:

        One aspect of Cantor's theory is to establish under what circumstances two sets $A$ and $B$ have equally many elements.
    The solution to this problem seems very easy if the sets $A$ and $B$ are both finite:
    simply count the number of elements in each set, and if the numbers agree, then the sets have equally many elements.
    However, in modern mathematics one is forced to study sets which have {\em infinitely many} elements, and in such cases `counting' may not even make sense.
    Fortunately, there is a way of determining when two sets have equally many elements which,
    even in the case of finite sets, is older than the idea of `counting', and this older method is what Cantor uses.

\VA

        \underline{Example} Anthropologists tell us that there were primitive societies
    whose concept of `number' was restricted to `one', `two' and `many' (or, perhaps, `several').
    Suppose that the king of such a society needs to know whether there are as many spears available in storage as there are warriors;
    could he do so? The answer is `Yes': he could tell the warriors to each take one spear from storage;
    if, after this, every warrior has one spear, and there are no spears left over, then the king knows that there are equally many spears as warriors.
    Note that this process does not involve `counting' the number of spears and the number of warriors; indeed this king could not count numbers that high.
    It is simply a matter of `pairing off' spears and warriors, so that each spear is carried by one warrior, and each warrior holds one spear.

\VA

        The preceding suggests a way of determining whether two sets $A$ and $B$, possibly infinite, have equally many elements:
    if it is possible to `pair off' the elements of the sets, so that in this process each element of $A$ gets paired with exactly one element of $B$
    and each element of $B$ gets paired with exactly one element of $A$, then the sets have equally many elements.
    This primitive analysis is made more precise in the following definition.
}%EndFootnotesize
\end{quotation}

        \subsection{\small{\bf Definition}}
            \label{DefA12.70}\IndBD{cardinality}{exact pairing}

        Let $(A,B)$ be an ordered pair of nonempty sets.

        (1) An {\bf exact pairing of $\Bfm{A}$ with $\Bfm{B}$} is a subset $F$ of the Cartesian product $A{\times}B$ which has the following properties:

\VA

        \h \underline{Pairing Condition (i)} For each element $a$ in $A$ there is a unique element $b$ in $B$ such that $(a,b){\in}F$;

        \h \underline{Pairing Condition (ii)} For each $b$ in $B$ there is a unique $a$ in $A$ such that $(a,b){\in}F$.

\VA

\noindent If an ordered pair $(a,b)$ is an element of an exact pairing $F$, then one also says that {\bf $\Bfm{a}$ is paired with $\Bfm{b}$ by $\Bfm{F}$}.

\V

        (2) One says that {\bf $\Bfm{A}$ has equally many elements as $\Bfm{B}$}, or, using more modern terminology,
    that {\bf $\Bfm{A}$ has the same cardinality as $\Bfm{B}$}, provided there exists at least one exact pairing of $A$ with $B$.

\V

        (3) Let $k$ be a natural number, and recall that ${\NN}_{k}$ denotes the set of all natural numbers $m$ such that $1\,\,{\leq}\,\,m\,\,{\leq}\,\,k$.
    One says that a set $A$ is a {\bf finite set}\IndBD{cardinality}{finite sets}
    provided either $A \,=\, {\emptyset}$ or there exists a natural number $k$ such that $A$ has the same cardinality as ${\NN}_{k}$.
    All other sets are said to be {\bf infinite sets}\IndBD{cardinality}{infinite sets}.

\VV

        \subsection{\small{\bf Remarks}}
            \label{RemrkA12.80}

\hspace*{\parindent} (1) Note that the statement `$A$ has the same cardinality as $B$'
    does {\em not} mean the same as the statement `$B$ has the same cardinality as $A$'. Indeed, the former statement concerns a subset of $A{\times}B$,
    while the latter statement concerns a subset of $B{\times}A$, a set which need not equal $A{\times}B$.
    Nevertheless, the two statements are logically equivalent. More precisely, suppose that $A$ has the same cardinality as $B$,
    and let $F$ be an exact pairing of $A$ with~$B$. Associate with $F$ a corresponding subset $G$ of $B{\times}A$ by the rule
        \begin{displaymath}
        G \,=\, \{(b,a){\in}B{\times}A: (a,b){\in}F\}.
        \end{displaymath}
    It is clear that $G$ is an exact pairing of $B$ with $A$, so that $B$ has the same cardinality as $A$.
    One calls $G$ the {\bf reverse exact pairing associated with $\Bfm{F}$}\IndBD{cardinality}{reverse exact pairing}.
    It is clear that $F$ is then the reverse exact pairing associated with~$F$.

\V

        (2) The previous discussion makes precise the concept of two sets having `equally many elements'.
    It is then natural to consider pairs of sets which do {\em not} have `equally many elements',
    and the question of whether one of these sets must have `fewer' elements than the other.
    The analysis of this question is fairly simple for finite sets; indeed, it falls under the heading of `well-known facts about natural numbers'.
    However, for general sets the situation is somewhat unintuitive. Fortunately, we don't need this general theory in the main body of {\ThisText},
    so it is relegated to Appendix~B.

\VV

        The formulation of the concept of `same cardinality' given above, in terms `exact pairings' is used here for historical reasons:
    the basic idea of pairing up objects is quite ancient. From here on, however, we use the conventional modern formulation in terms of bijections.
    

\V

        \subsection{\small{{\bf Theorem}}}
        \label{ThmA30.55}

\V

        Let $A$ and $B$ be nonempty sets. Then $A$ has the same cardinality as~$B$,
    in the sense of Definition~\Ref{DefA12.70}, if, and only if, there exists a bijection of $A$ onto~$B$.

        More precisely, if $F$ is an exact pairing of $A$ with $B$, then $F$, viewed as a subset of $A{\times}B$,
    is a bijection $F:A \,{\rightarrow}\, B$ of $A$ onto~$B$. Conversely, if $F:A \,{\rightarrow}\, B$ is a bijection,
    then $F$ satisfies the two pairing conditions of Definition~\Ref{DefA12.70}, and thus is an exact pairing of $A$ with~$B$.
    Furthermore, the reverse exact pairing $G$ associated with $F$ is the inverse $G \,=\, F^{-1}:B \,{\rightarrow}\, A$ of the bijection~$F$.

\V

        The simple proof is left as an exercise. %% WRITE UP THE EXERCISE.

\VV


        The reformulation of `exact pairings' in terms of `bijections' given above
    allows one to use known properties of the latter concept to prove some simple facts about `equal cardinality'.


\V
\V

        \subsection{\small{\bf Theorem}}
            \label{ThmA15.15}

\V

\hspace*{\parindent}(a) Let $A$ be a set. Then $A$ has the same cardinality as $A$.

\V

            (b) Let $A$ and $B$ be sets, If $A$ has the same cardinality as $B$ then $B$ has the same cardinality as $A$.


\V

            (c) Let $A$, $B$ and $C$  be sets.
    If $A$ has the same cardinality as $B$, and $B$ has the same cardinality as $C$, then $A$ has the same cardinality as $C$.

\V

            (d) Suppose that $A$, $B$, $C$ and $D$ are nonempty sets such that $A$ has the same cardinality as $C$ and $B$ has the same cardinality as $D$.
    Then $A{\times}B$ has the same cardinality as $C{\times}D$.
\V

            (e) Suppose that $A$ and $B$ are nonempty sets.
    Then $A{\times}B$ and $B{\times}A$ have the same cardinality.

\V

        \underline{Outline of Proof}

\V

        (a) Use the bijection $I_{A}:A \,{\rightarrow}\, A$. (Recall that $I_{A}$ is the `identity map on~$A$'.)

\V

        (b) If $F:A \,{\rightarrow}\, B$ is a bijection of $A$ onto $B$, then $F^{-1}:B \,{\rightarrow}\, A$ is a bijection of $B$ onto $A$.

\V

        (c) If $F:A \,{\rightarrow}\, B$ and $G:B \,{\rightarrow}\, C$ are bijections, 
    then $G{\circ}F:A \,{\rightarrow}\, C$ is a bijection of $A$ onto $C$.

\V

        (d) and (e): The simple proofs are left as an exercise.

\VV

            \subsection{\small{\bf Examples}}
            \label{ExampA15.20}

\hspace*{\parindent}
    (1) Let $A \,=\, \{p,q,r,s,t\}$ be the set consisting of certain (lower case) letters of the English alphabet,
    and let $B \,=\, \{$\mbox{Oh}, \mbox{say}, \mbox{can}, \mbox{you}, \mbox{see}\} be the set consisting of the first few words of the US national anthem.
    There are many different bijections of $A$ onto $B$; here are two examples, viewed as subsets of the Cartesian product $A{\times}B$:

       \h (a) $F_{1} \,=\, \{(p,\mbox{Oh}), (q,\mbox{say}), (r,\mbox{can}), (s,\mbox{you}), (t,\mbox{see})\}$.

       \h (b) $F_{2} \,=\, \{(r,\mbox{you}), (p,\mbox{say}), (t,\mbox{can}), (q,\mbox{Oh}), (s,\mbox{see})\}$.

\V

        (2) Let $A$ be the set ${\NN}$ of all natural numbers,
    and let $B$ be the set of all perfect squares of natural numbers.
    That is,
        \begin{displaymath}
        A \,=\, \{1,2,3,4,5,\,{\ldots}\,\} \mbox{ and } B \,=\, \{1,4,9,16,25,\,{\ldots}\,\}
        \end{displaymath}
    There is an obvious bijection of $A$ onto $B$, namely the function $F:A \,{\rightarrow}\, B$ given by $F(k) \,=\, k^{2}$ for all $k$ in $A$.

\V
            \subsection{\small{\bf Remark}}
            \label{RemrkA15.25}
        Example (2) is originally due to Galileo, in his famous book {\em Dialogues Concerning Two New Sciences}.
    The fact it describes is usually called the `Galileo Paradox'\IndBD{cardinality}{Galileo paradox}. The `paradox' for Galileo, 
    expressed in modern terminology, is the counter-intuitive fact that a set can the same cardinality as one of its {\em proper} subsets.


\V
\V

        The following statements about finite sets fall under the heading of `well-known facts from arithmetic', and thus are accepted here without proof.
    They are listed explicitly here for ease of reference. Their proofs are relegated to Appendix~B.

\V


            \subsection{\small{\bf Theorem}}
            \label{ThmA15.30}

\hspace*{\parindent}(a) Let $X$ be a nonempty finite set. Suppose that there are natural numbers $k$ and $m$ such that $X$
    has the same cardinality as ${\NN}_{k}$ and the same cardinality as ${\NN}_{m}$; then $k \,=\, m$.
    Stated otherwise: if $X$ is a nonempty finite set, then there is a unique natural number $k$ such that $X$ has the same cardinality as ${\NN}_{k}$.

        {\bf Remark} The number $k$ described here is called the {\bf number of elements of of $X$}\IndBD{cardinality}{number of elements of a finite set}.
    One sometimes abbreviates this number as $\#(X)$. It is also convenient to write $\#({\emptyset}) \,=\, 0$.

\V

        (b) If $Y$ is a subset of a finite set $X$, then $Y$ is a finite set, and $\#(Y)\,\,{\leq}\,\,\#(X)$. Moreover, the only time one gets
    $\#(Y) \,=\, \#(X)$ is when $Y \,=\, X$. In particular, $X$ cannot have the same cardinality as one of its proper subsets.

\V

        (c) Suppose that $\{X_{1},X_{2},\,{\ldots}\,X_{n}\}$ is a finite collection of finite sets.
    Then the union $X_{1}\,{\cup}\,X_{2}\,{\cup}\,\,{\ldots}\,\,{\cup}\,X_{n}$ is also a finite set. More precisely,
        \begin{displaymath}
         \#(X_{1}\,{\cup}\,X_{2}\,{\cup}\,\,{\ldots}\,\,{\cup}\,X_{n})
    \,\,{\leq}\,\,
        \#(X_{1}) + \#(X_{2}) + \,{\ldots}\,+\#(X_{n}).
        \end{displaymath}
    One gets equality in this last relation if, and only if, the sets are mutually disjoint,
    in the sense that $X_{i}\,{\cap}\,X_{j} \,=\, {\emptyset}$ whenever $i \,\,{\neq}\,\, j$.

\V

\StartSkip{
            \subsection{\small{\bf Corollary}}
            \label{CorA15.40}

\V

        (a) Let $X$ be a finite nonempty set. Suppose that $f:X \,{\rightarrow}\, X$ is an injection with domain $X$ and values in $X$.
    Then $f$ is also a surjection onto~$X$; thus, $f$ is a bijection of $X$ onto~$X$.

\V

        (b) Let $X$ be any infinite set. If $Y$ is a finite subset of $X$ then $X\,{\setminus}\,Y$ is infinite.

\V

        (c) The set ${\NN}$ is infinite.

\V


        {\bf Proof}\,  (a) Since $f$ is an injection on $X$, its image $Y \,=\, f[X]$ is a subset of the target set $X$
    with the same cardinality as~$X$. Thus by Part~(b) of the previous theorem $Y \,=\, X$,
    so $f$ is also a {\em surjection} onto~$X$, and thus a bijection, as claimed.

\V

        (b) This follows from Part~(c) of the preceding theorem after noting that $X \,=\, (X\,{\setminus}\,Y)\,{\cup}\,Y$.


        (c) Since the `Galileo Paradox' holds in ${\NN}$, it follows from Part~(b) of the preceding theorem that ${\NN}$ cannot be a finite set.
    Thus ${\NN}$ must be an infinite set.

}%\EndSkip

\StartSkip{
            \subsection{\small{\bf Remark}}
            \label{RemrkA15.25}

        Example~(2) shows that it is possible for a set to have the same cardinality as one of its proper subsets.
    This fact is sometimes called the `Galileo Paradox'\IndBD{cardinality}{Galileo Paradox},
    since it was discussed in Galileo's famous book {\em Dialogues Concerning Two New Sciences}.
    It seems likely that Galileo found this situation to be paradoxical because it appears that he held the view that any
    `reasonable' definition of the concept of `number of elements' of an infinite set ought to satisfy the following conditions:

\VA

        \h (i) If there exists a complete pairing of a set $A$ with a set $B$, then $A$ and $B$ have the `same number of elements'; and

        \h (ii) If $B$ is a proper subset of a set $A$, then $A$ and $B$ do {\em not} have the `same number of elements'.

\VA

\noindent In these terms, Example~(2) implies for Galileo that there is no reasonable definition of `number of elements' that could apply to infinite sets; 
    an infinite set is simply infinite, but nothing more detailed along this line can be said.
    In a sense, this `Galilean viewpoint' says that all infinite sets are equally infinite, with none being bigger or smaller than the other.

        In contrast, Cantor was able to develop a theory of sets in which one {\em can}
    usefully formulate a concept of one infinite set having `fewer elements' than another infinite set.
    The key is to drop Condition~(ii) from the requirements for a `reasonable definition'.
    In {\TheseNotes} we consider only a limited portion of Cantor's theory of infinite sets.

\VV


        In light of Galileo's Paradox for infinite sets, it is natural to wonder if there might be an analogous paradox for finite sets.
    That is, could there exist a finite set $X$ which has the same cardinality as one of its proper subsets?
    Similarly, could there exist a finite set $Y$ which simultaneously has the same cardinality as ${\NN}_{k}$ and as ${\NN}_{m}$ for natural numbers $k$ and $m$ such that $k \,\,{\neq}\,\, m$?
    If such sets were to exist, then the entire basis for the `counting' process, which one learns as a child, would fall apart.
    Since in {\TheseNotes} we are allowed to accept as `known' the basic facts concerning natural numbers learned as children,
    including the validity of the `counting process', the short answer is `Don't worry about it!'.
    Nevertheless, it is useful to state some of the facts that we use constantly in carrying out that `counting process'.

}%\EndSkip
    
\V
\V

        Bijections of a finite set onto itself have a special terminology.

            \subsection{\small{\bf Definition}}
            \label{DefA15.50}

\V

        Let $X$ be a finite nonempty set. Then a bijection $f:X \,{\rightarrow}\, X$ is called a {\bf permutation}\IndBD{bijections}{permutations} of~$X$.

\VV

\begin{quotation}
{\footnotesize \underline{\Notes} (on the counting process)\IndB{\notes}{on the counting process}:
    
        (1) Part~(a) of Theorem~\Ref{ThmA15.30} contains the key to the standard process of `counting' the number of elements of a nonempty finite set.
    The phrasing of this result makes it appear, however, that one must first come up with the natural number~$k$ and then find an exact pairing~$F$.
    In practice the method is different.

        For example, suppose that we wish to `count out' a large, but finite, collection $A$ of marbles which sit inside an urn.
    (Why an urn, and not a large box? Basically: It's a tradition in mathematics to use urns -- often Greek urns -- for counting problems.)
    Reach into the urn, pull out a marble while saying `one', and set that marble aside (outside the urn, of course).
    Then reach into the urn again, pull out another marble while saying `two', and set the new marble aside.
    Keep doing this until the marbles in the urn run out.
    The last number $k$ spoken in this process is the number of marbles originally in the urn,
    and the process of pulling out marbles establishes the complete pairing of $A$ with ${\NN}_{k}$.
    In particular, the value of $k$ is established only at the end of the `counting' process, as is the corrresponding complete pairing~$F$.

\V

        (2) The counting process described above uses the infinite set ${\NN} \,=\, \{1,2,3,\,{\ldots}\,99, 100, 101,\,{\ldots}\,\}$ as a `standard comparison set for counting'.
    In contrast, a couple of millenia ago, Julius Caesar probably would have used the set $\{I, II, III, \,{\ldots}\, XCIX, C, CI, \,{\ldots}\,\}$ as his `standard comparison set' for counting counting out the Roman legions.
    In any event, every such `standard comparison set' for counting enjoys the following properties:

        \h (a) The `standard comparison set' has a natural ordering and a unique initial element relative to that ordering.
    For instance, in the set ${\NN}$ the ordering is the usual one, and the initial element is~$1$.

        \h (b) There is a systematic procedure for going from one element of the comparison set to the next higher element.
    For instance, in the set ${\NN}$ the procedure can be stated simply:
    `Add~$1$ to the given element to get the next higher one'.
    To see just how systematic, and well-known, this procedure is, consider the following {\em extremely} large element of ${\NN}$:
        \begin{displaymath}
        37182946822901028333009155404045373779925111110382238549871172499.
        \end{displaymath}
    If this is the first time you are reading this {\em \Note}, then the probability is high that you have never encountered this gigantic number before.
    Indeed, it is so large that relatively few people could actually {\em speak} its name.
    (In the United States its name would start `$37$~vigintillion\,{\ldots}\,'; in Europe it would start `$37$~decilliard\,{\ldots}\,.)
    Nevertheless, what you learned as a child provides all you need to know to write down the next higher natural number; try to do so before reading further.

\V
\V

        You should get
        \begin{displaymath}
        37182946822901028333009155404045373779925111110382238549871172500.
        \end{displaymath}
    (This is one of the great features of the Arabic numerals. Had the original number been expressed in Roman numerals,
    the result might well have been less simple.) The process used in obtaining the successor of the given giant number can be thought of as `adding $1$'.
    However, it is likely that most people would simply look at the digits of the original number and write down the answer directly,
    without really doing `addition' as such.

        \h (c) By starting with the initial element discussed in~(a), and repeating the procedure discussed in (b),
    one eventually obtains every element of the comparison set.

\noindent It turns out that these properties allow one to uniquely construct the other properties of the standard comparison set; see Appendix~A.
}%EndFootnotesize
\end{quotation}



\VV

                        \section{Countable and Uncountable Sets}
                        \label{SectA20}\IndB{ZZ Sections}{\Ref{SectA20} Countable and Uncountable Sets}

            \subsection{\small{\bf Definition}}
            \label{DefA20.30}\IndBD{set theory}{countable sets}\IndBD{set theory}{uncountable sets}

        A set $X$ is said to be {\bf countable} provided either $X$ is finite or $X$ has the same cardinality as ${\NN}$.
    If the latter situation holds, then $X$ is said to be {\bf countably infinite}, or, sometimes, {\bf denumerable}.
    A set which is not countable is said to be {\bf uncountable}.

\V

        \subsection{\small{{\bf Example}}}
        \label{ExampA20.30}

        Let $X \,=\, {\ZZ}$, the set of all integers. Then ${\ZZ}$ is countable; indeed, it is countably infinite.

        Indeed, define $F:{\NN} \,{\rightarrow}\, {\ZZ}$ by the rule
        \begin{displaymath}
        F(1) \,=\, 0; \h F(2\,k) \,=\, k \mbox{ for all $k$ in ${\NN}$};
    \h F(2\,k-1) \,=\, -k \mbox{ for all $k$ in ${\NN}$}.
        \end{displaymath}
    It is easy to see that the map $F:{\NN} \,{\rightarrow}\, {\ZZ}$ is a bijection.


\V

            \subsection{\small{\bf Remarks}}
            \label{RemrkA20.40}

\hspace*{\parindent}(1) The usage of the terms `countable', `countably infinite' and `denumerable' here is quite common in the mathematical literature,
    but many authors follow a slightly different usage. For example, some use `countable' for what we call `countably infinite' or `denumerable';
    for such authors a finite set is not countable. In contrast, some authors use `denumerable' for what we call `countable';
    they would then need to write `denumerably infinite' for what we call `countably infinite'.

\V

        (2) As has already been pointed out, in this chapter we treat the set ${\NN}$ of natural numbers as a `primitive concept' related to `counting'.
    It is clear, however, that any other countably infinite set would work just as well for the purpose of `counting'.
    In Chapter~\Ref{ChaptB} we replace our `primitive' notion of ${\NN}$ with a certain countable subset of the real numbers.
    This subset can be used not just for counting, but also for interacting directly with other real numbers; see Theorem~\Ref{ThmB25.20}.

\V
\V

            \subsection{\small{\bf Theorem}}
            \label{ThmA20.10}

        Let $A$ be a subset of ${\NN}$. Then $A$ is countable. More precisely, $A$ is a finite set if it is bounded in ${\NN}$,
    while it is countably infinite if it is unbounded in~${\NN}$. (As usual, the empty set is viewed as being a bounded subset of~${\NN}$.)

\V

        \underline{Proof}: The result is obviously true if $A \,=\, {\emptyset}$, so without loss of generality assume that $A$ is nonempty.

\V

         \underline{Case 1} Suppose that $A$ is a bounded subset of ${\NN}$, so that
    there exists a natural number $m$ such that $k\,\,{\leq}\,\,m$ for all $k$ in~$A$.
    Then clearly $A \,{\subseteq}\, {\NN}_{m}$ and thus, by Part~(b) of Theorem~\Ref{ThmA15.30}, $A$ is a finite set, and thus $A$ is countable.

        \underline{Case 2} Suppose that $A$ is an unbounded subset of~${\NN}$. The `obvious' choice of a bijection
    $F:{\NN} \,{\rightarrow}\, A$ is given by the following rule:
        \begin{displaymath}
        F(m) \,=\, \mbox{ the $m$-th smallest element of the set $A$}.
        \end{displaymath}
    What follows simply makes this a bit more precise.

        For each element $m$ in $A$ let $A_{m}$ denote the set of all natural numbers $k$ in $A$ such that $k\,\,{\leq}\,\,m$;
    that is, $A_{m} \,=\, A\,{\cap}\,{\NN}_{m}$. Note that $A_{m}$ is nonempty because, by definition, $m$ itself is an element of $A_{m}$.
    Also, $A_{m}$ is a finite set since it is a subset of the finite set ${\NN}_{m}$.
    Now define a function $G:A \,{\rightarrow}\, {\NN}$ by the rule $G(m) \,=\, \#(A_{m})$; that is, $G(m)$ is the number of elements of the finite set~$A_{m}$.

        It is clear that the map $G:A \,{\rightarrow}\, {\NN}$ is a surjection. Indeed, let $B \,=\, G[X]$. Note that if $m$ is the smallest element of $A$, which exists by the Least-Natural-Number Principle,
    then $A_{m} \,=\, \{m\}$, so that $G(m) \,=\, 1$; that is, $1{\in}B$. Firthermore, suppose that $k{\in}B$, so that there exists $m$ in $A$ such that $k \,=\, \#(A_{m})$.
    Let $n$ be the smallest element of the nonempty set $A\,{\setminus}\,A_{m}$. Then clearly $A_{n} \,=\, A_{m}\,{\cup}\,\{n\}$.
    Since $n \not \in A_{m}$, it follows that $\#(X_{n}) \,=\,\#(A_{m}) + 1 \,=\, k+1$; that is, $k+1 \,=\, G(n)$, so $(k+1){\in}B$.
    It now follows from the Principle of Mathematical Induction that $B \,=\, {\NN}$, so that the function $G:A \,{\rightarrow}\, {\NN}$ is a surjection.

        Likewise, it is clear that the function $G:A \,{\rightarrow}\, {\NN}$ is an injection.
    Indeed, suppose that $m$ and $n$ are elements of $A$ with $m \,\,{\neq}\,\, n$; without lose of generality, assume that $m\,<\,n$.
    Then it is clear that $A_{m}$ is a {\em proper} subset of $A_{n}$, so that $\#(A_{m})\,<\,\#(A_{n})$; that is, $G(m)\,<\,G(n)$.

        It follows that the map $G:A \,{\rightarrow}\, {\NN}$ is a bijection. Let $F \,=\, G^{-1}:{\NN} \,{\rightarrow}\, A$.
    Then $F:{\NN} \,{\rightarrow}\, A$ is also a bijection, and it follows that $A$ is a countable set, as required; indeed, $A$ is countably infinite.

\VV

            \subsection{\small{\bf Remarks}}
            \label{RemrkA20.10B}

\V

\hspace*{\parindent}(1) It is clear that $F$ is strictly increasing on $\Bfm{{\NN}}$,
    in the sense that $F(i)\,<\,F(j)$ whenever $i, j$ in ${\NN}$ satisfy $i\,<\,j$.
    Conversely, $F:{\NN} \,{\rightarrow}\, A$ is the only bijection with this property.
    For that reason, in {\ThisText} we refer to the map $F$ just constructed as the {\bf strictly increasing map of $\Bfm{{\NN}}$ onto $\Bfm{A}$}
    \IndBD{functions}{strictly increasing maps of ${\NN}$ into ${\NN}$}; we denote this bijection by ${\Psi}_{A}$. (The latter notation is \underline{not} standard.)
    Clearly the quantity ${\Psi}_{A}(k)$ agrees with one's intuitive concept of the $k$-th smallest element of the subset~$A$.

\V

        (2) It is an easy exercise to show that if $F:{\NN} \,{\rightarrow}\, {\NN}$ is a strictly increasing function with values in ${\NN}$,
    then for each $k$ in ${\NN}$ one has $F(k)\,\,{\geq}\,\,k$. Futhermore, if $F(n) \,=\, n$ for a particular $n$ in ${\NN}$,
    then $F(k) \,=\, k$ for all $k$ in ${\NN}$ such that $1\,\,{\leq}\,\,k\,\,{\leq}\,\,n$.

\V

        (3) If $A$ is an infinite subset of ${\NN}$, then it is possible to express $A$ as $A \,=\, \{k_{1}, k_{2}, \,{\ldots}\,k_{m},\,{\ldots}\,\}$,
    with each $k_{m}$ being an element of~${\NN}$. However, the set notation allows the possibility that the numbers
    $k_{1}$, $k_{2}$ and so on are not in increasing order; indeed, it allows the possibility that the same number may appear more than once in this list.
    Of course one could simply append the phrase `where $k_{1}\,<\,k_{2}\,<\,\,{\ldots}\,\,<\,k_{m}\,<\,{\cdot}$' to the equation;
    but this gets tedious when done repeatedly. Another shorter solution is to add the phrase `where $k_{m} \,=\, {\Psi}_{A}(m)$'.
    However, the most common solution is to write instead $A \,=\, \{k_{1}\,<\,k_{2}\,<\,\,{\ldots}\,k_{m}\,<\,\,{\ldots}\,\}$.
    In {\ThisText} we usually follow the last approach.

%% EXERCISE

\VV


            \subsection{\small{\bf Corollary}}
            \label{CorA20.20}

\V

        If one removes a finite subset from ${\NN}$, what remains still has the same cardinality of the original set ${\NN}$.

\V

        \underline{Proof} This follows from the preceding theorem by noting that  removing a bounded subset from ${\NN}$ leaves an unbounded subset of ${\NN}$.

\V

        \underline{Remarks}:

\V

        (1) One tends to feel that a finite set which has a very, very large number of elements is `a nearly infinite set'.
    The preceding corollary says that this feeling, although perhaps natural, is very, very misleading.

\V

        (2) Note that Chapter Quote~(4) for this chapter provides a poetic illustration of the content of the preceding corollary:
    `removing' the first $10,000$ numbers from ${\NN}$ does not diminish the `size' of the set of numbers remaining.
    Because of the source of this quote, we refer to this corollary as the {\bf Amazing Grace Property for $\Bfm{{\NN}}$}.
\IndB{Amazing Grace property}{for ${\NN}$}


\V

        (3) The situation becomes more complicated if one removes an {\em infinite} set from ${\NN}$.
    Indeed, the resulting set may have the same cardinality as ${\NN}$ (e.g., remove all the odd numbers),
    or it may be a finite set (e.g., remove all the natural numbers greater than~$5$).

\V
\V


        The next result gives analogs, for general countable sets, of parts of Theorem~\Ref{ThmA20.10} and Corollary~\Ref{CorA20.20};
    the simple proof is left to the reader.


            \subsection{\small{\bf Theorem}}
            \label{ThmA20.50}

        \hspace*{\parindent}(a) Every subset of a countable set is also countable.

\V

        (b) If $Y$ is an infinite subset of a countably infinite set, then $Y$ is countably infinite.

\V

        (c) (`Amazing Grace' Property of Countably Infinite Sets) \IndB{Amazing Grace property}{for countably infinite sets}
    If one removes a finite subset from a countably infinite set, then what remains is a countably infinite set.

\V
\V

        The next theorem provides a useful tool for proving that a given nonempty set is countable without actually needing to find a bijection.


\V

            \subsection{\small{\bf Theorem}}
            \label{ThmA20.25A}

\V

        Suppose that $Y$ is a nonempty set. Then a necessary and sufficient condition
    for $Y$ to be countable is that there exist a surjection of ${\NN}$ onto~$Y$.


\V

        {\bf Proof} Suppose that there exists a function $f:{\NN} \,{\rightarrow}\, Y$ of ${\NN}$ onto~$Y$.
    Define a corresponding function $h:Y \,{\rightarrow}\, {\NN}$ by the rule that if $y{\in}Y$,
    then $h(y)$ is the smallest element of the subset $f^{-1}[\{y\}]$. (This subset of ${\NN}$ is nonempty because $f$ maps ${\NN}$ onto~$Y$.
    The existence of a unique {\em smallest} element of this set then follows from the Least-Natural-Number Principle.)
    Let $W \,=\, h[Y]$. It is clear that $h:Y \,{\rightarrow}\, W$ is a bijection of $Y$ onto~$W$. Indeed, $h$ automatically maps $Y$ onto~$h[Y]$.
    Furthermore, the fact that $h$ is one-to-one follows from the fact that $f(h(y)) \,=\, y$ for each $y$ in $Y$,
    so that $h(y_{1}) \,=\, h(y_{2})$ implies $y_{1} \,=\, y_{2}$ because $f$ is a function and thus has a unique values at each point.
    It follows from the proceding that $Y$ has the same cardinality as a nonempty subset of ${\NN}$.
    It then follows from Theorem~\Ref{ThmA20.10} and Theorem~\Ref{ThmA15.15} that $Y$ is countable, as claimed.

        The proof of the converse, namely that if $Y$ is countable then there exists a surjection of ${\NN}$ onto~$Y$, is obvious and is left to the reader.

\V

            \subsection{\small{\bf Corollary}}
            \label{CorA20.25B}

\V

        Suppose that $Y$ is a nonempty set. Then a necessary and sufficient condition
    for $Y$ to be countable is that for every countably infinite set $X$ there exist a surjection of $X$ onto~$Y$.

\V

        The trivial proof is left as an exercise.

\VV

        {\bf Remark} By expressing the preceding results in terms of surjections, and not bijections,
    we are able to prove some theorems about `countability' without needing to always separate into separate `finite' and `countably infinite' cases.
    An important tool for doing that is the following result.


\VV

            \subsection{\small{\bf Important Example}}
            \label{ExampA20.60}

        There is a well-known fact about natural numbers which one learns in elementary arithmetic:
    If $m{\in}{\NN}$, then there are unique natural numbers $k$ and $n$ such that $m \,=\, 2^{k-1}(2n-1)$.
    That is, $m$ can be expressed, in exactly one way, as the product of a (nonnegative) power of $2$ multiplied by an odd natural number.
    For instance:
        \begin{displaymath}
        36 \,=\, 2{\cdot}18 \,=\, 2^{2}{\cdot}9 \,=\, 2^{2}{\cdot}(2{\cdot}5-1).
        \end{displaymath}
    Thus, in this case $k \,=\, 3$ and $n \,=\, 5$.

        Now for each $k$ in ${\NN}$ let $X_{k}$ denote the set of  all natural numbers of the form $2^{k-1}(2n-1)$ for $n$ in ${\NN}$.
    That is,
        \begin{displaymath}
        X_{k} \,=\, \{2^{k-1}{\cdot}1, 2^{k-1}{\cdot}3, 2^{k-1}{\cdot}5,\,{\ldots}\,2^{k-1}{\cdot}(2n-1),\,{\ldots}\,\}
        \end{displaymath}
    Note that these sets form a countably infinite family $\{X_{1},X_{2},\,{\ldots}\,X_{n},\,{\ldots}\,\}$ of subsets of ${\NN}$ such that

       \h (i)\,\, Each set $X_{k}$ is countably infinite; indeed, one obvious bijection of ${\NN}$ with $X_{k}$ is given by the rule $f_{k}(n) \,=\, 2^{k-1}(2n-1)$ for each $n$ in~${\NN}$.

       \h (ii)\, If $k \,\,{\neq}\,\, l$ then $X_{k}\,{\cap}\,X_{l} \,=\, {\emptyset}$;
    that is, the sets in this family are pairwise disjoint;

       \h (iii) ${\bigcup}_{k=1}^{{\infty}} X_{k} \,=\, {\NN}$.

\VA

    The next result illustrates how one can use this decomposition.

\StartSkip{

        The set ${\NN}$ of all natural numbers plays a central role in the theory of sets.
    We begin this section by studying some of the set-theoretic properties of the set ${\NN}$.
    The most important tools for this study are the Principle of Mathematical Induction and the Least-Natural-Number Principle;
    see Theorem~\Ref{PrinA10.11} above. We repeat them here for convenience.

\V


            \subsection{\small{\bf Two Principal Principles}}
            \label{PrinA20.02B}

\hspace*{\parindent}(1) (Principle of Mathematical Induction) \IndB{natural numbers}{mathematical induction, principle of} Suppose that $A$ is a set of natural numbers such that $1{\in}A$, and $k+1$ is in $A$ whenever $k$ is. Then every natural number is a member of $A$.

\V

        (2) (Least-Natural-Number Principle) \IndB{natural numbers}{least natural number, principle of}
    Suppose that $C$ is a nonempty subset of ${\NN}$. Then $C$ has a smallest element; that is, there is a unique natural number $m$ such that

        \h (i)\, $m$ is an element of $C$, and

        \h (ii) if $k$ is any element of $C$, then $m\,\,{\leq}\,\,k$.

\VV


        The next results summarize, and expand on, the content of Parts~(4) and~(5) of Theorem~\Ref{PrinA10.11} above.

\V

 %           \subsection{\small{\bf Definition}}
%            \label{DefA20.05}\IndBD{bounded, unbounded}{subsets of ${\NN}$}

        Recall that a nonempty subset $X$ of ${\NN}$ is said to be {\bf bounded in ${\NN}$}\IndB{bounded, unbounded}{subsets in ${\NN}$}

    if there exists $m$ in ${\NN}$ such that $x\,\,{\leq}\,\,m$ for all $x$ in $X$; equivalently, if there exists $m$ such that $X \,{\subseteq}\, {\NN}_{m}$.
    If no such $m$ exists, then $X$ is said to be {\bf unbounded}.

        By convention, the empty set is said to be a bounded subset of ${\NN}$.

\V
\V



%\StartSkip{

        The following result has been known since at least the time of the ancient Greek geometers;
    indeed, the (standard) proof given here is usually attributed to Euclid.

\V

            \subsection{\small{\bf Theorem}}
            \label{ThmA20.25}

\V


        There are infinitely many prime numbers.

\V

        {\bf Proof}\,  Let $k$ be a natural number, and let $N \,=\, 1+(1{\cdot}2{\cdot}\,{\ldots}\,{\cdot}k)$.
    It is clear that if $m$ is any natural number such that $2\,\,{\leq}\,\,m\,\,{\leq}\,\,k$ then $m$ is {\em not} a factor of $N$.
    Indeed, if $N \,=\, m{\cdot}n$ for some natural number $n$ then one has
        \begin{displaymath}
        m{\cdot}n \,=\, 1+(1{\cdot}2{\cdot}\,{\ldots}\,{\cdot}k), \mbox{ hence }
    1 \,=\, m{\cdot}n - (1{\cdot}2{\cdot}\,{\ldots}\,{\cdot}k)
        \end{displaymath}
    However, both terms on the right have $m$ as a factor, so one can write
        \begin{displaymath}
        1 \,=\, m{\cdot}q \mbox{ where } q \,=\, n-(1{\cdot}\,{\ldots}\,(m-1){\cdot}(m+1){\cdot}\,{\ldots}\,k).
        \end{displaymath}
    That is, if $N$ has a factor $m$ such that $2\,\,{\leq}\,\,m\,\,{\leq}\,\,k$, then $1$ can be expressed as the product of natural numbers one of which is bigger than~$1$, a clear impossibility.

        Thus, one can conclude that if $m$ is any factor of $N$ such that $m\,\,{\geq}\,\,2$, then $m\,>\,k$.
    But $N$ is either prime or it is composite. If it is prime, then it is a prime number bigger than $k$.
    And if it is composite then, by Lemma~\Ref{LemmaA20.04C}, it has prime factors, which by what has just been proved must also be bigger than $k$.

        In other words, if $k$ is any natural number then there exists at least one prime number bigger than~$k$.
    That is, the set of prime numbers is not bounded, and thus, by Part~(c) of Theorem~\Ref{ThmA20.10}, the set of prime numbers is an infinite subset of ${\NN}$.


\VV

}%\EndSkip



\V
\V

            \subsection{\small{\bf Theorem}}
            \label{ThmA20.70}

        Suppose that $S$ is a set which can be expressed as the union of a nonempty countable family of countable nonempty sets.
    Then $S$ is itself a countable set.

\V

        \underline{Proof}: Let ${\cal F}$ be a nonempty countable family of nonempty countable sets such that $S \,=\, {\bigcup}\,{\cal F}$.
    It follows from Theorem~\Ref{ThmA20.25A} that there exists a surjection $f:{\NN} \,{\rightarrow}\, S$ of ${\NN}$ onto~${\cal F}$.
    As in Example~\Ref{ExampA20.60} above, for each $k$ in ${\NN}$ let $X_{k}$ be the countably infinite subset of ${\NN}$
    consisting of all natural numbers of the form $2^{k-1}\,(2\,n-1)$ with $n$ in ${\NN}$.
    For each $k$ in ${\NN}$ let $g_{k}: X_{k} \,{\rightarrow}\, S$ be a surjection of the countably infinite $X_{k}$ onto the countable subset~$f(k)$.
    Since the sets of the form $X_{k}$, with $k$ in ${\NN}$, are mutually disjoint,
    it follows from Theorem~\Ref{ThmA30.27}, the `Union-of-Finctions Theorem', that
    there is a function $g:{\NN} \,{\rightarrow}\, S$ such that for each $k$ in ${\NN}$ one has $g_{k} \,=\, g|_{X_{k}}$.
    It is clear that $g:{\NN} \,{\rightarrow}\, S$ is a surjection, and thus, by Corollary~\Ref{CorA20.25B}, the set $S$ is countable, as claimed.
  
\V

            \subsection{\small{\bf Corollary}}
            \label{CorA20.80}

        The following sets are all countably infinite.

        (a) The Cartesian product ${\NN}{\times}{\NN}$.

\V

        (b) The set ${\ZZ}$ of all integers.

\V

        (c) The set ${\QQ}^{+}$ of all positive rational numbers.

\V

        (d) The set ${\QQ}$ of {\em all} rational numbers.

\V

        \underline{Proof}: Note first that each of the sets mentioned above is obviously an infinite set, so we need only prove they are all countable.

\V

        (a) For each $k$ in ${\NN}$ let $Y_{k}$ be the set of all ordered pairs of the form $(k,m)$ for $m$ in ${\NN}$,
    and let ${\cal F}$ be the family of all sets of the form $Y_{k}$ with $k$ in~${\NN}$.
    It is obvious that ${\cal F}$ is a countably infinite family of countable sets, and that the union of this family is~${\NN}{\times}{\NN}$.
    It follows from Theorem~\Ref{ThmA20.70} that ${\NN}{\times}{\NN}$ is countable.

\V

        (b) Define a map $f:{\NN}{\times}{\NN} \,{\rightarrow}\, {\ZZ}$ by the rule $f(m,n) \,=\, n-m$ for all pairs $(m,n)$ in~${\NN}{\times}{\NN}$.
    It is clear that $f$ is a surjection of the countable set ${\NN}{\times}{\NN}$ onto the set~${\ZZ}$.
    It follows from Theorem~\Ref{ThmA20.25A} that ${\ZZ}$ is countable. (Note that we gave a more direct proof of this fact above in Exampl~\Ref{ExampA20.30}.)

\V

        (c) Define a function $g:{\NN}{\times}{\NN} \,{\rightarrow}\, {\QQ}^{+}$ by the rule $g(m,n) \,=\, m/n$ for each pair $(m,n)$ in ${\NN}{\times}{\NN}$.
    By definition of `rational numbers', it is clear that $g$ is a surjection of the countable set ${\NN}{\times}{\NN}$ onto the infinite set~${\QQ}^{+}$.
    It follows as before that ${\QQ}^{+}$ is countable.

\V

        (d) The proof of this is left as an exercise. %% EXERCISE? ALSO, EXERCISE PROVING PART (A) USING FACTORIZATION n = 2^{k-1}(2m-1)? 


\VV


        The fact that ${\QQ}$ has the same cardinality as ${\NN}$ (see Corollary~\Ref{CorA20.80} above) should appear counter-intuitive:
    Geometrically speaking, the natural numbers are scattered discretely along the positive real axis;
    in particular, any interval of length less than one has at most one natural number in it.
    In contrast, the real axis is `densely populated' by rationals; more precisely,
    every interval in the real axis of positive length, no matter how small, contains infinitely many rational numbers.

        Once one accepts the fact that ${\QQ}$ is countably infinite, it then is natural to conjecture that {\em all} infinite sets are countably infinite.
    If this conjecture were valid, then the `Galileo Paradox' (see Remark~\Ref{RemrkA15.25})
    could be interpreted to say that no infinite set is `larger' than any other infinite set. The next example shows that this conjecture is not correct.

\V

            \subsection{\small{\bf Example} (Existence of Uncountable Sets)}
            \label{ExampA20.85}

        Let $Y$ be the set of real numbers $y$ in the closed interval $[0,1]$ such that $y$ admits a decimal representation
    of the form $y \,=\, 0.d_{1}\,d_{2}\,\,{\ldots}\,d_{n}\,\,{\ldots}\,$, where each decimal digit $d_{n}$ is either $0$ or~$9$.
    It is clear from well-known properties of the decimal representation of real numbers that if $y \,=\, 0.d_{1}\,d_{2}\,\,{\ldots}\,d_{n}\,\,{\ldots}\,$
    and $y' \,=\, 0.d_{1}'\,d_{2}'\,\,{\ldots}\,d_{n}'\,\,{\ldots}\,$ are such decimal representations of numbers $y$ and~$y'$,
    respectively, then $y \,=\, y'$ if, and only if, $d_{n} \,=\, d_{n}'$ for each number $n$ in ${\NN}$.

\V

        \underline{Claim} If $F:{\NN} \,{\rightarrow}\, Y$ is a function with domain ${\NN}$ and with values in the set $Y$, then it is not a surjection.
    In particular, it follows from Theorem~\Ref{ThmA20.25A} that the set $Y$ is uncountable.

\V

        \underline{Proof of Claim} Define a number $z \,=\, 0.c_{1}\,c_{2}\,\,{\ldots}\,c_{n}\,\,{\ldots}\,$ in $Y$ by the following rule:
    if the $n$-th decimal digit of $F(n)$ is~$0$, then $c_{n} \,=\, 9$; but if the $n$-th decimal digit of $F(n)$ is~$9$, then $c_{n} \,=\, 0$.
    It is clear that $z$ is in $Y$, and that for each $n$ the $n$-th decimal digit of $z$ differs from the $n$-th decimal digit of~$F(n)$.
    It follows that for each $n$ one has $z \,\,{\neq}\,\, F(n)$. In particular, $z$ is not in the image of the function $F$,
    hence $F$ does not map ${\NN}$ onto~$Y$, as claimed

\VV

        {\bf Remarks} (1) The description of the set $Y$ above uses familiar properties of the decimal representation of real numbers.
    In the current chapter we take such properties for granted, but later we prove them rigorously using the axioms for ${\RR}$ in Chapter~\Ref{ChaptB}.

\V

        (2) The set $Y$ constructed above is sometimes called the {\bf Cantor Middle-Eight-Tenths Set};
    \IndBD{set theory}{Cantor middle-eight-tenths set} see the exercises for an explanation for this name.
    %EXERCISE
    This set is just one of a family of similar subsets of ${\RR}$, called {\bf Cantor sets}\IndBD{set theory}{Cantor sets},
    which play an important role in analysis; such sets are studied in more detail in Appendix~B.

\VV


                        \section{Sequences and Subsequences}                        
                            \label{SectA40}\IndB{ZZ Sections}{\Ref{SectA40} Sequences and Subsequences}

\V

        {\bf Preliminaries} The intuitive concept of an `infinite sequence' is quite ancient, and should be familiar to everyone.
    The usual presentation of this idea is that it is an `infinite ordered list of objects': $(x_{1}, x_{2},\,{\ldots}\,x_{k},\,{\ldots}\,)$.
    For example, associated with the rational number $1/12$ is the repeating decimal representation $0.08333\,{\ldots}\,$.
    This decimal expression actually encodes the sequence $(0.0, 0.08, 0.083, 0.0833,\,{\ldots}\,)$ of all the truncated decimal approximations of~$1/12$.
    The view of a `sequence' being an ordered list of objects also matches the use of this word in ordinary English.

        It is assumed above that the reader already understands what it means to be an `ordered list of objects';
    that is, it is treated as a `primitive concept': `You know one when you see one'.
    In practice this viewpoint causes no logical difficulties, and indeed much of the time we find it the most useful way to interpret this concept.      
    However, one of the goals of modern mathematics is to formulate all important concepts ultimately in terms of set theory.
    The standard approach, which is presented below, is based on the following observation:
    in an ordered list of the type we are considering, there is a first object in the list,
    followed by the second object, then the third object, and so on; the process never stops.
    The next definition formulates this primitive concept in a a modern way using the `function' concept.

\V

        \subsection{\small{{\bf Definition}}}
        \label{DefA40.20}\IndB{sequences}{ {\bf definition of a sequence}}

\V

        Let $X$ be a nonempty set of objects.

\V

        (1) A function ${\xi}:{\NN} \,{\rightarrow}\, X$, whose domain is ${\NN}$ and whose values are all in $X$,
    is said to be an {\bf infinite sequence in $\Bfm{X}$}.
    If $j{\in}{\NN}$ then the point ${\xi}(j)$ is called the {\bf $\Bfm{j}$-th term of the sequence ${\xi}$}\IndBD{sequences}{terms of a sequence}.
    \IndBD{sequences}{infinite sequences}

\V

        (2) The set $\{x_{1}, x_{2},\,{\ldots}\,x_{k},\,{\ldots}\,\}$, whose elements are the terms of the sequence ${\xi}$,
    is called the {\bf term-set}\IndBD{sequences}{term-set of a sequence} of the sequence~${\xi}$, and in {\ThisText} is denoted by~$S_{{\xi}}$.


\VV

        \underline{Notes} (1) We shall use both the `function' interpretation of sequences, as given in the preceding definition,
    as well as the classic `ordered list' interpretation. It is always easy to reformulate the one in terms of the other.

\V

        (2) In the context of sequences, we often refer to a natural number which appear as a subscript,
    such as the $j$ in the expression $x_{j}$, as an {\bf index} (plural: `indices').\IndBD{sequences}{index; indices}

\VV

        \subsection{\small{{\bf Examples}}}
        \label{ExampA40.30}

\hspace*{\parindent}
        (1) Let $X$ be a nonempty set, and let $c$ be any element of $X$. Suppose that ${\xi}:{\NN} \,{\rightarrow}\, X$ is a constant function,
    with ${\xi}(k) \,=\, c$ for all $k$ in ${\NN}$. Then ${\xi}$ corresponds to the `constant ordered list' $(c,c,\,{\ldots}\,c,\,{\ldots}\,)$.
    We often refer to such a sequence as a {\bf constant sequence}\IndBD{sequences}{constant sequences}.
    The term-set for this sequence is the singleton set $S_{{\xi}} \,=\, \{c\}$.

\V

        (2) Consider the list $(1,0,1,0,1,0,\,{\ldots}\,)$; the pattern should be easy to discern.
    This list can be described by a function ${\xi}:{\NN} \,{\rightarrow}\, {\ZZ}$ using the following rule:
        \begin{displaymath}
        {\xi}(k) \,=\, 
        \left\{
        \begin{array}{ll}
        1 & \mbox{if $k$ is odd} \\
        0 & \mbox{if $0$ if $k$ is even}
        \end{array}
                        \right.
        \end{displaymath}
    The reader is encouraged to show that the function ${\xi}$ can also be described by a single formula:
        \begin{displaymath}
        {\xi}(k) \,=\, \frac{1 - (-1)^{k}}{2} \mbox{ for all $k$ in ${\NN}$}.
        \end{displaymath}

        In contrast, consider a similar ordered list $(0,1,0,1,0,1,\,{\ldots}\,)$.
    It is described by the function ${\zeta}:{\NN} \,{\rightarrow}\, {\ZZ}$
    whose formula can be written as follows:
        \begin{displaymath}
        {\zeta}(k) \,=\, \frac{1 + (-1)^{k}}{2} \mbox{ for all $k$ in ${\NN}$}.
        \end{displaymath}
    It is clear that the functions ${\xi}$ and ${\zeta}$ are not equal to each other; for example, ${\xi}(1) \,=\, 1$ while ${\zeta}(1) \,=\, 0$.
    That is, the two sequences here, although they are very similar, do not equal each other. (See Remark~(1) below as well.)

        Note that the sequences ${\xi}$ and ${\zeta}$ have the same (doubleton) term-sets:
        \begin{displaymath}
        S_{{\xi}} \,=\, \{1,0\} \mbox{ while } S_{{\zeta}} \,=\, \{0,1\} \,=\, \{1,0\}.
        \end{displaymath}

\V

        (3) The sequence $\left({\displaystyle 1, \frac{1}{2}, \frac{1}{3},\,{\ldots}\,\frac{1}{k},\,{\ldots}\,}\right)$,
    whose $k$-th term is the number $1/k$, is called the {\bf harmonic sequence}.\IndBD{sequences}{harmonic sequence}

        Similarly, the sequence ${\displaystyle \left(1, -\frac{1}{2}, \frac{1}{3}, -\frac{1}{4},\,{\ldots}\,(-1)^{k-1}\frac{1}{k},\,{\ldots}\,\right)}$ is called the {\bf alternating harmonic sequence},\IndBD{sequences}{alternating harmonic sequence}
    since it is obtained by alternating the signs of the terms of the harmonic sequence.

\V

        (4) A sequence of the form $(A, A\,r, A\,r^{2},\,{\ldots}\,A\,r^{n},\,{\ldots}\,)$ is called a {\bf geometric sequence with initial term $\Bfm{A}$ and common ratio $\Bfm{r}$}.\IndBD{sequences}{geometric sequences}
    If either $A$ or $r$ equals zero, the correspond sequence is of little interest: $(0,0,\,{\ldots}\,0,\,{\ldots}\,)$ or $(A,0,0\,{\ldots}\,0)$.
    In the more interesting case that $A \,\,{\neq}\,\, 0$ and $r \,\,{\neq}\,\, 0$, one has $r \,=\, (A\,r^{n+1})/(Ar^{n})$ for each $n$.
    This explains the `$r$ is the common ratio' terminology. Of course, it is clear why $A$ is called the `initial term' of this sequence.

\VV

        \underline{Remarks}

\V

        (1) Many authors would abbreviate the notation $(x_{1}, x_{2}, \,{\ldots}\,x_{k},\,{\ldots}\,)$
    for a sequence ${\xi}$ by the expression $\{x_{k}: k{\in}{\NN}\}$, or even by just $\{x_{k}\}$ with the tacit understanding that the index $k$ ranges over the set~${\NN}$.
    In particular, they would use the `braces' $\{$ and $\}$, instead of our use of the parentheses $($ and $)$ as the delimiters.

    Unfortunately, the notation $\{x_{k}: k{\in}{\NN}\}$ is also a common abbreviation for the {\em set of values} $\{x_{1}, x_{2},\,{\ldots}\,x_{k}, \,{\ldots}\,\}$
    of the function~${\xi}$; that is, the term-set $S_{{\xi}}$ as described above. As Example~(2) above illustrates, however,
    two different sequences can have the same term-set, so this `braces' notation can lead to confusion.
    To avoid such confusion is why we prefer to use the `parentheses' notation for sequences in {\ThisText}.

\V

        (2) In {\ThisText} we often follow the common custom of abbreviating the phrase `infinite sequence' to just `sequence'.
    The analogous concept of `finite sequence' has already been described in the discussion of `ordered tuples';
    see the beginning of Section~\Ref{SectA12}, where this idea is treated as a `primitive concept'.

\VV

        {\bf Subsequences of an Infinite Sequence}
    \IndBD{sequences}{subsequences}

\V
\V

        There is an important technique for constructing new sequences from a given sequence.

\V

        {\bf Preliminary Example} Let ${\xi} \,=\, (x_{1}, x_{2},\,{\ldots}\, x_{k},\,{\ldots}\,)$ be the Alternating Harmonic Sequence described above;
    thus, ${\xi}(k) \,=\, x_{k} \,=\, (-1)^{k-1}/k$ for each natural number~$k$. The corresponding ordered list is
        \begin{displaymath}
        {\xi} \,=\, 
        (x_{1}, x_{2},\,{\ldots}\,x_{k},\,{\ldots}\,)
    \,=\,
        \left(1, -\frac{1}{2}, \frac{1}{3}, -\frac{1}{4},\,{\ldots}\,\right)
    \h ({\ast})
        \end{displaymath} 
    If one deletes from this list the terms $x_{k}$ with index $k$ even, and the retains, in their original order, the terms $x_{k}$ with index $k$ odd,
    one obtains an infinite ordered `sublist' ${\zeta} \,=\, (z_{1}, z_{2},\,{\ldots}\,z_{m},\,{\ldots}\,)$ of the original list ${\xi}$:
        \begin{displaymath}
        {\zeta} \,=\, \left(1, \frac{1}{3}, \frac{1}{5}, \,{\ldots}\,\frac{1}{2\,m-1}\,{\ldots}\,\right);
        \end{displaymath}
    in the `function' viewpoint, one has ${\zeta}(m) \,=\, 1/(2\,m-1)$ for each $m$ in~${\NN}$.

        The key step in forming the `sublist' ${\zeta}$ from the original list ${\xi}$ is choosing the set $A$ of which indices $k$ to retain;
    in this example, $A \,=\, \{1, 3, 5, \,{\ldots}\,(2\,m-1),\,{\ldots}\,\}$.

        Now let us repeat this `deletion/retention' process to form a third ordered list ${\tau} \,=\, (t_{1}, t_{2},\,{\ldots}\,t_{n},\,{\ldots}\,)$.
    More precisely, let ${\tau}$ be the list obtained from the subsequence ${\zeta}$ by retaining
    the terms $z_{m}$ for which $2\,m-1$ is a multiple of~$3$ and deleting the others.
    One sees easily that the retained terms are $z_{m}$ with $m$ of the form $m \,=\, 2 + 3\,(n-1)$ with $n$ in~${\NN}$;
    that is, with $m \,=\, 2, 5, 8, 11, \,{\ldots}\,$
        \begin{displaymath}
        {\tau} \,=\, \left(\frac{1}{3}, \frac{1}{9}, \frac{1}{15},\,{\ldots}\,\right)
        \end{displaymath}
    Note that ${\tau}$ can be interpreted simultaneously as a sublist of ${\zeta}$, and thus a {\em sub}sublist of the original list~${\xi}$,
    and also directly as a sublist of the original list~${\xi}$. In the former interpretation, the list ${\tau}$ is obtained
    by retaining the terms $z_{m}$ for which $m$ is in the set $B \,=\, \{2, 5, 8, \,{\ldots}\}$.
    In the latter interpretation, the list ${\tau}$ is obtained from the original list ${\xi}$ by retaining the terms $x_{k}$
    for which $k$ is in the set $C \,=\, \{3, 9, 15, \,{\ldots}\,\}$. That is, one can obtain the subsublist ${\tau}$ from the original list ${\xi}$
    in two stages: first, delete the indices $k$ with $k$ even, retaining the indices in the set $A$ described above;
    then delete even more indices $k$ from $A$ to get the retained indices forming the set~$C$.

        These ideas are extended and formalized in the following definition. However, instead of using words such as `sublist' or `subsublist',
    we follow the usual custom and use words such as `subsequence' and `subsubsequence'.

\VV


        \subsection{\small{{\bf Definition}}}
        \label{DefA40.40}

        Let $X$ be a nonempty set, and let ${\xi} \,=\, (x_{1}, x_{2},\,{\ldots}\,)$ be an infinite sequence in~$X$.

\V

            (1) Suppose that $A \,=\, \{k_{1}\,<\,k_{2}\,<\,\,{\ldots}\,\,<\,k_{m}\,<\,\,{\ldots}\,\}$ is an infinite subset of~${\NN}$.
    (See Part~(3) of Remark~\Ref{RemrkA20.10B} for an explanation of this notation.)
    Then the sequence ${\zeta} \,=\, (x_{k_{1}}, x_{k_{2}},\,{\ldots}\,x_{k_{m}},\,{\ldots}\,)$
    is called the {\bf subsequence of $\Bfm{{\xi}}$ determined by the set $\Bfm{A}$}.
    \IndBD{sequences}{subsequence determined by an infinite subset of ${\NN}$} Equivalently, ${\zeta} \,=\, {\xi}{\circ}{\Psi}_{A}:{\NN} \,{\rightarrow}\, X$,
    where ${\Psi}_{A}:{\NN} \,{\rightarrow}\, A$ is the strictly increasing map of ${\NN}$ onto $A$ described in Part~(1) of Remark~\Ref{RemrkA20.10B};
    that is, ${\Psi}_{A}(m)$ is the $m$-th smallest element of the set~$A$. In {\ThisText},
    the subsequence ${\zeta}$ arising from ${\xi}$ this way is denoted~${\xi}_{A}$.
    (The notation ${\xi}_{A}$ is not standard, but it is convenient.)

\V

        (2) More generally, let $m$ be a natural number. Suppose that ${\cal A} \,=\, (A_{1}, A_{2},\,{\ldots}\,A_{m})$
    is an ordered $m$-tuple of infinite subsets of~${\NN}$ such that $A_{j} \,{\subseteq}\, A_{j+1}$ for each $j \,=\, 1,2,\,{\ldots}\,m-1$.
    One calls ${\cal A}$ a {\bf subsequence structure of order \Bfm{m}}.\IndBD{sequences}{subsequence structures of finite order}
        Furthermore, the sequence ${\xi}_{A_{m}}$ is called the {\bf $\Bfm{m}$-th order subsequence of $\Bfm{{\xi}}
    $\IndBD{sequences}{subsequences of order $m$} associated with the subsequence structure~${\cal A}$}.

\V

        \underline{Note} A subsequence of order $1$ is simply a subsequence. Subsequences of order~$2$ are often called {\em sub}subsequences;
    however it becomes tedious to replace `order~$m$' by $m$ copies of the syllable `sub' when $m\,\,{\geq}\,\,3$.
    Sometimes the original sequence ${\xi}$ is referred to as a `subsequence of order~$0$' of itself.

\VV

        \subsection{\small{{\bf Examples}}}
        \label{ExampA40.41A}

\V

\hspace*{\parindent}(1) Consider a sequence ${\xi} \,=\, (x_{1}, x_{2},\,{\ldots}\,x_{k},\,{\ldots}\,)$, thought of as an ordered list.
    Let $n$ be a natural number, and let $A \,=\, \{n, n+1, \,{\ldots}\,\}$; that is,
    $A$ is the (infinite) subset of ${\NN}$ obtained by omitting the first $n-1$ natural numbers from~${\NN}$. (Note that if $n \,=\, 1$ then $A \,=\, {\NN}$.)
    The resulting subsequence ${\zeta}$ of ${\xi}$, viewed as an ordered list, is $(x_{n}, x_{n+1},\,{\ldots}\,)$;
    viewing ${\zeta}$ as a function, one has ${\zeta}(m) \,=\, {\xi}(m+n-1)$ for every $m$ in~${\NN}$.
    One calls any subsequence of ${\xi}$ obtained this way a {\bf tail of $\Bfm{{\xi}}$};\IndBD{sequences}{tail of a sequence}
    specifically, the sequence ${\zeta}$ constructed here is the {\bf $\Bfm{n}$-tail of~${\xi}$}.

\V

        (2) It is clear that every sequence can be viewed as a subsequence of itself.
    Indeed, note that ${\Psi}_{{\NN}} \,=\, I_{{\NN}}$, the identity map on ${\NN}$, and thus
        \begin{displaymath}
        {\xi} \,=\, {\xi}{\circ}I_{{\NN}} \,=\, {\xi}_{{\NN}}.
        \end{displaymath}
    By repeating this argument, one also sees that for every $m$ in ${\NN}$ the sequence ${\xi}$ can be viewed as a subsequence of order $m$ of itself;
    namely, it is the subsequence of order $m$ associated with the subsequence structure
    ${\cal A} \,=\, (A_{1}, A_{2},\,{\ldots}\,A_{m})$, where $A_{j} \,=\, {\NN}$ for each~$j$.


\V

        (3) More generally, suppose that $A$ is an infinite subset of ${\NN}$ and that ${\zeta} \,=\, {\xi}_{A}$.
    Then for every $m$ one can view ${\zeta}$ as being the $m$-th order subsequence of ${\xi}$ associated with the associated with the subsequence structure ${\cal A} \,=\, (A_{1}, A_{2},\,{\ldots}\,A_{m})$, where $A_{j} \,=\, A$ for each~$j$.

\VV


        \subsection{\small{{\bf Remark}}}
        \label{RemrkA40.42A}

\V

        The `subsequence structure' terminology is not standard, but the underlying concept is present in all analysis texts, often in hidden form.
    The standard way of dealing with subsequences of order $2$ or higher is by the use of multiply-subscripted indices.

\V

        \subsection{\small{{\bf Example}}}
        \label{ExampA40.42B}

\V

        In Chapter~\Ref{ChaptC} one learns about an important property, call it Property~X, which pertains to infinite sequences of real numbers.
    It is not important for the purposes of this example to know what this property is; one needs to know only that some sequences have it, some don't.
    Furthermore, if a given sequence has Property~X, then so does every subsequence of it.
    In the same chapter there is also a major theorem which can be phrased here as follows:

\VA

        {\bf Major Theorem} If ${\xi} \,=\, (x_{1}, x_{2},\,{\ldots}\,x_{k},\,{\ldots}\,)$ is a sequence of real numbers,
    then at least one subsequence of ${\xi}$ has Property~X.

\VA

\noindent There is an extension of this theorem, {\em not} stated in Chapter~\Ref{ChaptC}, which applies to sequences of points in Euclidean space:

\VA

        {\bf Corollary of Major Theorem} Suppose that ${\sigma} \,=\, (P_{1}, P_{2},\,{\ldots}\,P_{k},\,{\ldots}\,)$ is a sequence of points in ${\RR}^{3}$,
    the standard Euclidean space of dimension~$3$ from high-school analytical geometry.
    Write $P_{k} \,=\, (x_{k}, y_{k}, z_{k})$ where $x_{k}$, $y_{k}$ and $z_{k}$ are all real numbers.
    Let ${\xi} \,=\, (x_{1}, x_{2},\,{\ldots}\,x_{k},\,{\ldots}\,)$, ${\eta} \,=\, (y_{1}, y_{2},\,{\ldots}\,y_{k},\,{\ldots}\,)$,
    and ${\zeta} \,=\, (z_{1}, z_{2},\,{\ldots}\,z_{k},\,{\ldots}\,)$ be the corresponding `component' real sequences.

        \underline{Claim} There exists a subsequence of the sequence ${\sigma}$ for which
    each of the component real sequences ${\xi}$, ${\eta}$ and ${\zeta}$ has Property~X.

        \underline{Note} At first this sounds obvious. Indeed, it is given that the sequence ${\xi}$ has a subsequence with Property~X,
    and likewise for the sequences ${\eta}$ and~${\zeta}$. It is tempting to express this in the following index form:

\VA

        \h There is a subsequence $(x_{k_{1}}, x_{k_{2}},\,{\ldots}\,x_{k_{m}},\,{\ldots}\,)$ with Property~X. Likewise,
        there is a subsequence $(y_{k'_{1}}, y_{k'_{2}},\,{\ldots}\,y_{k'_{m}},\,{\ldots}\,)$ with Property~X,
    and a subsequence $(z_{k''_{1}}, z_{k''_{2}},\,{\ldots}\,z_{k''_{m}},\,{\ldots}\,)$ with Property~X.

\VA

\noindent The use of the `primes' above reflects the fact that different sequences of reals
    may well require different choices of indices to obtained a subsequence which has Property~$X$.
    What the Corollary requires, however, is a single choice of indices which works simultaneously for all three sequences ${\xi}$, ${\eta}$ and~${\zeta}$.
    At this point one might even begin to doubt the correctness of the claim; but in fact it is true.

\V

        \underline{First Proof of Claim}\,(using indices) Let $(x_{k_{1}}, x_{k_{2}},\,{\ldots}\,x_{k_{m}},\,{\ldots}\,)$
    be a subsequence of the real sequence ${\xi}$ which has Property~X, and let $(P_{k_{1}}, P_{k_{2}},\,{\ldots}\,P_{k_{m}},\,{\ldots}\,)$
    be the corresponding subsequence of~${\sigma}$. Note that $P_{k_{m}} \,=\, (x_{k_{m}}, y_{k_{m}}, z_{k_{m}})$ for each index~$m$.
    In particular, the choice of a subsequence of ${\xi}$ with Property~X leads to choices of subsequences of ${\eta}$ and ${\zeta}$ as well;
    but the latter subsequences need not have Property~X. However, since the Major Theorem applies to {\em every} real sequence,
    it implies that the subsequence $(y_{k_{1}}, y_{k_{2}},\,{\ldots}\,y_{k_{m}},\,{\ldots}\,)$
    of ${\eta}$ has itself a subsequence with Property~X. Let $(y_{k_{m_{1}}}, y_{k_{m_{2}}},\,{\ldots}\,y_{k_{m_{n}}},\,{\ldots}\,)$
    be such a subsubsequence of~${\eta}$. This in turn determines a subsubsequence of the original point sequence ${\sigma}$, namely
        \begin{displaymath}
        \left(P_{k_{m_{1}}}, P_{k_{m_{2}}},\,{\ldots}\,P_{k_{m_{n}}},\,{\ldots}\,\right).
        \end{displaymath}
    The $n$-th term of this subsubsequence of ${\sigma}$ is $P_{k_{m_{n}}} \,=\, \left(x_{k_{m_{n}}}, y_{k_{m_{n}}}, z_{k_{m_{n}}}\right)$.
    That is, choosing the appropriate subsubsequence of ${\eta}$ to have Property~X leads to a corresponding subsubsequence of ${\sigma}$,
    which in turn leads to corresponding subsubsequences of ${\xi}$ and ${\zeta}$.
    The first of these subsubsequences, being a subsequence of a subsequence ${\xi}$ having Property~X,
    also has Property~X, by the fact given above that if a sequence has Property~X, then so does every one of its subsequences.
    Unfortunately, there is no reason to expect that the subsubsequence of ${\zeta}$ constructed here has Property~X.
    However, it does have itself have a subsequence, which would then be a subsubsubsequence of the original sequence~${\zeta}$, with Property~X.
    As is the custom at this stage of such an argument, the remaining details are left to the reader;
    but notice that the final answer involves expressions such as $P_{k_{m_{n_{q}}}}$ whose stacked indices are hard to read.

\VA

        \underline{Second Proof of Claim} (using infinite subsets of ${\NN}$)  Let $A$ be such an infinite subset of ${\NN}$ for which the subsequence 
    ${\xi}_{A}$ has Property~X; such $A$ exists by applying the Major Theorem to~${\xi}$.
    Next let $B$ be an infinite subset of $A$ for which ${\eta}_{B}$ has Property~X;
    once again, the fact that ${\eta}_{A}$ has a subsequence with Property~X follows from the Major Theorem;
    the fact that a subsequence of ${\eta}_{A}$ can be expressed in the form ${\eta}_{B}$ for some infinite subset $B$ of $A$ has already been noted.
    Similarly, let $C$ be an infinite subset of $B$ such that ${\zeta}_{C}$ has Property~X.
    (Note that the ordered triple $(A,B,C)$ is a subsequence structure of order~$3$.)
    It follows easily from the fact that if a sequence has Property~X, then so does each of its subsequences,
    that ${\sigma}_{C} \,=\, ({\xi}_{C}, {\eta}_{C}, {\zeta}_{C})$ is a subsequence of ${\sigma}$ with the required property.


\VV

        \subsection{\small{{\bf Remarks}}}
        \label{RemrkA40.42C}

\V

\hspace*{\parindent}(1) If $A$ and $B$ are infinite subsets of ${\NN}$ such that ${\xi}_{A} \,=\, {\xi}_{B}$, it need not be the case that $A \,=\, B$.
    For example, if ${\xi}$ is a constant sequence then clearly ${\xi}_{A} \,=\, {\xi}_{B} \,=\, {\xi}$ for every such pair of subsets $A$ and~$B$.
    However, if, when viewed as a function ${\xi}:{\NN} \,{\rightarrow}\, X$, the sequence ${\xi}$ is one-to-one,
    then it is easy to see that ${\xi}_{A} \,=\, {\xi}_{B}$ implies $A \,=\, B$.

% EXERCISE

\V

        (2) The difference between the two proofs above is one of notation. For example,
    the notation $(x_{k_{1}}, x_{k_{2}},\,{\ldots}\,x_{k_{m}},\,{\ldots}\,)$ simply lists out `explicitly' the elements of the set $A$ in increasing order;
    indeed, it is clear that $k_{m} \,=\, {\Psi}_{A}(m)$; the $m$-th smallest element of~$A$.
    However, only the existence of a suitable infinite subset $A$ of ${\NN}$ is used, and not the fact that its terms can be written in a particular order.
    The introduction of the subscripted indices $k_{m}$ does nothing except to complicate the notation.
    Nevertheless, from time to time in {\ThisText} we shall use subscripted indices,
    simply because that is the most common notation in analysis books and papers, so one must become familiar with it as well.


\VV

        Subsequence structures of {\em infinite} order also are important in analysis.
    However, the way they arise and are used is different from the situation with subsequence structures of finite order.

\V

        \subsection{\small{{\bf Definition}}}\IndBD{sequences}{subsequence structures of infinite order}
        \label{DefA40.45}

\V

         A {\bf subsequence structure of infinite order} is an infinite sequence $(A_{1}, A_{2},\,{\ldots}\,A_{m},\,{\ldots}\,)$
    of infinite subsets of ${\NN}$ such that for each $k$ in ${\NN}$ one has $A_{k+1} \,{\subseteq}\, A_{k}$.

\VV

        \subsection{\small{{\bf Examples}}}
        \label{ExampA40.47}

\V

\hspace*{\parindent}(1) For each $m$ in ${\NN}$ let $A_{m} \,=\, \{m, m+1, \,{\ldots}\,\}$. Then ${\cal A} \,=\, (A_{1}, A_{2},\,{\ldots}\,A_{m},\,{\ldots}\,)$
    is also subsequence structure of infinite order. Note that the intersection $\bigcap_{m=1}^{{\infty}} A_{m}$ of the sets $A_{m}$ is empty.

\V

        (2) For each $m$ in ${\NN}$ let $A_{m}$ be the infinite subset of ${\NN}$ given by
        \begin{displaymath}
        A_{m} \,=\, (1, 2^{m-1}{\cdot}2, 3, 2^{m-1} \,{\cdots}\, 4, 5, \,{\ldots}\,);
        \end{displaymath}
    the pattern is clear: ${\Psi}(k) \,=\, k$ if $k$ is odd, while ${\Psi}(k) \,=\, 2^{m-1}{\cdot}k$ if $k$ is even.
    It is clear that $A_{m+1} \,{\subseteq}\, A_{m}$ for each natural number~$m$,
    so that ${\cal A} \,=\, (A_{1}, A_{2},\,{\ldots}\,A_{m},\,{\ldots}\,)$ is a subsequence structure of infinite order.
    It is also clear that the intersection $\bigcap_{m=1}^{{\infty}} A_{m}$ of the sets
    $A_{m}$ is the infinite subset $B \,=\, \{1, 3, 5, \,{\ldots}\,\}$ of~${\NN}$.

\VV

        Let ${\cal A} \,=\, (A_{1}, A_{2},\,{\ldots}\,A_{m},\,{\ldots}\,)$ be a subsequence sructure of infinite order,
    and let ${\xi}:{\NN} \,{\rightarrow}\, X$ be a sequence with values in a nonempty set~$X$.
    The structure ${\cal A}$ determines for each $m$ a corresponding subsequence of ${\xi}$, namely ${\xi}_{A_{m}}$,
    such that for each $m$ in ${\NN}$ the sequence ${\xi}_{A_{m+1}}$ is itself a subsequence of~${\xi}_{A_{m}}$.
    It is natural to ask whether there exists a subsequence ${\zeta}$ of ${\xi}$ which is simultaneously a subsequence of ${\xi}_{A_{m}}$ for each~$m$.
    If there is, ${\zeta}$ must be of the form ${\zeta} \,=\, {\xi}_{B}$ for some
    infinite subset $B$ of ${\NN}$ such that $B \,{\subseteq}\, A_{m}$ for each~$m$.
    That is, $B$ must be an infinite subset of $\bigcap_{m=1}^{{\infty}} A_{m}$.

        Example (1) above shows that such an infinite subset $B$ of ${\NN}$ may fail to exist.
    However, a slight weakening of the requirement that $B$ be a subset of each $A_{m}$ allows one to procede in a useful manner.

\V


        \subsection{\small{{\bf Definition}}}
        \label{DefA40.48}

\V

        Let $A$ and $B$ be infinite subsets of ${\NN}$. One says that {\bf $\Bfm{B}$ is eventually a subset of $\Bfm{A}$} 
    provided there exists a natural number $N$ such that if $n{\in}B$ and $n\,\,{\geq}\,\,N$ then $n{\in}A$;
    equivalently, if there are at most finitely many elements of $B$ that are {\em not} in~$A$.

\V


        \subsection{\small{{\bf Example}}}
        \label{ExampA40.50}

\V

        Let ${\cal A} \,=\, (A_{1}, A_{2},\,{\ldots}\,A_{m},\,{\ldots}\,)$ be a subsequence stucture of infinite order.
    Then there exists an infinite subset $B$ of ${\NN}$ such that for each $m$ in ${\NN}$ the set $B$ is eventually a subset of $A_{m}$.
    For instance, let $n_{1}$ be any element of the set~$A_{1}$. Then let $n_{2}$ be any element of $A_{2}$ such that $n_{2}\,>\,n_{1}$;
    such $n_{2}$ exists because $A_{2}$ is an infinite subset of~${\NN}$. Continuing this way,
    suppose that $n_{1}$, $n_{2}$,\,{\ldots}\,$n_{m}$ have been defined so that
    $n_{1}\,<\,n_{2}\,<\,\,{\ldots}\,\,<\,n_{m}$, and $n_{j}{\in}A_{j}$ for each $j \,=\, 1,2,\,{\ldots}\,m$.
    Then define $n_{m+1}$ to be an element of $A_{m+1}$ such that $n_{m+1}\,>\,n_{m}$.
    It is easy to see that the set $B \,=\, \{n_{1}, n_{2},\,{\ldots}\,n_{m},\,{\ldots}\,\}$
    is an infinite subset of ${\NN}$ such that for each $m$ the set $B$ is eventually a subset of~$A_{m}$.
    Indeed, it is clear that, for each $m$ in ${\NN}$, the set $\{n_{m}, n_{m+1}, n_{m+2},\,{\ldots}\,\}$ is a subset of $A_{m}$.


        \underline{Special Case} Choose $n_{1}$ to be the {\em least} element of $A_{1}$,
    choose $n_{2}$ to be the {\em least} element of $A_{2}$ such that $n_{2}\,>\,n_{1}$, and so on.
    These explicit choices are possible because of the Least-Natural-Number Principle.

\VV

        The construction described in the preceding example is used frequently enough in analysis to deserve its own terminology.

\V

        \subsection{\small{{\bf Definition}}}\IndBD{sequences}{cross section of a subsequence structure}
        \label{DefA40.60}

\V

        Let ${\cal A} \,=\, (A_{1}, A_{2},\,{\ldots}\,A_{m},\,{\ldots}\,)$ be a subsequence structure of infinite order. An infinite subset
    $B \,=\, \{n_{1}\,<\,n_{2}\,<\,\,{\ldots}\,\,<\,n_{m}\,<\,\,{\ldots}\,\}$ of ${\NN}$ is said to be a
    {\bf cross section of $\Bfm{{\cal A}}$}\IndBD{sequences}{cross section of a subsequence structure}
    provided that for each $m$ in ${\NN}$ one has $n_{m}{\in}A_{m}$.

        If, in addition, the numbers $n_{m}$ are chosen as in the Special Case in the preceding example,
    then the set $B$ is called the {\bf minimal cross section of $\Bfm{{\cal A}}$}.
    \IndC{sequences}{cross section of a subsequence structure}{minimal cross section}



\V

        {\bf Remarks} (1) Let ${\cal A} \,=\, (A_{1}, A_{2},\,{\ldots}\,A_{m},\,{\ldots}\,)$
    be a subsequence structure of infinite order, as above. Suppose that $B \,=\, \{n_{1}\,<\, n_{2}\,<\,\,{\ldots}\,\,<\,n_{m}\,<\,\,{\ldots}\,\}$
    is the minimal cross section of ${\cal A}$, and that $C \,=\, \{l_{1}\,<\, l_{2}\,<\,\,{\ldots}\,\,<\,l_{m}\,<\, \,{\ldots}\,\}$
    is an arbitrary cross section. It is an easy exercise to show that $n_{m}\,\,{\leq}\,\,j_{m}$ for all~$m$. %% EXERCISE

\V

        (2) Suppose that the intersection of the sets $A_{m}$, for $m$ in ${\NN}$, is an {\em infinite} subset $C$ of~${\NN}$.
    Then certainly $C$ is a cross section of~${\cal A}$, but it need not be the minimal cross section.

\V

        (3) Given a subsequence structure ${\cal A} \,=\, (A_{1},A_{2},\,{\ldots}\,A_{m},\,{\ldots}\,)$,
    it may be possible to construct an infinite subset $D$ of ${\NN}$ which is eventually a subset of each set $A_{m}$,
    but which is {\em not} a cross section of~${\cal A}$; for instance, $D$ might include a natural number which is smaller than the smallest element of~$A_{1}$.
    However, it is an easy exercise to show that any such $D$ has an infinite subset $B$ which {\em is} a cross section of~${\cal A}$.
    In practice this means there is no loss by dealing only with cross sections of the given subsequence structure.

\VV

        \subsection{\small{{\bf Example}}} 
        \label{ExampA40.70}

\V


\hspace*{\parindent}
    Let ${\xi} \,=\, (x_{1}, x_{2},\,{\ldots}\,x_{k},\,{\ldots}\,)$ be a sequence of real numbers such that ${\xi}$ is unbounded above,
    in the sense that for every number $M$ there exists at least one index $k$ such that $x_{k}\,>\,M$.


\V
        \underline{Claim} The sequence ${\xi}$ has a subsequence ${\zeta} \,=\, (z_{1}, z_{2},\,{\ldots}\,z_{m}, \,{\ldots}\,)$
    such that $z_{m}\,>\,m$ for each index~$m$.

\V

        \underline{Proof of Claim}\, For each natural number $m$ let $A_{m}$ be the set of all indices $k$ such that $x_{k}\,>\,m$.
    The hypothesis that the original sequence ${\xi}$ is unbounded above clearly implies that each set $A_{m}$ is an infinite subset of~${\NN}$.
    Also it is clear that for each $m$ one has $A_{m+1} \,{\subseteq}\, A_{m}$,
    so that ${\cal A} \,=\, \{A_{1}, A_{2},\,{\ldots}\,\}$ is an infinite-order subsequence structure.
    Let $B \,=\, \{k_{1}\,<\,k_{2},\,{\ldots}\,\,<\,k_{m}\,<\,\,{\ldots}\,\}$ be a cross section of ${\cal A}$, as described above. Set $z_{m} \,=\, x_{k_{m}}$ for each $m$ in~${\NN}$.
    Then it is clear that the subsequence ${\zeta} \,=\, (z_{1}, z_{2},\,{\ldots}\,z_{m},\,{\ldots}\,)$ of ${\xi}$ has the required property.
    Indeed, one has $z_{m} \,=\, x_{k_{m}}$. However, $k_{m}{\in}A_{m}$ by construction, so $x_{k_{m}}\,>\,m$, by the definition of the set $A_{m}$.
    That is, $z_{m}\,>\,m$ for each index $m$, as required.

\V

        Let us finish this subsection with a bit of terminology that will be useful later on.

\VV
        \subsection{\small{{\bf Definition}}}\IndBD{sequences}{sequence eventually has a property}
        \label{DefA40.80}

        A sequence ${\xi} \,=\, (x_{1}, x_{2},\,{\ldots}\,x_{k},\,{\ldots}\,)$ is said to {\bf eventally have a certain property}
    provided there exists a natural number $N$ such that if $k\,\,{\geq}\,\,N$ then the subsequence $(x_{N+1}, x_{N+2},\,{\ldots}\,x_{N+k},\,{\ldots}\,)$ has the given property.

\V

        {\bf Example}\,Let ${\xi} \,=\, (-1, 3, 4, 7, \,{\ldots}\,7, 7\,{\ldots}\,)$ whose first three terms are $x_{1} \,=\, -1$, $x_{2} \,=\, 3$, $x_{3} \,=\, 4$,
    and whose terms $x_{k}$ for $x\,\,{\geq}\,\,4$ are all equal to~$7$. Then the sequence ${\xi}$ is not constant, but it is {\em eventually} constant.



        \section{{\bf Binary Operations on a Set}}
        \label{SectA60}\IndB{ZZ Sections}{\Ref{SectA60} Binary Operations on a Set}

        In this section a new class of functions is introduced. Examples of such functions have been studied from ancient times,
    and new ones arise frequently in many branches of modern mathematics. The discussion of this topic is placed here
    because this type of function plays an important role in the next chapter.


        \subsection{\small{{\bf Definitions}}}
        \label{DefA60.10}

        Let $A$ be a nonempty set.

\V

        (1) Suppose that $f:A^{2} \,{\rightarrow}\, A$ is a function whose domain is the Cartesian product of a nonempty set $A$ with itself,
    and whose values are in $A$. Then one says that $f$ is a
    {\bf binary operation\IndBD{operations/operators}{binary operations} on $\Bfm{A}$}.

        \underline{Note} The word {\bf operator} is often used in place of `operation' in this context.


\V

        (2) A binary operation $f:A^{2} \,{\rightarrow}\, A$ is said to be {\bf commutative}\IndC{operations/operators}{binary operations}{commutative} if
        \begin{displaymath}
        f(x,y) \,=\, f(y,x) \mbox{ for all $x$ and $y$ in $A$}.
        \end{displaymath}
    It is said to be {\bf associative}\IndC{operations/operators}{binary operations}{associative} if
        \begin{displaymath}
        f(f(x,y),z) \,=\, f(x,f(y,z)) \mbox{ for all $x$, $y$ and $z$ in $A$}.
        \end{displaymath}

\V
\V


        \subsection{\small{{\bf Examples}}}
        \label{ExampA60.20}

\V

\hspace*{\parindent} (1) The `Sum Function' $S:{\NN}^{2} \,{\rightarrow}\, {\NN}$ and the `Product Function' $P:{\NN}^{2} \,{\rightarrow}\, {\NN}$,
    given by the rules
        \begin{displaymath}
        S(x,y) \,=\, x+y \mbox{ and } P(x,y) \,=\, x{\cdot}y \h \mbox{ for all $(x,y)$ in ${\NN}^{2}$},
        \end{displaymath}
    are familiar binary operations on ${\NN}$. There are analogous binary operations of `sum' and `product' on ${\ZZ}$, ${\QQ}$ and ${\RR}$.
    It is well known that each one of these operations is both commutative and associative, although the `$S$' and `$P$' formulation may obscure this fact.
    For example, when the associative law for $S$, namely
        \begin{displaymath}
        S(S(x,y),z) \,=\, S(x,S(y,z)),
        \end{displaymath}
    is reformulated using the plus sign, one gets the more familiar looking
        \begin{displaymath}
        (x+y) + z \,=\, x + (y+z)
        \end{displaymath}

\V

       (2) Closely related to sums and products in algebra are differences and quotients. Unfortunately, the situation now becomes less pleasant.

        For example, one can define the `difference' $D(x,y)$ for all $(x,y)$ in ${\NN}^{2}$, but the values of the function $D$ need not be in~${\NN}$.
    Since the values of a binary operator on a set $A$ must all lie in~$A$, it follows that this function is not a binary operator on~${\NN}$.
    This is not an issue in ${\ZZ}$, ${\QQ}$ or ${\RR}$, so in each of these cases the well-known `difference' function is a true binary operator.
    However, in each of these cases the operator is neither commutative nor associative.

        In the case of `quotients', once again there is the issue that the quotient of two elements of the set may fail to be in the given set.
    More serious is that in all these sets division by $0$ is not allowed, so in none of these cases is there a true binary operator.

\V

       (3) In Example~(1) above we saw binary operations which are both commutative and associative,
    while in Example~(2) we saw binary operations which enjoy neither of these properties.
    It is also possible for a binary operation to have one of these properties but not the other.

\VA

        \h (i)\, Define the so-called `Absolute Difference' function $\hat{D}:{\ZZ}^{2} \,{\rightarrow}\, {\ZZ}$ by the rule $\hat{D}(x,y) \,=\, |x-y|$.
    It is obvious that this binary operation on ${\ZZ}$ is commutative, and it is easy to check that it fails to be associative.


        \h (ii) Let $X$ be a nonempty set and let $A$ be the set of all functions $f:X \,{\rightarrow}\, X$ with domain $X$ and having values in~$X$.

\VA

\noindent Define the {\bf Composition Operation} $C$ on $A$ to be the binary operation $C:A^{2} \,{\rightarrow}\, A$
    given by the rule $C(f,g) \,=\, f{\circ}g$, where the latter expression is described in Definition~\Ref{DefA30.130}.
    It is clear that the binary operation $C$ is associative no matter which nonempty set $X$ is used;
    see Remark~\Ref{RemrkA30.140} and Theorem~\Ref{ThmA30.160}. However, if the set $X$ has more than one element, then $C$ is not commutative.

\VV

        \underline{Remark} The preceding examples point out a notational difficulty associated with defining `binary operations' as functions.
    For instance, the `functional' notation for sums is $S(x,y)$, with the symbol $S$ for ths operation located to the left of both numbers being summed.
    In contrast, the common notation for the sum of two numbers $x$ and $y$ is $x+y$,
    with the symbol for this operation, the `plus' sign $+$, placed between the numbers.
    Roughly speaking, the difference between these two perfectly valid notational choices corresponds to the difference between pronouncing them
    as `the sum of $x$ and $y$' or `$x$ plus $y$'.
    Similarly, one can say `the product of $x$ and $y$', or `$x$ times $y$'; `the difference between $x$ and $y$', or `$x$ minus $y$;
    `the composition of $f$ with $g$,' or `$f$ circle $g$'.

        Most people prefer to use the `symbol-between-the-inputs' notation instead of the `function' notation (e.g., $x+y$ instead of $S(x,y)$).
    The official name of this preferred notation is the
    {\bf infix representation}\IndBD{operations/operators}{infix representations} of the binary operation.
    To accomodate this notational preference, it is common when discussing binary operations `in the abstract' to choose a `generic' symbol,
    such as ${\ast}$, to act as the (infix) symbol of a `generic' binary operation $f:A^{2} \,{\rightarrow}\, A$,
    much as the plus sign $+$ is the infix symbol of the operation~$S$.
    With such a choice, one then normally writes $x{\ast}y$ instead of $f(x,y)$. 
    Likewise, one often refers to `the binary operation~${\ast}$' instead of the more proper usage, `the binary operation~$f$'.
    Note that with the infix notation the commutative and associative laws take the more familiar forms
        \begin{displaymath}
        x{\ast}y \,=\, y{\ast}x \mbox{ and } (x{\ast}y){\ast}z \,=\, x{\ast}(y{\ast}z), \mbox{ respectively}.
        \end{displaymath}


\VV

        Expressions which involve repeated applications of a binary operator, but involving no parentheses, appear frequently in mathematics;
    for instance, in arithmetic one might encounter the expression $1-2-3$, which involves two applications of the `difference' operation.
    (Try computing the value of this expression before reading further.)

        More generally, if ${\ast}$ is a binary operator on a set $A$, the question arises as to
    how should one interpret a parenthesis-free expression of the form $x_{1}{\ast}x_{2}{\ast}x_{3}{\ast}\,{\ldots}\,{\ast}x_{n}$.
    Of course, the issue is that technically such expressions should be meaningless, since a binary operation can act on only a pair of objects.

        For simplicity, first consider the case $n \,=\, 3$. There are two obvious interpretations of the expression $x_{1}{\ast}x_{2}{\ast}x_{3}$:

\VA

        \underline{Interpretation 1} Carry out the operations successively `from left to right'. 
    More precisely, define $x_{1}{\ast}x_{2}{\ast}x_{3}$ to mean $(x_{1}{\ast}x_{2}){\ast}x_{3}$.
    That is, first perform the ${\ast}$ on the left, and then the ${\ast}$ on the right.

        \underline{Interpretation 2} Carry out the operations successively `from right to left'. 
    More precisely, set $x_{1}{\ast}x_{2}{\ast}x_{3} \,=\, x_{1}{\ast}(x_{2}{\ast}x_{3})$.

\VA

\noindent It is clear that if the operation ${\ast}$ is associative, then these two interpretations are in agreement, but not so if ${\ast}$ is not associative.

\V

        {\bf Example} Suppose that ${\ast}$ is the binary operation of `subtraction' on the set ${\ZZ}$ of all integers.
    It is easy to check that $1-2-3 \,=\, -4$ under the `left-to-right' computation, but $1-2-3 \,=\, 2$ under the `right-to-left' computation.
    (Compare this with the value for this expression you obtained above.)

\V

        In {\ThisText} we follow the standard convention and use the `left-to-right interpretation'
    in extending this discussion to expressions of the form $x_{1}{\ast}x_{2}{\ast}x_{3}{\ast}\,{\ldots}\,{\ast}x_{n}$. More precisely:

\VV

            \subsection{\small{\bf Definition}}
            \label{DefA60.30}

\V

        Let $f:A^{2} \,{\rightarrow}\, A$ be a binary operation on a nonempty set~$A$, with corresponding `infix' symbol~${\ast}$.
    The {\bf left-to-right extension of the operation $\Bfm{{\ast}}$ to $\Bfm{k}$-tuples},
    where $k\,\,{\geq}\,\,3$, is given recursively so that the following laws hold:

        \h If $k \,=\, 3$ then $x_{1}{\ast}x_{2}{\ast}x_{3} \,=\, (x_{1}{\ast}x_{2}){\ast}x_{3}$.

        \h If $k\,>\,3$, then $x_{1}{\ast}x_{2}{\ast} \,{\ldots}\,{\ast}x_{k}{\ast}x_{k+1} \,=\, (x_{1}{\ast}x_{2}{\ast} \,{\ldots}\,{\ast}x_{k}){\ast}x_{k+1}$.
                                          
\VV


        {\bf Remarks} (1) The corresponding `right-to-left extension' is easy to define, but we do not use it in {\ThisText}.

\V

        (2) See the {\Note} after Example~\Ref{ExampA30.150} for a possible explanation for preferring the `left-to-right' interpretation.

\VV

%%%
\begin{quotation}
{\footnotesize \underline{\Notes} (on the representations of binary operations)\IndB{\notes}{on the representations of binary operations}:

\V

        (1) There are some places in mathematics in which the `right-to-left interpretation' of extensions of binary operations are in common use.
        For example, consider the usual `exponentation' binary operator $^{{\wedge}}$,
    defined on natural numbers by the rule $x^{{\wedge}}y \,=\, x^{y}$. This is often used in place of
    the standard `raised exponent' notation in scientific calculators, where the use of raised symbols is inconvenient.
    For example, calculus texts typically interpret the expression $10^{2^{3}}$ to mean $10^{(2^3)} \,=\, 10^{8}$;
    that is, $10^{{\wedge}}2^{{\wedge}}3 \,=\, 10^{{\wedge}}(2^{{\wedge}}3)$, which is the `right-to-left' extension of the operator~$^{{\wedge}}$.
    In contrast, scientific calculators would say that $10^{2^{3}} \,=\, (10^{2})^{3} \,=\, 10^{(2\,{\cdot}\,3)} \,=\, 10^{6}$;
    that is, $10^{{\wedge}}2^{{\wedge}}3 \,=\, (10^{{\wedge}}2)^{{\wedge}}3$, which is the left-to-right interpretation.
    As always, the easy way to avoid any ambiguity is to insert parentheses as needed.


        (2) The `infix representation' of a binary operation $f:A^{2} \,{\rightarrow}\, A$ described above is so called
    because it locates (`fixes') the symbol ${\ast}$ for the operation between (`inside') the two inputs, as in $x{\ast}y$.
    In contrast, the functional representation for the same quantity places the symbol $f$ for the operation before the inputs $x$ and~$y$: $f(x,y)$.
    This is essentially what computer scientists call the `prefix representation' of the binary operation,
    except they would write $f\,x\,y$ in place of $f(x,y)$. They also use the so-called `postfix representation': $x\,y\,f$.
    These notations are also known as the `Polish'\IndC{\notes}{on infix, prefix, postfix representations}{Polish/Reverse Polish notations}\IndD{Polish/Reverse Polish notations}{\notes} and `Reverse Polish' notations, respectively, in honor of the Polish logician Jan Lukasiewicz,\IndC{\notes}{on infix, prefix, postfix representations}{{\L}ukasiewicz, Jan}\IndD{Lukasiewicz, Jan}{\notes}
    who introduced such notations as a way to completely avoid the use of parentheses in complicated expressions built out of binary operations.
    For example, the `prefix' version of the expression $x + a\,(y - z\,(b+c))$ is $S\,x\,P\,a\,D\,y\,P\,z\,S\,b\,c$;
    the `postfix' version is $b\,c\,S\,z\,P\,y\,D\,a\,P\,x$.
    Note that in each of these expressions the order in which the binary operations are evaluated is completely determined:
    in the prefix notation one evaluates the operations from right to left, while in the postfix notation the order is from left to right.
    (It is likely that this last fact explains why the postfix notation is more widely used than the prefix; see the {\Note} on the `left-to-right bias'.)
}%EndFootnotesize
\end{quotation}
%##


\VV

        The algebra for repeated applications of a binary operator becomes much simpler if the operator is associative.
    It becomes simpler still if the operator is also commutative. In what follows, all the expressions are defined as in Definition~\Ref{DefA60.30}.

            \subsection{\small{\bf Theorem}}
            \label{ThmA60.50}

        Let $f:A^{2} \,{\rightarrow}\, A$ be a binary operation on a nonempty set~$A$, and let ${\ast}$ be the corresponding infix symbol of this operation.

\V

        (a) Assume that the operation ${\ast}$ is associative. Let $k$ and $m$ be natural numbers,
    and let $(x_{1}, x_{2},\,{\ldots}\,x_{k}, x_{k+1},\,{\ldots}\,x_{k+m})$ be an element of $A^{k+m}$. Then
        \begin{displaymath}
        \left(x_{1}{\ast}x_{2}{\ast}\,{\ldots}\,{\ast}x_{k}\right)
    {\ast}
        \left(x_{k+1}{\ast}x_{k+2}{\ast}\,{\ldots}\,{\ast}x_{k+m}\right)
     \,=\, 
  x_{1}{\ast}x_{2}{\ast}\,{\ldots}\, {\ast}x_{k}{\ast}x_{k+1}{\ast}\,{\ldots}\,{\ast}x_{k+m}.
        \end{displaymath}
    
\V

        (b) Assume that ${\ast}$ is both commutative and associative. Then the the operation ${\ast}$ has a stronger version of commutivity:

        Let $k$ be a natural number, and let $p:{\NN}_{k} \,{\rightarrow}\, {\NN}_{k}$ be a permutation of the finite set ${\NN}_{k}$
    (see Definition~\Ref{DefA15.50}).
    Then for every $k$-tuple $(x_{1}, x_{2},\,{\ldots}\,x_{k})$ in $A^{k}$ one has
        \begin{displaymath}
        x_{p(1)}{\ast}x_{p(2)}{\ast}\,{\ldots}\,{\ast}x_{p(k)} \,=\, 
        x_{1}{\ast}x_{2}{\ast}\,{\ldots}\,{\ast}x_{k}.
        \end{displaymath}

\V

        {\bf Outline of Proof} The details of the proof are left as an exercise. What follows are hints:

        (a) Use mathematical induction on the index $m$.

\V

        (b) Use mathematical induction on the index $k$; break into the special cases $p(k) \,=\, k$ and $p(k) \,\,{\neq}\,\, k$.
    (I assume that you let the induction hypothesis be that the statement holds for $k-1$.)

\V

            \subsection{\small{\bf Remark}}
            \label{RemrkA60.60}

        The conclusion of Part (b) of the preceding theorem, namely that the binary operation~${\ast}$ enjoys the stronger form of `commutivity' given there,
    does not remain true if the hypothesis that~${\ast}$ be associative is omitted.
    That is, ordinary commutivity of~${\ast}$ is not enough by itself to guarantee the stronger form of commutivity.
    This contrasts with the situation in Part~(a) for which assuming ordinary associativity for ${\ast}$ does guarantee the stronger form of associativity.

%% EXERCISE INVOLVING ABSOLUTE-DIFFERENCE

\VV

        The next definition is encountered more often in the algebraic branches of moderm mathematics than in analysis, but it does get used here too.
    It makes precise the concept of two binary operations being `equivalent', in the sense that
    every statement which can be expressed purely in terms of the first operation corresponds to a fact about the second.

\V

            \subsection{\small{\bf Definition} (Isomorphism)}
            \label{DefA60.70}

\V

        Let $(A,{\ast})$ and $(A',{\ast}')$ be binary operations on the sets $A$ and $A'$, respectively.

\V

        (1) An {\bf isomorphism of $\Bfm{(A,{\ast})}$
    \IndC{operations/operators}{binary operations}{isomorphism, isomorphic}
    with $\Bfm{(A',{\ast}')}$} is a bijection ${\varphi}:A \,{\rightarrow}\, A'$ of $A$ onto $A'$ such that
    ${\varphi}(a_{1}{\ast}a_{2}) \,=\, ({\varphi}(a_{1})){\ast}'({\varphi}(a_{2}))$
    for each ordered pair $(a_{1},a_{2})$ in $A^{2}$.

        \underline{Note} If, in a given context, the binary operations ${\ast}$ and~${\ast}'$ are clear,
    one often refers more briefly to `the isomorphism $f:A \,{\rightarrow}\, A'$.

\V

        (2) Two binary operations are said to be {\bf isomorphic (to each other)} if there exists an isomorphism of one with the other.

\VV

            \subsection{\small{\bf Examples}}
            \label{ExampA60.80}

\V

\hspace*{\parindent} (1) Let ${\varphi}:{\ZZ} \,{\rightarrow}\, {\ZZ}$ be the bijection given by the rule ${\varphi}(k) \,=\, -k$ for each integer~$k$.
    It follows from the equation $-(k+m) \,=\, (-k) + (-m)$, valid  for integers,
    that ${\varphi}$ is an isomorphism of the operation of addition on~${\ZZ}$.
    However, since $-(1{\cdot}1) \,=\, -1$, while $(-1){\cdot}(-1)) \,=\, 1$, the map ${\varphi}$ is {\em not} an isomorphism of multiplication of integers.

\V

        (2) Let $A \,=\, {\NN}$, and let $A' \,=\, \{2, 2^{2}, \,{\ldots}\, 2^{n},\,{\ldots}\,\}$, the set of all positive powers of~$2$.
    Let~${\ast}$ denote the usual binary operation of `addition of natural numbers' on~$A$.
    Likewise, let~${\ast}'$ denote the restriction to the set $A'$ of the usual binary operation of `multiplication of natural numbers';
    it is clear from the standard laws of powers of natural numbers that ${\ast}'$ is a binary operation on the set~$A'$.
    Let ${\varphi}:A \,{\rightarrow}\, A'$ be given by the rule ${\varphi}(k) \,=\, 2^{k}$.
    It follows from the usual rules for exponents that ${\varphi}$ is an isomorphism of $(A,{\ast})$ with~$(A',{\ast}')$.

\V

        (3) It is an easy exercise to show that if ${\varphi}:A \,{\rightarrow}\, A'$ is an isomorphism of $(A,{\ast})$ with $(A',{\ast}')$, 
    then ${\varphi}^{-1}:A' \,{\rightarrow}\, A$ is an isomorphism of $(A',{\ast}')$ with $(A,{\ast})$.

%% EXERCISE {\varphi}^{-1} is also an isomorphism

\V

        (4) Suppose ${\varphi}:A \,{\rightarrow}\, A'$ is a bijection of the set $A$ onto the set~$A'$. If $(A',{\ast})$ is a binary operation on the set~$A'$, 
    then there is a unique binary operation $(A,{\ast})$ on $A$ for which ${\varphi}$ is an isomorphism. It is given by the rule
        \begin{displaymath}
        a_{1}{\ast}a_{2} \,=\, {\varphi}^{-1}[{\varphi}(a_{1}){\ast}'{\varphi}(a_{2})] \mbox{ for each ordered pair $(a_{1},a_{2})$ in $A^{2}$}.
        \end{displaymath}
    It is called the {\bf binary operation induced on $A$ by the bijection ${\varphi}$ from the binary operation $(A',{\ast}')$}.\IndBD{functions}{binary operation induced by a bijection}
    Intuitively speaking, one uses the bijection ${\varphi}$ to relate the pair $(a_{1},a_{2})$ in $A^{2}$
    to the corresponding pair $(a_{1}',a_{2}')$ in $A'^{2}$;
    then one uses the operation ${\ast}'$ to get a third element $a_{3}' \,=\, a_{1}'{\ast}'a_{2}'$ in~$A'$.
    Finally, $a_{1}{\ast}a_{2}$ is the element $a_{3}$ in $A$ which corresponds under the bijection ${\varphi}$ to the element $a_{3}'$.

\VV

        The significance of ${\varphi}$ being an isomorphism of the binary operation $(A,{\ast})$ with $(A',{\ast}')$
    is that these operations then have exactly the same algebraic properties. More precisely, if an equation involving only the operation ${\ast}$ and certain elements $a_{1}$, $a_{2}$,\,{\ldots}\,$a_{n}$ of $A$ is valid,
    then the equation one obtains by replacing each occurance of ${\ast}$ by ${\ast}'$,
    and each occurance of $a_{j}$ by $a'_{j} \,=\, {\varphi}(a_{j})$ for each $j \,=\, 1,2,\,{\ldots}\,n$, is also valid.
    For example, if $(A,{\ast})$ is an associative operator, then so is $(A',{\ast}')$.
    Or if there exists an element $u$ in $A$ such that $u{\ast}a \,=\, a$ for each $a$ in~$A$,
    then $u'{\ast}'a' \,=\, a'$ for all $a'$ in $A'$, where $u' \,=\, {\varphi}(u)$.

\V

    Note that the objects in sets $A$ and $A'$ need not be of the same type for there to exist an isomorphism.

        {\bf Example} Let $A \,=\, \{0,1\}$ and let $A' \,=\, \{c,d\}$; thus $A$ consists of natural numbers,
    while $A'$ consists of letters, objects of different type.  Define binary operations $(A,{\ast})$ and $(A',{\ast}')$ as follows:
        \begin{displaymath}
        a_{1}{\ast}a_{2} \,=\, 0 \mbox{ for all $a_{1}, a_{2}$ in $A$ }; \h
        a_{1}'{\ast}'a_{2}' \,=\, c \mbox{ for all $a_{1}', a_{2}'$ in $A'$}
        \end{displaymath}
    It is clear that the map ${\varphi}:A \,{\rightarrow}\, A'$ given by the rule ${\varphi}(0) \,=\, c$, ${\varphi}(1) \,=\, d$ is an isomorphism.

\V

        The usual way to prove that two binary operations are isomorphic is to produce an isomorphism of one with the other, as in the preceding example.
    In contrast, the usual way to prove that two such operations are {\em not} isomorphic
    is to find an example of an algebraic property which holds for one but not the other.
    For example, the `absolute difference' operator on ${\ZZ}$ is commutative, but the `difference' operatior on ${\ZZ}$ is not.
    It follows that these binary operators are not isomorphic to each other.



%% EXERCISE `Isomorphic' is an equiv relation (without using that terminology.)




%% MAKE SURE TO PUT IT IN APPENDIX B!!


\StartSkip{
        This conjecture is {\em not} correct. Indeed, we construct below an explicit example, due to Cantor,
    of an uncountable subset of the closed unit interval $[0,1] \,=\, \{x: 0\,\,{\leq}\,\,x\,\,{\leq}\,\,1\}$.
    This construction involves the idea, familiar from grade-school arithmetic, of expressing a real number in terms of a `base'. 
    The most commonly used base is $10$, corresponding to the standard `decimal' representation;
    but other bases, notably  base~$2$ (binary) and base~$16$ (hexadecimal) are also used, especially in computer science.
    Thus, let us review -- without proofs -- the general procedure in the special case of numbers $x$ such that $0\,\,{\leq}\,\,x\,\,{\leq}\,\,1$.

\V

            \subsection{\small{\bf Definition}}
            \label{DefA20.85}

        Let $n$ be a natural number, with $n\,\,{\geq}\,\,2$, and let $S_{n} \,=\, \{0,1,2,\,{\ldots}\,n-1\}$ denote the {\bf base~$n$ digits}.
    For now let $x$ be a real number such that $0\,<\,x\,<\,1$.

\VA

        (1) The {\bf Type I digits of $\Bfm{x}$ in base-$\Bfm{n}$} are the numbers $a_{1}$, $a_{2}$,\,{\ldots}\, in $S_{n}$ given recursively as follows:

        \h $a_{1}$ is the largest base~$n$ digit such that ${\displaystyle \frac{a_{1}}{n}\,\,{\leq}\,\,x}$.

        \h If the base~$n$ digits $a_{1}$,\,{\ldots}\,$a_{k}$ have been defined, then $a_{k+1}$ is the largest base~$n$ digit such that
    ${\displaystyle \frac{a_{1}}{n} + \frac{a_{2}}{n^{2}} + \,{\ldots}\, + \frac{a_{k}}{n^{k}} + \frac{a_{k+1}}{n^{k+1}}\,\,{\leq}\,\,x}$.

        The {\bf Type I base-$n$ representation of $\Bfm{x}$} is $0 \stackrel{.}{(n)}a_{1}\,a_{2}\,\,{\ldots}\,a_{k}\,\,{\ldots}\,$
    in both this and the following representation the leading zero is conventional but optional.

\VA

        (2) The {\bf Type II digits of $\Bfm{x}$ in base~$\Bfm{n}$} are defined almost the same as in~(1) above;
    the only difference is that the inequality $\,\,{\leq}\,\,$ in~(1) is replaced throughout by the {\em strict} inequality~$\,<\,$.
    For convenience let us denote these digits by $b_{1}$, $b_{2}$,\,{\ldots}\,.

        The {\bf Type II base-$n$ representation of $\Bfm{x}$} is $0 \stackrel{.}{(n)}b_{1}\,b_{2}\,\,{\ldots}\,b_{k}\,\,{\ldots}\,$.

\VA

        (3) The {\bf base-$n$ representation of the number $x \,=\, 0$} is $0.0\,0\,\,{\ldots}\,$; there is only one such representation.
    Likewise, the two base-$n$ representations of the number $x \,=\, 1$ are $1\stackrel{.}{(n)}000\,{\ldots}\,$ (Type~I)
    and $0\stackrel{.}{(n)}(n-1)\,(n-1)\,{\ldots}\,$ (Type~II).

\VA



        {\bf Remarks} (1) For most values of $x$ such that $0\,<\,x\,<\,1$, all the Type~I and Type~II base-$n$ digits of $x$ are the same,
    and thus the corresponding base-$n$ representations are the same. The exception occurs if for some $k$ one has
    $a_{k}\,>\,0$ and ${\displaystyle \frac{a_{1}}{n} + \frac{a_{2}}{n^{2}} + \,{\ldots}\, + \frac{a_{k}}{n^{k}} \,=\, x}$.
    In that case one has $b_{i} \,=\, a_{i}$ for all $i$ such that $1\,\,{\leq}\,\,i\,\,{\leq}\,\,k-1$, $b_{k} \,=\, a_{k} - 1$,
    while $b_{j} \,=\, n-1$ and $a_{j} \,=\, 0$ for all $j\,>\,k$.

        (2) The `Type I', `Type II' terminology is nonstandard; it is inttroduced here only for convenience.

        (3) Of course the concept of `base~$n$ representation' applies to {\em all} real numbers, not just those in $[0,1]$.
    However, we need the concept here only for such numbers.

\VV

        The base used in the next definition is $n \,=\, 3$, corresponding to the so-called `ternary representation' of numbers.

\V

            \subsection{\small{\bf Definition}}
            \label{DefA20.100}

        The {\bf Cantor ternary set}\IndBD{set theory}{Cantor (ternary) set} (usually shortened to `the {\bf Cantor set}') is the set of all real numbers $x$
    which admit a representation in base~$3$ of the form $x \,=\, 0\stackrel{(3)}{.}c_{1}c_{2}\,{\ldots}\,c_{k}\,{\ldots}\,$,
    in which each of the ternary digits $c_{1}$, $c_{2}$, \,{\ldots}\, equals either $0$ or~$2$.
    For brevity, we shall refer to such a ternary representation as a {\bf $1$-free representation}.

\V

        \subsection{\small{{\bf Examples}}}
        \label{ExampA20.105}

\hspace*{\parindent}(1) The numbers $0$ and $1$ are in the Cantor set, since $0 \,=\, 0\stackrel{(3)}{.}0000\,{\ldots}\,$ and $1 \,=\, 0\stackrel{(3)}{.}2222\,{\ldots}\,$.

\V

        (2) The numbers $\frac{1}{3}$ and $\frac{2}{3}$ are in the Cantor set.
    Indeed, although the number $\frac{1}{3}$ does admit the ternary representation $0\stackrel{(3)}{.}10000\,{\ldots}\,$,
    which does {\em not} consist of all zeros and twos, it also admits the $1$-free representation $0\stackrel{(3)}{.}0222\,{\ldots}\,$.
    More generally, suppose that $x \,=\, \stackrel{(3)}{.}b_{1}\,{\ldots}\,b_{k}1000\,{\ldots}\,$, in which all the initial digits
    $b_{1}$,\,{\ldots}\,$b_{k}$ are either $0$ or $2$, the $(k+1)$-st digit is $1$, and all later digits are $0$.
    Then $x$ is in the Cantor set, since it has the $1$-free representation $x \,=\, \stackrel{(3)}{.}b_{1}\,{\ldots}\,b_{k}02222\,{\ldots}\,$.

        The case for $\frac{2}{3}$ is simpler, since its simplest ternary expression is $0\stackrel{(3)}{.}2000\,{\ldots}\,$, which is already $1$-free.
    (Of course this number admits the alternate expression $0\stackrel{(3)}{.}12222\,{\ldots}\,$, which is not $1$-free.)

\V

        (3) Suppose that $x$ satisfies $\frac{1}{3}\,<\,x\,<\,\frac{2}{3}$.
    Then $x$ is {\em not} in the Cantor set.
    Indeed, by the results of the previous example, one can write
        \begin{displaymath}
        0\stackrel{(3)}{.}1000\,{\ldots}\,\,{\ldots}\,\,<\,x\,<\,0.12222
        \end{displaymath}
    which implies that {\em every} ternary representation of $x$ must start $0\stackrel{(3)}{.}1\,{\ldots}\,$.
    In particular, $x$ does not admit a $1$-free ternary representation, and thus is not in the Cantor set.

\V

        (4) It is clear that if a number in $[0,1]$ has a $1$-free ternary representation, then this representation is unique.
    It follows that if $x$ and $y$ are elements of $C$, then $x \,=\, y$ if, and only if, their $1$-free ternary representations are exactly the same.

\VV

            \subsection{\small{\bf Theorem}}
            \label{ThmA20.110}

        The Cantor ternary set is uncountable.

\V
        \underline{Proof}: Let $C$ denote the Cantor ternary set. We must prove that there does not exist a bjection of ${\NN}$ onto~$C$.
    In fact, we prove a slightly stronger result: there does not even exist a function a surjection of ${\NN}$ onto~$C$.

        Indeed, suppose that $F:{\NN} \,{\rightarrow}\, C$ is any function with domain ${\NN}$ and values in~$C$.
    Define a point $p$ in $C$ by the following rule: for each $k{\in}{\NN}$, let $a_{k}$ be the $k$-th digit in the $1$-free ternary representation of $F(k)$;
    then the $k$-th ternary digit in the $1$-free ternary representation of $p$ is $2$ if $a_{k} \,=\, 0$, $0$ if $a_{k} \,=\, 2$.
    It is clear that $p$ is an element of $C$. Furthermore, by construction, for each $k$ in ${\NN}$ the $k$-th digit
    in the $1$-free ternary representation of $p$ is unequal to the corresponding digit of $a_{k}$,
    and so for each $k$ in ${\NN}$ one has $p \,\,{\neq}\,\, F(k)$; see Remark~(4) above.
    In particular, $p$ is not in the range of~$F$, so $F$ does not map ${\NN}$ surjectively onto~$C$.

\V


        Now that it is known that uncountable sets do exist, it is appropriate to state a few simple facts about such sets.



            \subsection{\small{\bf Theorem}}
            \label{ThmA20.112}

\V

        Let $A$ be an uncountable set.

\V

        (a) If $A$ has the same cardinality as a set $B$, then $B$ is also uncountable.

\V

        (b) If $B$ is a superset of $A$, i.e., $A \,{\subseteq}\, B$, then $B$ is also uncountable.

\V

        (c) The set $A$ has at least one countably infinite subset.

\V

        (d) If $S$ is a countable subset of $A$, then $A$ has the same cardinality as the complement $A\,{\setminus}\,S$ of $S$ in $A$.
    In particular, this complement is also uncountable.

\V

        {\bf Proof} (a) Suppose, to the contrary, that the set $B$ is countably infinite.
    (The easier part of the proof, to show that $B$ cannot be finite, is left as an exercise.)
    Let $F:{\NN} \,{\rightarrow}\, B$ be a bijection of ${\NN}$ onto $B$, and let $G:A \,{\rightarrow}\, B$ be a bijection of $A$ onto~$B$.
    Then the map $G^{-1}{\circ}F:{\NN} \,{\rightarrow}\, A$ would be a bijection of ${\NN}$ onto $A$, contradicting the hypothesis that $A$ is uncountable.

\V

        (b) This follows immediately from Theorem~\Ref{ThmA20.50}.

\V

        (c) For each $k$ in ${\NN}$ define an element $x_{k}$ of $A$ as follows:

        \h (i)\,\, Choose $x_{1}$ to be any element of $A$. (Since $A$ is infinite, it is certainly nonempty, so such $x_{1}$ does exist.)

        \h (ii)\, Choose $x_{2}$ to be any element of $A{\setminus}\{x_{1}\}$.

        \h (iii) Choose $x_{3}$ to be any element of $A{\setminus}\{x_{1},x_{2}\}$.

        \h (iv) Continue this process so that for each $k$ in ${\NN}$, $x_{k+1}$ is an element of the set $A{\setminus}\{x_{1},x_{2},\,{\ldots}\,x_{k}\}$.

\noindent It is clear that each of the sets $A{\setminus}\{x_{1},x_{2},\,{\ldots}\,x_{k}\}$ is nonempty.
    Indeed, if this set {\em were} empty, then $A$ would  be the finite set $\{x_{1},x_{2},\,{\ldots}\,x_{k}\}$,
    contrary to the hypothesis that $A$ is uncountable.

        Finally, let $U \,=\, \{x_{1},x_{2},\,{\ldots}\,x_{k},\,{\ldots}\,\}$. Then it is clear that the set $U$ is countably infinite; indeed, the function $F:{\NN} \,{\rightarrow}\, U$,
    given by the rule $F(k) \,=\, x_{k}$ for each $k$ in ${\NN}$, is clearly a bijection of ${\NN}$ onto $U$.

\V

        (d) To simplify the discussion, assume that $S$ is countably {\em infinite}.
    (The easier part of the proof, to show that $B$ cannot be finite, is left as an exercise.)
    Let $F:{\NN} \,{\rightarrow}\, S$ be a bijection of ${\NN}$ onto $S$, and set $y_{k} \,=\, F(k)$ for each $k$ in ${\NN}$;
    note that if $i \,\,{\neq}\,\, j$ then $y_{i} \,\,{\neq}\,\, y_{j}$.
    Next, let $B \,=\, A\,{\setminus}\,S$. It is clear that $B$ is also uncountable;
    indeed, if it were not, then one could express $A$ as the union $A \,=\, S\,{\cup}\,B$ of countable sets,
    so that, by Theorem~\Ref{ThmA20.70}, $A$ would also be countable, contrary to the hypothesis that $A$ is {\em un}countable.
    Then by Part~(c) there exists a countably infinite subset $\{x_{1}, x_{2},\,{\ldots}\,x_{k},\,{\ldots}\,\}$ of $B$, with $x_{i} \,\,{\neq}\,\, x_{j}$ if $i \,\,{\neq}\,\, j$.
    Define a function $F:B \,{\rightarrow}\, A$ by the rule
        \begin{displaymath}
        F(z) \,=\, \left\{
        \begin{array}{ll}
        x_{k} & \mbox{if $z$ is of the form $x_{2k}$ for some $k$}         \\
        y_{k} & \mbox{if $z$ is of the form $x_{2k-1}$ for some $k$}       \\
        z     & \mbox{if $z$ is {\em not} of the form $x_{k}$ for some $k$}
        \end{array}
        \right.
        \end{displaymath}
\noindent It is easy to see that $F$ is bijection of $B$ onto $A$.



            \subsection{\small{\bf Corollary}}
            \label{CorA20.115}

\V

        The following sets of real numbers are uncountable:

        (a) ${\RR}$; \h (b) any interval in ${\RR}$ \h (c) the set of irrational numbers.

\V

       The simple proof is left as an exercise.
 

\V

        \underline{Remark} Part (d) shows, in effect, that an uncountable set is {\em much} `larger' than any countable set.
    Indeed, this result can be thought of as an uncountable version of the `Amazing Grace Property'\IndB{Amazing Grace}{Amazing Grace Property for uncountable sets}; see Part~(c) of Theorem~\Ref{ThmA20.50}.

\V
\V

            \subsection{\small{\bf Remarks}}
            \label{RemrkA20.125}

\V

        \hspace*{\parindent}(1) Example~\Ref{ExampA20.105}~(3) above suggests a more geometric way to think about the Cantor ternary set:
    instead of describing the set in terms of which numbers are the members of the set,
    describe it in terms of the numbers which musty be removed from $[0,1]$ to get the set.
    Indeed, the Cantor set $C$ consists of those numbers $x$ in the interval $[0,1]$ which admit a $1$-free ternary representation $0\stackrel{(3)}{.}b_{1}b_{2}\,{\ldots}\,$.
    Thus one can also describe $C$ as the set that results from removing from $[0,1]$ all those $x$ whose ternary representation {\em must} include at least one digit equal to~$1$.
    For instance, Example~\Ref{ExampA20.105}~(3) can be interpreted as removing from $[0,1]$ those $x$ whose ternary representation 
    $0.b_{1}b_{2}\,{\ldots}\,b_{k}\,{\ldots}\,$ {\em must} have $b_{1} \,=\, 1$.
    What is left after removing this `open middle third' of the original interval $[0,1]$ is a set consisting of two subintervals, $[0,\frac{1}{3}]$ and $[\frac{2}{3},1]$.
    The former subinterval consists of those numbers in $[0,1]$ which admit a ternary representation in which $b_{1} \,=\, 0$;
    likewise, those in the second subinterval consist of those numbers which admit a ternary representation in which $b_{1} \,=\, 2$.

       Now remove the open middle third from each of the subintervals obtained in the previous step.
    This has the effect of removing from $[0,1]$ those numbers for which $b_{1}$ can be $0$ or $2$, but for which $b_{2}$ {\em must} be~$1$.
    By continuing indefinitely this process of removing middle open intervals, 
    one is finally left with those numbers in $[0,1]$ for which none of the digits $b_{i}$ {\em must} be $1$; that is, with the Cantor set.

        \underline{Note} Because of this construction, which is actually the one Cantor used to construct this set,
    some authors refer to the Cantor Ternary set as the {\bf Middle-Thirds Set}\IndBD{set theory}{Middle-Thirds Set}.

\V

        (2) In the preceding `Middle Thirds' construction of the Cantor set $C$, at each stage of the process only finitely many open intervals are removed;
    the two end points of each removed interval are left in the Cantor set.
    In particular, the endpoints of the removed subintervals form a countably infinite subset of $C$.

        Let $\hat{C}$ denote the set obtained by removing from $C$ the left endpoints of these removed subintervals.
    (It is easy to see that the $1$-free ternary representation of a left endpoint of a removed subinterval must consist entirely of $2$s from some point on.
    In contrast, the right endpoints of these intervals have $1$-free ternary representation that consist of all $0$s from some point on.)
    Since $\hat{C}$ is obtained from $C$ by removing a countably infinite subset, it follows from Theorem~\Ref{ThmA20.112} that the set $\hat{C}$ has the same cardinality as $C$.
    It is easy to see from our earlier analysis that the numbers in $\hat{C}$ are precisely those in $C$ which have a $1$-free ternary representation whose digits include infinitely many zeros.

\V

        (3) Many students believe that after the process of removing open middle-thirds described above is completed,
    all that remains, namely the Cantor set, is the set of endpoints of the removed intervals.
    Clearly this cannot be true, since the set of those endpoints is countable, while the Cantor set is uncountable.

\v
\V

        It has already been observed that cetain sets, such as ${\RR}$ and intervals in ${\RR}$, are uncountable; see Theorem~\Ref{ThmA20.112} and Corollary~\Ref{CorA20.115}.
    The next result makes this more precise.

\V

            \subsection{\small{\bf Theorem}}
            \label{ThmA20.130}

        The cardinality of the closed interval $[0,1]$ is the same as the cardinality of the Cantor ternary set.


\V

        \underline{Proof}: Let $C$ denote the Cantor set, and let $\hat{C}$ be the subset of $C$ described in the preceding remark.
    Since $\hat{C}$ and $C$ have the same cardinality, it suffices to show that $\hat{C}$ has the same cardinality as the interval $[0,1]$.
    To that end, define a function $F:\hat{C} \,{\rightarrow}\, [0,1]$ by the following rule:
    if $x{\in}\hat{C}$, and $0\stackrel{(3)}{.}b_{1}b_{2}\,{\ldots}\, $ be its $1$-free ternary representation, then
        \begin{displaymath}
        F(x) \,=\, 0 \stackrel{(2)}{.}c_{1}c_{2}\,{\ldots}\, c_{k}\,{\ldots}\,, \mbox{ where $c_{k} \,=\, b_{k/2}$}.
        \end{displaymath}
    Note that for $F(x)$ one uses the {\em binary} representation, not the ternary.
    It is easy to see that $F$ is a bijection of $\hat{C}$ onto $[0,1]$, and thus $[0,1]$ has the same cardinality as $C$ and as ${\cal {\NN}}$.


\V
\V

        The next results are analogs, for $C$ and $[0,1]$, respectively, of Corollary~\Ref{CorA20.80}.

\V
\V


            \subsection{\small{\bf Theorem}}
            \label{ThmA20.140}

\hspace*{\parindent}
    (a) The Cartesian product $C{\times}C$ of the Cantor set $C$ has the same cardinality as $C$.

\V

        (b) The square $[0,1]{\times}[0,1]$ has the same cardinality as the interval $[0,1]$.

\V

        \underline{Proof}: (a) Define $F:C{\times}C \,{\rightarrow}\, C$ by the following rule:
    if $x$ and $y$ are in $C$, with $x \,=\, 0\stackrel{(3)}{.}b_{1}b_{2}\,{\ldots}\,$ and $y \,=\, 0\stackrel{(3)}{.}c_{1}c_{2}\,{\ldots}\,$ being the respective $1$-free ternary representations,
    then
        \begin{displaymath}
        F(x,y) \,=\, 0\stackrel{(3)}{.}b_{1}c_{1}b_{2}c_{2},\,{\ldots}\,b_{k}c_{k}\,{\ldots}\,
        \end{displaymath}
    It is clear that $F$ is a bijection of $C{\times}C$ onto $C$.

\V

        (b) This follows from the preceding result, together with Part~(e) of Theorem~\Ref{ThmA15.15} and the fact that $C$ and $[0,1]$ have the same cardinality.

\V
\V
}%\EndSkip

\StartSkip{

              \section{Bijections Induced from Injections/Surjections}
                        \label{SectA50}\IndB{ZZ Sections}{\Ref{SectA50} Bijections Induced from Injections/Surjections}

        Recall that a function $f:X \,{\rightarrow}\, Y$ is a bijection provided it is both an injection and a surjection.
    If the function $f:X \,{\rightarrow}\, Y$ has only one of these properties, it is still possible to associate with $f$ a bijection in a natural way.
    First consider the simpler case, in which $f$ is an injection.

        \subsection{\small{{\bf Theorem}}}
        \label{ThmA50.55A}

        Let $f:X \,{\rightarrow}\, Y$ be an injection. Then there is a unique subset $W$ of $B$ such that $f:X \,{\rightarrow}\, W$ is a bijection;
    namely, $W \,=\, f[X]$, the image of the function~$f$. One calls the bijection $f:X \,{\rightarrow}\, W$
    the {\bf bijection induced by the injection $\Bfm{f}$}\IndC{functions}{bijections}{bijection induced by an injection}


\V

        The trivial proof is left as an exercise. %% EXERCISE??

\VV


        The situation when $f:X \,{\rightarrow}\, Y$ is a surjection seems to be as easy to handle.
    Indeed, the `surjection' hypothesis is equivalent to the statement that for each $y$ in $Y$ the inverse image $f^{-1}[\{y\}] \,{\subseteq}\, X$ is nonempty.
    Thus the `obvious' solution is to let $U$ be a subset of $X$ obtained by choosing exactly one element $x$ out of each set $f^{-1}[\ \,{\subseteq}\, y\}]$
    and then letting $U$ be the set of all $x$ in~$X$ chosen this way. It is clear that the restriction $f|_{U}:U \,{\rightarrow}\, Y$ is a bijection.

        The problem with this construction is that usually there is no `natural' way to choose a particular $x$ in the set $f^{-1}[\{y\}]$,
    so that the subset $U \,{\subseteq}\, X$ has a certain arbitrariness. An important exception is if $X$ is a subset of~${\NN}$,
    in which case the `natural' choice for $x$ is the least element of the set~$f^{-1}[\{y\}]$ ; see the proof of Theorem~\Ref{ThmA20.25A}.
    The next definition associates with the original surjection $f:X \,{\rightarrow}\, Y$ a bijection $\hat{f}:U \,{\rightarrow}\, Y$.
    The construction of the new domain $U$ avoids the arbitrariness observed above;
    however, the cost of avoiding arbitrariness is that $U$ is not a subset of the original domain~$X$.
    The construction is used in many areas of modern mathematics.

\V

        \subsection{\small{{\bf Definition}}}
        \label{DefA50.60}

\V

        Suppose that $X$ and $Y$ are nonempty sets and that $f:X\,{\rightarrow}\,Y$ is a surjection of $X$ onto $Y$.

\V

        (1) For each element $y{\in}Y$ let $X_{y;f}$ denote the subset of $X$ consisting of all elements $x{\in}X$ such that $f(x) \,=\, y$;
    that is, $X_{y;f} \,=\, f^{-1}[\{y\}]$; see Part~(2) of Definition~\Ref{DefA30.15}.
    The set $X_{y;f}$ is called the {\bf level set of the function $\Bfm{f:X \,{\rightarrow}\, Y}$ at level $y$}.\IndBD{functions}{level set of a function}
    The family of all the level sets of the surjection $f:X \,{\rightarrow}\, Y$ is called the {\bf quotient set of $X$ associated with $f$};
    \IndB{functions}{quotient set of a surjective function} it is denoted by $X/(f)$.
    In symbols:
        \begin{displaymath}
        X/(f) \,=\, \{S{\subseteq}X: S \,=\, X_{y;f} \mbox{ for some $y{\in}Y$}\}.
        \end{displaymath}
    The expression $X/(f)$ is often pronounced {\bf $\Bfm{X}\mbox{ mod } \Bfm{f}$}, where `mod' is short for `modulo'.

\V

        (2) Associated with the surjection $f:X \,{\rightarrow}\, Y$ is a map $\hat{f}:X/(f) \,{\rightarrow}\, Y$ defined by the rule
        \begin{displaymath}
        \hat{f}(X_{y;f}) \,=\, y \mbox{ for each $y$ in $Y$}.
        \end{displaymath}
    It is called the {\bf natural bijection}
    \IndBD{functions}{natural bijection associated with a surjection} associated with the given surjection.

\V

        (3) Also associated with the surjection $f:X \,{\rightarrow}\, Y$ is a surjection
    $P_{f}:X \,{\rightarrow}\, X/(f)$ given by the rule $P_{f}(x) \,=\, X_{f(x); f}$.
    This function is called the {\bf quotient map associated with~$\Bfm{f}$}\IndBD{functions}{quotient map associated with a surjection}.

\VV

        {\bf Remarks} (1) The `quotient set', `quotient map' and `modulo' terminology come from analogous situations in algebra.

\V
        (2) The proof that $\hat{f}$ is a bijection from $X/(f)$ onto $Y$ is left as an easy exercise,
    as is the proof that the quotient map $P_{f}$ is a surjection. The quotient set $X/(f)$ plays the role of the `new domain' $U$ discussed above.

%% INCLUDE THESE EXERCISES

\V

        (3) It can happen that the original surjection $f:X \,{\rightarrow}\, Y$ is already a bijection.
    Indeed, it is obvious that this occurs if, and only if, each of the level sets $X_{y;f}$ is a singleton set.
    In this case the elements of the quotient set $X/(f)$ consist of the singleton sets of the form $\{x\}$ with $x$ in $X$,
    and the natural bijection $\hat{f}:X/(f) \,{\rightarrow}\, Y$ takes the form $\hat{f}(\{x\}) \,=\, f(x)$ for each $x$ in $X$.
    It is customary in this case to identify $X/(f)$ with $X$ itself. Normally this abuse of notation causes no difficulty.

% DISCUSS UNIVERSAL MAPS IN A SIDE COMMENT?

\VV

        \subsection{\small{{\bf Examples}}}
        \label{ExampA50.70}

\hspace*{\parindent}
        (1) Define a function $f:{\ZZ} \,{\rightarrow}\, \{0,1\}$ by the rule that $f(k) \,=\, 0$ if $k$ is an even integer,
    and $f(k) \,=\, 1$ if $k$ is an odd integer. It is obvious that this is a surjection.
    If we let $E$ and $O$ denote the sets of even and odd integers, respectively, then it is clear that ${\ZZ}/(f) \,=\, \{E,O\}$.
    Also, $\hat{f}(E) \,=\, 0$ and $\hat{f}(O) \,=\, 1$, while $P_{f}(k) \,=\, E$ if $k$ is even and $P_{f}(k) \,=\, O$ if $k$ is~odd.
    It is customary in this situation to write ${\ZZ}_{2}$ in place of ${\ZZ}_{(f)}$.
    It is equally common to write ${\ZZ}_{2} \,=\, \{0,1\}$, but technically this is an abuse of notation; it usually causes no confusion.

\V

        (2) There are two obvious surjections of ${\RR}^{2}$ onto ${\RR}$:

\VA

        \h (i)\, $f_{1}:{\RR}^{2} \,{\rightarrow}\, {\RR}$ given by the rule $f(x_{1},x_{2}) \,=\, x_{1}$;

        \h (ii) $f_{2}:{\RR}^{2} \,{\rightarrow}\, {\RR}$ given by the rule $f_{2}(x_{1},x_{2}) \,=\, x_{2}$.

\VA

\noindent If we view ${\RR}^{2}$ geometrically as the usual Euclidean plane from analytical geometry,
    then the level sets associated with $f_{1}$ are precisely the vertical lines of this plane, and ${\RR}^{2}_{f_{1}}$ is the set of all such lines.
    Similarly, the level sets of the surjection $f_{2}$ are the horizontal lines of that plane, and ${\RR}^{2}_{f_{2}}$ is the set of all such lines.

\V

        (3) Define $f:{\NN}{\times}{\NN} \,{\rightarrow}\, {\ZZ}$ by the rule $f(i,j) \,=\, j-i$ for all $(i,j)$ in~${\NN}^{2}$.
    It is clear that $f:{\NN}{\times}{\NN} \,{\rightarrow}\, {\ZZ}$ is a surjection.
    (Note that in forming these differences we treat ${\NN}$ as a subset of ${\ZZ}$.)
    It is easy to see that if $(m_{0},n_{0})$ is a particular element of ${\NN}^{2}$,
    then the level set of the function $f$ containing the pair $(m_{0},n_{0})$ is precisely
    the set of ordered pairs $(m,n)$ in ${\NN}^{2}$ such that $n-m \,=\, n_{0}-m_{0}$. Alternatively,
    it is precisely the set of all pairs $(m,n)$ in ${\NN}^{2}$ such that $n+m_{0} \,=\, n_{0} + m$.
    Note that the latter formulation does not involve subtraction of natural numbers;
    in particular, the elements of the quotient set ${\NN}^{2}/(f)$ can be described purely in terms of ${\NN}$ and addition of natural numbers,
    without directly using subtraction.
    

\VV

       % \subsection{\small{{\bf Remark}}}
       % \label{RemrkA50.80}

%%%
\begin{quotation}
{\footnotesize \underline{\Note}\IndB{\notes}{on constructions of ${\ZZ}$ from {\NN}} (on constructions of ${\ZZ}$ from {\NN})

        Many authors construct the set ${\ZZ}$ of all integers from the set ${\NN} \,=\, \{1, 2, 3, \,{\ldots}\,\}$
    of all natural number as is done in elementary arithmetic: first, they adjoin to ${\NN}$ the new number~$0$;
    then they adjoin to ${\NN}$ the new numbers $-1$, $-2$,\,{\ldots}\, obtained by placing a `minus sign' before each natural number.
    Finally, they define the usual operations of addition and multiplication of integers in the usual manner.
    For example, they define $3 - 7 \,=\, -(7 - 3)$, where $7 - 3$ is the usual subtraction of a smaller natural number from a larger,
    so the right side makes sense. With this construction the set ${\NN}$ is a subset of the set ${\ZZ}$; namely, it is the set of {\em positive} integers.
    Likewise, they define the usual ordering of the integers so that $j\,<\,k$ in ${\ZZ}$ if, and only if,
    there exists a positive integer (i.e., a natural number) $i$ such that $i+j \,=\, k$.
    The usual algebraic properties of ${\ZZ}$ then follow easily from the corresponding properties of~${\NN}$.
    This is the viewpoint we adopt on the relation between ${\NN}$ and ${\ZZ}$ in the main body of {\ThisText}.


        In contrast, many modern authors prefer to construct ${\ZZ}$ from ${\NN}$ in a more complicated way, using the results of Example~(3) above.
    First, they use the natural bijection $\hat{f}:{\NN}^{2} \,{\rightarrow}\, {\ZZ}$, together with the results of Part~(4) of Example~\Ref{ExampA60.80},
    to obtain a pair of binary operations $+'$ and~${{\cdot}'}$ on ${\NN}^{    2}/(f)$ which are isomorphic to the usual $+$ and~${\cdot}$ on~${\NN}$.
    However, it has already been pointed out above that the set ${\NN}^{2}/(f)$ can be described purely in terms of ${\NN}$,
    with no reference to the set~${\ZZ}$ or the function~$f$. To emphasize this fact, let us temporarily use the notation ${\ZZ}'$ in place of ${\NN}^{2}/(f)$.
    Now ${\ZZ}'$ is a set with a pair of binary operations $+'$ and ${\cdot}'$. It is an easy exercise to describe the binary operations $+'$ and ${\cdot}'$
    purely in terms of ${\NN}$, with no reference to the set ${\ZZ}$ or the function~$f$.
    The modern construction of ${\ZZ}$ from ${\NN}$ then consists of defining a `new and improved' version of the integers,
    incuding addition and multiplication, namely the ${\NN}'$ with the operations $+'$ and~${\cdot}'$ described above.
    Finally, one erases all references to how this construction came about, and erases the `primes' in ${\ZZ}'$, $+'$ and~${\cdot}'$.
    Of course, this `new and improved' version of ${\ZZ}$ does not have the original set ${\NN}$ as a subset, in contrast with the original construction.
    This modern approach is carried out in Appendix~A.
}%EndFootNoteSize
\end{quotation}
%##

% EXERCISES NEED
}%\EndSkip


%-----------------
\StartSkip{

        An important process, which appears in all parts of modern mathematics, is to express a given set as the union of subsets which are mutually disjoint.
    The terminology and notation used in describing this process depends on the specific context. The terminology we use here is fairly `generic'.


\V


        \subsection{\small{{\bf Definition}}}
        \label{DefA50.85}

\hspace*{\parindent}
        Let $X$ be a nonempty set.
    Suppose that ${\cal F}$ is a family of subsets of $X$ with the following properties:

        \h (i) \,\, (Nontriviality Property) Every set in the family ${\cal F}$ is nonempty.

        \h (ii) \, (Disjointness Property) The sets in the family ${\cal F}$ are mutually disjoint;
    that is, if $S$ and $T$ are in the family ${\cal F}$, and $S \,\,{\neq}\,\, T$, then $S\,{\cap}\,T \,=\, {\emptyset}$.

        \h (iii) (Union Property) The union of the family ${\cal F}$ is the given set $X$;
    in symbols,
        \begin{displaymath}
        X \,=\, {\bigcup}_{S{\in}{\cal F}} S.
        \end{displaymath}
    Then one says that the family ${\cal F}$ is {\bf a partition of $\Bfm{X}$}.\IndB{partition}{partition of a set} One also uses the word `partition' as a verb:
    to chose a particular family ${\cal F}$ is `{\bf to partition~$\Bfm{X}$}.

\V



        {\bf Remark} The use of the word `partition' here, in the sense of a `partition of a set', is standard in mathematics.
    Unfortunately, there is a second use of the word `partition', also standard in mathematics, that is different; namely, `partition of an interval'; see Definition~\Ref{DefB20.130}.
    Usually the context makes it clear which sense of the word `partition' is meant;
    but if needed for clarity, we refer to the first sense as a `set-partition'\IndC{partition}{of a set}{set-partition vs interval-partition}, and the second as an `interval-partition'.

\V
\V

        \subsection{\small{{\bf Examples}}}
        \label{ExampA50.70}

\hspace*{\parindent}
        (1) Let $X$ be any nonempty set, and let ${\cal F}$ be the family which has exactly one element, namely the set $X$ itself (thought of as an object).
    Then ${\cal F}$ is clearly a partition of $X$; it is called the {\bf trivial partition of $\Bfm{X}$}.

\V

        (2) Let $X \,=\, {\RR}^{2} \,=\, {\RR}{\times}{\RR}$. There are two fairly obvious ways to partition this~$X$:
    as the union of horizontal lines and as the union of vertical lines. More precisely, define families ${\cal F}_{1}$ and ${\cal F}_{2}$ as follows:

        \h ${\cal F}_{1}$ consists of all subsets $Y_{b}$, with $b{\in}{\RR}$, of the form $Y_{b} \,=\, \{(x,b): x{\in}{\RR}\}$.

        \h ${\cal F}_{2}$ consists of all subsets $Z_{a}$, with $a{\in}{\RR}$, of the form $Z_{a} \,=\, \{(a,x): x{\in}{\RR}\}$.

\noindent It is clear that ${\cal F}_{1}$ and ${\cal F}_{2}$ are both partitions of~$X$, and they are {\em different} partitions.


\V

        (3) Let $X \,=\, {\NN}$, and let ${\cal F} \,=\, \{A,B\}$, where $A$ is the set of all even natural numbers,
    and $B$ is the set of all odd natural numbers. It is clear that ${\cal F}$ is a partition of~$X$.

\V

        (4) Using this new `partition' terminology, one sees that Example~\Ref{ExampA20.60}
    provides a partition ${\cal F}$ of ${\NN}$ which has infinitely many members, each itself being a countably infinite subset of ${\NN}$.

\V

        (5) Suppose that ${\cal F}$ is a partition of a set $X$, and that, for each set $A$ in the family ${\cal F}$,
    the family ${\cal G}_{A}$ is a partition of the set $A$. Then one defines a corresponding partition ${\cal H}$ of $X$ by the rule
    ${\cal H} \,=\, \{C: C{\in}{\cal G}_{A} \mbox{ for some $A{\in}{\cal F}$}\}$.
    Any partition ${\cal H}$ of $A$ obtained from ${\cal F}$ this way is said to be a {\bf refinement of $\Bfm{{\cal H}}$},
    or to be {\bf finer than $\Bfm{{\cal F}}$}. Likewise, one says that ${\cal F}$ is {\bf coarser than $\Bfm{{\cal H}}$}.
    Note that it is possible for ${\cal H}$ to equal ${\cal F}$, namely when each partition ${\cal G}_{A}$ is the trivial partition of~$A$.

\V
\V


        There is another concept, namely that of an {\em equivalence relation on a set},
    which appears frequently in modern mathematics and which is equivalent to the concept of `partition of a set' described above.
    Because we do not use the concept of equivalence relation in the main body of {\TheseNotes}, its treatment is relegated to Appendix~B.


\V
\V


        There is a standard way of constructing partitions using surjections.

\V

        \subsection{\small{{\bf Definition}}}
        \label{DefA50.60}

        Suppose that $X$ and $Y$ are nonempty sets and that $f:X\,{\rightarrow}\,Y$ is a surjection of $X$ onto $Y$.
    For each element $y{\in}Y$ let $X_{y;f}$ denote the subset of $X$ consisting of all elements $x{\in}X$ such that $f(x) \,=\, y$;
    that is, $X_{y;f} \,=\, f^{-1}[\{y\}]$.
    (The set $X_{y;f}$ is often called the {\bf level set of $f$ at level $y$}.)
    The family of all the sets of the form $X_{y;f}$ is called the {\bf quotient set of $X$ associated with $f$}; we denote it by $X/(f)$.
    That is,
        \begin{displaymath}
        X/(f) \,=\, \{S{\subseteq}X: S \,=\, X_{y;f} \mbox{ for some $y{\in}Y$}\}.
        \end{displaymath}

\V

        \subsection{\small{{\bf Theorem}}}
        \label{ThmA50.80}

        Suppose that $f:X{\rightarrow}Y$ is a surjection of $X$ onto $Y$.
    Then the quotient set $X/(f)$ is a partition of~$X$. That is:

        \h (a) For each $y{\in}Y$ the set $X_{y;f}$ is nonempty; in particular, $X/(f)$ is a family of nonempty sets.

        \h (b) The sets in the family $X/(f)$ are mutually disjoint, in the sense that if $y_{1}$ and $y_{2}$ are elements of $Y$
    such that
        $y_{1} \,\,{\neq}\,\, y_{2}$, then $X_{y_{1};f}{\cap}X_{y_{2};f} \,=\, {\emptyset}$.

        \h (c) The union of the family $X/(f)$ is the original set $X$; in symbols,
        \begin{displaymath}
        {\bigcup}_{y{\in}Y} X_{y;f} \,=\, X.
        \end{displaymath}

\V

        Conversely, every partition ${\cal F}$ of $X$ can be expressed in the form ${\cal F} \,=\, X/(f)$ for some surjection $f$ of $X$ onto some set~$Y$.

\V

        {\bf Proof} To verify that $X/(f)$ is in fact a partition of $X$ is left as a simple exercise.

    To prove the converse, let $Y \,=\, {\cal F}$ itself, and define $f:X \,{\rightarrow}\, Y$
    by the rule that $f(x)$ is the unique set in the partition ${\cal F}$ containing $x$ as an element.
    It is easy to show that this choice of $Y$ and $f$ works.

\V
\V


        \subsection{\small{{\bf Remark}}}
        \label{RemrkA50.87}

\V

\hspace*{\parindent} The choice of $Y$ and $f$ used above is certainly not the only one that works.


\V
\V

        It often happens that one can use set-partitions to simplify the task of proving that two sets have the same cardinality.
    The next result forms the basis for this technique.

\V

        \subsection{\small{{\bf Theorem}}}
        \label{ThmA50.88A}

\V

        Let $X$ and $Y$ be nonempty sets, and let ${\cal F}$ and ${\cal G}$ on be partitions of $X$ and $Y$, respectively.
    Suppose that there exists a function $H:{\cal F} \,{\rightarrow}\, {\cal G}$ with the following properties:

        \h (i)\, $H$ is a bijection of ${\cal F}$ onto ${\cal G}$.

        \h (ii) For each set $S$ in the family ${\cal F}$, the sets $S$ and $H(S)$ have the same cardinality.

        Then $X$ and $Y$ have the same cardinality.

\V

        {\bf Proof}\,  For each $S$ in the family ${\cal F}$ let $f_{S}:S \,{\rightarrow}\, H(S)$ be a bijection of $S$ onto $H(S)$.
    Since the sets in a partition are mutually disjoint, one can use Theorem~\Ref{ThmA30.27} to conclude that the union of the functions $f_{S}$,
    as $S$ varies over the family ${\cal F}$, is a function $f:{\bigcup} {\cal F} \,{\rightarrow}\, {\bigcup} {\cal G}$.
    However, by the definition of `partition' one knows that ${\bigcup} {\cal F} \,=\, X$ and ${\bigcup} {\cal G} \,=\, Y$, so $f$ is a function from $X$ to $Y$.
    That $f$ is a bijection of $X$ onto $Y$ now follows easily.



\VV

        \subsection{\small{{\bf Binary Operations on a Set}}}
        \label{SectA60}

        The following special class of functions could have been discussed much earlier in this chapter.
    It is studied here, at the end of main part of this chapter, because functions of this type also appear at the beginning of the next chapter.


        \subsection{\small{{\bf Definitions}}}
        \label{DefA60.10}

        Let $A$ be a nonempty set.

\V

        (1) Suppose that $f:A^{2} \,{\rightarrow}\, A$ is a function whose domain is the Cartesian product of a nonempty set $A$ with itself,
    and whose values are in $A$. Then one says that $f$ is a
    {\bf binary operation\IndBD{operations/operators}{binary operations} on $\Bfm{A}$}.

        \underline{Note} The word {\bf operator} is often used in place of `operation' in this context.


\V

        (2) A binary operation $f:A^{2} \,{\rightarrow}\, A$ is said to be {\bf commutative}\IndC{operations/operators}{binary operations}{commutative} if
        \begin{displaymath}
        f(x,y) \,=\, f(y,x) \mbox{ for all $x$ and $y$ in $A$}.
        \end{displaymath}
    It is said to be {\bf associative}\IndC{operations/operators}{binary operations}{associative} if
        \begin{displaymath}
        f(f(x,y),z) \,=\, f(x,f(y,z)) \mbox{ for all $x$, $y$ and $z$ in $A$}.
        \end{displaymath}

\V
\V


        \subsection{\small{{\bf Examples}}}
        \label{ExampA60.20}

\V

        (1) The `sum function' $S:{\RR}^{2} \,{\rightarrow}\, {\RR}$,
    defined by $S(x,y) \,=\, x+y$ for all $(x,y)$ in ${\RR}^{2}$, is a binary operation on ${\RR}$.
    So is the `product function' $P:{\RR}^{2} \,{\rightarrow}\, {\RR}$, given by the rule 
        \begin{displaymath}
        P(x,y) \,=\, x{\cdot}y \mbox{ for all $x$ and $y$ in ${\RR}$}.
        \end{displaymath}

        It is well known that the sum operation $S$ and product operation $P$ described above are both commutative and associative.
    For example, the commutivity of the operation $S$, namely $S(x,y) \,=\, S(y,x)$, follows from the fact that $x+y \,=\, y+x$.
    The fact that $S$ is also associative may be less obvious, since the equation describing this property in the preceding definition is complicated:
        \begin{displaymath}
        S(S(x,y),z) \,=\, S(x,S(y,z)).
        \end{displaymath}
    The left side of this equation is, by the definition of the operation $S$
        \begin{displaymath}
        S(S(x,y),z) \,=\, S(x+y,z) \,=\, (x+y)+z.
        \end{displaymath}
    Likewise, the right side is
        \begin{displaymath}
        S(x,S(y,z) \,=\, x+S(y,z) \,=\, x+(y+z).
        \end{displaymath}
    The fact that $(x+y) + z \,=\, x+(y+z)$ for all real numbers
    $x,y,z$ is a well-known fact about addition.

\V

       (2) The `difference function' $D:{\RR}^{2} \,{\rightarrow}\, {\RR}$, defined by the equation $D(x,y) \,=\, x-y$ is a binary operation on ${\RR}$.
    So is the `absolute difference function' $\hat{D}:{\RR}^{2} \,{\rightarrow}\, {\RR}$, given by the formula $\hat{D}(x,y) \,=\, |x-y|$.

       It is a simple exercise to show that the difference operator $D$ is neither commutative nor associative,
    while the absolute-difference operator $\hat{D}$ is commutative but not associative.

\V

       (3) Let $X$ be a nonempty set and let $A$ be the set of all functions $f:X \,{\rightarrow}\, X$ with domain $X$ and having values in~$X$.
    Define the {\bf Composition Operation} $C$ on $A$ to be the binary operation $C:A^{2} \,{\rightarrow}\, A$ given by the rule $C(f,g) \,=\, f{\circ}g$, where the latter expression is described in Definition~\Ref{DefA30.130}.

       It is clear that the binary operation $C$ is associative no matter which nonempty set $X$ is used;
    see Remark~\Ref{RemrkA30.140} and Theorem~\Ref{ThmA30.160}.
    However, if the set $X$ has more than one element, then $C$ is not commutative.

\V

        \underline{Remark} The preceding examples point out a notational difficulty associated with defining `binary operations' as functions.
    For instance, the `functional' notation for sums is $S(x,y)$, with the symbol $S$ for ths operation located to the left of both numbers being summed.
    In contrast, the common notation for the sum of two numbers $x$ and $y$ is $x+y$,
    with the symbol for this operation, the `plus' sign $+$, placed between the numbers.
    Roughly speaking, the difference between these two perfectly valid notational choices corresponds to the difference between pronouncing them
    as `the sum of $x$ and $y$' or `$x$ plus $y$'.
    Similarly, one can say `the product of $x$ and $y$', or `$x$ times $y$'; `the difference between $x$ and $y$', or `$x$ minus $y$;
    `the composition of $f$ with $g$,' or `$f$ circle $g$'.

        Most people prefer to use the `symbol-between-the-inputs' notation instead of the `function' notation (e.g., $x+y$ instead of $S(x,y)$).
    (An exception to this statement might occur with, say, the `absolute difference' binary operation $\hat{D}$.)
    The official name of this preferred notation is the
    {\bf infix representation}\IndBD{operations/operators}{infix representations} of the binary operation.
    To accomodate this notational preference, it is common when discussing binary operations `in the abstract' to choose a `generic' symbol,
    such as ${\ast}$, to act as the (infix) symbol of a `generic' binary operation $f:A^{2} \,{\rightarrow}\, A$,
    much as the plus sign $+$ is the infix symbol of the operation~$S$.
    With such a choice, one then normally writes $x{\ast}y$ instead of $f(x,y)$. 
    Likewise, one often refers to `the binary operation~${\ast}$' instead of the more proper usage, `the binary operation~$f$'.
    Note that with the infix notation the commutative and associative laws take the more familiar forms
        \begin{displaymath}
        x{\ast}y \,=\, y{\ast}x \mbox{ and } (x{\ast}y){\ast}z \,=\, x{\ast}(y{\ast}z),
        \end{displaymath}
    respectively.

\V

        By its very definition, a binary operation on a set $A$ acts only on {\em pairs} of objects in the set $A$.
    Nevertheless, it is quite common in mathematics to encounter expressions which involve multiple appearances of binary operations.
    For example, consider the following expressions involving binary operations acting on numbers:
        \begin{displaymath}
        (i)\,   (a+b){\cdot}(c+d); \h
        (ii)\,  a{\cdot}b + a{\cdot}c; \h
        (iii)\, 1 - 3 + 5 - 7 + 9
        \end{displaymath}

        In Expression~$(i)$ the multiplication obviously cannot be carried out unless one first determines the values of the two factors $a+b$ and $c+d$;
    it does not matter which of these sums is computed first, but the presence of the parentheses makes it easy to organize the calculation.

        Expression $(ii)$, in contrast, involves no parentheses. Nevertheless, one is expected to realize that this expression is shorthand for
    $(a{\cdot}b) + (a{\cdot}c)$: first compute $a{\cdot}b$ and $c{\cdot}d$, in order to know the numbers to be added.
    How do we know that the expression means this? Because it was drilled into us by our algebra teachers under the heading of `Precedence of Operators'.
    \IndBD{operations/operators}{precedence of operations}
    These rules include, for example:

\VA

        \h `First evaluate any expressions which appear inside parentheses, starting with the inmost such expressions if they are nested;
    then carry out multiplications before additions. In cases of expressions of equal precedence, normally carry them out left to right.'

\VA

        Expression $(iii)$ involves two additions and two subtractions, yet has no parentheses. Try evaluating it before reading further.

        The convention with an expression such as $(iii)$ is this: carry out the operations successively, from left-to-right:
        \begin{displaymath}
        1 - 3 \,=\, -2; \h -2 + 5 \,=\, 3; \h 3 - 7 \,=\, -4; \h -4 + 9 \,=\, 5.
        \end{displaymath}
    Notice that if we carry out the operations right-to-left, we get an entirely different answer:
        \begin{displaymath}
        9 + 7 \,=\, 16; \h 16 - 5 \,=\, 11; \h 11 + 3 \,=\, 14; \h 14 - 1 \,=\, 13.
        \end{displaymath}
    Of course one could avoid all ambiguity, and the need for any `Precedence of Operations' conventions, by the appropriate insertion of parentheses.
    For example, the left-to-right calculation above is what one would computing the following expression: $((((1 - 3) + 5) - 7) + 9)$.
    Likewise, the right-to-left calculation above corresponds to the unambiguous expression $(1 - (3 + (5 - (7 + 9))))$.
    Such parenthesis-rich expressions tend to be hard to read, and are prone to errors; but if there is any chance of misunderstanding, they should be used.

\V

        {\bf Remark} See the {\Note} below, on `infix, prefix and postfix representations', for a discussion of some parenthesis-free notations.

\VV

%%%
\begin{quotation}
{\footnotesize \underline{\Note} (on infix, prefix and postfix representations of a binary operation)\IndB{\notes}{on infix, prefix, postfix representations}: The `infix representation' of a binary operation $f:A^{2} \,{\rightarrow}\, A$ described above is so called
    because it locates (`fixes') the symbol ${\ast}$ for the operation between (`inside') the two inputs, as in $x{\ast}y$.
    In contrast, the functional representation for the same quantity places the symbol $f$ for the operation before the inputs $x$ and~$y$: $f(x,y)$.
    This is essentially what computer scientists call the `prefix representation' of the binary operation,
    except they would write $f\,x\,y$ in place of $f(x,y)$. They also use the so-called `postfix representation': $x\,y\,f$.
    These notations are also known as the `Polish'\IndC{\notes}{on infix, prefix, postfix representations}{Polish/Reverse Polish notations}\IndD{Polish/Reverse Polish notations}{\notes} and `Reverse Polish' notations, respectively, in honor of the Polish logician Jan Lukasiewicz,\IndC{\notes}{on infix, prefix, postfix representations}{{\L}ukasiewicz, Jan}\IndD{Lukasiewicz, Jan}{\notes}
    who introduced such notations as a way to completely avoid the use of parentheses in complicated expressions built out of binary operations.
    For example, the `prefix' version of the expression $x + a\,(y - z\,(b+c))$ is $S\,x\,P\,a\,D\,y\,P\,z\,S\,b\,c$;
    the `postfix' version is $b\,c\,S\,z\,P\,y\,D\,a\,P\,x$.
    Note that in each of these expressions the order in which the binary operations are evaluated is completely determined:
    in the prefix notation one evaluates the operations from right to left, while in the postfix notation the order is from left to right.
    (It is likely that this last fact explains why the postfix notation is more widely used than the prefix; see the {\Note}) on the `left-to-right bias'.)
}%EndFootnotesize
\end{quotation}
%##

\VV


    The `left-to-right' process illustrated above is especially useful in {\TheseNotes} when applied to a single binary operation.

            \subsection{\small{\bf Definition}}
            \label{DefA60.30}

\V

        Let $f:A^{2} \,{\rightarrow}\, A$ be a binary operation on a nonempty set~$A$, with corresponding `infix' symbol~${\ast}$.
    The {\bf left-to-right extension of the operation $\Bfm{{\ast}}$ to $\Bfm{k}$-tuples}, where $k\,\,{\geq}\,\,3$, is the function $f_{k}:A^{k} \,{\rightarrow}\, A$ defined recursively as follows:

        \h $k \,=\, 2$: $f_{2} \,=\, f$, the original binary operation.

        \h $k \,=\, 3$: $f_{3}(x_{1}, x_{2}, x_{3}) \,=\, f((x_{1}, x_{2}), x_{3})$.

        \h If $f_{k-1}:A^{k-1} \,{\rightarrow}\, A$ has been defined, then 
    $f_{k}(x_{1}, x_{2}, \,{\ldots}\,x_{k-1}, x_{k}) \,=\, f(f_{k-1}(x_{1}, x_{2}, \,{\ldots}\,x_{k-1}), x_{k})$.

\noindent The `infix' representation of the function $f_{k}$ is
    $f_{k}(x_{1}, x_{2}, \,{\ldots}\,x_{k-1}, x_{k}) \,=\, x_{1}{\ast}x_{1}{\ast}\,{\ldots}\,{\ast}x_{k-1}{\ast}x_{k}$.
    With this representation the recursion above takes the form

        \h $x_{1}{\ast}x_{2}{\ast}\,{\ldots}\,{\ast}x_{k-1}{\ast}x_{k} \,=\, (x_{1}{\ast}x_{2}{\ast}\,{\ldots}\,{\ast}x_{k-1}){\ast} x_{k}$.
                                          
\VV

            \subsection{\small{\bf Remark}}
            \label{RemrkA60.40}

        (1) The `left-to-right' process described in the preceding definition is one of many ways to extend the operation ${\ast}$ to $k$-tuples.
    For example, in the case $k \,=\, 4$ one might have defined the expression $x_{1}{\ast}_{2}{\ast}x_{3}{\ast}x_{4}$ to mean either of the following quantities:
        \begin{displaymath}
        x_{1}\,{\ast}\,(_{2}\,{\ast}\,(x_{3}\,{\ast}\,x_{4})); \h
        (x_{1}\,{\ast}\,x_{2})\,{\ast}\,(x_{3}\,{\ast}\,x_{4}); \h
        \end{displaymath}
    For most operations these last expressions equal neither each other nor the `left-to-right' value of $x_{1}{\ast}_{2}{\ast}x_{3}{\ast}x_{4}$ given above.

        In contrast, if the operation ${\ast}$ is associative, then it is known all such constructions lead to the same results.
    If, in addition, the operation ${\ast}$ is commutative, then even more can be said. The next result makes this more precise.

\VV

            \subsection{\small{\bf Theorem}}
            \label{ThmA60.50}

        Let $f:A^{2} \,{\rightarrow}\, A$ be a binary operation on a nonempty set~$A$, and let ${\ast}$ be the corresponding infix symbol of this operation.

\V

        (a) Assume that the operation ${\ast}$ is associative. Let $k$ and $m$ be natural numbers,
    and let $(x_{1}, x_{2},\,{\ldots}\,x_{k}, x_{k+1},\,{\ldots}\,x_{k+m})$ be an element of $A^{k+m}$. Then
        \begin{displaymath}
        \left(x_{1}{\ast}x_{2}{\ast}\,{\ldots}\,x_{k}\right)
    {\ast}
        \left(x_{k+1}{\ast}x_{k+2}{\ast}\,{\ldots}\,x_{k+m}\right)
     \,=\, 
  x_{1}{\ast}x_{2}{\ast}\,{\ldots}\,x_{k}{\ast}x_{k+1}{\ast}\,{\ldots}\,x_{k+m}.
        \end{displaymath}
    
\V

        (b) Assume that ${\ast}$ is both commutative and associative. Then the the operation ${\ast}$ has a stronger version of commutivity:

        Let $k$ be a natural number, and let $p:{\NN}_{k} \,{\rightarrow}\, {\NN}_{k}$ be a permutation of the finite set ${\NN}_{k}$
    (see Definition~\Ref{DefA15.50}).
    Then for every $k$-tuple $(x_{1}, x_{2},\,{\ldots}\,x_{k})$ in $A^{k}$ one has
        \begin{displaymath}
        x_{p(1)}{\ast}x_{p(2)}{\ast}\,{\ldots}\,{\ast}x_{p(k)} \,=\, 
        x_{1}{\ast}x_{2}{\ast}\,{\ldots}\,{\ast}x_{k}.
        \end{displaymath}
    Both sides of the preceding are defined as in Definition~\Ref{DefA60.30}.

\V

        {\bf Outline of Proof} The details of the proof are left as an exercise. What follows are hints:

        (a) Use mathematical induction on the index $m$.

\V

        (b) Use mathematical induction on the index $k$; break into the special cases $p(k) \,=\, k$ and $p(k) \,\,{\neq}\,\, k$.
    (I assume that you let the induction hypothesis be that the statement holds for $k-1$.)

\V

            \subsection{\small{\bf Remark}}
            \label{RemrkA60.60}

        The conclusion of Part (b) of the preceding theorem, namely that the binary operation~${\ast}$ enjoys the stronger form of `commutivity' given there,
    does not remain true if the hypothesis that~${\ast}$ be associative is omitted.
    That is, ordinary commutivity of~${\ast}$ is not enough by itself to guarantee the stronger form of commutivity.
    This contrasts with the situation in Part~(a) for which assuming ordinary associativity for ${\ast}$ does guarantee the stronger form of associativity.

%% EXERCISE INVOLVING ABSOLUTE-DIFFERENCE

\VV

        The next definition is encountered more often in the algebraic branches of moderm mathematics than in analysis, but it does get used here too.
    It makes precise the concept of two binary operations being `equivalent', in the sense that
    every statement which can be expressed purely in terms of the first operation corresponds to a fact about the second.

\V

            \subsection{\small{\bf Definition} (Isomorphism)}
            \label{DefA60.70}

\V

        Let $(A,{\ast})$ and $(A',{\ast}')$ be binary operations on the sets $A$ and $A'$, respectively.

\V

        (1) An {\bf isomorphism of $\Bfm{(A,{\ast})}$
    \IndC{operations/operators}{binary operations}{isomorphism, isomorphic}
    with $\Bfm{(A',{\ast}')}$} is a bijection ${\varphi}:A \,{\rightarrow}\, A'$ of $A$ onto $A'$ such that
    ${\varphi}(a_{1}{\ast}a_{2}) \,=\, ({\varphi}(a_{1})){\ast}'({\varphi}(ya_{2})$
    for each ordered pair $(a_{1},a_{2})$ in $A^{2}$.

\V

        (2) Two binary operations are said to be {\bf isomorphic (to each other)} if there exists an isomorphism of one with the other.

\VV

            \subsection{\small{\bf Examples}}
            \label{ExampA60.80}

\V

        (1) Let ${\varphi}:{\ZZ} \,{\rightarrow}\, {\ZZ}$ be the bijection given by the rule ${\varphi}(k) \,=\, (-1){\cdot}k$ for each integer~$k$.
    It follows from the distributive laws for integers that ${\varphi}$ is an isomorphism of the operation of addition on~${\ZZ}$.
    However, since $(-1){\cdot}(-1) \,=\, 1\,1$, not $-(1{\cdot}1)$, the map ${\varphi}$ is {\em not} an isomorphism of multiplication.

\V

        (2) Let $A \,=\, {\NN}$, and let $A' \,=\, \{2, 2^{2}, \,{\ldots}\, 2^{n},\,{\ldots}\,\}$, the set of all positive powers of~$2$.
    Note that when restricted to the set~$A$, addition is a binary operation; call it~${\ast}$.
    Likewise, when restricted to~$A'$, multiplication is also a binary operation; call it~${\ast}'$.
    Let ${\varphi}:A \,{\rightarrow}\, A'$ be given by the rule ${\varphi}(k) \,=\, 2^{k}$.
    It follows from the usual rules for exponents that ${\varphi}$ is an isomorphism of $(A,{\ast})$ with~$(A',{\ast}')$.

\V

        (3) It is an easy exercise to show that if $(A,{\ast})$ is isomorphic with $(A'{\ast}')$,
    then $(A',{\ast}')$ is isomorphic with $(A,{\ast})$.

%% EXERCISE {\varphi}^{-1} is also an isomorphism

\V

        (4) Suppose ${\varphi}:A \,{\rightarrow}\, A'$ is a bijection of the set $A$ onto the set~$A'$. If $(A',{\ast})$ is a binary operation on the set~$A'$, 
    then there is a unique binary operation $(A,{\ast})$ on $A$ for which ${\varphi}$ is an isomorphism. It is given by the rule
        \begin{displaymath}
        a_{1}{\ast}a_{2} \,=\, {\varphi}^{-1}[{\varphi}(a_{1}){\ast}'{\varphi}(a_{2})] \mbox{ for each ordered pair $(a_{1},a_{2})$ in $A^{2}$}.
        \end{displaymath}
    It is called the {\bf binary operation induced on $A$ by the bijection ${\varphi}$ from the binary operation $(A',{\ast}')$}.
    Intuitively speaking, one uses the bijection ${\varphi}$ to relate the pair $(a_{1},a_{2})$ in $A^{2}$
    to the corresponding pair $(a_{1}',a_{2}')$ in $A'^{2}$;
    then one uses the operation ${\ast}'$ to get a third element $a_{3}' \,=\, a_{1}'{\ast}'a_{2}'$ in~$A'$.
    Finally, $a_{1}{\ast}a_{2}$ is the element $a_{3}$ in $A$ which corresponds under the bijection ${\varphi}$ to the element $a_{3}'$.

%% EXERCISE `Isomorphic' is an equiv relation (without using that terminology.)
}%\EndSkip

\newpage

%\thispagestyle{myheadings}

\V
\V

\StartSkip{
                        \section{ADDENDUM ONE TO CHAPTER~\ref{ChaptA}: Axioms for ${\NN}$.}
                        %\label{SectAAdd1}


\V
\V

%\markboth{Addendum to Chapter~\ref{ChaptA}: Peano's Axioms and %Counting}{Addendum to Chapter~\ref{ChaptA}: Peano's Axioms and Counting}

\V
\V

        In this addendum we present an axiomatic approach to the concept of `counting'.
     The usual custom is to refer to the axioms discussed here as the `Peano Axioms'.
    However, since they apparently were discovered earlier (and independently) by Dedekind,
    in {\TheseNotes} we follow the usage of several authors and refer to them as the {\em Dedekind-Peano axioms}.
    The approach in this addendum largely follows that of Dedekind in his famous essay {\em Was sind und was sollen die Zahlen};
    of course, Dedekind's terminology and notation have been upgraded to reflect the more modern usage.


        \underline{Note} If you have never worked through the `Dedekind-Peano' axiomatic approach to the natural numbers,
    it is worth your time to at least skim through the material in this addendum.
    This material is not required for later chapters, however, so we label the various topics discussed here (definitions, theorems, remarks, etc)
    with the prefix `Add1-\Ref{ChaptA}' (short for `Addendum~One to Chapter~\Ref{ChaptA}').

\V
\V

        In Definition~\Ref{DefA12.70} we characterize what it means for a finite nonempty set $A$ to have (exactly) $k$ elements, for some $k{\in}{\NN}$,
    in terms of a complete pairing of $A$ with the subset~${\NN}_{k}$ of the `standard counting set~${\NN}$; that is, the set of standard counting numbers.
    Of course other sets could have been chosen to play the role of `standard counting set';
    for example, in many computer spreadsheets the columns are labeled by letters, not natural numbers:
        \begin{displaymath}
        A, B, \,{\ldots}\,Z, A\,A, A\,B,\,{\ldots}\,A\,Z, B\,A, B\,B\,{\ldots}\,
        \end{displaymath}
    In this addendum we characterize axiomatically the properties which any such comparison set ought to enjoy.


\V

        {\bf Add1-\Ref{ChaptA} 1: Definition} A {\bf counting structure} is a pair of objects $(X,{\sigma})$ consisting of a nonempty set $X$ together with a function ${\sigma}:X \,{\rightarrow}\, X$ which satisfies the following {\bf Dedekind-Peano Axioms}:

\V

        (a) The function ${\sigma}$ is one-to-one on $X$, and there is exactly one element of $X$ which is {\em not} in the image ${\sigma}(X)$.
    This element is denoted $u_{{\sigma}}$; the letter $u$ stands for `unit'.

\V

        (b) Suppose that $A$ is any subset of $X$ with the following properties:

            \h (i)\, The element $u_{{\sigma}}$ is in the set $A$;

            \h (ii)  For every element $x$ in $A$ the element ${\sigma}(x)$ is also in $A$;
    that is, ${\sigma}[A] \,{\subseteq}\, A$.

\noindent Then $A \,=\, X$.

\V


        {\bf Add1-\Ref{ChaptA} 2: Remarks}

        (1) \underline{Concerning Axiom (a)} The function ${\sigma}$ associated with the counting structure $(X,{\sigma})$ is usually called the {\bf successor function} of that structure,
    and if $x$ is any element of $X$ then ${\sigma}(x)$ is called the {\bf successor of $x$}.
    The requirement that ${\sigma}$ be one-to-one then can be phrased as `No  element of $X$ can be the successor of more than one element'.
    Likewise, the requirement on the special element $u_{{\sigma}}$ can be phrased as `The special element $u_{{\sigma}}$ is not the successor of any element, and it is the {\em unique} element of $X$ which is not a successor'.
    Because of this last fact, one often refers to $u_{{\sigma}}$ as the {\bf initial element of $X$}.
    When there can be no confusion, one normally writes the simpler $u$ instead of $u_{{\sigma}}$.

        Note that most authors assume the existence, but not the uniqueness, of an element $u$ in $X$ which is not the successor of any element.
    They can do this because the uniqueness can be trivially deduced later on using Axiom~(b).
    The choice, whether to treat the `uniqueness' as part of an axiom or as a theorem to be proved later on, is thus largely a matter of taste.

\V

        (2) \underline{Concerning Axiom (b)} For obvious reasons, this axiom is called the {\bf Induction Axiom},
    and any nonempty subset of $X$ which satisfies Part~(ii) of this condition is called an {\bf inductive subset of $X$}.
    Peano uses essentially this axiom in his formulation; that is, he {\em assumes} as an axiom the `Principle of Mathematical Induction'.

        In contrast, the analogous axiom in Dedekind's formulation can be phrased as follows:

        \h `The set $X$ is the intersection of the family of all the inductive subsets of $X$ containing the element $u$.'

\noindent (Note that $X$ itself is an inductive subset of $X$ containing $u$, so the family in question is not empty.)
    In particular, Dedekind does {\em not} assume the Principle of Mathematical Induction as an axiom;
    instead he {\em proves} that Principle as a consequence of his axioms.
    Likewise, one can prove that the Peano axiom implies the Dedekind version. (Both proofs are trivial.)
    In any event, one needs both the `Principle of Mathematical Induction' and Dedekind's `intersection of inductive subsets' construction to work out the theory;
    the choice, of which is to be an axiom and which is to be a theorem, is thus largely a matter of taste.

\V
\V

        {\bf Add1-\Ref{ChaptA} 3: Examples}

\V

        (1) Let $X$ be the standard set ${\NN} \,=\, \{1,2,3,\,{\ldots}\,\}$, whose elements are described by Arabic (decimal) numerals.
    Let the function ${\sigma}:{\NN} \,{\rightarrow}\, {\NN}$ be given by the usual rule for finding the successor of a natural number $k$:
    if the right-most (decimal) numeral of a number $k$ is one of the digits $0$, $1$,\,{\ldots}\,$8$, then replace that digit by the next higher one,
    and leave the other digits alone.
    If the decimal expression for $k$ ends with a string of one or more `$9$'s on the right, to get ${\sigma}(k+1)$ replace each such $9$ with the digit $0$,
    and increase the right-most non-$9$ digit to the next higher digit; if {\em all} the numerals of $k$ are $9$,
    then ${\sigma}(k+1)$ has initial numeral $1$ followed by as many $0$s as $k$ has $9$s.
    The initial element for this counting structure is~$1$.

        \underline{Note} A faster way of describing the successor function in this example would be to simply say ${\sigma}(k) \,=\, k+1$.
    The reason for using the wordier description given above is to emphasize that one does not have to know about `addition' --
    not even the special case of `addition with $1$' -- to characterize the successor function.
    Because of this, when we later {\em define} addition for arbitrary counting structures in terms of the successor function,
    we can avoid the sensation that the definition is somehow `circular' -- we define addition in terms of the successor function,
        which itself is often defined in terms of `addition with $1$'.
    Having done so in this key example, however, we take the easy way out in some of the following examples
    and describe the successor function there in terms of addition.

\V

        (2) The set $X$ is $\hat{{\NN}} \,=\, \{0,1,2,\,{\ldots}\,\}$, the function ${\sigma}:\hat{{\NN}} \,{\rightarrow}\, \hat{{\NN}}$ is given by ${\sigma}(k) \,=\, k+1$.
    Then $u \,=\, 0$.

\V

        (3) The set $X$ consists of all elements of ${\NN}$ starting with $7$:
    $X \,=\, \{7, 8, 9, \,{\ldots}\,\}$.
    The function ${\sigma}$ is given as usual by ${\sigma}(k) \,=\, k+1$.
    In this case the initial element is $u \,=\, 7$.

\V

        (4) The set $X$ consists of all the {\em even} natural numbers; that is, $X \,=\, \{2,4,6,\,{\ldots}\,\}$.
    The function ${\sigma}$ is given by the rule ${\sigma}(k) \,=\, k+2$, so that $u \,=\, 2$.

\V

        (5) The set $X$ consists of the standard Roman numerals
        \begin{displaymath}
        I, II, III, IV, V,\,{\ldots}\,X,\,{\ldots}\,C,\,{\ldots}\,M,\,{\ldots}\,
        \end{displaymath}
    Since we shall not be using these numerals extensively, we shall leave to the reader the happy task of determining the corresponding successor function~${\sigma}$.

    The reader should be able to easily figure out the pattern and from that to determine the corresponding `successsor function'~${\sigma}$.

\V
\V

        {\bf Add1-\Ref{ChaptA} 4: Theorem} Suppose that $(X,{\sigma})$ is a counting structure with initial element~$u$.
    Then for all $x$ in $X$ one has ${\sigma}(x) \,\,{\neq}\,\, x$.

\V

        {\bf Proof}\,  Let $A$ be the set of all $x$ in $X$ such that ${\sigma}(x) \,\,{\neq}\,\, x$.
    Certainly the initial element $u$ is in $A$; for if not then one would have ${\sigma}(u) \,=\, u$, contrary to the fact that the initial element is not in the image of the function ${\sigma}$.

        Next, suppose that $x{\in}A$. If ${\sigma}(x)$ were not in $A$, then one would have ${\sigma}({\sigma}(x)) \,=\, {\sigma}(x)$.
    But by the fact that ${\sigma}$ is one-to-one, one would then also have ${\sigma}(x) \,=\, x$, contrary to the induction hypothesis that $x{\in}A$.
    Thus, if $x{\in}A$ then ${\sigma}(x){\in}A$ as well.
    By the Induction Axiom it follows that $A \,=\, X$, and the desired result follows.

\V
\V


        Example~(3) above illustrates a way of obtaining new counting structures from a given such structure.

\V

        {\bf Add1-\Ref{ChaptA} 5: Theorem} Suppose that $(X,{\sigma})$ is a counting structure with initial element~$u$.
    Let $x_{1}$ be an element of $X$, and let $X_{1}$ denote the intersection of the family ${\cal F}_{1}$ of all the inductive subsets of $X$ which contain the element $x_{1}$.
    Then $X_{1}$ is a nonempty subset of $X$.
    Furthermore, if ${\sigma}_{1}$ denotes the restriction of the function ${\sigma}$ to the subset $X_{1}$,
    then $(X_{1},{\sigma}_{1})$ is a counting structure, and its initial element is $x_{1}$.

\V

        {\bf Proof}\,  Let $A$ be the set of all $x_{1}$ in $X$ for which the conclusion of the theorem is true.
    It suffices to show that $A \,=\, X$.

        \underline{Initial Step} Clearly $u{\in}A$, since by the Induction Axiom the only inductive subset of $X$ containing $u$ is $X$ itself, and thus when $x_{1} \,=\, u$ one has $X_{1} \,=\, X$ and ${\sigma}_{1} \,=\, {\sigma}$.

        \underline{Inductive Step} Now suppose that $w{\in}A$, and let $W$ denote the intersection of all inductive subsets of $X$ containing $w$,
    and let ${\sigma}_{w}$ denote the restriction of ${\sigma}$ to $W$. Then, by the definition of the set~$A$,
    the pair $(W,{\sigma}_{w})$ is a counting structure with initial element~$w$.
    Let $x_{1} \,=\, {\sigma}(w)$, and let ${\cal F}_{1}$, $X_{1}$ and ${\sigma}_{1}$ be as in the statement of the theorem.
    Note that the family ${\cal F}_{1}$ is nonempty, since $X$ itself is an inductive set containing $x_{1}$.
    In adddition, by definition of ${\cal F}_{1}$, every set in the family ${\cal F}_{1}$ contains $x_{1}$, hence so does the intersection~$X_{1}$.
    Thus, $x_{1}{\in}X_{1}$, so in particular $X_{1} \,\,{\neq}\,\, {\emptyset}$.
    Next, suppose that $y{\in}X_{1}$. Then for every set $Y$ in the family ${\cal F}_{1}$ one has $y{\in}Y$;
    and since each such set $Y$ is an inductive subset of $X$, it follows that ${\sigma}(y){\in}Y$ as well.
    Thus, ${\sigma}(y)$ is also in the intersection $X_{1}$, hence $X_{1}$ is an inductive set.
    In particular, the restriction ${\sigma}_{1}$ of ${\sigma}$ to $X_{1}$ maps $X_{1}$ into itself.
    It is clear that ${\sigma}_{1}$ is one-to-one on $X_{1}$, since it is the resriction to $X_{1}$ of the one-to-one function ${\sigma}$ on $X$.
    Furthermore, if $z$ is a point of $X_{1}$ such that $z \,\,{\neq}\,\, x_{1}$, then $z$ must be of the form ${\sigma}_{1}(x)$ for some $x$ in $X_{1}$.
    Indeed, if this were not the case, consider the set $Y \,=\, X_{1}{\setminus}\{z\}$.
    Since $z \,\,{\neq}\,\, x_{1}$ it is clear that $x_{1}{\in}Y$.
    And since $z$ is not in ${\sigma}_{1}(X_{1})$, and $X_{1}$ is an inductive subset of $X$,
    it is clear that $Y$ is a nonempty inductive subset of $X$ containing $x_{1}$.
    Thus, $X_{1}$, being the intersection of all such sets, must be a subset of $Y$.
    However, this is impossible since $z{\in}X_{1}$ but $z$ is {\em not} in $Y$.

        All that is left to show is that $x_{1}$ is not in ${\sigma}_{1}(X_{1})$.
    Since, by definition, $x_{1} \,=\, {\sigma}(w)$, and ${\sigma}$ is one-to-one on $X$, this means one need only show that $w$ is not in $X_{1}$.
    But if $w$ were in $X_{1}$, then $X_{1}$ would be an inductive subset of $X$ containing $w$,
    hence one would have $W \,{\subseteq}\, X_{1}$, since $W$ is the intersection of all such subsets.
    On the other hand, $w$ is in $W$, and $W$ is an inductive subset of $X$, so $x_{1} \,=\, {\sigma}(w)$ is also in $W$, so $W$ is an inductive subset of $X$ containing $x_{1}$.
    Since $X_{1}$ is the intersection of all such subsets of $X$, it follows that $X_{1} \,{\subseteq}\, W$.
    Combining these results, one sees that if $w{\in}X_{1}$, then $X_{1} \,=\, W$.
    However, since $w{\in}A$ it follows that $w$ is the initial element of $W$, hence if one removes $w$ from $W \,=\, X_{1}$ one would get a proper subset of $X_{1}$ which contains $x_{1} \,=\, {\sigma}(w)$ and is inductive.
    (Note that ${\sigma}(w) \,\,{\neq}\,\, w$ because $w$ is the initial element of $W$; that is, $x_{1} \,\,{\neq}\,\, w$. Thus, removing $w$ from $W$ does not remove $x_{1}$ from $W$.)
    This would contradict the definition of $X_{1}$ as the intersection of all such subsets of $X$.

\V

        {\bf Add1-\Ref{ChaptA} 6: Definition} Let $(X,{\sigma})$ be a counting structure with initial element $u$.
    Let $x_{1}$ be an element of $X$. Then the counting structure $(X_{1},{\sigma}_{1})$ with initial element $x_{1}$
    described in the preceding theorem is called the {\bf counting substructure of $(X,{\sigma})$ determined by $x_{1}$}.
    The set $X_{1}$ so described is denoted $<x_{1}>_{{\sigma}}$, and the correspondng function ${\sigma}_{1}$ is denoted ${\sigma}_{x_{1}}$.

\V
\V

        By a similar line of reasoning one can prove the following result; the details are left as an exercise.

\V

        {\bf Add1-\Ref{ChaptA} 7: Corollary} Let $(X,{\sigma})$ be a counting structure with initial element $u$.
    Let $x_{1}$ be an element of $X$, and let $(X_{1},{\sigma}_{1})$ be the counting substructure of $(X,{\sigma})$ determined by $x_{1}$.
    Then the counting substructure of $(X,{\sigma})$ determined by $x_{2} \,=\, {\sigma}(x_{1})$ is of the form $(X_{2},{\sigma}_{2})$,
    where $X_{2} \,=\, {\sigma}(X_{1}) \,=\, X_{1}{\setminus}\{x_{1}\}$.

\V
\V

        {\bf Add1-\Ref{ChaptA} 8: Theorem} Let $(X,{\sigma})$ be a counting structure with initial element $u$.
    Let $x_{1}$ and $x_{2}$ be elements of $X$ such that $x_{1} \,\,{\neq}\,\, x_{2}$, and let $(X_{1},{\sigma}_{1})$ and $(X_{2},{\sigma}_{2})$ be the corresponding counting substructures of $(X,{\sigma})$.
    Then exactly one of the following statements is true:

        \h (i)\, $x_{1}$ is in $X_{2}$

        \h (ii)  $x_{2}$ is in $X_{1}$

\V

        {\bf Proof}\,  To see that {\em at most} one of these properties can hold for such $x_{1}$ and $x_{2}$,
    suppose that $x_{1}$ is in $X_{2}$. Then $X_{2}$ is an inductive subset of $X$ which contain $x_{1}$.
    Since $x_{2} \,\,{\neq}\,\, x_{1}$, and (by the preceding theorem) $x_{2}$ is the initial element of the set $X_{2}$,
    it follows that the set $Y \,=\, X_{2}{\setminus}\{x_{2}\}$ obtained by removing $x_{2}$ from $X_{2}$ is also an inductive subset of $X$ which contains $x_{1}$.
    Since $X_{1}$ is, by definition, the intersection of such subsets, it follows that $X_{1} \,{\subseteq}\, Y$.
    But $Y$ does not contain $x_{2}$, hence neither does $X_{1}$, as claimed.
    A similar argument shows that if $x_{2}$ is in $X_{1}$ then $x_{1}$ cannot be an element of $X_{2}$.

        To see that {\em at least} one of these properties must hold, let $A$ be the set of all $x_{1}$ in $X$ such that if $x_{2}$ is an element of $X$ not equal to $x_{1}$, then either (i) or (ii) holds.

        \underline{Initial Step} Certainly $x_{1} \,=\, u$ is in $A$, since in this case $X_{1} \,=\, X$ and thus (ii) holds for every $x_{2}$.

        \underline{Induction Step} Suppose that $w{\in}A$, and let $(W,{\sigma}_{w})$ denote the counting substructure of $(X,{\sigma})$ determined by $w$.
    Let $x_{1} \,=\, {\sigma}(w)$, and suppose that $x_{2}$ is an element of $X$ with $x_{2} \,\,{\neq}\,\, x_{1}$.
    Let $X_{1}$ and $X_{2}$ be as in the statement of the theorem. Note that, by the preceding corollary, one has $X_{1} \,=\, {\sigma}[W]$.
    If $x_{2} \,=\, w$ then $x_{1} \,=\, {\sigma}(x_{2})$, and thus $x_{1}$ is an element of $W_{2}$, so (i) holds.
    Thus, suppose $x_{2} \,\,{\neq}\,\, w$.
    Then, by the induction hypothesis that $w$ is in $A$, it follows that either $w$ is in $X_{2}$ or $x_{2}$ is in $W$.
    In the former case it follows (from the fact that $X_{2}$ is an inductive set) that $x_{1} \,=\, {\sigma}(w)$ is also in $X_{2}$, and thus (i) holds.
    In the latter case, since $x_{2} \,\,{\neq}\,\, w$, it follows from the fact that ${\sigma}[W] \,=\, W{\setminus}\{w\}$, that $x_{2}{\in}{\sigma}[W]$; that is, since ${\sigma}[W] \,=\, X_{1}$, $x_{2}{\in}X_{1}$, and thus in this case (ii) holds.
    Thus, in all the cases either (i) or (ii) holds, hence ${\sigma}(w)$ is also in $A$.

        It now follows from the Induction Axiom that $A \,=\, X$, and the desired theorem follows.

\V
\V

        In light of the preceding theorem, it is now easy to introduce the concept of `greater than' (or equivalently, `less than') for any counting structure.

\V

        {\bf Add1-\Ref{ChaptA} 9: Definition} Let $(X,{\sigma})$ be a counting structure. Let $x_{1}$ and $x_{2}$ be elements of $X$ with $x_{1} \,\,{\neq}\,\, x_{2}$,
    and let $(X_{1},{\sigma}_{1})$ and $(X_{2},{\sigma}_{2})$ denote the counting substructures of $(X,{\sigma})$ determined by $x_{1}$ and $x_{2}$, respectively.
    One says that {\bf $x_{2}$ is greater than $x_{1}$} or, equivalently, {\bf $x_{1}$ is less than $x_{2}$}, with respect to the given structure $(X,{\sigma})$, provided $x_{2}$ is in $X_{1}$.
    In this case one writes $x_{2}\,>_{(X,{\sigma})}\,x_{1}$ (equivalently, $x_{1}\,<_{(X,{\sigma})}\,x_{2}$);
    or, if the choice of counting structure $(X,{\sigma})$ is understood from the context, simply $x_{2}\,>\,x_{1}$ (equivalently, $x_{1}\,<\,x_{2}$).

        More generally, one writes $x_{2}\,\,{\geq}\,\,x_{1}$, or, equivalently, $x_{1}\,\,{\leq}\,\,x_{2}$, if either $x_{1} \,=\, x_{2}$ or $x_{2}\,>\,x_{1}$.

        If $w$ is any element of $X$, then $X_{w}$ denotes the set of all elements $x$ of $X$ such that $x\,\,{\leq}\,\,w$;
    this set is called the {\bf initial section of $X$}.
    More generally, if $w_{1}$ and $w_{2}$ are elements of $X$ such that $w_{1}\,\,{\leq}\,\,w_{2}$,
    then $X_{[x_{1},x_{2}]}$ denotes the set of all $x$ in $X$ such that $w_{1}\,\,{\leq}\,\,x\,\,{\leq}\,\,w_{2}$.
    Note that $X_{w} \,=\, X_{[u,w]}$.

\V

        {\bf Add1-\Ref{ChaptA} 10: Examples} $X_{u} \,=\, \{u\}$; $X_{{\sigma}(u)} \,=\, \{u,{\sigma}(u)\}$.
    More generally, for each $x$ in $X$ one has $X_{{\sigma}(x)} \,=\, X_{x}\,{\cup}\,\{{\sigma}(x)\}$.

\V

        The next result follows easily from what precedes, so the proof is left as an exercise.

\V

        {\bf Add1-\Ref{ChaptA} 11: Theorem} Let $(X,{\sigma})$ be a counting structure, and let $\,<\,$ denote the corresponding `less than' relation.
    Then:

\V

        (a) (`The Trichotomy Law') If $x_{1}$ and $x_{2}$ are elements of $X$, then exactly one of the following statements is true:

        \h (i)\,\,$x_{1} \,=\, x_{2}$

        \h (ii)\, $x_{1}\,<\,x_{2}$

        \h (iii) $x_{2}\,<\,x_{1}$

\V

        (b) (`The Transitivity Law') If $x_{1}$, $x_{2}$ and $x_{3}$ are elements of $X$ such that $x_{1}\,<\,x_{2}$ and $x_{2}\,<\,x_{3}$, then $x_{1}\,<\,x_{3}$.

\V
\V


        {\bf Add1-\Ref{ChaptA} 12: Theorem} Let $(X,{\sigma})$ be a counting structure. If $x_{1}$ is any element of $X$, then $x_{1}\,<\,{\sigma}(x_{1})$.
    Moreover, then there is no element $w$ of $X$ such that $x_{1}\,<\,w\,<\,{\sigma}(x_{1})$.
    (This is often phrased: `There is no element of $X$ between two consecutive elements of $X$'.)

\V

        {\bf Proof}\,  Let $x_{2} \,=\, {\sigma}(x_{1})$, and as usual denote the counting substructures of $(X,{\sigma})$ determined by $x_{1}$ and $x_{2}$, respectively, by $(X_{1},{\sigma}_{1})$ and $(X_{2},{\sigma}_{2})$.
    It follows from the corollary above that $X_{2} \,=\, X_{1}{\setminus}\{x_{1}\}$; that is, $X_{2}$ is obtained by removing from $X_{1}$ the single element $x_{1}$.
    Now suppose that there exists $w$ in $X$ such that $x_{1}\,<\,w\,<\,x_{2}$.
    Denote the counting substructure of $(X,{\sigma})$ determined by $w$ as $(X_{w},{\sigma}_{w})$.
    Then, by the definition of the relation `$\,<\,$', the element $w$ must be in the set $X_{1}$ but not in the set $X_{2}$.
    However, the only element of $X_{1}$ which is not in $X_{2}$ is $x_{1}$, which would imply $w \,=\, x_{1}$.
    This would contradict the Trichotomy Law, since it is given that $x_{1}\,<\,w$.
    Thus, no such $w$ can exist, which proves the desired result.

\V


        {\bf Add1-\Ref{ChaptA} 13: Theorem} Let $(X,{\sigma})$ be a counting structure. Then every nonempty subset $Y$ of $X$ has a least element;
    that is, there is an element $y_{0}$ in $X$ such that $y_{0}{\in}Y$ and $y_{0}\,\,{\leq}\,\,y$ for all $y$ in~$Y$.

\V

        This is essentially just the `Least-Natural-Number Principle',
    but expressed in the more general context of counting structures.
    The proof is left as an exercise.

\V
\V


        The next result says, in effect, that all counting structures are equivalent in a natural sense,
    and thus it does not matter which specific example one uses as one's `standard counting structure'.

\V

        {\bf Add1-\Ref{ChaptA} 14: Theorem} Let $(X,{\sigma})$ and $(Y,{\tau})$ be counting structures, with initial elements $u$ and $v$, respectively.
    Then there exists a unique bijection $F:X \,{\rightarrow}\, Y$ of $X$ onto $Y$ such that

        \h (i)\, $F(u) \,=\, v$;

        \h (ii) $F({\sigma}(x)) \,=\, {\tau}\left(F(x)\right)$ for all $x$ in~$X$.

\V

        {\bf Proof}\,  The proof of the stated result follows directly from the following.

        \underline{Claim} For each $w$ in $X$ there exists a unique function $F_{w}: X_{{\sigma}(w)} \,{\rightarrow}\, Y$
    such that $F_{w}(u) \,=\, v$ and $F_{w}({\sigma}(x)) \,=\, {\tau}\left(F_{w}(x)\right)$ for all $x$ in $X_{w}$.

        \underline{Proof (`by Contradiction') of the Claim} Let $C$ denote the set of all $w$ in $X$ for which it is {\em not}
    the case that there exists a unique function with the indicated properties.
    If $C \,\,{\neq}\,\, {\emptyset}$, then by the Theorem of the Least Element the set $C$ must have a least element; call it $m$.
    Clearly $m \,\,{\neq}\,\, u$, since it is obvious that the function $F_{u}:X_{{\sigma}(u)} \,{\rightarrow}\, Y$ given by the rule $F_{u}(u) \,=\, v$, $F_{u}({\sigma}(u)) \,=\, {\tau}(v)$ has the desired properties, and is the only such function.
    Thus, $m$ must be of the form $m \,=\, {\sigma}(w_{1})$ for some (unique) $w_{1}$ in $X$; clearly $w_{1}\,<\,m$.
    Since, by hypothesis, $m$ is the {\em least} element of $C$, it follows that $w_{1}$ is not in $C$,
    and thus there is exactly one function $F_{w_{1}}:X_{{\sigma}(w_{1})} \,{\rightarrow}\, Y$ which has the desired properties.
    Note that the domain of $F_{w_{1}}$ can also be written as $X_{m}$ since $m \,=\, {\sigma}(w_{1})$.
    Now define $F_{m}:X_{{\sigma}(m)} \,{\rightarrow}\, Y$ by the rule
        \begin{displaymath}
        F_{m}(x) \,=\, F_{w_{1}}(x) \mbox{ if $x{\in}X_{m}$}; \h F_{m}({\sigma}(m)) \,=\, {\tau}\left(F_{m}(m)\right).
        \end{displaymath}
    It is clear that this function also satisfies the conditions of the `Claim', and thus $m$ is not in $C$.
    That is, assuming that $C \,\,{\neq}\,\, {\emptyset}$ leads to an element which is simultaneously in $C$ and not in $C$, which is impossible.
    Thus, $C \,=\, {\emptyset}$, and the claim follows.

        The theorem now follows easily.
    Indeed, it is clear that the set $X$ is the union of the nonempty subsets of the form $X_{x}$ for $x$ in $X$.
    Moreover, since the intersection of sets $X_{x_{1}}$ and $X_{x_{2}}$ is of the form $X_{x}$, with $x$ being the larger of $x_{1}$ and $x_{2}$,
    it follows from the uniqueness properties enjoyed by the functions $F_{w}$ described in the Claim that Theorem~\Ref{ThmA30.27} can be applied to conclude that there is a unique function $F:X \,{\rightarrow}\, Y$ whose restriction to each set $X_{{\sigma}(w)}$ equals $F_{w}$.
    In light of the results of the `Claim', this function clearly satisfies Conditions~(i) and~(ii) of the theorem, and is the only function that does.
    To see that $F$ is a bijection of $X$ onto $Y$, first note that in the special case $(Y,{\tau}) \,=\, (X,{\sigma})$ one gets that there is a unique function $H:X \,{\rightarrow}\, X$ such that $H(u) \,=\, u$ and $H({\sigma}(x)) \,=\, {\sigma}\left(H(x)\right)$ for all $x$ in $X$.
    However, it is clear that the identity map $I_{X}$ on $X$ has these properties, so in this case $H \,=\, I_{X}$.
    Next, note that by reversing the roles of $(X,{\sigma})$ and $(Y,{\tau})$ in the theorem,
    it follows that there exists a unique function $G:Y \,=\, X$ such that $G(v) \,=\, u$ and $G({\tau}(z)) \,=\, {\sigma}\left(G(z)\right)$ for all $z$ in $V$.
    Now let $H:X \,{\rightarrow}\, X$ be the composition $H \,=\, G{\circ}F$. Then $H(u) \,=\, G(F(u)) \,=\, G(v) \,=\, u$, and $H({\sigma}(x)) \,=\, G((F({\sigma}(x)))) \,=\, G({\tau}\left(F(x))\right) \,=\, {\sigma}(G(F(x))) \,=\, {\sigma}(H(x))$ for all $x$.
    Thus by what was observed above, it follows that $G \,=\, I_{X}$. In a similar way one gets $F{\circ}G \,=\, I_{Y}$.
    It now follows from Part~(c) of Theorem~\Ref{ThmA30.160} that $F$ is a bijection of $X$ onto $Y$, and that $G \,=\, F^{-1}$.

\V
\V

        The Peano Axioms are strong enough to characterize all the main features of the standard comparison sets for counting.
    For example, here is how to define `addition'.

\V

        {\bf Add1-\Ref{ChaptA} 15: Theorem} Let $(X,{\sigma})$ be a counting structure with initial element~$u$.
    Then there is a unique function $S_{{\sigma}}:X{\times}X \,{\rightarrow}\, X$, called the {\bf sum function associated with the structure $(X,{\sigma})$},
    with the following properties: If $x$ is any element of $X$, then

        (a) $S_{{\sigma}}(x,u) \,=\, S_{{\sigma}}(u,x) \,=\, {\sigma}(x)$;

        (b) $S_{{\sigma}}(x,{\sigma}(y)) \,=\, {\sigma}(S_{{\sigma}}(x,y))$ for all $y$ in $X$.

\noindent If the context makes clear which counting structure $(X,{\sigma})$ is under discussion,
    one normally drops the explicit reference to ${\sigma}$ and writes $S$ instead of the more proper $S_{{\sigma}}$.

\V

        \underline{NOTE} To understand how these formulas arise, first think of the expression $S(x,y)$ as a shorthand for `the {\em sum} of $x$ and $y$'.
    Then in the context of  ${\NN}$, for which $u \,=\, 1$ and ${\sigma}(x) \,=\, x+1$, the formulas become
        \begin{displaymath}
        \mbox{(i) } S(x,1) \,=\, x+1 \mbox{ and } \mbox{(ii) } S(x,y+1) \,=\, S(x,y)+1.
        \end{displaymath}
    Equation~(i) says that the `sum' $S$ agrees with the usual addition~$+$ in ${\NN}$ when applied to $x$ and $1$;
    that is, the `sum of $x$ and $1$', as defined by the function $S$, equals the usual $x+1$ in ${\NN}$.
    Equation~(ii) says, in effect, that if $S(x,y)$ agrees with the usual $x+y$ in ${\NN}$ for a particular second summand $y$,
    then it continues to agree with the usual addition for the next larger second summand $y+1$.
    Indeed, if $S(x,y) \,=\, x+y$, then $S(x,y)+1 \,=\, (x+y)+1 \,=\, x+(y+1)$, where the last equation reflects the associative law for ordinary addition of  natural numbers.
    Thus, Equation~(ii) becomes $S(x,y+1) \,=\, x+(y+1)$. Combining these observations with induction on the second summand $y$ then yields the fact that, 
    in the case of ${\NN}$, the sum $S$ satisfies $S(x,y) \,=\, x+y$ for {\em all} $x$ and $y$.

\V

        {\bf Proof of Theorem}

\V

        \underline{Uniqueness of $S$} Suppose that $S_{1}$ and $S_{2}$ are both functions which satisfy the conditions stated in the theorem.
    Then certainly $S_{1}(x,u) \,=\, S_{2}(x,u)$ for all $x$ in $X$, since, by~(a), both quantities equal ${\sigma}(x)$.

        Next, let $A$ denote the set of $y$ in $X$ such that $S_{1}(x,y) \,=\, S_{2}(x,y)$ for all $x$ in $X$.
    By what was just proved, it is clear that $u{\in}A$.
    Furthermore, if $y{\in}A$, then by~(b) one has
        \begin{displaymath}
        S_{1}(x,{\sigma}(y)) \,=\, {\sigma}(S_{1}(x,y)) \mbox{ and }
        S_{2}(x,{\sigma}(y)) \,=\, {\sigma}(S_{2}(x,y)) \mbox{ for all $x$ in $X$}.
        \end{displaymath}
    However, by the hypothesis that $y{\in}A$ one has $S_{1}(x,y) \,=\, S_{2}(x,y)$, so that ${\sigma}(y)$  is also in $A$.
    Now the Induction Axiom implies that $A \,=\, X$.
    Thus, $S_{1}(x,y) \,=\, S_{2}(x,y)$ for all $(x,y)$ in $X{\times}X$, so $S_{1} \,=\, S_{2}$, as claimed.

\V

        \underline{Existence of $S$} According to Definition~\Ref{DefA30.10}, a function with domain $X{\times}X$ and values in $X$ is a subset of the
    Cartesian product $Z \,=\, (X{\times}X){\times}X$ which satisfies certain properties.
    The approach followed here is to construct the subset of $Z$ corresponding to the desired function $S$ -- viewed as a  subset of $Z$ --
    as the disjoint union of smaller subsets of $Z$. In effect, we use the fact that $Z$  can be expressed as the disjoint union
        \begin{displaymath}
        Z \,=\, {\bigcup}_{x{\in}X} \left(\{x\}{\times}X\right){\times}X
        \end{displaymath}

        Let $A$ be the set of all $x$ in $X$ such that the following holds:
    There exists a nonempty subset $Y_{x}$ of $Z$ such that

        \h (i)\,\, Every element of $Y_{x}$ is of the form $((x,y),z)$ for some $y$ and $z$ in $X$.
    That is, $Y_{x}$ is a subset of $\left(\{x\}{\times}X\right){\times}X$.

        \h (ii)\, For every $y$ in $X$ there is exactly one element of the form $((x,y),z)$ in $Y_{x}$.
    That is, $Y_{x}$ is a function (in the sense of Definition~\Ref{DefA30.10}) with domain $\{x\}{\times}X$ and values in $X$.

        \h (iii) The points $((x,u),{\sigma}(x))$ and $((u,x),{\sigma}(x))$ are in $Y_{x}$.
    Likewise, for every $y$ in $X$ if $((x,y),z)$ is in $Y_{x}$ then $((x,{\sigma}(y)),{\sigma}(z))$ is also in $Y_{x}$.
    That is, $Y_{x}$ satisfies Conditions~(a) and~(b) for the desired function~$S$.

\noindent It is easy to show, by Mathematical Induction, that $A \,=\, X$:


        \underline{Initial Step} To see that $u{\in}A$, define $Y_{u}$ to be the set of all $((x,y),z)$ of the form $((u,y),{\sigma}(y))$ for $y$ in $X$.
    Since ${\sigma}$ is a function with domain $X$ and with values in $X$, it is clear that Conditions~(i) and~(ii) for the set $Y_{u}$ hold.
    As for Condition~(iii), note that when $y \,=\, u$ then the element $((u,y),{\sigma}(y))$ becomes $((u,u),{\sigma}(u))$, so that the first portion of the condition is satisfied.
    Likewise, if $((u,y),z)$ is in $Y_{u}$, then (by definition of $Y_{u}$) one has $z \,=\, {\sigma}(y)$.
    But (again be the definition of $Y_{u}$) one also has $((u,{\sigma}(y)),{\sigma}({\sigma}(y)))$ in $Y_{u}$;
    that is, the second part of Condition~(iii) also holds, so $u{\in}A$.

        \underline{Induction Step} Suppose that $x{\in}A$, and let $Y_{x}$ be a set which satisfies Conditions~(i), (ii) and~(iii).
    Then for each $y$ in $X$ there is a unique element $y'$ in $X$ such that $((x,y),y')$ is in $Y_{x}$.
    (Of course $y'$  depends on both $x$ and $y$.)
    Using this notation, define $Y_{{\sigma}(x)}$ to be the set of all elements  of $Z$ of the form $(({\sigma}(x),y),{\sigma}(y'))$ with $y$ in $X$.
    It is easy to see, from the properties of $Y_{x}$, that $Y_{{\sigma}(x)}$ also satisfies Conditions~(i), (ii) and~(iii), and thus ${\sigma}(x)$ is in $A$.

        Finally, define $S$ to be the union of the sets $Y_{x}$, with $x$ in $X$, constructed above.
    The sets $Y_{x}$ are clearly disjoint, so it is easy to see that the set $S$ is a function with domain $X{\times}X$ and with values in $X$.

    And since each set $Y_{x}$ satisfies Conditions~(i), (ii) and~(iii), it is clear that the function $S$ satisfies Conditions~(a) and~(b) of the theorem.

\V
\V

        In a like manner one can define `multiplication'.

\V

        {\bf Add1-\Ref{ChaptA} 16: Theorem} Let $(X,{\sigma})$ be a counting structure with initial element~$u$.
    Then there is a unique function $P_{{\sigma}}:X{\times}X \,{\rightarrow}\, X$, called the {\bf product function associated with the structure $(X,{\sigma})$},
    with the following properties: If $x$ is any element of $X$, then

        (a) $P_{{\sigma}}(x,u) \,=\, P_{{\sigma}}(u,x) \,=\, x$;

        (b) $P_{{\sigma}}(x,{\sigma}(y)) \,=\, S(P_{{\sigma}}(x,y),x)$ for all $y$ in $X$, where $S$ denotes the sum function $S_{{\sigma}}$ associated with $(X,{\sigma})$.

\noindent As usual, if there is no possibility of confusion one normally writes $P$ instead of $P_{{\sigma}}$.

\V

        {\bf Proof}\,  Left to the reader.

\V
\V


        {\bf Add1-\Ref{ChaptA} 17: Examples}

\V

        (1) Let $X \,=\, {\NN} \,=\, \{1,2,3,\,{\ldots}\,\}$, with the usual rule for the successor function ${\sigma}$; see Example~P3~(1) above.
    Then the successor operation can be written
        \begin{displaymath}
        {\sigma}(x) \,=\, x+1 \mbox{ for all $x$ in ${\NN}$},
        \end{displaymath}
    where throughout this example the symbol $+$ denote the usual addition of natural numbers.
    Likewise, the operations $S$ and $P$ associated with this counting structure are clearly the usual addition and multiplication $+$ and ${\cdot}$ on ${\NN}$.
    For example, the condition $S(x,1) \,=\, {\sigma}(x)$ then takes the form
        \begin{displaymath}
        S(x,1) \,=\, x+1.
        \end{displaymath}
    Thus, by induction on $y$, if $x$ and $y$ are elements of ${\NN}$ such that $S(x,y) \,=\, x+y$,
then the condition $S(x,{\sigma}(y)) \,=\, {\sigma}\left(S(x,y)\right)$ takes the form
        \begin{displaymath}
        S(x,y+1) \,=\, (x+y)+1 \,=\, x+(y+1),
        \end{displaymath}
    in which the final equation reflects the usual properties of arithmetic in ${\NN}$.
    That is, $S(x,y) \,=\, x+y$ holds for all $x$, $y$  in ${\NN}$.
    A similar argument shows that $P(x,y) \,=\, x{\cdot}y$ for all $x$, $y$ in ${\NN}$.

\V

        (2) Now let $X \,=\, \hat{{\NN}} \,=\, \{0,1,2,\,{\ldots}\,\}$, so that the role of initial element $u$ is now played by the number~$0$.
    In this case the `addition' and `multiplication' functions associated with the given counting structure do {\em not} agree with the usual $+$ and ${\cdot}$ of numbers.
    For example, $x+u \,=\, x+0 \,=\, x \,\,{\neq}\,\, {\sigma}(x)$, since in $\hat{{\NN}}$ one has ${\sigma}(x) \,=\, x+1$.
    Thus, it is not the case that $S(x,y) \,=\, x+y$ for all $x$, $y$.
    Likewise, $x{\cdot}0 \,=\, 0 \,\,{\neq}\,\,x$ when $x \,\,{\neq}\,\, 0$,  so it is not the case that $P(x,y) \,=\, x{\cdot}y$ for all $x$, $y$.
    Indeed, one can easily show that in $\hat{{\NN}}$ one has
        \begin{displaymath}
        S(x,y) \,=\, x+y+1 \mbox{ and } P(x,y) \,=\, x(y+1) + y \mbox{ for all $x$, $y$ in $\hat{{\NN}}$}
        \end{displaymath}

        The fact that in the example of $\hat{{\NN}}$ the operations $S$ and $P$ as define above do not agree with the usual addition and multiplication on $\hat{{\NN}}$ is not a flaw.
    It simply reflects the fact that, in any choice of addition and multiplication on a counting structure $(X,{\sigma})$,
    one must decide the role to be played by the initial element $u$.
    The choice taken in {\TheseNotes} reflects the fact that we shall use ${\NN}$, not $\hat{{\NN}}$,
    as our primary model of a counting structure.
    It is an easy exercise to provide an alternative formulation of `addition'  and `multiplication' axioms for those who prefer that the initial element $u$ behave like $0$.

\V
\V

        {\bf Add1-\Ref{ChaptA} 18: Modified Notation} It is customary to use the more familiar notation $1_{{\sigma}}$, $x+_{{\sigma}}y$, $x{\cdot}_{{\sigma}}y$
    instead of $u_{{\sigma}}$, $S_{{\sigma}}(x,y)$ and $P_{{\sigma}}(x,y)$ when dealing with a general counting structure $(X,{\sigma})$.
    And, as usual, if the context makes clear which ${\sigma}$ is under consideration, the subscript ${\sigma}$ is normally omitted and one writes $1$, $x+y$ and $x{\cdot}y$ instead.
    With this notation, the basic defining properties of addition and multiplication take the following more familiar form for all $x$ (or, where appropriate, all $x$ and $y$) of $X$:
        \begin{displaymath}
        (i)\, {\sigma}(x) \,=\, x+1 \,=\, 1+x;\, (ii)\, x+(y+1) \,=\, (x+y)+1; \, (iii)\, x{\cdot}1 \,=\, 1{\cdot}x \,=\, x; \, (iv)\, x{\cdot}(x+1) \,=\, x{\cdot}y+x \h ({\ast})
        \end{displaymath}

\V
\V

        The operations of addition and multiplication for a counting structure obey the usual rules of grade-school arithmetic.

\V

        {\bf Add1-\Ref{ChaptA} 19: Theorem} Let $(X,{\sigma})$ be a counting structure, with initial element $1$, addition operation $+$ and multiplication ${\cdot}$.
    Then the following facts hold.

\V

        (a) (Commutative Laws) If $x$ and $y$  are in $X$  then
        \begin{displaymath}
        (i)\, x+y \,=\, y+x \mbox{ and } (ii)\, x{\cdot}y \,=\, y{\cdot}x.
        \end{displaymath}


\V

        (b) (Associative Laws) If $x$, $y$ and $z$ are in $X$  then
        \begin{displaymath}
        (i)\, (x+y)+z \,=\, x+(y+z) \mbox{ and } (ii)\, (x{\cdot}y){\cdot}z \,=\, x{\cdot}(y{\cdot}z).
        \end{displaymath}


\V

        (c) (Distributive Laws) If $x$, $y$ and $z$ are in $X$ then
        \begin{displaymath}
        (i)\, x{\cdot}(y+z) \,=\, x{\cdot}y + x{\cdot}z \mbox{ and } (ii)\, (x+y){\cdot}z \,=\, x{\cdot}y + x{\cdot}z.
        \end{displaymath}



\V

        {\bf Partial Proof} The laws above are grouped to emphasize the similarities shared by addition and multiplication, and to ease the task of learning their statements;
    for example, the two commutative laws are joined together, and are stated before the two (more complicated) associative laws.
    The proofs of the laws as given here, however, require handling them in a different order.
    For instance, we use the Commutative and Associative Laws for Addition, together with the Distributive Laws,
    in the proof of the Associative Law for Multiplication.
    As usual, since the structure of the proofs of the various laws are so similar, we leave some of the proofs as exercises.

\V

        \underline{Part $(i)$ of (b)} (Associative Law for Addition) Let $A_{1}$ denote the set of $z$ in $X$ such that $(x+y)+z \,=\, x+(y+z)$ for all $x$ and $y$ in $X$.
    It is clear that it suffices to show that $A_{1} \,=\, X$.

        \underline{Initial Step} Property~$(ii)$ of $({\ast})$ above states that $1{\in}A_{1}$.

        \underline{Inductive Step} Suppose that $z{\in}A_{1}$. Then for all $x$ and $y$ in $X$ one has
        \begin{displaymath}
        x+(y+(z+1)) \stackrel{(1)}{ \,=\, } x+((y+z)+1) \stackrel{(2)}{ \,=\, } (x+(y+z))+1  \stackrel{(3)}{ \,=\, } ((x+y)+z)+1  \stackrel{(4)}{ \,=\, }
        (x+y)+(z+1)
        \end{displaymath}
    That is, $(z+1)$ is also in $A_{1}$, so by mathematical induction $A_{2} \,=\, X$, as desired.

        Here are the justifications for the numbered equations above:

        \h Equation~(1): This comes by applying Property~(ii) of $({\ast})$ to the expression $y+(z+1)$.

        \h Equation~(2): This follows from the fact, proved above, that $1{\in}A_{1}$.

        \h Equation~(3): This reflects the induction hypothesis that $z{\in}A_{1}$.

        \h Equation~(4): This comes by applying Property~$(ii)$ of $({\ast})$ to the expression $((x+y)+z)+1$.

\V

        \underline{Part $(i)$ of $(a)$} (Commutative Law for Addition) Let $A_{2}$ be the set of all $y$ in $X$ such that $x+y \,=\, y+x$ for all $x$ in $X$.


        \underline{Initial Step} It is clear, from the defining proeprties of `addition',
    that $x+1 \,=\, 1+x \,=\, {\sigma}(x)$ for all $x$ in $X$, so certainly $1{\in}A_{2}$.

        \underline{Inductive Step} Suppose that $y{\in}A_{2}$. Then for all $x$ in $X$ one has
        \begin{displaymath}
        x+(y+1) \stackrel{(1)}{ \,=\, }
        (x+y)+1 \stackrel{(2)}{ \,=\, }
        (y+x)+1 \stackrel{(3)}{ \,=\, }
        y+(x+1) \stackrel{(4)}{ \,=\, }
        y+(1+x) \stackrel{(5)}{ \,=\, }
        (y+1)+x.
        \end{displaymath}
    That is, $(y+1){\in}A_{2}$, so $A_{2} \,=\, X$, and the desired result follows.

        Here are the justifications of the preceding equations:

        \h Equations $(1)$, $(3)$ and $(5)$: the Associative Law for Addition

        \h Equations $(2)$ and $(4)$: the fact that $1$ and (by the Induction Hypothesis) $y$ are both in $A_{2}$.


\V


        \underline{Part $(i)$ of(c)} (The First Distributive Law) Let $A_{3}$ be the set of all $z$ in $X$ such that $x{\cdot}(y+z) \,=\, x{\cdot}y + x{\cdot}z$ for all $x,y$ in $X$.

        \underline{Initial Step} Note that, from the defining properties of `multiplication', one has
        \begin{displaymath}
        x{\cdot}(y+1) \,=\, x{\cdot}y + x \,=\, x{\cdot}y+x{\cdot}1.
        \end{displaymath}
    That is, $x{\cdot}(y+1) \,=\, x{\cdot}y+x{\cdot}1$ for all $x$ and $y$ in $X$, hence $1{\in}A_{3}$.

        \underline{Induction Step} Suppose that $z{\in}A_{3}$. Then for all $x$ and $y$ in $X$ one has
        \begin{displaymath}
        x{\cdot}(y+(z+1)) \stackrel{(1)}{ \,=\, }
        x{\cdot}((y+z)+1) \stackrel{(2)}{ \,=\, }
        x{\cdot}(y+z) + x \stackrel{(3)}{ \,=\, }
        (x{\cdot}y + x{\cdot}z)+x \stackrel{(4)}{ \,=\, }
        x{\cdot}y+(x{\cdot}z+x) \stackrel{(5)}{ \,=\, }
        x{\cdot}y+x{\cdot}(z+1).
        \end{displaymath}
    Thus, $z+1$ is also in $A_{3}$. It now follows that $A_{3} \,=\, X$, so the First Distributative Law, $x{\cdot}(y+z) \,=\, x{\cdot}y + x{\cdot}z$, follows.

    The justifications of the preceding equations are as follows:

        \h Equations $(1)$ and $(4)$: The Associative Law for Addition

        \h Equations $(2)$ and $(5)$: Defining properties of `multiplication'

        \h Equation $(3)$: The induction hypothesis that $z{\in}A_{3}$.

\V

        \underline{Part $(ii)$ of(c)} (The Second Distributive Law) Let $A_{4}$ be the set of all $z$ in $X$ such that $(x+y){\cdot}z \,=\, x{\cdot}z + y{\cdot}z$ for all $x,y$ in $X$.

        \underline{Initial Step} Since $(x+y){\cdot}1 \,=\, x+y \,=\, x{\cdot}1 + y{\cdot}1$ by one of the defining properties of `multiplication',
    it follows that $1{\in}A_{4}$.

        \underline{Induction Step} Suppose that $z{\in}A_{4}$. Then for all $x$ and $y$ in $X$ one has
        \begin{displaymath}
        (x+y){\cdot}(z+1) \stackrel{(1)}{ \,=\, }
        (x+y){\cdot}z + (x+y) \stackrel{(2)}{ \,=\, }
        (x{\cdot}z+y{\cdot}z) + (x+y) \stackrel{(3)}{ \,=\, }
        (x{\cdot}z + x) + (y{\cdot}z + y) \stackrel{(4)}{ \,=\, }
        x{\cdot}(z+1) + y{\cdot}(z+1).
        \end{displaymath}
    Thus $z+1$ is also in $A_{4}$. It follows that $A_{4} \,=\, X$, so the desired result holds.

        The reader should be able to figure out the justifications for the preceding equations.
    Note that Equation~$(3)$ uses several applications of the commutative and associative laws for addition;
    be sure you can break it down to the individual applications of those laws.
    Also, be sure you can determine where the induction hypothesis gets used.

\V

        \underline{Part $(ii)$ of (a)} (The Commutative Law for Multiplication) Let $A_{5}$ be the set of all $y$ in $X$ such that $x{\cdot}y \,=\, y{\cdot}x$ for all $x$ in $X$.

        \underline{Initial Step} One of the defining proerties of  'multiplication' is that $x{\cdot}1 \,=\, 1{\cdot}x \,=\, x$ for all $x$ in $X$,
    so clearly $1{\in}A_{5}$.

        \underline{Induction Step} Suppose that $y{\in}X$. Then for all $x$ in $X$ one has
        \begin{displaymath}
        x{\cdot}(y+1) \,=\, x{\cdot}y+x \,=\, y{\cdot}x + x \,=\, y{\cdot}x + 1{\cdot}x \,=\, (y+1){\cdot}x.
        \end{displaymath}
    (The reader is invited to explain why each of these equations is valid.)
    In particular, $y+1$ is also in $A_{5}$, and thus $A_{5} \,=\, X$, as desired.

\V

        The proofs of the remaining laws are left as exercises.


\V
\V

        There is a simple relation between the operation of `addition' and the concept of `greater than'.

\V

        {\bf Add1-\Ref{ChaptA} 20: Theorem} Let $(X,{\sigma})$ be a counting structure, with associated initial element $1$,
    addition operation $+$ and `greater than' ordering $\,>\,$.
    Then a pair of elements $x$ and $y$ in $X$ satisfy the condition $y\,>\,x$ if, and only if, there exists $z$ in $X$ such that $y \,=\, x+z$.

\V

        {\bf Proof}  

\V

        (The `If' Part) Let $A$ be the set of all $z$ in $X$ such that for all $x$ in $X$ the elements $x$ and $x+z$ satisfy $x+z\,>\,x$.
    Certainly $1{\in}A_{1}$,  by Theorem~Add1-\Ref{ChaptA}~12.
    Next, suppose that $z{\in}A$.
    Then, for all $x$ in $X$, one has $(x+z)+1\,>\,x+z$ (since $1{\in}A$), and $x+z\,>\,x$ (since, by the induction hypothesis, $z{\in}A_{1}$).
    Then, from the Transitive Law one obtains $(x+z)+1\,>\,x$; that is, in light of the Associative Law, $x+(z+1)\,>\,x$.
    It follows that $z+1$ is also in $A$.
    Now apply the Principle of Mathematical Induction to conclude that $A \,=\, X$, as required.

\V

        (The `Only if' Part) Suppose that $x$ and $y$ are elements of $X$ such that $y\,>\,x$.
    Let $C$ be the set of all $w$ in $X$ such that $x+w\,\,{\geq}\,\,y$.
    By what was just proved, it is clear that $y{\in}C$, since $x+y\,>\,y$.
    In particular, $C$ is a nonempty subset of $X$, so, by Theorem~Add1-\Ref{ChaptA}~13, there is a smallest element of $C$; call it $z$.
    Clearly $x+z\,\,{\geq}\,\,y$, since $z$ is in $C$. If $z \,=\, 1$ then one has $x+1\,\,{\geq}\,\,y\,>\,x$,
    which implies $x+1 \,=\, y$, since there  are no elements of $X$ which lie between $x$ and $x+1$.
    Thus, suppose $z \,\,{\neq}\,\, 1$, so that $z \,=\, v+1$ for some $v$ in $X$.
    Since $z$ is the {\em smallest} element of $C$, and clearly $v\,<\,z$, it follows that $v$ is {\em not} in $C$.
    That is, it is not the case that $x+v\,\,{\geq}\,\,y$, hence one has $x+v\,<\,y$.
    Thus, one has $x+v\,<\,y\,\,{\leq}\,\,(x+v)+1$. Since there are no elements of $X$ between $(x+v)$ and $(x+v)+1$,
    it must be the case that $y \,=\, (x+v)+1 \,=\, x+(v+1) \,=\, x+z$, as claimed.

\V
\V

        There is a similar theorem involving multiplication and the ordering `greater than'.

\V

        {\bf Add1-\Ref{ChaptA} 21: Theorem} Let $(X,{\sigma})$ be a counting structure, with associated initial element $1$,
    multiplication operation ${\cdot}$ and `greater than' ordering $\,>\,$.
    If $x$ and $y$  are elements of $X$ such that $y\,>\,x$,
    then $y{\cdot}z\,>\,x{\cdot}z$ for all $x$ in $X$.

\V

        The simple proof is left as an exercise.

\V
\V


        There is a result, {\em not} one  of the standard facts from grade-school arithmetic, that is worth mentioning here.

\V
\V

        {\bf Add1-\Ref{ChaptA} 22: Theorem} Let $(X,{\sigma})$ and $(Y,{\tau})$ be counting structures with initial elements $1_{{\sigma}}$ and $1_{{\tau}}$,
    addition operations $+_{{\sigma}}$ and $+_{{\tau}}$,
    multiplication operations ${\cdot}_{{\sigma}}$ and ${\cdot}_{{\tau}}$, and orderings $\,>_{{\sigma}}$ and $\,>_{{\tau}}$, respectively.
    Furthemore, let $F:X \,{\rightarrow}\, Y$ be the bijection described in Theorem~Add1-\Ref{ChaptA}~14.
  Then the bijection $F$ preserves addition and multiplication, in the following sense:
        \begin{displaymath}
        F(x_{1}+_{{\sigma}}x_{2}) \,=\, F(x_{1}) +_{{\tau}} F(x_{2}) \mbox{ and }
        F(x_{1}{\cdot}_{{\sigma}}x_{2}) \,=\, F(x_{1}) {\cdot}_{{\tau}} F(x_{2})
    \mbox{ for all $x_{1},x_{2}$ in $X$}.
        \end{displaymath}
    Likewise, $F$ preserves the ordering, in the following sense:
        \begin{displaymath}
        \mbox{ If $x_{2}\,>_{{\sigma}}x_{1}$ then $F(x_{2})\,>_{{\tau}}F(x_{1})$}.
        \end{displaymath}
    (For readers with a background in modern algebra: the map $F$ is an {\em isomorphism} between the two counting structures.)


    The simple proof of this theorem is left as an exercise; it boils down to noticing that the definitions of
    addition, multiplication and the order all come from the properties of  the successor functions ${\sigma}$ and ${\tau}$;
    and the bijection $F$ `preserves' those functions because of the condition $F({\sigma}(x)) \,=\, {\tau}(F(x))$.

        The import of this result is that it does not matter which counting structure one elects to use: they are equivalent.
    From now on we shall use the standard example ${\NN}$ from grade-school arithmetic, for which the successor function is `addition by~$1$'.

\V
\V

        It is useful to prove some of the results that were accepted without proof earlier in {\TheseNotes}.
    For example, here is a more complete treatment of Theorem~\Ref{ThmA15.30}


        {\bf Add1-\Ref{ChaptA} 23: Theorem}
            %\subsection{\small{\bf Theorem}}
            %\label{ThmA15.30}

\hspace*{\parindent}(a) Let $X$ be a nonempty finite set. If $X$ has the same cardinality as ${\NN}_{k}$ and the same cardinality as ${\NN}_{m}$ for natural numbers $k$ and $m$, then $k \,=\, m$.

\V

        (b) If $Y$ is a subset of a finite set $X$, then $Y$ is a finite set, and $\#(Y)\,\,{\leq}\,\,\#(X)$.
    Moreover, the only time one gets $\#(Y) \,=\, \#(X)$ is when $Y \,=\, X$.
    In particular, $X$ cannot have the same cardinality as one of its proper subsets (i.e., there is no `Galileo Paradox' for finite sets.)


\V

        (c) Suppose that $\{X_{1},X_{2},\,{\ldots}\,X_{n}\}$ is a finite collection of finite sets.
    Then the union $X_{1}\,{\cup}\,X_{2}\,{\cup}\,\,{\ldots}\,\,{\cup}\,X_{n}$ is also a finite set. More precisely,
        \begin{displaymath}
         \#(X_{1}\,{\cup}\,X_{2}\,{\cup}\,\,{\ldots}\,\,{\cup}\,X_{n})
    \,\,{\leq}\,\,
        \#(X_{1}) + \#(X_{2}) + \,{\ldots}\,+\#(X_{n}).
        \end{displaymath}
    One gets equality in this last relation if, and only if, the sets are mutually disjoint,
    in the sense that $X_{i}\,{\cap}\,X_{j} \,=\, {\emptyset}$ whenever $i \,\,{\neq}\,\, j$.

\V


        {\bf Proof}\, 

\V

        (a) It follows easily from Part~(c) of Theorem~\Ref{ThmA15.15} that the issue to be proved reduces to this:
    if $k$ and $m$ are natural numbers such that ${\NN}_{k}$ has the same cardinality as ${\NN}_{m}$, then $k \,=\, m$;
    equivalently: if $k \,\,{\neq}\,\, m$, then ${\NN}_{k}$ does {\em not} have the same cardinality as ${\NN}_{m}$.
    Then in light of Part~(b) of the same theorem, the problem reduces to proving the following statement:

\V

        \h For every $j$ in ${\NN}$, if $k$ in ${\NN}$ satisfies the condition $k\,>\,j$, then ${\NN}_{j}$ does not have the same cardinality as ${\NN}_{k}$.

\V

\noindent We shall prove a slightly more precise result: For every $j$ in ${\NN}$. if $k{\in}{\NN}$ satisfies $k\,>\,j$,
    then there is no surjection of ${\NN}_{j}$ onto ${\NN}_{k}$.

        Indeed, let $A$ be the set of $j$ in ${\NN}$ for which this last statement is true.


        \underline{Initial Step} It is clear that $1{\in}A$.
    Indeed, suppose that $k\,>\,1$, so that $k\,\,{\geq}\,\,2$ and thus $1$ and $2$ are both elements of ${\NN}_{k}$.
    If $F:{\NN}_{1} \,{\rightarrow}\, {\NN}_{k}$ were a surjection onto ${\NN}_{k}$,
    then there would have to exist $x_{1}$ and $x_{2}$ in ${\NN}_{1}$ such that $F(x_{1}) \,=\, 1$ and $F(x_{2}) \,=\, 2$.
    However, the only element of ${\NN}_{1}$ is~$1$, so this would require $x_{1} \,=\, x_{1} \,=\, 1$, and thus $F(1) \,=\, 1$ and $F(1) \,=\, 2$.
    Viewing $F$ as a set of ordered pairs, this would mean that $(1,1){\in}F$ and $(1,2){\in}F$, contrary to the definition of `function'.

        \underline{Inductive Step} Suppose that $j{\in}A$. If $j+1$ were {\em not} in $A$,
    then there would have to exist a surjection $F$ from ${\NN}_{j+1}$ onto ${\NN}_{m}$ for some $m\,>\,j+1$.
    Note that in this case one would certainly have $k \,=\, m-1\,>\,j$. There are two cases to consider:

        \h \underline{Case 1}: Suppose that $F(j+1) \,=\, m$.
    Define $G:{\NN}_{j} \,{\rightarrow}\, {\NN}_{k}$ by the rule
        \begin{displaymath}
        G(i) \,=\, \left\{
        \begin{array}{cl}
        F(i) & \mbox{if $F(i) \,\,{\neq}\,\, m$} \\
           1 & \mbox{if $F(i) \,=\, m$}
        \end{array}
        \right.
        \end{displaymath}
    It is easy to see that $G$ would have to map ${\NN}_{j}$ onto ${\NN}_{k}$ with $k\,>\,j$.
    This would contradict the induction hypothesis that $j{\in}A$.

        \h \underline{Case 2}: Suppose that $F(j+1) \,\,{\neq}\,\, m$. Let $p \,=\, F(j+1)$, so that $1\,\,{\leq}\,\,p\,\,{\leq}\,\,k$.
    Now define $G:{\NN}_{j} \,{\rightarrow}\, {\NN}_{k}$ by the rule
        \begin{displaymath}
        G(i) \,=\,
        \left\{
        \begin{array}{cl}
        F(i) & \mbox{if $F(i) \,\,{\neq}\,\, m$} \\
          p  & \mbox{if $F(i) \,=\, m$}
        \end{array}
        \right.
        \end{displaymath}
    It is easy to see that $G$ maps ${\NN}_{j}$ onto ${\NN}_{k}$, contrary to the hypothesis that $j{\in}A$.

    This argument shows that $j+1$ is also in $A$. Thus, by the Principle of Mathematical Induction one concludes that $A \,=\, {\NN}$. The desired result now follows.

\V

        (b) and (c): These follow easily from Part~(a) combined with Mathematical Induction. The details are left as exercises.

\VV

        There are many more results about ${\NN}$ (or, if you prefer, about counting structures) that one could list.
    However, the main purpose of this addendum is to convince the reader  that the standard properties of ${\NN}$ can be derived from the Dedekind-Peano axioms.
    The results already given here are sufficient for that purpose.

\newpage

                        \section{ADDENDUM TWO TO CHAPTER~\ref{ChaptA}: Further Results in Set Theory}
                        \label{SectAAdd2}

\VV

        In this second addendum we consider some standard results in Set Theory with wich evry mathematician should become familiar.
    This material is not required for later chapters, however, so we label the various topics discussed here (definitions, theorems, remarks, etc)
    with the prefix `Add2-\Ref{ChaptA}' (short for `Addendum~Two to Chapter~\Ref{ChaptA}').

\VV

                 \subsection{\small{\bf Theorem (DeMorgan's Laws for Sets)}}
            %\label{ThmA10.30}
            \index{DeMorgan's laws for sets}

        Let ${\cal A}$ be a nonempty family of sets, and let $X$ be a set; we do {\em not} assume that $X$ is a member of the family ${\cal A}$.
    Let ${\cal B}$ be the family of all sets $Y$ which can be expressed in the form $Y \,=\, X{\setminus}A$ for at least one set $A$ in the family ${\cal A}$. Then

\V

        (i) $X{\setminus}\left({\bigcup}\, {\cal A}\right) \,=\, {\bigcap}\, {\cal B}$.
    \h
        (ii) $X{\setminus}\left({\bigcap}\, {\cal A}\right) \,=\, {\bigcup}\, {\cal B}$.

\noindent Using the alternate notation introduced in Part~(d) of Definition~\Ref{DefA10.15} above,
    these set identities can be written, without needing to introduce the family~${\cal B}$, as follows:
        \begin{displaymath}
        (i)\,\, X{\setminus}\left({\bigcup}_{A{\in}{\cal A}}\, A\right) \,=\, {\bigcap}_{A{\in}{\cal A}} (X{\setminus}A) \h
        (ii)\,\, X{\setminus}\left({\bigcap}_{A{\in}{\cal A}}\, A\right) \,=\, {\bigcup}_{A{\in}{\cal A}} (X{\setminus}A).
        \end{displaymath}
\V
\V

        \underline{Proof of (i)} (The proof of (ii) is similar, and is left as an exercise): Suppose that $c$ is an element of the set $X{\setminus}\left({\bigcup}\, {\cal A}\right)$.
	Then $c$ is in $X$ but $c$ is not in ${\bigcup}\,{\cal A}$.
    To say that $c$ is not in ${\bigcup}\,{\cal A}$ means that for each $A$ in the family ${\cal A}$, $c$ is not in $A$.
	Thus, for each such $A$ one has $c$ in $X$ but $c$ not in $A$;
    hence one has $c{\in}(X{\setminus}A)$.
    Thus, $c$ is in each of the sets of the family ${\cal B}$, hence $c$ is in ${\bigcap}\,{\cal B}$.
	It follows that
        \begin{displaymath}
        X{\setminus}\left({\bigcup}\, {\cal A}\right) \,{\subseteq}\, {\bigcap}\,{\cal B} \h ({\ast})
        \end{displaymath}

		Likewise, suppose that $p$ is an element of ${\bigcap}\,{\cal B}$.
    Then $p$ is in each of the sets of the family ${\cal B}$;
    that is, $p$ is in every set of the form $X{\setminus}A$ with $A$ in the family ${\cal A}$.
    That is, for each such $A$ the point $p$ is in $X$ but not in $A$.
    Since $p$ fails to be in any of these sets $A$, it follows that $p$ is also not in ${\bigcup}\,{\cal A}$;
    and since $p$ is in $X$, it then follows that $p$ is in $X{\setminus}\left({\bigcup}\,{\cal A}\right)$.
    That is,
        \begin{displaymath}
        {\bigcap}\,{\cal B} \,{\subseteq}\, X{\setminus}\left({\bigcup}\, {\cal A}\right) \h ({\ast}{\ast})
        \end{displaymath}


        The set relations $({\ast})$ and $({\ast}{\ast})$ then imply, by Theorem~\Ref{ThmA10.10},
    that $ X{\setminus}\left({\bigcup}\, {\cal A}\right) \,=\, {\bigcap}\,{\cal B}$, as claimed.
    

\V

        {\bf Remark} The preceding theorem is sometimes expressed informally as follows:

        \h (i)\, The complement of a union is the intersection of the complements;

       \h (ii) The complement of an intersection is the union of the complements.


\VV

\V

        \subsection{\small{\bf Remark} Russell's Paradox}
        %\label{RemrkA10.35}
        \IndBD{set theory}{Russell's Paradox}

        The theory of sets is a very deep subject, and is still an area of active research.
    Fortunately, the use of sets in {\TheseNotes} does not require a deep knowledge of this theory.
    Nevertheless, it is appropriate to mention one topic from the wider theory of sets.

        The basic issue arises directly from the definition of a `set' as being simultaneously a collection of objects and an object in its own right.
    As has already been seen, this allows the construction of sets whose individual elements are themselves sets.

\V

        {\bf Example}: Let us say that a set $Y$ has Property~R provided that the set $Y$,
    thought of as an object in its own right, is {\em not} an element of the set~$Y$, thought of as a collection of objects.
    (Note that all the sets we have considered so far do have Property~R.)
    Now define the set $X$ be the family of all sets $Y$ such that $Y$ has Property~R.

        \underline{Question} Does the set $X$ have Property~R?

        \underline{Analysis} Suppose that the set $X$ {\em does} have Property~R.
    Then, by the very definition of the set $X$ just given, the elements of $X$ include {\em every} set having Property~R and thus include $X$ itself.
    That is, $X$, viewed as an object, is an element of $X$, viewed as a set.
    However, by definition of Property~R, this last fact means that $X$ does not have Property~R, which contradicts the supposition that $X$ does have Property~R.

        Now suppose that $X$ does {\em not} have Property~R. Then, by definition of `Property~R',
    the set $X$, thought of as an object, {\em is} an element of the set $X$.
    But by the very definition of $X$ given above, each element of the set $X$ -- including now $X$ itself --
    is a set which has Property~R, contradicting the supposition that $X$ does not have Property~R.

    In summary: assuming that $X$ {\em does} have Property~R implies that $X$ does {\em not} have Property~R;
    while assuming $X$ does {\em not} have Property~R implies that $X$ {\em does} have Property~R.
        This mysterious state of affairs is called {\bf Russell's Paradox},
    in honor of the British philosopher Bertrand Russell, who discovered it in~$1901$.
    It is well beyond the scope of {\TheseNotes} to consider a proper analysis of such set-theoretic paradoxes;
    for that, the reader should pick up a book on the logical foundations of mathematics.
    Instead, we follow the common approach in Analysis and assume that the sets we deal with are all subsets of some fixed (but unspecified) `universal set' which is big enough for our purposes but `small enough' to avoid such paradoxes.
    In particular, this approach only sets $X$ which satisfy the relation $X \not \in X$.

\VV


        (4) Suppose that $X$ is a nonempty set and let $k$ be a natural number. If $X_{1}$, $X_{2}$,\,{\ldots}\,$X_{k}$ are nonempty subsets of $X$,
    then the set of all $k$-tuples $g:{\NN}_{k} \,{\rightarrow}\, X$ such that $g(j){\in}X_{j}$ for each $j \,=\, 1,2,\,{\ldots}\,k$ is denoted $X_{1}{\times}X_{2}{\times}\,{\ldots}\,{\times}X_{k}$; it is called the {\bf Cartesian product} of these sets.
    This is sometimes written more briefly by expressions such as ${\prod}_{j \,=\, 1}^{n} X_{j}$, where, as usual, the symbol $\prod$ stands for `product'.

        More generally, suppose that ${\varphi}:Z \,{\rightarrow}\, {\cal P}(X){\setminus}\{{\emptyset}\}$ is a function defined on a nonempty set $Z$, 
    with values being nonempty subsets of $X$.
    For each $i$ in $Z$ let $X_{i} \,=\, {\varphi}(i)$.
    Then the corresponding {\bf Cartesian product of the indexed family $\Bfm{X}_{i}$}, denoted ${\prod}_{i{\in}Z} X_{i}$,
    consists of the functions $g:Z \,{\rightarrow}\, X$ such that $g(i){\in}X_{i}$ for each $i$ in $Z$.
    The set $X_{i}$ is called the {\bf $\Bfm{i}$-th factor} in this product.

        It is convenient to extend these ideas to cases in which one of the `factors' is the empty set by declaring that such a product to also be the empty set.

        \underline{Remark} For small values of $k$ it is customary to use older language.
    For instance, an ordered $2$-tuple is often called an {\bf ordered pair}. Of course this conflicts with the primitive (i.e., Kuratowski) concept of `ordered pair.
    The way to get around this ambiguity is to think of the definition of $2$-tuple (as a function defined on the set $\{1,2\}$) as the `new, improved' type of ordered pair, while the Kuratowski definition describes the 'primitive ordered pair'.
    From this point on in {\TheseNotes} the phrase `ordered pair' means this new, improved version unless stated otherwise.

\V
\V

        Associated with a set $X$ is a second set whose elements are precisely the subsets of $X$,
    each such subset being thought of as a single object in its own right.

\V

        \subsection{\small{\bf Definition}}
        %\label{DefA10.40}

        Let $X$ be a set. The {\bf power set of $\Bfm{X}$}\IndBD{set theory}{power set} is the collection whose elements are precisely the subsets of $X$.
    That is, to say that an object $C$ is an element of the power set of $X$ means that $C$ is a subset of $X$.
    Some authors denote the power set of $X$ by the symbol ${\cal P}(X)$; some denote it by the symbol $2^{X}$ (whence the name `{\em power} set').
    We shall use the ${\cal P}(X)$ notation in {\TheseNotes}.
    (See Example~(5) below for the origin of the `exponential' notation $2^{X}$ mentioned here.)

\V

        \subsection{\small{\bf Examples}}
        %\label{ExampA10.50}

\hspace*{\parindent}
        (1) Suppose that $X \,=\, \{c\}$ for some object $c$, so that $X$ is a singleton  set.
    It is obvious that ${\cal P}(X)$ has exactly two (different) subsets, namely $X$ itself and the empty set ${\emptyset}$.
    (You should try to provide a correct proof before going on. You might also wish to read the \Note\, `on the power set of a singleton set'.)

\V

        (2) A similar analysis, which is left as an exercise, shows that if $X \,=\, \{c,d\}$ where 
$c \,{\neq}\, d$, (i.e., if $X$ is a doubleton set),
    then ${\cal P}(X) \,=\, \{{\emptyset}, \{c\}, \{d\}, X\}$.
	In particular, if $X$ has exactly two elements, then ${\cal P}(X)$ has exactly four elements.

\V

        (3) The empty set ${\emptyset}$ has a subset, namely itself; see Part~(b) of Theorem~\Ref{ThmA10.25}.
    It is also clear that ${\emptyset}$ has no other subsets, and thus that ${\cal P}({\emptyset}) \,=\, \{{\emptyset}\}$.
    In particular, the power set of the empty set is \underline{not} the empty set, since ${\cal P}({\emptyset})$ does have an element, namely the set ${\emptyset}$, thought of as an object in its own right.

\V

        (4) It is possible that $X$ and ${\cal P}(X)$ can have one or more elements in common.
    For instance, let $c$ be an object, and let $X \,=\, \{c,\{c\}\}$.
    Thus, $X$ is a set with two distinct elements, namely the object $c$ and the singleton set $\{c\}$, thought of as an object in its own right.
    It follows from the results of Example~(2) above that the power set ${\cal P}(X)$ consists of the four elements ${\emptyset}$, $\{c\}$, $\{\{c\}\}$ and $X$.
    Notice that the second entry in this list is the set $\{c\}$, which is also an element of $X$.

        A simpler example of this type is $X \,=\, \{{\emptyset}\}$;
    that is, $X$ is as in Example~(1) above, with $c$ equal to the empty set ${\emptyset}$, thought of as an object in its own right.
    Then the result of Example~(1) takes the form ${\cal P}(X) \,=\, \{{\emptyset},X\}$.
    In particular, the object ${\emptyset}$ is both an element of $X$ and an element of ${\cal P}(X)$.

\V

        (5) We shall see later that if $X$ is a set with exactly $n$ members, where $n$ is some natural number,
    then ${\cal P}(X)$ has exactly~$2^{n}$ members; and of course if $X$ has no members (i.e., if $X \,=\, {\emptyset}$),
    then ${\cal P}(X)$ has~$1 \,=\, 2^{0}$ members. The exponential notation $2^{X}$ grew out of these facts.

\V

%%% 
\begin{quotation}
{\footnotesize \underline{\Note} (on the power set of a singleton set)\IndB{\notes}{on the power set of a singleton set}: 
    In Example (1) above it is asserted that the fact that $X \,=\, \{c\}$ has exactly two subsets, namely, $X$ itself and ${\emptyset}$.
    Whenever you see such an assertion of `obviousness' in a math context, beware:
    the author may be trying to slide something by you. And even if you agree that the stated result is `obvious',
    you should always be prepared to give a {\em proper} proof; that is, a proof which arises from definitions and previously-accepted, results using correct logic.
    For example, the following is a `fake proof':

\VA

        \h `The sets $X$ and ${\emptyset}$ are certainly subsets of $X$, and I can't think of any others.'

\VA

\noindent Here is a proper proof:

        First note that, by Part~(b)(i) of Theorem~\Ref{ThmA10.25}, the sets ${\emptyset}$ and $X$ are, indeed, subsets of $X$;
    in particular, by the definition of `power set' and `subset', $\{{\emptyset}, X\} \,{\subseteq}\, {\cal P}(X)$.
    (This is essentially how the `fake proof' above starts.)

        To see that there are no other subsets of $X$, i.e., no other elements of ${\cal P}(X)$, let $Y$ be any nonempty subset of $X$.
    Since, by hypothesis, $Y \,\,{\neq}\,\, {\emptyset}$, it follows,
    by the definition of `empty set', that there must be at least one element in the set $Y$.
    Let $d$ be any element of $Y$. Since, by hypothesis, $Y \,{\subseteq}\, X$, it follows (from the definition of `subset') that $d$ is an element of $X$.
    However, by the Fundamental Principle of Set Theory, combined with the hypothesis that $X \,=\, \{c\}$,
    so that $c$ is the {\em only} element of $X$, it follows that $d \,=\, c$.
    That is, every element of $Y$ equals $c$, so $Y$ and $X$ have exactly the same elements,
    namely the single element $c$. Thus, by the Fundamental Principle of Set Theory, one has $Y \,=\, X$.
    That is, if $Y \,{\subseteq}\, X$ and $Y \,\,{\neq}\,\, {\emptyset}$, then $Y \,=\, X$.
    It follows that ${\cal P}(X) \,{\subseteq}\, \{{\emptyset},X\}$. However, it was already noted above that ${\cal P}(X) \,{\supseteq}\, \{{\emptyset},X\}$.

    
    In the latter case, $Y$ must have at least one element (by definition of `not the empty set'),
    and any such element must be an element of $X$ (by definition of $Y$ being a {\em subset} of $X$).
    If $d$ is any element of $Y$, then, as just shown, $d$ must be an element of $X$ and thus, by the hypothesis that $X \,=\, \{c\}$, one must have $d \,=\, c$.
}%EndFootnotesize
\end{quotation} 
%##


\V
\V


        \underline{Preliminary Comment} One knows that if $X$ is a finite set with exactly $n$ elements,
    then the corresponding power set ${\cal P}(X)$ has exactly $2^{n}$ elements. In particular, the power set ${\cal P}(X)$ has more elements than the original set $X$;
    moreover, the larger $n$ is, the greater the difference in the sizes of the sets.
    This observation may make the next result seem almost `obvious'.

\V

            \subsection{\small{\bf Theorem} (Cantor's Power-Set Theorem)} \IndBD{set theory}{Cantor's Power-Set Theorem}
            %\label{ThmA20.90}

        Let $X$ be a set, and let $Y \,=\, {\cal P}(X)$ be the corresponding power set of $X$.

    Then $X$ does {\em not} have the same cardinality as $Y$; that is, there does not exist a bijection of $X$ onto ${\cal P}(X)$.
    Indeed, even more can be said; namely, if $X \,\,{\neq}\,\, {\emptyset}$ and $F:X \,{\rightarrow}\, {\cal P}(X)$ is any function with domain $X$ and values in ${\cal P}(X)$,
    then $F$ does {\em not} map $X$ onto ${\cal P}(X)$; that is, $F$ is {\em not} a surjection of $X$ onto~${\cal P}(X)$.
    In particular, anyone who claims to have constructed an example of a bijection of $X$ onto ${\cal P}(X)$ is wrong,
    since there does not exist a surjection, much less a bijection.

\V


        \underline{Proof}: \underline{Case 1} Suppose that $X$ is the empty set.
    Recall that ${\cal P}({\emptyset}) \,=\, \{{\emptyset}\}$, so ${\cal P}({\emptyset})$ is a nonempty set.
    Since, as has already been noted, the empty set does not have the same cardinality as a nonempty set,
    it follows that the claimed result is true when $X$ is empty. (More intuitively: The empty set has no elements, while ${\cal P}({\emptyset})$ has one element.)

\V

        \underline{Case 2} Suppose that $X$ is nonempty, and suppose that $F:X \,{\rightarrow}\, {\cal P}(X)$ is a function with domain $X$ and values in ${\cal P}(X)$.
    Let $S$ be the set of all $x$ in $X$ such that $x$ is {\em not} an element of the set $F(x)$.

        \h \underline{Claim} The set $S$ is not in the image of the function~$F$.

        \h \underline{Proof of Claim} Suppose, to the contrary, that $S$ can be expressed as $F(x_{0})$ for some $x_{0}$ in $X$.
    If $x_{0}$ is in $S$, then (by definition of $S$) $x_{0}$ is {\em not} an element of  $F(x_{0})$; that is, since $S$ is supposed to equal $F(x_{0})$, one has $x_{0}$ {\em not} in $S$.
    Similarly, if $x_{0}$ is {\em not} in $S$, then (again by the definition of $S$) $x_{0}$ must be an element of $F(x_{0})$; that is, $x_{0}$ is an element of $S$.
    Thus, assuming that there exists $x_{0}$ in $X$ such that $S \,=\, F(x_{0})$ leads to the existsence of an element, namely this $x_{0}$,
    which is simultaneously an element of $S$ and {\em not} an element of~$S$. No such $x_{0}$ can exist, hence $S$ is not in the image of $F$.


\V
\V

            \subsection{\small{\bf Corollary}}
            %\label{RemrkA20.92}

        There exist sets which are uncountable.

\V

        {\bf Proof}\, 

\V

        Let $Y \,=\, {\cal P}({\NN})$, the power set of ${\NN}$.
    It is clear that $Y$ is not finite since it has the infinite subset
    $\{\{n\}: n{\in}{\NN}\}$ whose elements are the singleton sets of natural numbers.
    In addition, by Cantor's Power-Set Theorem above, $Y$ does not have the same cardinality as ${\NN}$;
    that is, $Y$ is not countably infinite. It follows that the set $Y$ is not countable.

\V
\V

        The uncountable set ${\cal P}({\NN})$ is difficult to visualize. Fortunately, it is possible to interpret it geometrically as a subset of the real number line.
    The basic idea is to use the representation of subsets of ${\NN}$, in terms of sequences of $0$s and~$1$s, discussed in Example~\Ref{ExampA40.30}~(6).
    For convenience we break up the discussion into several parts.

\V



                        \section{`Ordered Pairs' in Terms of Sets (Kuratowski)}
                        %\label{SectA12A}

\V


    In the current section we illustrate the `reduction to set theory' process by expressing the important concept of `an ordered pair of objects' purely in terms of sets.

        Most students first encounter the idea of an `ordered pair of objects' in analytical geometry:
    one characterizes the location of a point (i.e., a `dot') in the $xy$-plane in terms of a pair of numbers,
    the `Cartesian coordinates' of the point (relative to a choice of origin and coordinate axes).
    The order in which these numbers are written makes a difference; for instance,
    the pair $(2,-3)$ corresponds to a geometric point in the fourth quadrant of the $xy$-plane,
    while the pair $(-3,2)$ corresponds to a geometric point in the second quadrant.

        More generally, if $x$ and $y$ are any objects, one seeks a purely set-theoretic way to encode the main information contained in intuitive concept of `the ordered pair $(x,y)$':

\VA

        \h (i) The concept should be expressed purely in terms of sets formed from the objects $x$ and~$y$.

        \h (ii) If $x \,\,{\neq}\,\, y$, then the definition should allow one to distinguish which of these objects is to be the `first' and which is to be the `second'.

\VA

\noindent Notice that the `obvious' solution, namely to define the desired ordered pair as the set $\{x,y\}$, does not satisfy Condition~(ii);
    indeed, one has $\{x,y\} \,=\, \{y,x\}$, so this doubleton set does not single out one of the objects $x$ or $y$ as somehow being `preferred'.

        Around 1914 the American mathematician Norbert Wiener developed a suitable set-theoretic treatment of `ordered pairs';
    this was simplified by the Polish mathematician Kasimir Kuratowski in~1921. We follow Kuratowski's approach here.

\V
\V

        \subsection{\small{{\bf Definition} (Kuratowski Ordered Pairs})}
        \label{DefA12.10}\IndB{ordered pairs}{Kuratowski definition}

        Let $x$ and $y$ be objects. Then the {\bf Kuratowski ordered pair whose first entry is $\Bfm{x}$ and whose second entry is $\Bfm{y}$} is the set $\{\{x\},\{x,y\}\}$.
    If $x \,=\, y$ one says that the ordered pair is of {\bf Type~I}\IndC{ordered pairs}{Kuratowski definition}{Type I}, while if $x \,\,{\neq}\,\, y$ then it is of {\bf Type~II}\IndC{ordered pairs}{Kuratowski definition}{Type II}.

\V

        \underline{Remarks}

\V

        (1) For convenience one normally denotes the ordered pair whose first entry is $x$ and whose second entry is $y$ by the standard symbol $(x,y)$,
    where the first entry of the ordered pair appears on the left in this notation and the second on the right;
    in the spoken form, one then refers to `the ordered pair $x$\,~$y$', with the first entry of the pair spoken first.
    Note that neither of these conventions distinguishes `first entry' in a purely set-theoretic way:
    the phrase `on the left' introduces a visual aspect, while the phrase `spoken first' introduces a temporal aspect.

\V

        (2) In the Kuratowski formulation, the ordered pair with first entry $x$ and second entry $y$ is either a singleton set, if $x \,=\, y$, or a doubleton set, if $x \,\,{\neq}\,\, y$.

\V

        (3) As was indicated above, other set-theoretic definitions of `ordered pairs' have been proposed.
    These are not simply rewordings of the Kuratowski definition which describe the same objects.
    For instance, in the Kuratowski formulation the ordered pair whose first entry is the number $x$
    and whose second entry is the number~$y$ is the set $\{\{x\}, \{x,y\}\}$, thought of as a single object.
    In the earlier formulation of Norbert Wiener, however, the same ordered pair is defined to be the set $\{\{\{x\},{\emptyset}\}, \{\{y\}\}\}$.
    In particular, the Wiener version of the ordered pair $(x,y)$ is a set which includes the object $\{\{y\}\}$ as an element;
    in contrast, the Kuratowski version is a set which does {\em not} have $\{\{y\}\}$ as an element.
    It follows from the Fundamental Principle of Set Theory that these objects (i.e., sets) cannot be equal,
    so the definitions themselves, while superficially similar, are fundamentally different.
    More precisely, one cannot take, say, the Kuratowski definition of the ordered pair $(x,y)$
    and then prove that $(x,y)$ is also given by the Wiener definition.
    (Compare this situation with the discussion above on defining even and odd integers.)
    Instead, the purpose of such constructions in modern mathematics is to provide a precise construction, purely in terms of sets,
    of concrete objects whose set-theoretic properties correspond precisely to the properties our understanding of the given intuitive concept.

\V
\V

%%% 
\begin{quotation}
{\footnotesize \underline{\Note} (on Kuratowski ordered pairs)\IndB{\notes}{on Kuratowski ordered pairs}:
    The symbols used to formulate the preceding definition, when combined with the standard $(x,y)$ notation,
    may make it appear that almost nothing has really happened. However, this perception changes when one tries to use this definition `with one's eyes closed'.
    Indeed, the true test of whether the Kuratowski definition `works', i.e., whether it does accurately encode the intuitive idea of `ordered pair'
    in a purely set-theoretic way, is this: given any object $Z$, one ought to be able to tell,
    using set-theoretic ideas alone, whether $Z$ is an ordered pair in the sense of Kuratowski;
    if it is, one ought to be able to determine the original objects from which the ordered pair $Z$ is formed,
    and also to determine which of these objects is to be the `first'.
    This determination should involve only set-theoretic ideas, and not involve spatial notions such as `the object on the left',
    or temporal notions such as `the first object mentioned'. Here is how the Kuratowski formulation carries this out:

       \h Step 1: Given an object $Z$, determine whether it is a set.
    If it is not a set, then it cannot be an ordered pair, so stop. Otherwise:

       \h Step 2: If $Z$ is a set, determine whether it is either a singleton or a doubleton set.
    If $Z$ is neither a singleton set nor a doubleton set, then (Remark~2 above) it cannot be an ordered pair, so stop. Otherwise:

       \h Step 3:

            \h \h (a) If $Z$ is a singleton, determine whether its unique element is itself a singleton set.
    If it is not, then $Z$ cannot be an ordered pair, so stop. However, if the unique element of $Z$ {\em is} a singleton set $A$,
    let $x$ be the unique element of $A$. Then this analysis shows that $Z$ is the ordered pair $\{\{x\}\} \,=\, \{\{x\},\{x\}\} \,=\, \{\{x\},\{x,x\}\}$ 
    whose first entry is $x$ and whose second entry is also $x$. Success!

        \h \h (b) If $Z$ is a doubleton set, determine whether one of its two elements is a singleton set and the other is a doubleton set.
    If this is not the case, then $Z$ cannot be an ordered pair, so stop. Otherwise:

        Step 4: For convenience, call the element of $Z$ that is a singleton set $B$, and call the element of $Z$ that is a doubleton set $C$.
    If $B$ is not a subset of $C$, then $Z$ cannot be an ordered pair, so stop. Otherwise:

        Step 5: Let $x$ be the unique element of $B$, and let $D \,=\, C\,{\setminus}\,B$.
    Since $B$ is a subset of $C$, it is clear that $D$ is obtained by removing $x$ from $C$.
    It follows that $D$ is also a singleton set whose unique element does {\em not} equal $x$.
    Now let $y$ be the unique element of $D$. Then it is clear that $Z \,=\, \{\{x\},\{x,y\}\}$. Success!

\V

       \underline{Note} The preceding analysis may seem overly fussy, but it is forced on us because the object $Z$ may be quite complicated.

        \underline{Example}: Consider the following object:         \begin{displaymath}
Z \,=\, 
                \{
            \{
        \{
           \{
            \{
              \{a\},\{a,b\}
            \}
           \}
             ,
        \{
           \{\{a\},\{a,b\}\} , c
            \}
        \}
            \}
                         ,
            \{
        \{
           \{
            \{
              \{a\},\{a,b\}
            \}
           \}
             ,
        \{
           \{\{a\},\{a,b\}\} , c
            \}
        \},
          \{\{a\},\{a,\{\{b\},\{b,c\}\}\}\}
            \}
                \}
        \end{displaymath}
%% MAKE SURE THIS OBJECT ACTUALLY WORKS SHOULD BE (x,y), WHERE
%%  x=((a,b),c), y=(a,(b,c))
    where $a$, $b$ and $c$ are distinct objects.
    The reader is encouraged to determine whether $Z$ is an ordered pair in the Kuratowski sense.
}%EndFootNoteSize
\end{quotation} 
%##

\V
\V


        It is fairly straight forward to generalize the Kuratowski construction to define `ordered triples', `ordered quadruples', and so on.
    However, the results become increasingly complicated. Instead we handle such extensions in an alternate way in Section~~\Ref{SectA30}.
    At that time it also will be convenient to provide a `new, improved' formulation for ordered pairs.
    The formulation there will ultimately be based on the Kuratowski construction given above,
    but from then on the Kuratowski ordered pair will be treated as the `primitive' version.
    This process of evolving from a `primitive definition' of ordered pair to an `improved definition' should sound familiar:
    a similar evolution process was described in `Warning~(b)' above for `Definitions'.

\V
\V

        One of the advantages of formulating concepts in terms of sets is that one has a precise way of determining when two sets are equal to each other; namely, when they have exactly the same elements (Axiom of Extension).
    In particular, the Kuratowski definition gives actual content to the following statement:


        \subsection{\small{\bf Theorem}}
            \label{ThmA12.20}

        A necessary and sufficient condition for ordered pairs $Z$ and $W$ to be equal is that the first entry of $Z$ equal the first entry of $W$ and the second entry of $Z$ equal the second entry of $W$.

\V

        \underline{Proof}:

        Let $a$ be the first entry of the ordered pair $Z$ and let $b$ be the second entry of $Z$.
    Likewise, let $c$ and $d$ be the first and second entries, respectively, of $W$.
    Then, in accordance with Kuratowski's definition, the statement to be proved is this:
        \begin{displaymath}
        \mbox{A necessary and sufficient condition for } \{\{a\},\{a,b\}\} \,=\, \{\{c\},\{c,d\}\} \mbox{ is that }
    a \,=\, c \mbox{ and } b \,=\, d.
        \end{displaymath}

        \underline{`Sufficient' Half} Suppose that $a \,=\, c$ and $b \,=\, d$.
    Then $\{a\} \,=\, \{c\}$ and $\{a,b\} \,=\, \{c,d\}$, so $\{\{a\}, \{a,b\}\} \,=\, \{\{c\},\{c,d\}\}$.
    (We have simply replaced `equals by equals'.) That is, $Z \,=\, W$, as claimed.

\V

        \underline{`Necessary' Half}: Suppose that $Z \,=\, W$.
    Then, by the Kuratowski definition of `ordered pairs', this can be written
        \begin{displaymath}
        \{\{a\},\{a,b\}\} \,=\, \{\{c\},\{c,d\}\} \h ({\ast})
        \end{displaymath}

        \underline{Case 1}: Suppose that $a \,=\, b$, so that $(a,b)$ is an ordered pair of Type~I (see Definition~\Ref{DefA12.10} above).
    Then $\{\{a\},\{a,b\}\} \,=\, \{\{a\}\}$; in particular, the left side of Equation~$({\ast})$ is a singleton set.
    Thus, from the `Axiom of Extension', it follows that the right side of Equation~$({\ast})$ must also be a singleton.
    That is, $(c,d)$ is also an ordered pair of Type~I, so $c \,=\, d$.
    Thus,
        \begin{displaymath}
        \{\{a\}\} \,=\, \{\{c\}\}.
        \end{displaymath}
    Apply the Axiom of Extension to the singleton sets $\{\{a\}\}$ and $\{\{c\}\}$ to get $\{a\} \,=\, \{c\}$;
    Apply the axiom again to the singleton sets $\{a\}$ and $\{c\}$ to get $a \,=\, c$.
    Since in this case one also has $a \,=\, b$ and $c \,=\, d$, it follows that $a \,=\, c$ and $b \,=\, d$, as claimed.

\V

        \underline{Case 2}: Suppose $a \,\,{\neq}\,\, b$. Then $Z \,=\, (a,b)$ is a Type~II ordered pair,
    hence $W \,=\, (c,d)$ is also of Type~II (since, by hypothesis, $Z \,=\, W$), and thus $c \,\,{\neq}\,\, d$.
    The equality $Z \,=\, W$ also implies that the element of $Z$ which is a singleton set must equal the element of $W$ which is a singleton set. That is, $\{a\} \,=\, \{c\}$, so by the Axiom of Extension again one has $a \,=\, c$.
    Likewise, the element of $Z$ which is a doubleton set must equal the element of $W$ which is a doubleton set,
    so $\{a,b\} \,=\, \{c,d\}$. Since, as was just shown, one has $a \,=\, c$, one can then write $\{a,b\} \,=\, \{a,d\}$;
    just replace $c$ by $a$ in the set $\{c,d\}$. The fact that $\{a,b\} \,=\, \{a,d\}$ means that $b$ must be one of the elements of the doubleton set $\{a,d\}$. Since we are assuming $a \,\,{\neq}\,\, b$, it follows that $b \,=\, d$, as required, and the desired result follows.

\VV

        In analysis, as elsewhere in mathematics, one encounters sequences which are constructed in a step-by-step manner,
    using the early entries to determine the later ones. For example, in the definition of the quantity $k!$,
    where $k$ is a natural number, one first sets $1! \,=\, 1$, and then $(k+1)! \,=\, k!(k+1)$.
    Such definitions are said to be {\bf recursive}.
    Likewise, the construction of the canonical bijection ${\Psi}_{C}$ in Definition~\Ref{DefA30.70} is given recursively.
    The main theoretical fact about recursive definitions is the following result.

\V

        \subsection{\small{{\bf Theorem}} (Dedekind's Theorem on Recursive Definitions)}\IndBD{recursive definitions}{Dedekind's recursive-definition theorem}
        \label{ThmA40.100}

        Let $Y$ be a nonempty set, let $y_{0}$ be a point of $Y$, and let $G:Y \,{\rightarrow}\, Y$ be a function with domain $Y$ and values in $Y$.
    Then the exists a unique function $f:{\NN} \,{\rightarrow}\, Y$ such that $f(1) \,=\, y_{0}$ and $f(k+1) \,=\, G(f(k))$ for all $k$ in ${\NN}$.

\V

        {\bf Proof}\,  The `uniqueness' portion is a simple consequence of the Principle of Mathematical Induction, and its proof is left as an exercise.
        To show that such $f$ exists, we use Theorem~\Ref{ThmA30.27} to reduce the problem to the existence of analogous functions on the subsets ${\NN}_{k}$ of ${\NN}$.

\V

        \underline{Claim} For each $k$ in ${\NN}$ there is a function $f_{k}:{\NN}_{k} \,{\rightarrow}\, Y$
    such that $f(1) \,=\, y_{0}$ and if $j{\in}{\NN}_{k}$ and $j\,<\,k$ then $f_{k}(j+1) \,=\, G(f_{k}(j))$.

        \underline{Proof of Claim} Let $A$ be the set of $k$ in ${\NN}$ such that such $f_{k}$ exists.
    Clearly $1{\in}A$: just define $f_{1}:{\NN}_{1} \,{\rightarrow}\, Y$ by the rule $f_{1}(1) \,=\, y_{0}$.

        Next, suppose that $k{\in}A$. Define $f_{k+1}:{\NN}_{k+1} \,{\rightarrow}\, Y$ by the rule
        \begin{displaymath}
        f_{k+1}(j) \,=\, f_{k}(j) \mbox{ if $1\,\,{\leq}\,\,j\,\,{\leq}\,\,k$};
        f_{k+1}(k+1) \,=\, G(f_{k}(k)).
        \end{displaymath}
    It is clear that $f_{k+1}$ has the desired properties, so that $k+1$ is also in $A$.
    Now the Principle of Mathematical Induction implies that $A \,=\, {\NN}$, so the Claim follows.

    It is also clear from the construction above that if $i$ and $j$ are elements of ${\NN}$ with $i\,<\,j$, then $f_{i}$ is the restriction to ${\NN}_{i}$ of $f_{j}$.
    Hence it follows from Theorem~\Ref{ThmA30.27}, the `Union-of-Functions Theorem',
    that the union of the functions $f_{k}$ for $k$ in ${\NN}$ is a function $f:{\NN} \,{\rightarrow}\, Y$;
    it is also clear that this function has the desired properties.

\V
\V

        \subsection{\small{{\bf Example}}}
        \label{ExampA40.110}

\V
\V

        The statement of Dedekind's Theorem above is phrased along the lines of the original Principle of Mathematical Induction.
    There is an alternate version which follows the phrasing of the Strong Principle of Mathematical Induction (Theorem~\Ref{ThmA20.04A}).

\V

        \subsection{\small{{\bf Theorem}} (Strong Form of Dedekind's Theorem on Recursive Definitions)}\IndC{recursive definitions}{Dedekind's recursive-definition theorem}{strong form}
        \label{ThmA40.120}


        Let $Y$ be a nonempty set, let $y_{0}$ be a point of $Y$, and let ${\cal B}$ be the set of all tuples in $Y$.
    Let $g:{\cal B} \,{\rightarrow}\, Y$ be a function with domain ${\cal B}$ and values in $Y$,
    and let $G:{\cal B} \,{\rightarrow}\, {\cal B}$ be the function defined by the following rule:

        If ${\sigma} \,=\, (y_{1},y_{2},\,{\ldots}\,y_{k})$ is an element of ${\cal B}$, then $G({\sigma})$ is the tuple $({\sigma},g({\sigma}))$;
    more precisely,
        \begin{displaymath}
        G((y_{1},y_{2},\,{\ldots}\,y_{k})) \,=\, (y_{1},x_{2},\,{\ldots}\,y_{k}, g((y_{1},y_{2},\,{\ldots}\,y_{k}))).
        \end{displaymath}
    Then the exists a unique function $f:{\NN} \,{\rightarrow}\, Y$ such that $f(1) \,=\, y_{0}$ and $f(k+1) \,=\, g((f(1),f(2),\,{\ldots}\,f(k))$ for all $k$ in ${\NN}$.

\V

        The simple proof is left as an exercise. (Hint: Apply the original form of the Dedekind Theorem to the map $G:{\cal B} \,{\rightarrow}\, {\cal B}$.)

\V
\V



        In {\TheseNotes} we have many occasions to construct sequences of objects.
    Often a proper treatment of these constructions should involve one or the other of the preceding Dedekind Theorems.
    In most of these situations, however, we leave the details of such a proper treatment to the reader,
    and follow a more informal approach in order to simplify the discussion.




%%% 
\begin{quotation}
{\footnotesize \underline{\Note} (on the Schr\"{o}der-Bernstein Theorem)\IndB{\notes}{on the Schr\"{o}der-Bernstein Theorem}: 
    The next result is not needed for the rest of {\TheseNotes} -- which is why it appears in a \Note -- but it is a powerful tool in set theory.

\V

        {\bf The Schr\"{o}der-Bernstein Theorem}\IndD{Schr\"{o}der-Bernstein Theorem}{\notes}

\V

        Suppose that $A$ and $B$ are nonempty sets such that $A$ has a subset $X$ with the same cardinality as $B$,
    and $B$ has a subset $Y$ with the same cardinality as $A$.
    Then $A$ has the same cardinality as $B$.

\V

        {\bf Proof}\,  Let $f:A \,{\rightarrow}\, Y$ and $g:B \,{\rightarrow}\, X$ and be bijections;
    such bijections exist because of the `equal cardinality' hypotheses.
    The key idea is given in the following analysis:

\V

       \underline{The Basic Schr\"{o}der-Bernstein Construction}

        Let $A' \,=\, g[Y]$. Clearly $A'$ is a subset of $X$, and $g$ maps $Y$ one-to-one onto $A'$;
    that is, the restriction of $g$ to $Y$ is a bijection of $Y$ onto $A'$. It follows that the composition $g{\circ}f$ maps $A$ bijectively onto $A'$.
    Likewise, let $B' \,=\, f[X]$. Then by a similar argument one sees that the composition $f{\circ}g$ maps $B$ bijectively onto $B'$

        Now let $C \,=\, A{\setminus}X$ and $D \,=\, X{\setminus}A'$; note that $C$ and $D$ are mutually disjoint.
    Since $A' \,{\subseteq}\, X \,{\subseteq}\, A$, it is also clear that $A \,=\, A'\,{\cup}\,C\,{\cup}\,D$, a disjoint union.
    Likewise, let $E \,=\, B{\setminus}Y$ and $F \,=\, Y{\setminus}B'$. Then it is clear that $B$ is the disjoint union $B \,=\, B'\,{\cup}\,E\,{\cup}\,F$ of the subsets $B'$, $E$ and $F$.

        It is also easy to see that the sets $C \,=\, A{\setminus}X$ and $F \,=\, Y{\setminus}B'$ have the same cardinality.
    More precisely, the function $f$ maps $A$ one-to-one onto $Y$ and $f$ maps $X$ one-to-one onto $B'$,
    so $f$ maps $A{\setminus}X$ one-to-one onto $Y{\setminus}B'$.
    Similarly, the function $g$ maps $E \,=\, B{\setminus}Y$ bijectively onto $D \,=\, X{\setminus}A'$.

        Finally, notice that $f$ maps $A'$ into $B' \,=\, f[X]$ since $A' \,{\subseteq}\, X$; likewise, $g$ maps $B'$ into $A'$.
    In addition, the restrictions of $f$ to $A'$ and $g$ to $B'$ are one-to-one functions, since the original $f$ and $g$ are one-to-one.
    In particular, $A'$ has a subset $X'$ with the same cardinality as $B'$, namely $X' \,=\, f[A']$;
    likewise, $B'$ has a subset $Y'$ with the same cardinality as $A'$, namely $Y' \,=\, g[B']$.
    Thus, the `Basic Construction' can be repeated on the sets $A'$, $B'$, $X'$ and $Y'$ to express $A'$ and $B'$ as disjoint unions of the form $A' \,=\, A''\,{\cup}\,C'\,{\cup}\,D'$ and $B' \,=\, B''\,{\cup}\,E'\,{\cup}\,F'$.


\V

        The rest of the proof consists primarily of carrying out the `Basic Construction' above infinitely many times.
    To do this, however, it is convenient to introduce numerical subscripts instead of `primes'.
    Thus, let us write $A_{0}$, $X_{0}$, and $A_{1}$ instead of $A$, $X$, $A'$; and write $C_{0} \,=\, A_{0}{\setminus}X_{0}$ and $D_{0} \,=\, X_{0}{\setminus}A_{1}$ 
    instead of $C \,=\, A{\setminus}X$ and $D \,=\, X{\setminus}A'$.
    Likewise, write $B_{0}$, $Y_{0}$ and $B_{1}$ instead of $B$, $Y$ and $B'$; and write $E_{0}$ and $F_{0}$ instead of $E$ and $F$.
    And when one repeats the `Basic Construction', simply increase the indices by~$1$ instead of slapping on another `prime'.

        By doing this, for each $k \,=\, 0,1,2,\,{\ldots}\,$ one obtains sets $A_{k}$, $X_{k}$, $C_{k}$, $D_{k}$, and $B_{k}$, $Y_{k}$, $E_{k}$ and $F_{k}$, which satisfy the following relations:

\V

        \h (a) $A_{0}$, $B_{0}$, $X_{0}$ and $Y_{0}$ equal the original sets $A$, $B$, $X$ and $Y$.

        \h (b) $Y_{k} \,=\, f[A_{k}]$ and $X_{k} \,=\, g[B_{k}]$.

        \h (c) $C_{k} \,=\, A_{k}{\setminus}X_{k}$ and $D_{k} \,=\, X_{k}{\setminus}A_{k+1}$;
    likewise, $E_{k} \,=\, B_{k}{\setminus}Y_{k}$ and $F_{k} \,=\, Y_{k}{\setminus}B_{k+1}$.

        \h (d) $A_{k}$ is the disjoint union of $A_{k+1}$, $C_{k}$ and $D_{k}$;
    likewise, $B_{k}$ is the disjoint union of $B_{k+1}$, $E_{k}$ and $F_{k}$.

        \h (e) $C_{k}$ and $F_{k}$ have the same cardinality; likewise, $D_{k}$ and $E_{k}$ have the same cardinality.

\V

\noindent From the preceding one then can write
        \begin{displaymath}
        A \,=\, A_{0} \,=\, A_{1}\,{\cup}\,C_{0}\,{\cup}\,D_{0} \,=\, A_{2}\,{\cup}\,C_{1}\,{\cup}\,D_{1}\,{\cup}\,C_{0}\,{\cup}\,D_{0} \,=\, 
A_{3}\,{\cup}\,C_{2}\,{\cup}\,D_{2}\,{\cup}\,C_{1}\,{\cup}\,D_{1}\,{\cup}\,C_{0}\,{\cup}\,D_{0} \,=\, \,{\ldots}\,.
        \end{displaymath}
    Likewise,
        \begin{displaymath}
        B \,=\, B_{0} \,=\, B_{1}\,{\cup}\,E_{0}\,{\cup}\,F_{0} \,=\, B_{2}\,{\cup}\,E_{1}\,{\cup}\,F_{1}\,{\cup}\,E_{0}\,{\cup}\,F_{0} \,=\,
B_{3}\,{\cup}\,E_{2}\,{\cup}\,F_{2}\,{\cup}\,E_{1}\,{\cup}\,F_{1}\,{\cup}\,E_{0}\,{\cup}\,F_{0} \,=\, \,{\ldots}\,.
        \end{displaymath}
    All the unions shown here are {\em disjoint} unions.

        Since $A_{k+1} \,{\subseteq}\, A_{k}$ for each $k$, one can conclude that
        \begin{displaymath}
        A \,=\, P\,{\cup}\, C_{0}\,{\cup}\,D_{0}\,{\cup}\,C_{1}\,{\cup}\,D_{1}\,{\cup}\,\,{\ldots}\,\,{\cup}\,C_{k}\,{\cup}\,D_{k}\,{\cup}\,\,{\ldots}\, \h ({\ast})
        \end{displaymath}
    where $P \,=\, A_{0}\,{\cap}\,A_{1}\,{\cap}\,\, {\ldots}\,\,{\cap}\,A_{k}\,{\cap}\,\,{\ldots}\,$.
    Likewise,
        \begin{displaymath}
        B \,=\, Q\,{\cup}\, E_{0}\,{\cup}\,F_{0}\,{\cup}\,E_{1}\,{\cup}\,F_{1}\,{\cup}\,\,{\ldots}\,\,{\cup}\,E_{k}\,{\cup}\,F_{k}\,{\cup}\,\,{\ldots}\, \h ({\ast}{\ast})
        \end{displaymath}
    where $Q \,=\, B_{0}\,{\cap}\,B_{1}\,{\cap}\,\, {\ldots}\,\,{\cap}\,B_{k}\,{\cap}\,\,{\ldots}\,$.

        \underline{Claim} The sets $P$ and $Q$ have the same cardinality.

        \underline{Proof of Claim} First note that $A_{k+1} \,{\subseteq}\, X_{k} \,{\subseteq}\, A_{k}$, so $P \,=\,X_{1}\,{\cap}\,X_{2}\,{\cap}\,\,{\ldots}\,\,{\cap}\,X_{k}\,{\cap}\,\,{\ldots}\,$.
    Likewise, $B_{k+1} \,{\subseteq}\, Y_{k} \,{\subseteq}\, B_{k}$, so $Q \,=\, Y_{1}\,{\cap}\,Y_{2}\,{\cap}\,\,{\ldots}\,\,{\cap}\,Y_{k}\,{\cap}\,\,{\ldots}\,$.

        Suppose first that $P$ is nonempty, and let $x$ be an element of $P$. Then for each $k$, $x{\in}A_{k}$, hence $f(x){\in}Y_{k}$ (since $f$ maps $A_{k}$ to $Y_{k}$).
    Thus, $f(x)$ is in the intersection of the sets $Y_{1}$, $Y_{2}$,\,{\ldots}\,, hence $f(x){\in}Q$. That is, $f$ maps $P$ {\em into} $Q$.
    To see that $f$ maps $P$ {\em onto} $Q$, let $y$ be any element of $Q$. Then for each $k$, one has $y{\in}Y_{k}$; hence, since $Y_{k} \,=\, f[A_{k}]$,
    one has $f(x_{k})$ for some element $x_{k}$ in $A_{k}$. And since $f$ is a bijection on $X$, one has $x_{1} \,=\, x_{2} \,=\, \,{\ldots}\,$.
    Call this common value $x$, so $x{\in}A_{k}$ for each $k$ and thus $x{\in}P$.
    That is $f$ maps $P$ {\em onto} $Q$.  It follows that $f$ maps $P$ bijectively onto $Q$, hence $P$ and $Q$ have the same cardinality, as claimed.

        It is easy to verify by a similar argument that if $P \,=\, {\emptyset}$ then $Q \,=\, {\emptyset}$;
    thus $P$ and $Q$ have the same cardinality in this case as well.

        Now consider the right sides of Equations~$({\ast})$ and~$({\ast}{\ast})$ above,
    which express $A \,=\, A_{0}$ and $B \,=\, B_{0}$ as disjoint unions of sets.
    We have already proved that for each $k$ the sets $C_{k}$ and $F_{k}$ have the same cardinality,  as do the sets $D_{k}$ and $E_{k}$.
    And since $P$ and $Q$ also have the same cardinality, Theorem~\Ref{ThmA50.88A} now implies that $A$ and $B$ have the same cardinality, as claimed.

\V

The reader is encouraged to review the examples considered in Sections~\Ref{SectA15}, \Ref{SectA20} and~\Ref{SectA25} and see whether some of them could have been obtained more easily using the Schr\"{o}der-Bernstein theorem.

%\StartSkip{

\V

        {\bf Remark} The reader is encouraged to review the examples considered in Sections~\Ref{SectA15}, \Ref{SectA20} and~\Ref{SectA25} and see how the results obtained there could have been proved using the Schr\"{o}der-Bernstein theorem.
%}%\EndSkip
}%EndFootnotesize
\end{quotation} 
%##



        {\bf Problem} Precisely define the concept of `relation'.

\V

        As a starting point, consider the definition of `relation' given in one dictionary:

        \h `A relation is a logical or natural association between two or more things.'
    (Of course in the special case of a {\em binary} relation, the phrase `or more' would be omitted.)


\noindent That is, a relation is defined to be a type of association. However, the same dictionary goes on to define `association' as follows:


        \h `An association is a mental connection or relation between thoughts, feelings, ideas, or sensations.'

\noindent One can combine these to say, in effect, that

        \h `A relations is an association, and an association is a relation'.


\noindent This is a `circular definition'. It appears that the concept of `relation' must fall under Justice Stewart's dictum:

        \h `I can't define it, but I know it when I see it'.

\V

        Nevertheless, mathematicians have formulated a precise definition, based purely on set-theoretic concepts; this definition is given below.
    In principle it could be given here, with no further introduction, since all the words which appear in it already make sense.
    However,as was observed above in the discussion of the `Definition-Theorem-Proof' style of mathematical exposition,
    in reality formal definitions arise only {\em after} one understands what the relevant features of the situation being described.
    One normally gets that understanding through a supply of examples which indicate what features any reasonable formal definition ought to have.
    Here is a short list of such examples of relations, both from within mathematics and from ordinary life:

\V

       \h (1) `John is a son of Jane.' (Relation: `is a son of')

\VA

       \h (2) `Jane is the mother of Jill.' (Relation: is the mother of')

\VA

       \h (3) `John is a son of Jane and George.' (Relation: is a son of')

\VA

       \h (4) `The number $x$ is greater than the number $y$. (Relation: `is greater than')

\VA

       \h (5) `The number $y$ is greater than the number $x$'. (Relation: `is greater than')

\VA

       \h (6) `The number $x$ is the square of the number $y$.' (Relation: `is the square of')



\VA

        These examples indicate some features that any reasonable definition of the concept `relation' ought to have,
    where by `reasonable' is meant a definition which corresponds well to one's intuitive notion of the concept.

        \h (a) A `relation' should relate two or more objects; for instance, Example~(3) relates three objects (John, Jane and George),
    while the other examples relate pairs of objects. In {\TheseNotes} the focus is on relations of the latter type, called {\em binary} relations.
    (This is partially because such relations are the most common in mathematics,
    and partially because more general relations can often be reduced to the binary case.)

        \h (b) The order in which the objects are listed may make a difference. For instance, in Example~(2)
    the statements `Jane is the mother of Jill' and `Jill is the mother of Jane' both make grammatical sense, but they mean very different things.
    Likewise, the only difference between Statements~(4) and~(5) is the order in which the numbers $x$ and~$y$ are listed.
    If  $x \,\,{\neq}\,\, y$ then the order makes a difference in the truth of the stated relationship.

        \h (c) The sets from which the objects being related are drawn must be specified, and these sets need not be the same.
    For instance, in Example~(1) the context suggests that, in the relation `$x$ is a son of $y$',
    the object $x$ (`John' here) should be chosen from, say, the set of all human males;
    in contrast, it is not so clear whether the $y$ should be drawn fron the set of, say, all humans, or all human females, or all human parents.
    Likewise, in Example~(6) it makes a difference whether the numbers $x$ and $y$ are to be chosen from the natural numbers or from the real numbers.

        \h (d) Of course the real question for any such binary relation is this: which pairs are in the given relationship?
    (Once that is answered, the issue of which pairs are {\em not} in the relationship is automatically settled.)

        \h (e) The definition must allow for the possibility that there are no pairs in the given relationship.
    For instance, the relation described by the inequality $x^{2}\,<\,-y^{2}$' is satisfied by no pair of real numbers.

        Having said all that, here is the standard definition of `binary relation' in mathematics:

\V

        \subsection{\small{{\bf Definition}}}
        \label{DefA12.60}\IndC{relations}{binary}{from a given set to a given set}\IndD{binary relations}{relations}

\V

        (1) Let $X$ and $Y$ be a pair of nonempty sets.
    A {\bf binary relation from $\Bfm{X}$ to $\Bfm{Y}$} is a (possibly empty) subset of the Cartesian product $X{\times}Y$.
    If $R$ is such a relation, i.e., if $R \,{\subseteq}\, X{\times}Y$, and if $(x,y)$ is an element of $R$, one says that {\bf \Bfm{x} and \Bfm{y} are in the  relation~$R$}.
    One frequently indicates this state of affairs by writing $x\,R\,y$ instead of the more usual $(x,y){\in}R$.

        If $Y \,=\, X$, then one normally speaks of a {\bf relation \underline{on} $\Bfm{X}$}\IndC{relations}{binary}{on a given set} instead of a relation \underline{from} $X$ to~$X$.

        (2) If $R$ is a binary relation from $X$ to $Y$, as above, then the corresponding
    {\bf negated binary relation}\IndC{relations}{binary}{negated relation} from $X$ to~$Y$, often denoted ${\not}R$,
    is the complement $X{\times}Y\,{\setminus}\,R$; that is, it is the set of all ordered pairs $(x,y)$, with $x$ in $X$ and $y$ in $Y$, such that $(x,y)$ is {\em not} in the set~$R$.

        (3) A {\bf formal binary relation}\IndC{relations}{binary}{formal} is an ordered pair $(U,R)$,
    where $U$ is an ordered pair $(X,Y)$ of nonempty sets and $R$ is a subset of $X{\times}Y$.

\VV

        \subsection{\small{{\bf Some Nonmathematical Examples of Binary Relations}}}
        \label{ExampA12.65A}

\V


        (1) Let $W$ be the set consisting of the following women; the numbers following their names are their ages as of January~1, 2000:

        \begin{center}
        Abigail (85), Betty (65), Carrie (22), Debbie (45), Edie (34) and Francine (42)
        \end{center}

        Here are the familial relations between these women:


        Betty is the daughter of Abigail; Carrie is the daughter of Francine; Debbie is the daughter of Betty.

        \underline{Problem} Let $X \,=\, Y \,=\, W$, and consider the binary relation on $W$, `is the daughter of'.
    Describe this relation in terms of the preceding definition; that is, as a set of ordered pairs.

        \underline{Solution} To save a little writing, abbreviate the names of the six women to their first initials, so that $W \,=\, \{A,B,C,D,E,F\}$.
    Then the relation is the following set $R$ of ordered pairs:
        \begin{displaymath}
        R \,=\, \mbox{\{(B,A), (C,F), (D,B)\}.}
        \end{displaymath}

\V

        (2) Let $W$ be the same set as in the preceding example.

        \underline{Problem} As before, let $X \,=\, Y \,=\, W$, but now consider the binary relation,
    again on $W$, described by `is exactly twenty years younger than' (on January~1, 2000, of course).
    Describe this relation in terms of a set of ordered pairs.

        \underline{Solution} It is easy to see that the answer is exactly the same set $R$ as in the preceding example.

\V

        (3) Let $\hat{W} \,=\, W\,{\setminus}\,\{E\} \,=\, \{A, B, C, D, F\}$, and once again consider the binary relation described by `is the daughter of', but now on the set~$\hat{W}$.
    It is clear that the corresponding set of ordered pairs is the same as in the preceding examples.
    Nevertheless, in light of Part~(3) of Definition~\Ref{DefA12.60} they are considered to be different.
    Indeed, as `formal' binary relations the first is the ordered pair $((W,W),R)$ while the second is $(\hat{W},\hat{W},R)$.
    Since $W \,\,{\neq}\,\, \hat{W}$, these two ordered pairs are physically different objects.

\V

        \underline{Remarks} (a) The relations discussed in Examples~(1) amd~(2) above are, intuitively speaking, quite dissimilar:
    one concerns the specific relation of daughters to mothers, while the other concerns age differences.
    Nevertheless, from the viewpoint of Definition~\Ref{DefA12.60} they are literally the same object.

        In contrast, the binary relation described in Example~(3) appears to be the same as that in Example~(1), even when speaking intuitively.
    Nevertheless, in terms of Definition~\Ref{DefA12.60} they must be considered to be different, because the underlying sets $W$ and $\hat{W}$ are not equal.
    If this seems strange, consider the alternative: if these relations were literally the same, then the corresponding negated relations would be equal.
    However, the set of ordered pairs associated with the {\em negated} relation for Example~(1) includes,
    among several others, the pair $(E,A)$: Edie is not the daughter of Abigail.
    In contrast, the pair $(E,A)$ cannot be part of the negated relation for Example~(3), since $E$ is not in the set~$W'$.


\VV

        \subsection{\small{{\bf Some Mathematical Examples of Binary Relations}}}
        \label{ExampA12.65B}

\V

        (1) Some of the standard well-known examples of mathematical binary relations have been alluded to before:
    `greater than' `less than', `equal to' and so on. To formulate these precisely in the terms of Definition~\Ref{DefA12.60},
    one needs to specify the sets which pay the role of $X$ and $Y$ in that definition.
    For instance, the relation `is greater than', denoted `$\,>\,$', certainly applies when $X \,=\, Y \,=\, {\RR}$, the set of all real numbers.
    In this case, the corresponding set of ordered pairs is $R \,=\, \{(x,y): x{\in}{\RR}, y{\in}{\RR}, x\,>\,y\}$.

        The corresponding negated relation, denoted $\not>$ and pronounced `not greater than',
    consists of those elements $(x,y)$ in ${\RR}{\times}{\RR}$ for which $x\not>y$.
    This is equivalent to the relation `less than, or equal to', denoted 	`$\,\,{\leq}\,\,$' on the same set.

\V

        (2) Let $X \,=\, \{1,2,3,4,5\}$ and let $R$ be the binary relation on $X$ decribed as the set of all ordered pairs $(x,y)$ in $X{\times}X$
    such that $x \,\,{\neq}\,\, y$ and $x-y$ is a whole-number multiple of~$3$. One easily verifies that $R \,=\, \{(4,1), (5,2)\}$.

\V

        (3) Let $X$ be as in the preceding example but now let $R'$ be the binary relation on $X$
    decribed as the set of all ordered pairs $(x,y)$ in $X{\times}X$ such that $x-y$ is a whole-number multiple of~$6$;
    that is, $x-y \,=\, 6\,k$ for some $k$ in ${\NN}$. Clearly, $R' \,=\, {\emptyset}$.

\V

        (4) Let $\hat{X} \,=\, \{4, 5, 6, 7, 8\}$ and let $R''$ be described as the set of all ordered pairs $(x,y)$ in $\hat{X}{\times}\hat{X}$ such that $x-y$ is a whole-number multiple of~$10$
    Clearly $R'' \,=\,{\emptyset}$, so $R''$ equals the corresponding set $R'$ from the preceding example.
    Nevertheless, the binary relations $R'$ and $R''$ are treated as being different:
    the sets $X$ and $\hat{X}$ on which these relations are defined are not the same.



        \underline{Remarks} (1) The phrasing `relation {\em from} $X$ {\em to} $Y$' emphasizes the requirement, already mentioned above,
    that the definition should allow the possibility that the order ($X$ is first, $Y$ is second) in a relation might make a difference.
    Indeed, the phrases `from $X$ to $Y$' and `from $Y$ to $X$' certainly do not signify the same ideas.
    However, some authors use instead the phrasing `relation of $X$ {\em with} $Y$'.
    Linguistically speaking, this means the same as `relation of $Y$ with $X$', which hides the order dependence.
    Such authors rely on the convention that by writing $X{\times}Y$, as opposed to $Y{\times}X$,
    one tacitly treats $X$ as the first set, $Y$ as the second. (See the {\Note} below on the `left-to-right bias' in mathematics.)
    This usage is mildly sloppy, but seems to cause no confusion.

        (2) Some authors abbreviate the content of Definition~\Ref{DefA12.60} to the following:

\VA

        \h `A binary relation is a set $R$ of ordered pairs of objects'

\VA

\noindent In this formulation there is no reference to any given sets from which the entries of the ordered pairs in $R$ are to be drawn.
    Stated this way, the binary relation {\em is} the set $R$ itself. With that viewpoint, it would follow that if $R \,{\subseteq}\, X{\times}Y$,
    and $X'$ and $Y'$ are proper supersets of $X$ and $Y$, respectively, then the same object, $R$,
    would be a binary relation from $X$ to $Y$ and, simultaneously, a binary relation from $X'$ to $Y'$.
    This is {\em not} the intent of Definition~\Ref{DefA12.60}, as is made clear in the examples.
    

        (3) The restriction that $X$ and $Y$ be nonempty is to avoid situations which are of no interest whatsoever.
    In contrast, the definition {\em does} allow the possibility that the subset $R$ might be empty, since that fact might reflect something of interest;
    namely, that no pairs $(x,y)$ in $X{\times}Y$ happen to be in the given relation.

        (4) The preceding definition uses only subsets of the Cartesian product $X{\times}Y$, and the latter concept is defined purely in set-theoretic terms.
    Thus, Definition~\Ref{DefA12.60} does formulate the concept of `relation' purely in terms of set theory.
    However, by identifying a relation from $X$ to $Y$ with a subset of $X{\times}Y$,
    the definition does allow the possibility of two relations, which intuitively to be seem very different, being treated as the same; see below.


\V
\V

        One of the most important types of binary relations on a set is a so-called `equivalence relation'.

\V


        \subsection{\small{{\bf Definition}}}
        %\label{DefA50.90}\IndC{relations}{binary}{equivalence relations}\IndD{equivalence relations}{relations}

        Let $X$ be a nonempty set.
    An {\bf equivalence relation on $X$} is a subset $W$ of $X{\times}X$ with the following properties:

        \h (i) (Reflexivity) If $x{\in}X$ then $(x,x){\in}W$.

\V

        \h (ii) (Symmetry) If $(x,y){\in}W$ then $(y,x){\in}W$.

\V

        \h (iii)(Transitivity) If $(x,y){\in}W$ and $(y,z){\in}W$ then $(x,z){\in}W$.

\V

        One often indicates that $(x,y){\in}W$ by the notation $x \stackrel{W}{\,\sim\,}y$;
    the expression  $x\stackrel{W}{\,\sim\,y}$ is pronounced `$x$ is equivalent to $y$ with respect to~$W$'.
    If the choice of equivalence relation $W$ is understood from the context, then this notation may be simplified to $x\,{\sim}\,y$,
    which is pronounced `$x$ is equivalent to $y$'; in this situation we may also refer to `the equivalence relation ${\sim}$'.

        If $x$ is any element of $X$ then $[x]_{W}$ denotes the set of all $y$ in $X$ such that $x \stackrel{W}{\,\sim\,}y$.
    The set $[x]_{W}$ is called the {\bf equivalence class of $\Bfm{x}$ relative to~$W$};
    as usual, the explicit reference to the equivalence relation $W$ may be dropped if it is clear from the context.


        \subsection{\small{{\bf Examples}}}
        \label{ExampA50.100}

\hspace*{\parindent}
        (1) The relation of `equality' is an equivalence relation on any nonempty set.
    For this equivalence relation, the equivalence class $[x]$ of $x$ is simply the singleton set~$\{x\}$.

\V

        (2) Suppose that ${\cal F}$ is a partition of a nonempty set $X$.
    Then ${\cal F}$ determines an equivalence relation $W_{{\cal F}}$ on $X$ by the rule that $x \stackrel{W_{{\cal F}}}{\,{\sim}\,} y$ if, and only if,
    $x$ and $y$ lie in the same element of the family ${\cal F}$. Indeed, suppose that $x{\in}X$.
    Then the fact that ${\bigcup} {\cal F} \,=\, X$ implies that there is an element $S$ in the family ${\cal F}$ such that $x{\in}S$.
    Clearly $x$ and $x$ are in $S$. Likewise, if $x$ and $y$ are both in the same element $S$ of ${\cal F}$ then $y$ and $x$ are both in $S$.
    Finally, suppose that $x$ and $y$ are both in the same element $S$ of ${\cal F}$ and that $y$ and $z$ are both in the same element $T$ of ${\cal F}$.
    Then $S$ and $T$ have an element in common, namely $y$, so $S\,{\cap}\,T \,\,{\neq}\,\, {\emptyset}$.
    By the fact that ${\cal F}$ is a partition it follows that $S \,=\, T$, and thus $x$ and $z$ are both in $T$.

        It is clear that if $x{\in}X$ then the equivalence class $[x]$ is precisely the unique set $A$ in the partition ${\cal F}$ such that $x{\in}A$.

\V

        (3) Suppose that $f:X \,{\rightarrow}\, Y$ is a surjection of a set $X$ onto a set~$Y$.
    Then $f$ determines an equivalence relation $W$ on $X$ by the rule $x \stackrel{W}{\,\sim\,}y$ if, and only if, $f(x) \,=\, f(y)$.
    We refer to this as the {\bf equivalence relation on $\Bfm{X}$ determined by~$\Bfm{f}$}, and we denote it by $W_{f}$.
    We also sometimes write $x\,{\sim}_{f}\,y$ instead of the more proper $x \stackrel{W_{f}}{\,\sim\,}y$.

\VV

        The next result summarizes the relations between these concepts.

        \subsection{\small{{\bf Theorem}}}
        \label{ThmA50.110}

        Let $X$ be a nonempty set.

\V

        (1) A subset $W$ of $X{\times}X$ is an equivalence relation on $X$ if, and only if,
    there exists a partition ${\cal F}$ on $X$ such that $W \,=\, W_{{\cal F}}$, where $W_{{\cal F}}$ is described above.
    The partition ${\cal F}$ is unique; that is, if ${\cal F}$ and ${\cal G}$ are partitions of $X$ such that $W_{{\cal F}} \,=\, W_{{\cal G}}$, then ${\cal F} \,=\, {\cal G}$.

\V

        (2) A subset $W$ of $X{\times}X$ is an equivalence relation on $X$ if, and only if,
    there exists a surjection $f:X \,{\rightarrow}\, Y$ of $X$ onto some set $Y$ such that such that $W \,=\, W_{f}$.
    (The set $Y$ is {\em not} at all unique, and therefore neither is the map~$f$.)

\V

        \underline{Proof}: (1) The `if' portion is essentially the content of Example~(2) above.
    The rest of the proof is left as a straight-forward exercise.

\V

        (2) This follows from Part~(1) together with the results of Theorem~\Ref{ThmA50.80}.

 
%\StartSkip{
      The next result says, in effect, that an equivalence relation on a set $X$ determines corresponding equivalence relations on the nonempty subsets of $X$.
    Likewise, a partition on $X$ determines corresponding partitions on the nonempty subsets of $X$.

\V

        \subsection{\small{{\bf Theorem}}}
                \label{ThmA50.115}

        Let $X$ be a nonempty set, and let $Y$ be a nonempty subset of $X$.

\V

        (a) Suppose that $W$ is an equivalence on $X$, and let $W|_{Y}$ denote the set $W\,{\cap}\,(Y{\times}Y)$.
    Then $W|_{Y}$ is an equivalence relation on $Y$.

\V

        (b) Let ${\cal F}$ be a partition of $X$, and let ${\cal F}_{Y}$ denote the family of all nonempty sets of the form $S\,{\cap}\,Y$, where $S$ is in the family ${\cal F}$.
    Then ${\cal F}_{Y}$ is a partition of $Y$.

\V

        (c) Suppose that $W$ is an equivalence relation on $X$, and let ${\cal F}$ be the partition of $X$ such that $W \,=\, W_{{\cal F}}$
    (see Part~(a) of Theorem~\Ref{ThmA50.110}).
    Then $W|_{Y} \,=\, W_{{\cal F}_{Y}}$.

\V

        {\bf Proof}\, 

\V

        (a) Suppose that $y{\in}Y$.
    Then $y{\in}X$ (since $Y$ is a subset of $X$), hence $(y,y){\in}W$ (since $W$ satisfies the Reflexivity condition).
    But $(y,y){\in}Y{\times}Y$ (by definition of Cartesian Product), so $(y,y){\in}W\,{\cap}\,Y{\times}Y$ (by definition of intersection).
    In particular, $W_{Y}$ satisfies the Reflexivity condition on $Y$.
    Similar arguments can be used to show that $W_{Y}$ also satisfies the Symmetry and Transitivity conditions on $Y$.

\V

        (b) First note that the family ${\cal F}_{Y}$ is nonempty.
    Indeed, let $y$ be an element of $Y$; such $y$ exists because $Y$ is assumed to be nonempty.
    Then (by definition of `partition') there exists a unique set $S$ in the family ${\cal F}$ such that $y{\in}S$.
    Thus $y$ is in both $S$ and $Y$, so $y{\in}(S\,{\cap}\,Y)$, hence the intersection $S\,{\cap}\,Y$ is nonempty.
    Thus $S\,{\cap}\,Y$ is an element of ${\cal F}_{Y}$, which implies that the family ${\cal F}_{Y}$ is nonempty.

        Next, consider a pair of sets $U$ and $V$ in the family ${\cal F}_{Y}$, with $U \,\,{\neq}\,\, V$.
    Then, by definition of this family, there exists elements $S$ and $T$ of ${\cal F}$ such that $U \,=\, S\,{\cap}\,Y$ and $V \,=\, T\,{\cap}\,Y$.
    Since $U\,\,{\neq}\,\, V$, it follows that $S \,\,{\neq}\,\, T$.
    Thus $S\,{\cap}\,T \,=\, {\emptyset}$, by the `Disjointness Property' of partitions.
    It follows that
        \begin{displaymath}
        U\,{\cap}\,V \,=\, (S\,{\cap}\,Y)\,{\cap}\,(T\,{\cap}\,Y) \,=\, (S\,{\cap}\,T)\,{\cap}\,(Y\,{\cap}\,Y) \,=\, {\emptyset}\,{\cap}\,Y \,=\, {\emptyset},
        \end{displaymath}
    by basic properties of `intersection'.
    That is, the family ${\cal F}_{Y}$ satisfies the `Disjointness Property' as well.

        Finally, it follows from the fact that $X \,=\, {\bigcup}_{S{\in}{\cal F}} S$, the definition of ${\cal F}_{Y}$,
    and basic properties of `union' and `intersection', that
        \begin{displaymath}
        Y \,=\, X\,{\cap}\,Y \,=\, \left({\bigcup}_{S{\in}{\cal F}} S\right)\,{\cap}\,Y \,=\, {\bigcup}_{S{\in}{\cal F}} (S\,{\cap}\,Y) \,=\, 
    {\bigcup}_{U{\in}{\cal F}_{Y}} U.
        \end{displaymath}
    (In the final equation any sets of the form $S\,{\cap}\,Y$ for which this intersection is empty can be ignored, since they do not contribute to the union.)
    Thus, ${\cal F}_{Y}$ satisfies the `Union Property' for partitions.

\V

        (c) The simple proof is left to the reader as an exercise.


\V
\V

        \subsection{\small{{\bf Definition}}}
                \label{DefA50.117}

        Let $X$ be a nonempty set and let $Y$ be a nonempty subset of $X$.

\V

        (a) If $W$ is an equivalence relation on $X$, then the {\bf equivalence relation on $Y$ induced from $W$} is the equivalence relation $W|_{Y} \,=\, Y\,{\cap}\,(Y{\times}Y)$ discussed in the preceding theorem.

\V

        (b)  If ${\cal F}$ is a partition of $X$, then the {\bf partition of $Y$ induced from ${\cal F}$} is the partition ${\cal F}_{Y}$ described in the preceding theorem.
    
%}%\EndSkip

 
        \subsection{\small{{\bf Definition}}}
                \label{DefA50.120}

        Let $W$ be an equivalence relation on a nonempty set $X$.

\V

        (1) For each $x$ in $X$ the set $W[x] \,=\, \{y{\in}X: (x,y){\in}W\})$ is called the {\bf equivalence class of $x$ with respect to $W$}.
    (If the equivalence relation $W$ under consideration is clear from the context,  we may abbreviate the notation $W[x]$ to $[x]$.)
    If $S$ is an equivalence class for the equivalence relation $W$ then each element of $S$ is called a {\bf representative of $S$} (relative to the given equivalence relation).
    (The element $x$ `represents' the equivalence class $S$ in the sense that one can write $S \,=\, [x]$;
    but of course the choice of $x$ used to represent $S$ this way is not unique unless $S$ happens to be a singleton set.)

\V

        (2) The set whose elements are the equivalence sets of $W$ is called the {\bf quotient set of $X$ with respect to $W$}; this set is denoted $X/W$.

\V

        Note: It is clear that the quotient set $X/W$ is the same as the partition ${\cal F}$ described in Part~(a) of Theorem~\Ref{A50.110}.
    It is also clear that $X/W \,=\, X/(f)$, where $f$ is the map described in Part~(b) of the same theorem.


\V
\V

        The next result ties together much of what we have just seen.


\V
\V

        \subsection{\small{{\bf Theorem}}}
                \label{ThmA50.125}

        Suppose that $f:X \,{\rightarrow}\, Y$ is a surjection of a nonempty set $X$ onto a set $Y$,
    and let $Z \,=\, X/(f)$ be the corresponding quotient set.
    Define a function $\hat{f}:Z \,{\rightarrow}\, Y$ as follows: if $S$ is an element of $Z$, so $S \,=\, f^{-1}[y]$ for some element $y$ in $Y$, set $\hat{f}(S) \,=\, y$.
    Then the function $\hat{f}$ is a bijection from $Z$ onto $Y$.

\V

        The simple proof is left as an exercise.

\VV

        \subsection{\small{{\bf Definition}}}
                \label{DefA50.127}

        The bijection $\hat{f}$ described in the preceding theorem is called the {\bf canonical bijection from $W$ onto $Y$ determined by the bijection $f:X \,{\rightarrow}\, Y$}.

                        \section{ADDENDUM THREE TO CHAPTER~\ref{ChaptA}: Construction of ${\QQ}$ from ${\NN}$}
                        \label{SectAAdd3}
\VV

        {\bf Introduction} In the main body of this chapter we accepted as `primitive truths' basic properties of the natural numbers and the rational numbers;
    but there was a promise to delve more deeply into the structure of such systems.
    Indeed, in Addendum~One the internal structure of the natural numbers is reduced to a consideration of the Dedekind-Peano axioms.
    Of course, the actual nature of these numbers, that is, the answer to the question
    `Exactly what is a natural number in some philosophical sense', is left open:
    We continue to treat these numbers as `primitive objects' which we do not define, but `we know them when we see them'. In particular,
    we do not prove that there exists a system of objects which satifies the Dedekind-Peano axioms; we accept our intuitive notions of ${\NN}$ as a given.

        Having done this, however, it is now easy to derive from this primitive notion of `Natural Number',
    in a rigorous manner which uses only these accepted facts about ${\NN}$ and accepted set-theoretic concepts,
    the rigorous construction of systems which correspond in every important way to our intuitive ideas of `integer' and `rational number'.
    The process lets the intuitive notion lead lead us, in a fairly natural way, to a rigorous construction of~${\QQ}$.
    The goal of the present section is such a contruction.

\V

    \underline{Note} The analogous questions for the real number system are postponed to Chapter~\Ref{ChaptB}.

\VV

%-----------------


        \subsection{\small{{\bf Construction 1: The Positive Rationals from the Natural Numbers}}}
                \label{ConstA50.130A}

 \V

        Let $X$ be the set ${\NN}{\times}{\NN}$ of all ordered pairs of natural numbers.
    The set $X$ is `rigorously defined', in the sense that we are taking both the set ${\NN}$ and the concept of `ordered pairs' as primitive concepts..
    Let $Y$ be the set ${\QQ}^{+}$ of all positive rational numbers', viewed as an intuitively understood system which eventually must be defined rigorously. 
    In terms of this intuition, there is a well-known surjective map ${\rho}:X \,{\rightarrow}\, {\QQ}^{+}$ defined by
    ${\rho}(j,k) \,=\, j/k$ for each ordered pair $(j,k)$ in~$X$; the Greek lettre `${\rho}$' stands for `ratio'.
    It is easy to see that the equivalence relation determined on $X$ by the surjection ${\rho}$ is this:
        \begin{displaymath}
        (j_{1},k_{1}) \,{\sim}\, (j_{2}, k_{2}) \mbox{ if, and only if, }
        j_{1}{\cdot}k_{2} \,=\, j_{2}{\cdot}k_{1} \h ({\ast})
        \end{displaymath}
    This equivalence relation, even though it arises in this discussion from an intitive understanding of `rational number', which includes the map~${\rho}$,
    is formulated in~$({\ast})$ purely in terms of the primitive notions of ordered pairs and the algebraic system ${\NN}$ as described by the Dedekind-Peano axioms.
    In particular, there is no mention in Condition~$({\ast})$ of either the `intuitive' concept of the set ${\QQ}^{+}$ or the `intuitive' map~${\rho}$.
    For that reason we use the symbol ${\sim}$ instead of the more proper ${\sim}_{{\rho}}$ in Condition~$({\ast})$.

        Return now to the intuitive discussion of~${\QQ}^{+}$. Let $A \,=\, X/({\rho})$ be the set of equivalence classes associated with the equivalence relation described above,
    and let $\hat{{\rho}}:A \,{\rightarrow}\, {\QQ}^{+}$ be the corresponding canonical bijection; see Definition~\Ref{DefA50.127} above.
   Note also that the inverse map $\hat{{\rho}}^{-1}:{\QQ}^{+} \,{\rightarrow}\, A$ is easy to compute:
    if $r{\in}{\QQ}^{+}$, express $r$ in the form $j/k$ as above; then $\hat{{\rho}}^{-1}(r)$ is the equivalence class with representative~$(j,k)$.
    Note that there is no need at this stage to verify that if $r$ is expressed as $j'/k'$ then $(j',k'){\sim}(j,k)$,
    since that is built into the definition of the equivalence relation determined by the surjection~${\rho}$.

        The bijection $\hat{{\rho}}$, together with the binary operation of `addition' already (intuitively) defined on the set~${\QQ}^{+}$,
    determines a corresponding operation of `addition' on $A$ for which the map ${\varphi}$ is an isomorphism; see Example~\Ref{ExampA60.80}~(4).
    More precisely, suppose that $z_{1}$ and $z_{2}$ are elements of~$A$,
    so that $z_{1} \,=\, \hat{{\rho}}^{-1}[\{r_{1}\}]$ and $z_{2} \,=\, \hat{{\rho}}^{-1}[\{r_{2}\}]$ for positive rationals $r_{1}$ and~$r_{2}$. Then define the sum $z_{1} + z_{2}$ by the rule
        \begin{displaymath}
        z_{1} + z_{2} \,=\, \hat{{\rho}}^{-1}[\{r_{1}+r_{2}\}],
        \end{displaymath}
    where the addition on the right is the (intuitive) addition of positive rational numbers.
    It is clear from the description of $\hat{{\rho}}^{-1}$ just given that if $r_{1} \,=\, j_{1}/k_{1}$ and $r_{2} \,=\, j_{2}/k_{2}$,
    then 
        \begin{displaymath}
        \hat{{\rho}}^{-1}(r_{1} + r_{2})
    \,=\, 
        \hat{{\rho}}^{-1}\left(\frac{j_{1}{\cdot}k_{2} + j_{2}{\cdot}k_{1}}{k_{1}{\cdot}k_{2}}\right),
        \end{displaymath}
    which is the equivalence class with representative $(j_{1}{\cdot}k_{2} + j_{2}{\cdot}k_{1}, k_{1}{\cdot}k_{2})$.
    Likewise, one sees that the bijection ${\rho}$, together with the (intuitive) concept of `multiplication' on ${\QQ}^{+}$,
    determines a `multiplication' on $A$, given by
        \begin{displaymath}
        z_{1}{\cdot}z_{2} \,=\, \hat{{\rho}}^{-1}[\{r_{1}{\cdot}r_{2}\}] \mbox{ for all $z_{1}$ and $z_{2}$ in $A$}.
        \end{displaymath}
    Using the same notation as above, one sees that $z_{1}{\cdot}z_{2}$ is the equivalence class
    with the representative $(j_{1}{\cdot}j_{2}, k_{1}{\cdot}k_{2})$.
    Furthermore, the `order' relation on ${\QQ}^{+}$ likewise determines a corresponding order relation on~$A$:
        \begin{displaymath}
        z_{1}\,<\,z_{2} \mbox{ if, and only if, } {\rho}(z_{1})\,<\,{\rho}(z_{2}).
        \end{displaymath}
    In terms of fractions used above, one has $z_{1}\,<\,z_{2}$ if, and only if, $j_{1}{\cdot}k_{2}\,<\,j_{2}{\cdot}k_{1}$.
    It is clear that the bijection $\hat{{\rho}}$ is an isomorphism between the operations of addition and multiplication,
    just defined on the set $A$, and the corresponding `intuitive' operations on~${\QQ}^{+}$;
    likewise, the bijection~$\hat{{\rho}}$ is an order-preserving map from $A$ onto~${\QQ}^{+}$.
    It follows that the algebraic properties of $A$ are the same as those on ${\QQ}^{+}$.
    For example, the `intuitive' understanding of ${\QQ}^{+}$ implies that there is a unique element in ${\QQ}^{+}$, the number~$1$, such that $r{\cdot}1\,=\, r$
    for all $r$ in~${\QQ}^{+}$. Likewise, for each $r$ in ${\QQ}^{+}$ there is a unique $s$ in ${\QQ}^{+}$ such that $r{\cdot}s \,=\, 1$.
    The existence of the isomorphism $\hat{{\rho}}$ then implies that the analogous properties hold for~$A$.

        As the formulas given above for $+$, ${\cdot}$ and~$\,<\,$ on $A$ indicate,
    the definitions of these concepts can also be obtained directly using only the equivalence relation~$\sim$, given by~$({\ast})$, and properties of~${\NN}$.
    That is, by using only the {\em results} of the intuitive discussion as a new starting point, and eliminating the intuitive discussion itself entirely,
    one can give a rigorous development of ${\QQ}^{+}$ directly from the properties of ${\NN}$ (and elementary set theory),
    as if one had never heard of ${\QQ}^{+}$ before. Here is how such a rigorous construction would normally be carried out:

        Given the set $X \,=\, {\NN}{\times}{\NN}$ and the equivalence relation~$(\sim)$ described above in Condition~$({\ast})$,
    let $A$ being the corresponding quotient set $X/\sim$. Define the binary operations of $+$ and~${\cdot}$ on $A$, and the order $\,<\,$, as follows:
    Let $z_{1}$ and $z_{2}$ be elements of $A$, i.e., equivalence classes associated with~${\sim}$,
    and let $(j_{1},k_{1})$ and $(j_{2},k_{2})$ in $X$ be representatives of $z_{1}$ and~$z_{2}$, respectively.
    Define $z_{1} + z_{2}$ to be the equivalence class which is represented by the ordered pair $(j_{1}{\cdot}k_{2} + j_{2}{\cdot}k_{1}, k_{1}{\cdot}k_{2})$.
    Likewise, define $z_{1}{\cdot}z_{2}$ to be the equivalence class represented by the ordered pair $(j_{1}{\cdot}j_{2}, k_{1}{\cdot}k_{2})$.
    Finally, define the relation $z_{1}\,<\,z_{2}$ to mean $j_{1}{\cdot}k_{2}\,<\,j_{2}{\cdot}k_{1}$.
    Of course these definitions might seem somewhat arbitrary without the earlier intuitive discussion using the surjection~${\rho}$;
    but technically speaking they do not refer to that discussion, and thus are ultimately based purely on the rigorously defined ${\NN}{\times}{\NN}$.
    Using the standard notation $[(j,k)]$ for the equivalence class with repressentative $(j,k)$,
    one can write 
        \begin{displaymath}
        [(j_{1},k_{1})] + [(j_{2},k_{2})] \,=\, [(j_{1}{\cdot}k_{2} + j_{2}{\cdot}k_{1}, k_{1}{\cdot}k_{2})], \h
        [(j_{1},k_{1})]{\cdot}[(j_{2},k_{2})] \,=\, [(j_{1}{\cdot}j_{2},{\cdot} k_{1}{\cdot}k_{2})], \h
        \end{displaymath}
        \begin{displaymath}
        [(j_{1},k_{1})] \,<\, {(j_{2},k_{2})} \mbox{ if, and only if, }
        j_{1}{\cdot}k_{2}\,<\,j_{2}{\cdot}k_{1}.
        \end{displaymath}
    The first need is to check that these constructions are {\bf well defined}\IndA{well defined constructions},
    in the sense that they does not depend on the choice of representatives of the classes $z_{1}$ and~$z_{2}$ used.
    Consider in more detail, for example, the definition of `multiplication' just given.
    Suppose that $(m_{1}, n_{1})$ and $(m_{2}, n_{2})$ are also representatives of $z_{1}$ and~$z_{2}$, respectively,
    so that by~$(\sim)$ one has $j_{1}{\cdot}n_{1} \,=\, k_{1}{\cdot}m_{1}$ and $j_{2}{\cdot}n_{2} \,=\, k_{2}{\cdot}m_{2}$.
    Then $(m_{1}{\cdot}m_{2},n_{1}{\cdot}n_{2})$ is equivalent to $((j_{1}{\cdot}j_{2}, k_{1}{\cdot}k_{2}))$,
    since $(m_{1}{\cdot}m_{2}){\cdot}(k_{1}{\cdot}k_{2}) \,=\, (n_{1}{\cdot}n_{2}{\cdot}(k_{1}{\cdot}k_{2}))$.
    That is, using different representatives for the equivalence classes $z_{1}$ and $z_{2}$ produce the same equivalence class $z_{1}{\cdot}z_{2}$, as required.
    The proofs that the operation of addition and the order relation are also well-defined are left as exercises.

%% EXERCISES +, \,<\, well-defined.

        The set $A$ of equivalence classes just constructed from ${\NN}$, together with the operations $+$ and ${\cdot}$, and the order relation $\,<\,$,
    can now  be considered as our our `official' definition of the system ${\QQ}^{+}$ of positive rational numbers, at least for the time being.
    (Later on we'll `improve' the construction.)

        Notice that system just constructed has a subsystem which behaves just like our original primitive system ${\NN}$ of natural numbers,
    namely the subset ${\NN}'$ of ${\QQ}^{+}$ consisting of all equivalence classes $z$ in $A$ of the form $[(j,1)]$ with $j$ in ${\NN}$.
    It is easy to see that $[(j_{1},1)] + [(j_{2},1)] \,=\, [((j_{1}+j_{2}),1)$ and $[(j_{1},1)]{\cdot}[(j_{2},1)] \,=\, [(j_{1}{\cdot}j_{2},1)]$.
    Likewise, $[(j_{1},1)]\,<\,[(j_{2},1)]$ if, and only if, $j_{1}\,<\,j_{2}$ in the original set~${\NN}$.
    We think of the set ${\NN}'$ so obtained as the `new and improved natural numbers':
    `new' because obviously the set ${\NN}'$ is different from the original set ${\NN}$;
    `improved', because these new numbers extend the original algebra of ${\NN}$ to the more inclusive arithmetic of~${\QQ}^{+}$.
    It is easy to see that in this arithmetic one has $[(1,1)]{\cdot}[(j,k)] \,=\, [(j,k)]$
    and $[(k,j)]{\cdot}[(j,k)] \,=\, [(k{\cdot}j,k{\cdot}j)] \,=\, [(1,1)]$. In particular,
    $[(1,1)]$ is the multiplicative unit, while $[(k,j)]$ is the multipicative inverse of $[(j,k)]$.
    By introducing the obvious `division' operation by $[(j_{1},k_{1})/(j_{2},k_{2})] \,=\, [(j_{1},k_{1})]{\cdot}[(k_{2},j_{2})]$,
    one gets the formula $[(j,k)] \,=\, [(j,1)]/[(k,1)]$. This is the `new and improved'
    version of the formula ${\rho}(j,k) \,=\, j/k$ used in the intuitive discussion above.

        Note that, by the preceding constructions, a positive rational number is an equivalence class of ordered pairs of the primitive natural numbers.
    In particular, the `new and improved' natural numbers are special types of such classes.



        \subsection{\small{{\bf Construction 2: The Rationals from the Positive Rationals}}}
                \label{ConstA50.130B}

 \V

        The next step is to rigorously extend the system ${\QQ}^{+}$, just obtained,
    to the system consisting of {\em all} the rational numbers, not just the positives.
    The procedure is, in spirit, similar to -- but, in the details, rather different from -- that used in Construction~(1), so we can be somewhat briefer.
    Indeed, if we let ${\QQ}$ denote for now the rational numbers of our intuition,
    there is a natural surjection ${\delta}:{\QQ}^{+}{\times}\,{\QQ}^{+}  \,{\rightarrow}\,  {\QQ}$ given by
        \begin{displaymath}
        {\delta}(z_{1},z_{2}) \,=\, z_{1} - z_{2}.
        \end{displaymath}
    (The symbol ${\delta}$ here stands for `difference'.) The equivalence relation on ${\QQ}^{+}{\times}\,{\QQ}^{+}$ determined by this surjection is
        \begin{displaymath}
        (z_{1},z_{2}){\sim}(z_{1}',z_{2}') \mbox{ if, and only if, }
        z_{1} + z_{2}' \,=\, z_{1}' + z_{2}
        \end{displaymath}
    Let ${\QQ}$ denote the set of equivalence classes arising from this equivalence relation on ${\QQ}^{+}{\times}\,{\QQ}^{+}$.
    It is easy to define the concepts of addition, multiplication and order on the set ${\QQ}$,
    using only the structures on~${\QQ}^{+}$, but not the intuitive map ${\Delta}$.
    For example, if $s \,=\, [(z_{1},z_{2}))]$ and $s' \,=\, [(z_{1}',z_{2}')]$ are elements of ${\QQ}$,
    then $s+s' \,=\, [(z_{1} + z_{1}', z_{2} + z_{2}')]$. Likewise, $s{\cdot}s' \,=\, [(z_{1}{\cdot}z_{1}' + z_{2}{\cdot}z_{2}', z_{1}{\cdot}z_{2}' + z_{2}{\cdot}z_{1}')]$.
    Likewise, $s\,<\,s'$ if, and only if, $z_{1} + z_{2}'\,<\,z_{1}' + z_{2}$. These constructions use only the rigorously defined structure of ${\QQ}^{+}$.

        There is a zero element in ${\QQ}$, namely the equivalence class with representative $(1,1)$,
    where $1$ now denotes the multiplicative identity in~${\QQ}^{+}$; any representative of the form $(c,c)$ with $c$ in ${\QQ}^{+}$ works too.
    One then defined the {\em positive rationals} to be those elements $[(z_{1},z_{2})]$ of ${\QQ}$ such that $[(z_{1},z_{2})]\,>\,[(1,1)]$.
    It is easy to check that this is equivalent to $z_{1}\,>\,z_{2}$ in ${\QQ}^{+}$,
    and that this set of `positive rationals' is isomorphic to~${\QQ}^{+}$ in the usual sense.
    Likewise, there is a subset of the set ${\QQ}$ just constructed which corresponds to the set ${\ZZ}$ of integers.

    Of course one needs to verify that these concepts do not depend on choices of representatives of equivalence classes in ${\QQ}^{+}{\times}\,{\QQ}^{+}$,
    and one needs to show that the copy of ${\QQ}^{+}$ in ${\QQ}$ just described is equivalent to the ${\QQ}^{+}$ already described.
    The details are tedious, so the usual custom, gladly followed here, is to leave the details to the reader.

\VV

 
%-----------------
\StartSkip{

        \subsection{\small{{\bf Examples}}
                \label{ExampA50.130}

 \V

\hspace*{\parindent} (1) Let $X$ be the set ${\NN}{\times}{\NN}$ of all ordered pairs of natural numbers, treated as a `rigorous' primitive concept.
    Let $Y$ be the set ${\QQ}^{+}$ of all positve rational numbers', viewed as an intuitively understood system which eventually must be defined rigorously. 
    In terms of this intuition, there is a well-known surjective map ${\rho}:X \,{\rightarrow}\, {\QQ}^{+}$ defined by
    ${\rho}(j,k) \,=\, j/k$ for each ordered pair $(j,k)$ in~$X$; `${\rho}$' stands for `ratio'.
    It is esay to see that the equivalence relation determined on $X$ by the surjection ${\rho}$ is this:
        \begin{displaymath}
        (j_{1},k_{1}) \,{\sim}\, (j_{2}, k_{2}) \mbox{ if, and only if, }
        j_{1}{\cdot}k_{2} \,=\, j_{2}{\cdot}k_{1} \h ({\ast})
        \end{displaymath}
    This equivalence relation, even though it arises in this discussion from an intitive understanding of `rational number', which includes the map~${\rho}$,
    is formulated here purely in terms of the primitive notions of ordered pairs and the algebraic system ${\NN}$ as described by the Dedekind-Peano axioms.
    In particular, there is no mention in Condition~$({\ast})$ of either the `intuitive' concept of the set ${\QQ}^{+}$ or the `intuitive' map~${\rho}$.
    For that reason we use the symbol ${\sim}$ instead of the more proper ${\sim}_{{\rho}}$ in Condition~$({\ast})$.

        Return now to the intuitive discussion of~${\QQ}$. Let $Z \,=\, X/({\rho})$ be the set of equivalence classes associated with the equivalence relation described above,
    and let $\hat{{\rho}}:Z \,{\rightarrow}\, {\QQ}^{+}$ be the corresponding canonical bijection; see Definition~\Ref{DefA50.127} above.
   Note also that the inverse map $\hat{{\rho}}^{-1}:{\QQ}^{+} \,{\rightarrow}\, Z$ is easy to compute:
    if $r{\in}{\QQ}^{+}$, express $r$ in the form $j/k$ as above; then $\hat{{\rho}}^{-1}(r)$ is the equivalence class with representative~$(j,k)$.
    Note that there is no need at this stage to verify that if $r$ is expressed as $j'/k'$ then $(j',k'){\sim}(j,k)$,
    since that is built into the definition of the equivalence relation determined by the surjection~${\rho}$.

        The bijection $\hat{{\rho}}$, together with the binary operation of `addition' already (intuitively) defined on the set~${\QQ}^{+}$,
    determines a corresponding operation of `addition on $Z$ for which the map ${\varphi}$ is an isomorphism; see Example~\Ref{ExampA60.80}~(4).
    More precisely, suppose that $z_{1}$ and $z_{2}$ are elements of~$Z$,
    so that $z_{1} \,=\, \hat{{\rho}}^{-1}[\{r_{1}\}]$ and $z_{2} \,=\, \hat{{\rho}}^{-1}[\{r_{2}\}]$ for positive rationals $r_{1}$ and~$r_{2}$. Then
        \begin{displaymath}
        z_{1} + z_{2} \,=\, \hat{{\rho}}^{-1}[\{r_{1}+r_{2}\}],
        \end{displaymath}
    where the addition on the right is the (intuitive) addition of positive rational numbers,
    while that on the left is the addition of elements of $Z$ being defined.
    It is clear from the description of $\hat{{\rho}}^{-1}$ just given that if $r_{1} \,=\, j_{1}/k_{1}$ and $r_{_{2} \,=\, j_{2}/k_{2}}$,
    then 
        \begin{displaymath}
        \hat{{\rho}}^{-1}(r_{1} + r_{2})
    \,=\, 
        \hat{{\rho}}^{-1}\left(\frac{j_{1}{\cdot}k_{2} + j_{2}{\cdot}k_{1}}{k_{1}{\cdot}k_{2}}\right),
        \end{displaymath}
    which is the equivalence class with representative $(j_{1}{\cdot}k_{2} + j_{2}{\cdot}k_{1}, k_{1}{\cdot}k_{2})$.
    Likewise, one sees that the bijection ${\rho}$, together with the (intuitive) concept of `multiplication' on ${\QQ}^{+}$,
    determines a `multiplication' on $Z$, given by
        \begin{displaymath}
        z_{1}{\cdot}z_{2} \,=\, \hat{{\rho}}^{-1}[\{r_{1}{\cdot}r_{2}\}] \mbox{ for all $z_{1}$ and $z_{2}$ in $Z$}.
        \end{displaymath}
    Using the same notation as above, one sees that $z_{1}{\cdot}z_{2}$ is the equivalence class
    with the representative $(j_{1}{\cdot}j_{2}, k_{1}{\cdot}k_{2})$.
    Furthermore, the `order' relation on ${\QQ}^{+}$ likewise determines a corresponding order relation on~$Z$:
        \begin{displaymath}
        z_{1}\,<\,z_{2} \mbox{ if, and only if, } {\rho}(z_{1})\,<\,{\rho}(z_{2}).
        \end{displaymath}
    In terms of fractions used above, one has $z_{1}\,<\,z_{2}$ if, and only if, $j_{1}{\cdot}k_{2}\,<\,j_{2}{\cdot}k_{1}$.
    It is clear that the bijection $\hat{{\rho}}$ is an isomorphism between the operations of addition and multiplication,
    just defined on the set $Z$, and the corresponding `intuitive' operations on~${\QQ}^{+}$;
    likewise, the bijection~$\hat{{\rho}}$ is an order-preserving map from $Z$ onto~${\QQ}^{+}$.
    It follows that the algebraic properties of $Z$ are the same as those on ${\QQ}^{+}$.
    For example, the `intuitive' understanding of ${\QQ}^{+}$ implies that there is a unique element in ${\QQ}^{+}$, the number~$1$, such that $r{\cdot}1\,=\, r$
    for all $r$ in~${\QQ}^{+}$. Likewise, for each $r$ in ${\QQ}^{+}$ there is a unique $s$ in ${\QQ}^{+}$ such that $r{\cdot}s \,=\, 1$.
    The existence of the isomorphism $\hat{{\rho}}$ then implies that the analogous properties hold for~$Z$.

        As the formulas given above for $+$, ${\cdot}$ and~$\,<\,$ on $Z$ indicate,
    the definitions of these concepts can also be obtained directly using only the equivalence relation~$\sim$, given by~$({\ast})$, and properties of~${\NN}$.
    That is, by using only the {\em results} of the intuitive discussion as a new starting point, and eliminating the intuitive discussion itself entirely,
    one can give a `rigorous' development of ${\QQ}^{+}$ directly from the properties of ${\NN}$ (and elementary set theory),
    as if one had never heard of ${\QQ}^{+}$ before. Here is how such a `rigorous' construction would normally be carried out:

        Given the set $X \,=\, {\NN}{\times}{\NN}$ and the equivalence relation~$(\sim)$ described above in Condition~$({\ast})$,
    let $Z$ being the corresponding quotient set $X/\sim$. Define the binary operations of $+$ and~${\cdot}$ on $Z$, and the order $\,<\,$, as follows:
    Let $z_{1}$ and $z_{2}$ be elements of $Z$, i.e., equivalence classes associated with~${\sim}$,
    and let $(j_{1},k_{1})$ and $(j_{2},k_{2})$ in $X$ be representatives of $z_{1}$ and~$z_{2}$, respectively.
    Define $z_{1} + z_{2}$ to be the equivalence class which is represented by the ordered pair $(j_{1}{\cdot}k_{2} + j_{2}{\cdot}k_{1}, k_{1}{\cdot}k_{2})$.
    Likewise, define $z_{1}{\cdot}z_{2}$ to be the equivalence class represented by the ordered pair $(j_{1}{\cdot}j_{2}, k_{1}{\cdot}k_{2})$.
    Finally, define the relation $z_{1}\,<\,z_{2}$ to mean $j_{1}{\cdot}k_{2}\,<\,j_{2}{\cdot}k_{1}$.
    Of course these definitions might seem somewhat arbitrary without the earlier intuitive discussion using the surjection~${\rho}$;
    but technically speaking they do not refer to that discussion, and thus are ultimately based purely on the rigorously defined ${\NN}{\times}{\NN}$.
    Using the standard notation $[(j,k])$ for the equivalence class with repressentative $(j,k)$,
    one can write 
        \begin{displaymath}
        [(j_{1},k_{1})] + [(j_{2},k_{2})] \,=\, [(j_{1}{\cdot}k_{2} + j_{2}{\cdot}k_{1}, k_{1}{\cdot}k_{2})], \h
        [(j_{1},k_{1})]{\cdot}[(j_{2},k_{2})] \,=\, [(j_{1}{\cdot}j_{2},{\cdot} k_{1}{\cdot}k_{2})], \h
        [(j_{1},k_{1})] \,<\, {(j_{2},k_{2})} \mbox{ if, and only if, }
        j_{1}{\cdot}k_{2}\,<\,j_{2}{\cdot}k_{1}.
        \end{displaymath}
    The first need is to check that these constructions are {\bf well defined}IndA{well defined constructions},
    in the sense that they does not depend on the choice of representatives of the classes $z_{1}$ and~$z_{2}$ used.
    Consider in more detail, for example, the definition of `multiplication' just given.
    Suppose that $(m_{1}, n_{1})$ and $(m_{2}, n_{2})$ are also representatives of $z_{1}$ and~$z_{2}$, respectively,
    so that by~$(\sim)$ one has $j_{1}{\cdot}n_{1} \,=\, k_{1}{\cdot}m_{1}$ and $j_{2}{\cdot}n_{2} \,=\, k_{2}{\cdot}m_{2}$.
    Then $(m_{1}{\cdot}m_{2},n_{1}{\cdot}n_{2})$ is equivalent to $((j_{1}{\cdot}j_{2}, k_{1}{\cdot}k_{2}))$,
    since $(m_{1}{\cdot}m_{2}){\cdot}(k_{1}{\cdot}k_{2}) \,=\, (n_{1}{\cdot}n_{2}{\cdot}(k_{1}{\cdot}k_{2}))$.
    That is, using different representatives for the equivalence classes $z_{1}$ and $z_{2}$ produce the same equivalence class $z_{1}{\cdot}z_{2}$, as required.
    The proofs that the operation of addition and the order relation are also well-defined are left as exercises.

%% EXERCISES +, \,<\, well-defined.

        The set $Z$ of equivalence classes just constructed from ${\NN}$, together with the operations $+$ and ${\cdot}$, and the order relation $\,<\,$,
    can now  be considered as our our `official' definition of the system ${\QQ}^{+}$ of positive rational numbers, at least for the time being.
    Notice that this system has a subsystem which behaves just like our original primitive system ${\NN}$ of natural numbers,
    namely the subset ${\NN}'$ of ${\QQ}^{+}$ consisting of all equivalence classes $z$ in $Z$ of the form $[(j,1)]$ with $j$ in ${\NN}$.
    It is easy to see that $[(j_{1},1)] + [(j_{2},1)] \,=\, [((j_{1}+j_{2}),1)$ and $[(j_{1},1)]{\cdot}[(j_{2},1)] \,=\, [(j_{1}{\cdot}j_{2},1)]$.
    Likewise, $[(j_{1},1)]\,<\,[(j_{2},1)]$ if,and only if, $j_{1}\,<\,j_{2}$ in the original set~${\NN}$.
    We think of the set ${\NN}'$ so obtained as the `new and improved natural numbers':
    `new' because obviously the set ${\NN}'$ is different from the original set ${\NN}$;
    `improved', because these new numbers extend the original algebra of ${\NN}$ to the more inclusive arithmetic of~${\QQ}^{+}$.
    It is easy to see that in this arithmetic one has $[(1,1)]{\cdot}[(j,k)] \,=\, [(j,k)]$
    and $[(k,j)]{\cdot}[(j,k)] \,=\, [(k{\cdot}j,k{\cdot}j)] \,=\, [(1,1)]$. In particular,
    $[(1,1)]$ is the multiplicative unit, while $[(k,j)]$ is the multipicative inverse of $[(j,k)]$.
    By introducing the obvious `division' operation by $[(j_{1},k_{1})/(j_{2},k_{2})] \,=\, [(j_{1},k_{1})]{\cdot}[(k_{2},j_{2})]$,
    one gets the formula $[(j,k)] \,=\, [(j,1)]/[(k,1)]$. This is the `new and improved'
    version of the formula ${\rho}(j,k) \,=\, j/k$ used in the intuitive discussion above.

        Note that, by the preceding constructions, a positive rational number is an equivalence class of ordered pairs of the primitive natural numbers.
    In particular, the `new and improved' natural numbers are special types of such classes.


\VV

        (2) The next step is to extend the system ${\QQ}^{+}$ just obtained to the system consisting of {\em all} the rational numbers, not just the positives.
    The procedure is, in spirit, similar to -- but, in the details, rather different from -- that used in Example~(1), so we can be somewhat briefer.
    Indeed, if we let ${\QQ}$ denote for now the rational numbers of our intuition,
    there is a natural surjection ${\delta}:{\QQ}^{+}{\times}{\QQ}^{+} \,{\supseteq}\, {\QQ}$ given by
        \begin{displaymath}
        {\delta}(z_{1},z_{2}) \,=\, z_{1} - z_{2}.
        \end{displaymath}
    (The symbol ${\delta}$ here stands for `difference'.) The equivalence relation on ${\QQ}^{+}{\times}{\QQ}^{+}$ determined by this surjection is
        \begin{displaymath}
        (z_{1},z_{2}){\sim}(z_{1}',z_{2}') \mbox{ if, and only if, }
        z_{1} + z_{2}' \,=\, z_{1}' + z_{2}
        \end{displaymath}
    Let ${\QQ}$ denote the set of equivalence classes arising from this equivalence relation on ${\QQ}^{+}{\times}{\QQ}^{+}$.
    It is easy to define the concepts of addition, multiplication and order on the set ${\QQ}$ using only the structures on~${\QQ}^{+}$, and not the intuitive map ${\delta}$.
    For example, if $s \,=\, [(z_{1},z_{2}))]$ and $s' \,=\, [(z_{1}',z_{2}')]$ are elements of ${\QQ}$,
    then $s+s' \,=\, [(z_{1} + z_{1}', z_{2} + z_{2}')]$. Likewise, $s{\cdot}s' \,=\, [(z_{1}{\cdot}z_{1}' + z_{2}{\cdot}z_{2}', z_{1}{\cdot}z_{2}' + z_{2}{\cdot}z_{1}')]$.
    Likewise, $s\,<\,s'$ if, and only if, $z_{1} + z_{2}'\,<\,z_{1}' + z_{2}$. These constructions use only the rigorously defined structure of ${\QQ}^{+}$.

        There is a zero element in ${\QQ}$, namely the equivalence class with representative $(1,1)$,
    where $1$ now denotes the multiplicative identity in~${\QQ}^{+}$; any representative of the form $(c,c)$ with $c$ in ${\QQ}^{+}$ works too.
    One then defined the {\em positive rationals} to be those elements $[(z_{1},z_{2})]$ of ${\QQ}$ such that $[(z_{1},z_{2})]\,>\,[(1,1)]$.
    It is easy to check that this is equivalent to $z_{1}\,>\,z_{2}$ in ${\QQ}^{+}$,
    and that this set of `positive rationals' is isomorphic to~${\QQ}^{+}$ in the usual sense.
    Likewise, there is a subset of the set ${\QQ}$ just constructed which corresponds to the set ${\ZZ}$ of integers.

    Of course one needs to verify that these concepts do not depend on choices of representatives of equivalence classes in ${\QQ}^{+}{\times}{\QQ}^{+}$,
    and one needs to show that the copy of ${\QQ}^{+}$ in ${\QQ}$ just described is equivalent to the ${\QQ}^{+}$ already described.
    The details are tedious, so the custom is to leave them to the reader.

\VV

}%\EndSkip
%------------------------

%--------------------------
\StartSkip{

\hspace*{\parindent} (3) The preceding examples first extended the positive integers to the positive rationals,
    then extended further to obtain all the rationals, including negative numbers.
    Historically speaking, this makes sense: the positive rationals appeared long before negative numbers.
    In modern mathematics, however, the custom is to start with ${\NN}$, then extend to ${\ZZ}$, the set of all integers,
    and finally extend from ${\ZZ}$ to~${\QQ}$, the set of all rationals. Here is the first stage of that process.

\V

        As before, start with with one's intuitive understanding of the set ${\ZZ}$ of all integers.
    There is a corresponding (intuitive) map ${\Delta}:{\NN}{\times}{\NN} \,{\rightarrow}\, {\ZZ}$ of ${\NN}{\times}{\NN}$ onto ${\ZZ}$ given by the rule
        \begin{displaymath}
        {\Delta}(j,k) \,=\, j-k \mbox{ for all $(j,k)$ in ${\NN}{\times}{\NN}$}
        \end{displaymath}
    (${\Delta}$ stands for `difference'.) It is easy to see that ${\Delta}$ is a surjection of (rigotously defined) set ${\NN}{\times}{\NN}$ onto the (intuitive) set ${\ZZ}$.
    Note also that the operation of addition of integers corresponds to a simple operation on pairs of natural numbers.
    Indeed, suppose that $m_{1} \,=\, {\Delta}(j_{1},k_{1}) \,=\, j_{1}-k_{1}$ and $m_{2} \,=\, {\Delta}(j_{2},k_{2}) \,=\, j_{2}-k_{2}$, with $(j_{1},k_{1})$, and $(j_{2},k_{2})$ being elements of ${\NN}{\times}{\NN}$.
    Then
        \begin{displaymath}
        m_{1} + m_{2} \,=\, (j_{1} - k_{1}) + (j_{2} - k_{2}) \,=\,(j_{1} + j_{2}) - (k_{1} + k_{2})
    \,=\,
        {\Delta}(j_{1} + j_{2}, k_{1} + k_{2})
        \end{displaymath}
    Similarly, the operation of multiplication of integers corresponds to a (somewhat less simple) operation on elements of ${\NN}{\times}{\NN}$,
    Indeed, if $m_{1} \,=\, j_{1}-k_{1}$ and $m_{2} \,=\, j_{2}-k_{2}$, then
        \begin{displaymath}
        m_{1}{\cdot}m_{2} \,=\, (j_{1}-k_{1}) {\cdot} (j_{2}-k_{2}) \,=\, (j_{1}{\cdot}j_{2} + k_{1}{\cdot}k_{2}) - (j_{1}{\cdot}k_{2} + k_{1}{\cdot}j_{2})
        \end{displaymath}
    That is,
        \begin{displaymath}
        m_{1}{\cdot}m_{2} \,=\, {\Delta}(j_{1}{\cdot}j_{2} + k_{1}{\cdot}k_{2},j_{1}{\cdot}k_{2} + k_{1}{\cdot}j_{2}) \h ({\ast}{\ast})
        \end{displaymath}

        The surjection ${\Delta}$ determines an equivalence relation $W_{{\Delta}}$ on ${\NN}{\times}{\NN}$ by the rule
        \begin{displaymath}
        (j,k) {\sim}_{{\Delta}} (j',k') \mbox{ if, and only if, } j-k \,=\, j'-k';
        \end{displaymath}
 see Example~\Ref{ExampA50.100}~(2).
    Note that this condition can be reformulated purely in terms of natural numbers as
        \begin{displaymath}
        (j,k) {\sim}_{{\Delta}} (j',k') \mbox{ if, and only if, } j + k' \,=\, j' + k \h ({\ast}{\ast}{\ast})
        \end{displaymath}
    Let $W$ be the quotient set corresponding to this equivalence relation on ${\NN}{\times}{\NN}$.
    Then Theorem~\Ref{ThmA50.125} produces a natural bijection $\hat{{\Delta}}:W \,{\rightarrow}\, {\ZZ}$.
    As in the preceding examples, this intuitive treatment can be reformulated purely in terms of the structure on ${\NN}$,
    with no reference to the map ${\Delta}$, to give a rigorous construction of ${\ZZ}$
    the tedious details are omitted here.

        Now that a rigorous construction of the set ${\ZZ}$ of all integers has been outlined,
    it is easy to use our experience from Example~(1) above to go directly from this set ${\ZZ}$ to a rigorous definition of the set ${\QQ}$ of all rationals.
    Indeed, let $X'$ be the set of all ordered pairs $(m,n)$ with $m$ and $n$ in ${\ZZ}$ and $n\,>\,0$.
    (Note that here $0$ means the integer, i.e., equivalence class of ordered pairs $(j,k)$ of natural numbers, for which $j \,=\, k$.
    Likewise, $m$ and $n$ are themselves equivalence classes of ordered pairs of natural numbers.)
    Define an equivalence relation ${\sim}'$ on $X'$ by the rule
        \begin{displaymath}
        (m_{1}, n_{1}) \,{\sim}'\, (m_{2},n_{2}) \mbox{ if, and only if, }
        m_{1}{\cdot}n_{2} \,=\, m_{2}{\cdot}n_{1};
        \end{displaymath}
     the multiplication indicated here is, of course, that defined rigotously on the set ${\ZZ}$ above.
    The addition, multiplication and order are then defined much as in Example~(1).
    As usual, the details that all of this works is left to the reader as an exercise.

\VV

        {\bf Remarks} (1) In both Examples (2) and (3) one rigorously constructs, from the same `primitive' system~${\NN}$,
    new systems which correspond to one's intuitive concept of `rational number'.
    However the {\em natures} of the individual objects in these systems are quite different. For instance,
    in Example~(3) the rational number~$0$ is an equivalence class consisting of ordered pairs of integers, which in turn are sets of ordered pairs of natural numbers.
    In contrast, the corresponding element~$0$ in Example~(2) is also an equivalence class,
    but one whose elements are ordered pairs of positive rationals, which in turn are also sets of ordered pairs of natural numbers, but different sets.
    In set-theoretic terms, these objects are unequal because of the Axiom of Extension.
    However, it is straight-forward, but extrewmely boring, to check that the two systems have the same algebraic properties as each other.
    Indeed, the main purpose of such constructions is to rigorously establish the existence of systems which correspond to our intuitive concept of~${\QQ}$.
    Of course both of these constructions are based on the set ${\NN}$ of natural numbers, which we have taken as a primitive concept:
    we do not here provide a rigorous construction of ${\NN}$ from objects which are even more primitive.

\V

        (2) It is clear that the original natural numbers are certainly not elements of the set ${\QQ}$,
    whether one uses the first construction or the second. Nevertheless, the set ${\QQ}$ does have a natural subset which correponds to the natural numbers.
    We follow the usual custom and treat these as `new, improved' natural numbers and thus treat ${\NN}$ as this subset of~${\QQ}$.
    The sam holds for the set ${\ZZ}$ of integers: we treat it as a subset of~${{\QQ}}$,
    Later on we `improve' these numbers again and replace them with a subset of the real numbers.

}%\EndSkip
%---------------------

%---------------------
\StartSkip{
        In the preceding construction we assume that both ${\NN}$ and ${\ZZ}$ are already known;
    the bijection $\hat{{\Delta}}$ then tells us that the (known) set ${\ZZ}$ has a lot of similarities with the quotient set $W$.
    However, because of Condition~$({\ast}{\ast}{\ast})$, it is possible to define the given equivalence relation on ${\NN}{\times}{\NN}$
    purely in terms of the set ${\NN}$ alone, without explicitly mentioning the set ${\ZZ}$ or the function ${\Delta}$.
    Likewise, the arguments of ${\Delta}$ on the right sides of Equations~$({\ast})$ and~$({\ast}{\ast})$ describe operations on elements of ${\NN}{\times}{\NN}$ which make sense without mentioning either ${\ZZ}$ or ${\Delta}$.
    Many authors exploit these facts to {\em define} the set ${\ZZ}$, together with its operations of addition and multiplication,
    purely in terms of the more primitive set ${\NN}$ and its operations. Here is how it works:

        \h (i)\,\, Inspired by Condition~$({\ast}{\ast}{\ast})$ above, let ${\sim}$ be the relation on ${\NN}{\times}{\NN}$ given by the condition
        \begin{displaymath}
        (j,k) {\sim} (j',k') \mbox{ if,and only if, } j+k' \,=\, j'+k.
        \end{displaymath}
    It is a simple exercise to show, using only the properties of ${\NN}$ (and without mentioning `zero' or `negative numbers') that ${\sim}$ is an equivalence relation on ${\NN}{\times}{\NN}$.
    Now one simply {\em defines} ${\ZZ}$ to be the quotient set of this equivalence relation.

        \h (ii)\, Inspired by Condition~$({\ast})$ above, define an operation of `addition' on the set ${\ZZ}$ just obtained as follows:
    Suppose that $m_{1}$ and $m_{2}$ are elements of ${\ZZ}$; that is, $m_{1}$ and $m_{2}$ are equivalence classes of the equivalence relation $\sim$ on ${\NN}{\times}{\NN}$.
    Let $(j_{1},k_{1})$ and $(j_{2},k_{2})$ be elements of the equivalence classes $m_{1}$ and $m_{2}$, respectively;
    using the notation of Definition~\Ref{DefA50.120}, one then has $m_{1} \,=\, [(j_{1},k_{1})]$ and $m_{2} \,=\, [(j_{2},k_{2})]$.
    Now {\em define} $m_{1}+m_{2}$ to be the equivalence class containing the ordered pair $(j_{1}+j_{2},k_{1}+k_{2})$.
    That is,
        \begin{displaymath}
        [(j_{1},k_{1})] + [(j_{2},k_{2})] \,=\, [(j_{1}+j_{2},k_{1}+k_{2})].
        \end{displaymath}
        This `definition' of $m_{1}+m_{2}$ has an obvious flaw: it uses a choice of representatives from $m_{1}$ and $m_{2}$,
    so it appears that the value of $m_{1}+m_{2}$ depends not only on the sets $m_{1}$ and $m_{2}$, but may depend on how one chooses these representatives.
    Fortunately, this apparent dependence is an illusion.
    Indeed, it is easy to show directly from the definition of the equivalence relation ${\sim}$ that if we replace $(j_{1},k_{1})$ by an equivalent element $(j_{1}',k_{1}')$,
    and replace $(j_{2},k_{2})$ by an equivalent $(j_{2}',k_{2}')$, then the resulting pair $(j'_{1}+j'_{2},k'_{1}+k'_{2})$ is equivalent to the original $(j_{1}+j_{2},k_{1}+k_{2})$;
    in other words, $[(j'_{1}+j'_{2},k'_{1}+k'_{2})] \,=\, [(j_{1}+j_{2},k_{1}+k_{2})]$.


        \h (iii) Inspired by Condition~$({\ast}{\ast})$ above, define an operation of `multipication' on the set ${\ZZ}$ as follows:
    Suppose that $m_{1}$ and $m_{2}$ are elements of ${\ZZ}$; that is, $m_{1}$ and $m_{2}$ are equivalence classes of the equivalence relation $\sim$ on ${\NN}{\times}{\NN}$.
    Let $(j_{1},k_{1})$ and $(j_{2},k_{2})$ be elements of the equivalence classes $m_{1}$ and $m_{2}$, respectively.
    Now {\em define} $m_{1}{\cdot}m_{2}$ to be the equivalence class containing the ordered pair $(j_{1}{\cdot}j_{1} + k_{1}{\cdot}k_{2}, j_{1}{\cdot}k_{2}+k_{1}{\cdot}j_{2}])$.
    That is,
        \begin{displaymath}
        [(j_{1},k_{1})] {\cdot} [(j_{2},k_{2})] \,=\, [(j_{1}{\cdot}j_{2} + k_{1}{\cdot}k_{2}, j_{1}{\cdot}k_{2} + k_{1}{\cdot}j_{2})].
        \end{displaymath}
    As with the definition of `addition' on ${\ZZ}$, one must verify that this construction of $m_{1}{\cdot}m_{2}$ does not depend on the choice of representatives of these sets.
    The analysis is slightly tedious, but not difficult; it is left as an exercise.

        \underline{Note} In the preceding construction, an `integer' turns out to be set of ordered pairs of natural numbers.
    Of course each such `ordered pair' $(j,k)$ is a set of sets of natural numbers, $\{\{j\},\{j,k\}\}$, if one uses the Kuratowski definition of `ordered pair';
    or, if one uses the `new and improved' definition of `ordered pair' given in Definition~\Ref{DefA30.30},
    $(j,k)$ is a set of sets of sets of natural numbers.
    In any event, an integer is a  type of object much more complicated than our original notion of `natural number'.
    In particular, the set ${\ZZ}$ just constructed does {\em not} have the set ${\NN}$ as a subset, since (as was just noted) none of the elements of ${\ZZ}$ is actually a natural number!
    This  should  seem  disconcerting, but the solution is simple:  the set ${\ZZ}$ does have a subset that behaves just like ${\NN}$;
    namely, the set of all equivalence classes of the form $[(k+1,1)]$ with $k$ in ${\NN}$.
    If we were going to stop with the set of integers, it would make sense to choose this subset as our preferred `new, improved' set of natural numbers.
    In fact, however, that honor will be saved for a set to be described in the next chapter.

\V

        (2) Let ${\QQ}$ denote the set of all rational numbers, and let ${\ZZ}^{*}$ denote the set of all nonzero integers.
    There is a natural function ${\rho}:{\ZZ}{\times}{\ZZ}^{*} \,{\rightarrow}\, {\QQ}$,
    given by the rule ${\rho}(j,k) \,=\, j/k$ for all $(j,k)$ in ${\ZZ}{\times}{\ZZ}^{*}$.
    It is easy to see that this function maps ${\ZZ}{\times}{\ZZ}^{*}$ surjectively onto ${\QQ}$,
    and thus ${\rho}$ determines an equivalence relation on ${\ZZ}{\times}{\ZZ}^{*}$.
    The function ${\rho}$ is certainly not an injection, however, since if a rational number $r$ can be expressed as $r \,=\, j/k$ with $j$ and $k$ in ${\ZZ}$ and $k \,\,{\neq}\,\, 0$,
    then it can also be expressed as $r \,=\, j'/k'$ with $j' \,=\, mj$ and $k' \,=\, mk$ for any $m$ in ${\ZZ}^{*}$.

       The surjection ${\rho}$ determines an equivalence relation on ${\ZZ}{\times}{\ZZ}^{*}$:
    $(j,k) {\sim} (j',k')$ provided ${\rho}(j,k) \,=\, {\rho}(j',k')$, i.e., $j/k \,=\, j'/k'$.
    As in  Example~(1) above, however, this condition can be formulated without explicitly mentioning either ${\rho}$ or the rational numbers:
        \begin{displaymath}
        (j,k) {\sim} (j',k') \mbox{ if, and only if, } j{\cdot}k' \,=\, j'{\cdot}k.
        \end{displaymath}
    And, as in Example~(1), one can define appropriate operations of `addition' and `multiplication' on the quotient set $\left({\ZZ}{\times}{\ZZ}^{*}\right)/{\sim}$ to make this set into a model of the rational numbers.
    This is the approach followed by many authors in their construction of ${\QQ}$.
    We shall not carry it  any further here, however, since we'll deal with ${\QQ}$ in a different manner in the next chapter.
}%\EndSkip %% NOT CLEAR WHY THIS EXTRA ENDSKIP IS NEEDED
}%\Endskip
}
%-----------------------------------------------

\newpage

\input{Exercises_M140AB_A_2017} %% NOTE: Automatically starts on a new page
